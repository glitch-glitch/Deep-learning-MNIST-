{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter 6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VofbcErR9HwM",
        "colab_type": "text"
      },
      "source": [
        "#Training Multiple Layers of Neurons"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0R_nrGHiub5K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5ba461a0-2e2a-4410-b37b-d628c89876a3"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8U9QOzs9T9c",
        "colab_type": "text"
      },
      "source": [
        "##Minimizing The Error on the MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoRATAkYcQ3D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "outputId": "7dac95b2-9c92-41ea-e07b-cb87d81b2229"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Produces two spirals\n",
        "def twoSpirals(N):\n",
        "  np.random.seed(1)\n",
        "  n = np.sqrt(np.random.rand(N,1)) * 780 * (2*np.pi)/360\n",
        "  x = -np.cos(n)*n\n",
        "  y = np.sin(n)*n\n",
        "  return (np.vstack((np.hstack((x,y)),np.hstack((-x,-y)))), \n",
        "          np.hstack((np.ones(N)*-1,np.ones(N))))\n",
        "\n",
        "X, y = twoSpirals(300)\n",
        "fig = plt.figure(figsize=(6,6))\n",
        "\n",
        "plt.plot(X[1,0],X[1,1],'+', color='#648fff', label='Positive Class')\n",
        "plt.plot(X[2,1],X[2,1],'_', color='#fe6100', label='Negative Class')\n",
        "\n",
        "for i in range(len(y)):\n",
        "  x1 = X[i,0]\n",
        "  x2 = X[i,1]\n",
        "  if (y[i] == 1):\n",
        "    plt.plot(x1,x2,'+', color='#648fff')\n",
        "  else:\n",
        "    plt.plot(x1,x2,'k_', color='#fe6100')\n",
        "plt.xlabel('$x_1$')\n",
        "plt.ylabel('$x_2$')\n",
        "plt.legend()\n",
        "plt.title('Sample two-spiral data')\n",
        "plt.axis('tight')\n",
        "plt.savefig('ch.6.two-spiral.data.png', dpi=350, bbox_inches='tight')\n",
        "# plt.savefig('ch.6.two-spiral.data.eps', dpi=350, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAGFCAYAAADn3WT4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/x8oMBE0z97JMgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSBf2dQpjXJr",
        "colab_type": "text"
      },
      "source": [
        "### Verification steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cb8nkb2sdbwm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "outputId": "ea8cc8f9-7d29-4081-bcd1-844167fd26bb"
      },
      "source": [
        "print(X[0])\n",
        "yv = np.zeros(X.shape)\n",
        "yv[y==1,0]=1\n",
        "yv[y==-1,1]=1\n",
        "print(yv[0])\n",
        "np.random.seed(1)\n",
        "w1 = 2.0*np.random.random((2, 3))-1.0\n",
        "w2 = 2.0*np.random.random((3, 2))-1.0\n",
        "print(w1)\n",
        "print(w2)\n",
        "\n",
        "print(X[0].dot(w1))\n",
        "print(1.0/(1.0+np.exp(-X[0].dot(w1))))\n",
        "\n",
        "z1 = X[0].dot(w1)\n",
        "o1 = 1.0/(1.0+np.exp(-X[0].dot(w1)))\n",
        "print(o1.dot(w2))\n",
        "o2 = 1.0/(1.0+np.exp(-o1.dot(w2)))\n",
        "print(o2)\n",
        "\n",
        "print(- ([1,0] - o2))\n",
        "print(o1.dot(w2) * (1- o1.dot(w2)))\n",
        "\n",
        "a=np.array([[-0.52476045, 0.50415211]])\n",
        "b=np.array([[-0.10894822,  0.01633295]])\n",
        "c=np.array([[3.79325728e-02, 3.64802735e-01, 1.20447478e-05]])\n",
        "print(a*b)\n",
        "np.set_printoptions(suppress=True)\n",
        "print(c.T.dot(a*b))\n",
        "\n",
        "print(w2 - (0.001 * (c.T.dot(a*b))))\n",
        "\n",
        "print((a*b).dot(w2.T))\n",
        "\n",
        "print(o1*(1-z1))\n",
        "\n",
        "\n",
        "p=X[0].reshape((1,2))\n",
        "q=(a*b).dot(w2.T)\n",
        "r=o1*(1-z1)\n",
        "print(p.T*(q*r))\n",
        "\n",
        "print(w1-(0.001*(p.T*(q*r))))\n",
        "np.set_printoptions(suppress=False)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "X_old = X\n",
        "X = StandardScaler().fit_transform(X_old)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[7.08535569 5.20423916]\n",
            "[0. 1.]\n",
            "[[-0.16595599  0.44064899 -0.99977125]\n",
            " [-0.39533485 -0.70648822 -0.81532281]]\n",
            "[[-0.62747958 -0.30887855]\n",
            " [-0.20646505  0.07763347]\n",
            " [-0.16161097  0.370439  ]]\n",
            "[ -3.23327435  -0.55457885 -11.32686981]\n",
            "[3.79325728e-02 3.64802735e-01 1.20447478e-05]\n",
            "[-0.09912288  0.01660881]\n",
            "[0.47523955 0.50415211]\n",
            "[-0.52476045  0.50415211]\n",
            "[-0.10894822  0.01633295]\n",
            "[[0.05717172 0.00823429]]\n",
            "[[0.00216867 0.00031235]\n",
            " [0.0208564  0.00300389]\n",
            " [0.00000069 0.0000001 ]]\n",
            "[[-0.62748175 -0.30887886]\n",
            " [-0.20648591  0.07763046]\n",
            " [-0.16161097  0.370439  ]]\n",
            "[[-0.03841748 -0.0111647  -0.00618927]]\n",
            "[0.16057899 0.56711462 0.00014847]\n",
            "[[-0.04370984 -0.04486212 -0.00000651]\n",
            " [-0.03210516 -0.03295151 -0.00000478]]\n",
            "[[-0.16591228  0.44069385 -0.99977124]\n",
            " [-0.39530275 -0.70645527 -0.81532281]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpM29x0o16pH",
        "colab_type": "text"
      },
      "source": [
        "### Backprop over MLP on the two-spirals dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUP5-0bI17Jc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Largely inspired by Omar U. Florez's\n",
        "\n",
        "def sigmoid(z, grad=False):\n",
        "  if grad:\n",
        "    return z*(1.0-z)\n",
        "  return 1.0/(1.0+np.exp(-z))\n",
        "\n",
        "def tanh(z, grad=True):\n",
        "  if grad:\n",
        "    return (1.0-z*z)\n",
        "  return (1.0-np.exp(-z))/(1.0+np.exp(-z))\n",
        "\n",
        "def inference(data, weights):\n",
        "  o1 = sigmoid(np.matmul(data, weights[0]))\n",
        "  logits = np.matmul(o1, weights[1])\n",
        "  probs = np.exp(logits)/np.sum(np.exp(logits), axis=1, keepdims=True)\n",
        "  return np.argmax(probs, axis=1)\n",
        "\n",
        "#size of minibatch: int(X.shape[0])\n",
        "N = 50\n",
        "\n",
        "input_dim = int(X.shape[1])\n",
        "hidden_dim = 3\n",
        "output_dim = 2\n",
        "num_epochs = 100000\n",
        "learning_rate= 1e-3\n",
        "reg_coeff = 1e-3\n",
        "losses = []\n",
        "accuracies=[]\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "# Initialize weights:\n",
        "np.random.seed(1)\n",
        "w1 = 2.0*np.random.random((input_dim, hidden_dim))-1.0      #w0=(2,hidden_dim)\n",
        "w2 = 2.0*np.random.random((hidden_dim, output_dim))-1.0     #w1=(hidden_dim,2)\n",
        "\n",
        "#Calibratring variances with 1/sqrt(fan_in)\n",
        "w1 /= np.sqrt(input_dim)\n",
        "w2 /= np.sqrt(hidden_dim)\n",
        "for i in range(num_epochs):\n",
        "  index = np.arange(X.shape[0])\n",
        "  np.random.shuffle(index)\n",
        "  index = index[:N]\n",
        "  #shuffle indices\n",
        "\n",
        "  #-----------------------------------------------------------------------------\n",
        "  # Forward step:\n",
        "  o1 = sigmoid(np.matmul(X[index], w1))                   #(N, 3)\n",
        "  logits = sigmoid(np.matmul(o1, w2))                     #(N, 2)\n",
        "  probs = np.exp(logits)/np.sum(np.exp(logits), axis=1, keepdims=True)\n",
        "  o2 = logits\n",
        "\n",
        "  #-----------------------------------------------------------------------------\n",
        "  # Definition of Loss function: mean squared error plus Ridge regularization\n",
        "  L = np.square(yv[index]-o2).sum()/(2*N) + reg_coeff*(np.square(w1).sum()+np.square(w2).sum())/(2*N)\n",
        "\n",
        "  losses.append([i,L])\n",
        "\n",
        "  #-----------------------------------------------------------------------------\n",
        "  # Backward step: Error = W_l e_l+1 f'_l\n",
        "  #       dL/dw2 = dL/do2 * do2/dz2 * dz2/dw2\n",
        "  dL_do2 = -(yv[index] - o2)                               #(N, 2)\n",
        "  do2_dz2 = sigmoid(o2, grad=True)            #(N, 2)\n",
        "  dz2_dw2 = o1                                            #(N, hidden_dim)\n",
        "  #Gradient for weight2:   (hidden_dim,N)x(N,2)*(N,2)\n",
        "  dL_dw2 = dz2_dw2.T.dot(dL_do2*do2_dz2) + reg_coeff*np.square(w2).sum()\n",
        "\n",
        "  #dL/dw1 = dL/do1 * do1/dz1 * dz1/dw1\n",
        "  #       dL/do1 = dL/dz2 * dz2/do1\n",
        "  #       dL/dz2 = dL/do2 * do2/dz2\n",
        "  dL_dz2 = dL_do2 * do2_dz2                               #(N, 2)\n",
        "  dz2_do1 = w2                                            #z2 = o1*w2\n",
        "  dL_do1 =  dL_dz2.dot(dz2_do1.T)                         #(N,2)x(2, hidden_dim)=(N, hidden_dim)\n",
        "  do1_dz1 = sigmoid(o1, grad=True)            #(N,hidden_dim)\n",
        "  dz1_dw1 = X[index]                                      #(N,2)\n",
        "  #Gradient for weight1:  (2,N)x((N,hidden_dim)*(N,hidden_dim))\n",
        "  dL_dw1 = dz1_dw1.T.dot(dL_do1*do1_dz1) + reg_coeff*np.square(w1).sum()\n",
        "\n",
        "  #weight updates:\n",
        "  w2 += -learning_rate*dL_dw2\n",
        "  w1 += -learning_rate*dL_dw1\n",
        "  if True: #(i+1)%1000==0:\n",
        "    y_pred = inference(X, [w1, w2])\n",
        "    y_actual = np.argmax(yv, axis=1)\n",
        "    accuracy = np.sum(np.equal(y_pred,y_actual))/len(y_actual)\n",
        "    accuracies.append([i, accuracy])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SBfyfrp7LVc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "outputId": "1133882e-fa14-4164-e230-6592474e78b0"
      },
      "source": [
        "print(o2[0], yv[index][0])\n",
        "plt.hist(o2[:,0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.61785329 0.37812645] [0. 1.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([5., 5., 6., 5., 5., 3., 5., 6., 4., 6.]),\n",
              " array([0.27173394, 0.31843704, 0.36514014, 0.41184323, 0.45854633,\n",
              "        0.50524942, 0.55195252, 0.59865562, 0.64535871, 0.69206181,\n",
              "        0.73876491]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDQDFEWoAKI5QA0BxhBoAiiPUAFDc/wDEtIOmAuQ7NwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzL41_zl5FXT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "26f389e0-5df7-4ed9-b999-b35fef13a3bf"
      },
      "source": [
        "plt.figure()\n",
        "for k in range(len(losses)):\n",
        "  if k%1000==0:\n",
        "    plt.plot(losses[k][0], losses[k][1], 'k.')\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "for k in range(len(accuracies)):\n",
        "  if k%1000==0:\n",
        "    plt.plot(accuracies[k][0], accuracies[k][1], 'k.')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD4CAYAAAAKA1qZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD4CAYAAAAKA1qZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5iRgZpaw/w/uRl62+FyX/AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faWwjOwIasaI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "outputId": "14958cb4-077c-4c69-bdae-6b87eeebc014"
      },
      "source": [
        "def getprobas(data, weights):\n",
        "  o1 = sigmoid(np.matmul(data, weights[0]))\n",
        "  logits = np.matmul(o1, weights[1])\n",
        "  return logits\n",
        "\n",
        "y_pred = inference(X, [w1, w2])\n",
        "y_actual = np.argmax(yv, axis=1)\n",
        "\n",
        "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
        "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n",
        "                     np.arange(y_min, y_max, 0.02))\n",
        "\n",
        "Z = getprobas(np.c_[xx.ravel(), yy.ravel()], [w1, w2])[:, 1]\n",
        "Z = Z.reshape(xx.shape)\n",
        "cm = plt.cm.bwr\n",
        "\n",
        "fig = plt.figure(figsize=(6,6))\n",
        "\n",
        "plt.contourf(xx, yy, Z, cmap=cm, alpha=.25)\n",
        "\n",
        "plt.plot(X[1,0],X[1,1],'+', color='#648fff', label='Positive Class')\n",
        "plt.plot(X[2,1],X[2,1],'_', color='#fe6100', label='Negative Class')\n",
        "\n",
        "for i in range(len(y)):\n",
        "  x1 = X[i,0]\n",
        "  x2 = X[i,1]\n",
        "  if y[i]==1: \n",
        "    if (y_pred[i] == 0):\n",
        "      plt.plot(x1,x2,'+', color='#648fff')\n",
        "    else:\n",
        "      plt.plot(x1,x2,'k.', alpha=0.25)\n",
        "  else:\n",
        "    if (y_pred[i] == 1):\n",
        "      plt.plot(x1,x2,'_', color='#fe6100')\n",
        "    else:\n",
        "      plt.plot(x1,x2,'k.', alpha=0.25)\n",
        "\n",
        "accuracy = np.sum(np.equal(y_pred,y_actual))/len(y_actual)\n",
        "\n",
        "plt.axis('tight')\n",
        "plt.xlim(min(X[:,0])-0.1, max(X[:,0])+0.1)\n",
        "plt.ylim(min(X[:,1])-0.1, max(X[:,1])+0.1)\n",
        "plt.xlabel('$x_1$')\n",
        "plt.ylabel('$x_2$')\n",
        "plt.legend()\n",
        "plt.title('3-neuron MLP trained with backprop on spiral dataset. Accuracy: '+str(accuracy))\n",
        "plt.savefig('ch.6.MLP.bp.spirals.png', dpi=350, bbox_inches='tight')\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh4AAAGFCAYAAACyivpXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\negfZwp8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFpwN_IL4yDv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3m1jYRa6jzJ2",
        "colab_type": "text"
      },
      "source": [
        "## Hyper-parameter optimization experiments\n",
        "Run these as many times as you wish"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuR_yskgjzm2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7af36d63-a520-4217-fe3a-13754ed53ad4"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "mlp = Sequential()\n",
        "mlp.add(Dense(3, input_dim=2, activation='sigmoid'))\n",
        "mlp.add(Dense(2, activation='sigmoid'))\n",
        "\n",
        "# reduce_lr = ReduceLROnPlateau(monitor='acc', factor=0.5,\n",
        "#                               patience=100, min_lr=0.00000001,\n",
        "#                               verbose = 1)\n",
        "\n",
        "mlp.compile(loss='mean_squared_error',\n",
        "            optimizer='sgd',\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "# trains the model\n",
        "mlp.fit(X, yv, epochs=1000, batch_size=60,\n",
        "        verbose=1, #callbacks=[reduce_lr], \n",
        "        validation_split = 0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 540 samples, validate on 60 samples\n",
            "Epoch 1/1000\n",
            "540/540 [==============================] - 2s 4ms/sample - loss: 0.2965 - accuracy: 0.4444 - val_loss: 0.1488 - val_accuracy: 1.0000\n",
            "Epoch 2/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2958 - accuracy: 0.4444 - val_loss: 0.1499 - val_accuracy: 1.0000\n",
            "Epoch 3/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2952 - accuracy: 0.4444 - val_loss: 0.1509 - val_accuracy: 1.0000\n",
            "Epoch 4/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2946 - accuracy: 0.4444 - val_loss: 0.1519 - val_accuracy: 1.0000\n",
            "Epoch 5/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2940 - accuracy: 0.4444 - val_loss: 0.1529 - val_accuracy: 1.0000\n",
            "Epoch 6/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2934 - accuracy: 0.4444 - val_loss: 0.1539 - val_accuracy: 1.0000\n",
            "Epoch 7/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2928 - accuracy: 0.4444 - val_loss: 0.1549 - val_accuracy: 1.0000\n",
            "Epoch 8/1000\n",
            "540/540 [==============================] - 0s 51us/sample - loss: 0.2922 - accuracy: 0.4444 - val_loss: 0.1559 - val_accuracy: 1.0000\n",
            "Epoch 9/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2916 - accuracy: 0.4444 - val_loss: 0.1570 - val_accuracy: 1.0000\n",
            "Epoch 10/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2910 - accuracy: 0.4444 - val_loss: 0.1580 - val_accuracy: 1.0000\n",
            "Epoch 11/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2904 - accuracy: 0.4444 - val_loss: 0.1590 - val_accuracy: 1.0000\n",
            "Epoch 12/1000\n",
            "540/540 [==============================] - 0s 54us/sample - loss: 0.2898 - accuracy: 0.4444 - val_loss: 0.1600 - val_accuracy: 1.0000\n",
            "Epoch 13/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2893 - accuracy: 0.4444 - val_loss: 0.1610 - val_accuracy: 1.0000\n",
            "Epoch 14/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2887 - accuracy: 0.4444 - val_loss: 0.1620 - val_accuracy: 1.0000\n",
            "Epoch 15/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2881 - accuracy: 0.4444 - val_loss: 0.1630 - val_accuracy: 1.0000\n",
            "Epoch 16/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2876 - accuracy: 0.4444 - val_loss: 0.1640 - val_accuracy: 1.0000\n",
            "Epoch 17/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2870 - accuracy: 0.4444 - val_loss: 0.1650 - val_accuracy: 1.0000\n",
            "Epoch 18/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2865 - accuracy: 0.4444 - val_loss: 0.1661 - val_accuracy: 1.0000\n",
            "Epoch 19/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2859 - accuracy: 0.4444 - val_loss: 0.1671 - val_accuracy: 1.0000\n",
            "Epoch 20/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2854 - accuracy: 0.4444 - val_loss: 0.1681 - val_accuracy: 1.0000\n",
            "Epoch 21/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2849 - accuracy: 0.4444 - val_loss: 0.1691 - val_accuracy: 1.0000\n",
            "Epoch 22/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2843 - accuracy: 0.4444 - val_loss: 0.1701 - val_accuracy: 1.0000\n",
            "Epoch 23/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2838 - accuracy: 0.4444 - val_loss: 0.1711 - val_accuracy: 1.0000\n",
            "Epoch 24/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2833 - accuracy: 0.4444 - val_loss: 0.1721 - val_accuracy: 1.0000\n",
            "Epoch 25/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2828 - accuracy: 0.4444 - val_loss: 0.1731 - val_accuracy: 1.0000\n",
            "Epoch 26/1000\n",
            "540/540 [==============================] - 0s 59us/sample - loss: 0.2823 - accuracy: 0.4444 - val_loss: 0.1741 - val_accuracy: 1.0000\n",
            "Epoch 27/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2818 - accuracy: 0.4444 - val_loss: 0.1751 - val_accuracy: 1.0000\n",
            "Epoch 28/1000\n",
            "540/540 [==============================] - 0s 51us/sample - loss: 0.2813 - accuracy: 0.4444 - val_loss: 0.1761 - val_accuracy: 1.0000\n",
            "Epoch 29/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2808 - accuracy: 0.4444 - val_loss: 0.1771 - val_accuracy: 1.0000\n",
            "Epoch 30/1000\n",
            "540/540 [==============================] - 0s 60us/sample - loss: 0.2803 - accuracy: 0.4444 - val_loss: 0.1781 - val_accuracy: 1.0000\n",
            "Epoch 31/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2798 - accuracy: 0.4444 - val_loss: 0.1790 - val_accuracy: 1.0000\n",
            "Epoch 32/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2794 - accuracy: 0.4444 - val_loss: 0.1800 - val_accuracy: 1.0000\n",
            "Epoch 33/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2789 - accuracy: 0.4444 - val_loss: 0.1810 - val_accuracy: 1.0000\n",
            "Epoch 34/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2784 - accuracy: 0.4444 - val_loss: 0.1820 - val_accuracy: 1.0000\n",
            "Epoch 35/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2780 - accuracy: 0.4444 - val_loss: 0.1830 - val_accuracy: 1.0000\n",
            "Epoch 36/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2775 - accuracy: 0.4444 - val_loss: 0.1840 - val_accuracy: 1.0000\n",
            "Epoch 37/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2771 - accuracy: 0.4444 - val_loss: 0.1850 - val_accuracy: 1.0000\n",
            "Epoch 38/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2766 - accuracy: 0.4444 - val_loss: 0.1859 - val_accuracy: 1.0000\n",
            "Epoch 39/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2762 - accuracy: 0.4444 - val_loss: 0.1869 - val_accuracy: 1.0000\n",
            "Epoch 40/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2758 - accuracy: 0.4444 - val_loss: 0.1879 - val_accuracy: 1.0000\n",
            "Epoch 41/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2753 - accuracy: 0.4444 - val_loss: 0.1888 - val_accuracy: 1.0000\n",
            "Epoch 42/1000\n",
            "540/540 [==============================] - 0s 55us/sample - loss: 0.2749 - accuracy: 0.4444 - val_loss: 0.1898 - val_accuracy: 1.0000\n",
            "Epoch 43/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2745 - accuracy: 0.4444 - val_loss: 0.1908 - val_accuracy: 1.0000\n",
            "Epoch 44/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2741 - accuracy: 0.4444 - val_loss: 0.1917 - val_accuracy: 1.0000\n",
            "Epoch 45/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2737 - accuracy: 0.4444 - val_loss: 0.1927 - val_accuracy: 1.0000\n",
            "Epoch 46/1000\n",
            "540/540 [==============================] - 0s 42us/sample - loss: 0.2733 - accuracy: 0.4444 - val_loss: 0.1936 - val_accuracy: 1.0000\n",
            "Epoch 47/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2729 - accuracy: 0.4444 - val_loss: 0.1946 - val_accuracy: 1.0000\n",
            "Epoch 48/1000\n",
            "540/540 [==============================] - 0s 42us/sample - loss: 0.2725 - accuracy: 0.4444 - val_loss: 0.1955 - val_accuracy: 1.0000\n",
            "Epoch 49/1000\n",
            "540/540 [==============================] - 0s 56us/sample - loss: 0.2721 - accuracy: 0.4444 - val_loss: 0.1965 - val_accuracy: 1.0000\n",
            "Epoch 50/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2718 - accuracy: 0.4444 - val_loss: 0.1974 - val_accuracy: 1.0000\n",
            "Epoch 51/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2714 - accuracy: 0.4444 - val_loss: 0.1984 - val_accuracy: 1.0000\n",
            "Epoch 52/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2710 - accuracy: 0.4444 - val_loss: 0.1993 - val_accuracy: 1.0000\n",
            "Epoch 53/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2707 - accuracy: 0.4444 - val_loss: 0.2002 - val_accuracy: 1.0000\n",
            "Epoch 54/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2703 - accuracy: 0.4444 - val_loss: 0.2012 - val_accuracy: 1.0000\n",
            "Epoch 55/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2699 - accuracy: 0.4444 - val_loss: 0.2021 - val_accuracy: 1.0000\n",
            "Epoch 56/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2696 - accuracy: 0.4444 - val_loss: 0.2030 - val_accuracy: 1.0000\n",
            "Epoch 57/1000\n",
            "540/540 [==============================] - 0s 53us/sample - loss: 0.2693 - accuracy: 0.4444 - val_loss: 0.2039 - val_accuracy: 1.0000\n",
            "Epoch 58/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2689 - accuracy: 0.4444 - val_loss: 0.2048 - val_accuracy: 1.0000\n",
            "Epoch 59/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2686 - accuracy: 0.4444 - val_loss: 0.2057 - val_accuracy: 1.0000\n",
            "Epoch 60/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2683 - accuracy: 0.4444 - val_loss: 0.2067 - val_accuracy: 1.0000\n",
            "Epoch 61/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2679 - accuracy: 0.4444 - val_loss: 0.2076 - val_accuracy: 1.0000\n",
            "Epoch 62/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2676 - accuracy: 0.4444 - val_loss: 0.2085 - val_accuracy: 1.0000\n",
            "Epoch 63/1000\n",
            "540/540 [==============================] - 0s 59us/sample - loss: 0.2673 - accuracy: 0.4444 - val_loss: 0.2093 - val_accuracy: 1.0000\n",
            "Epoch 64/1000\n",
            "540/540 [==============================] - 0s 51us/sample - loss: 0.2670 - accuracy: 0.4444 - val_loss: 0.2102 - val_accuracy: 1.0000\n",
            "Epoch 65/1000\n",
            "540/540 [==============================] - 0s 61us/sample - loss: 0.2667 - accuracy: 0.4444 - val_loss: 0.2111 - val_accuracy: 1.0000\n",
            "Epoch 66/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2664 - accuracy: 0.4444 - val_loss: 0.2120 - val_accuracy: 1.0000\n",
            "Epoch 67/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2661 - accuracy: 0.4444 - val_loss: 0.2129 - val_accuracy: 1.0000\n",
            "Epoch 68/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2658 - accuracy: 0.4444 - val_loss: 0.2138 - val_accuracy: 1.0000\n",
            "Epoch 69/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2655 - accuracy: 0.4444 - val_loss: 0.2146 - val_accuracy: 1.0000\n",
            "Epoch 70/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2652 - accuracy: 0.4444 - val_loss: 0.2155 - val_accuracy: 1.0000\n",
            "Epoch 71/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2650 - accuracy: 0.4444 - val_loss: 0.2164 - val_accuracy: 1.0000\n",
            "Epoch 72/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2647 - accuracy: 0.4444 - val_loss: 0.2172 - val_accuracy: 1.0000\n",
            "Epoch 73/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2644 - accuracy: 0.4444 - val_loss: 0.2181 - val_accuracy: 1.0000\n",
            "Epoch 74/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2641 - accuracy: 0.4444 - val_loss: 0.2189 - val_accuracy: 1.0000\n",
            "Epoch 75/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2639 - accuracy: 0.4444 - val_loss: 0.2197 - val_accuracy: 1.0000\n",
            "Epoch 76/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2636 - accuracy: 0.4444 - val_loss: 0.2206 - val_accuracy: 1.0000\n",
            "Epoch 77/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2634 - accuracy: 0.4444 - val_loss: 0.2214 - val_accuracy: 1.0000\n",
            "Epoch 78/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2631 - accuracy: 0.4444 - val_loss: 0.2222 - val_accuracy: 1.0000\n",
            "Epoch 79/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2629 - accuracy: 0.4389 - val_loss: 0.2231 - val_accuracy: 0.9500\n",
            "Epoch 80/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2626 - accuracy: 0.4222 - val_loss: 0.2239 - val_accuracy: 0.9167\n",
            "Epoch 81/1000\n",
            "540/540 [==============================] - 0s 43us/sample - loss: 0.2624 - accuracy: 0.4185 - val_loss: 0.2247 - val_accuracy: 0.9000\n",
            "Epoch 82/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2622 - accuracy: 0.4111 - val_loss: 0.2255 - val_accuracy: 0.8833\n",
            "Epoch 83/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2619 - accuracy: 0.3963 - val_loss: 0.2263 - val_accuracy: 0.8667\n",
            "Epoch 84/1000\n",
            "540/540 [==============================] - 0s 41us/sample - loss: 0.2617 - accuracy: 0.3889 - val_loss: 0.2271 - val_accuracy: 0.8333\n",
            "Epoch 85/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2615 - accuracy: 0.3833 - val_loss: 0.2279 - val_accuracy: 0.8333\n",
            "Epoch 86/1000\n",
            "540/540 [==============================] - 0s 51us/sample - loss: 0.2613 - accuracy: 0.3722 - val_loss: 0.2287 - val_accuracy: 0.8333\n",
            "Epoch 87/1000\n",
            "540/540 [==============================] - 0s 43us/sample - loss: 0.2611 - accuracy: 0.3685 - val_loss: 0.2295 - val_accuracy: 0.8167\n",
            "Epoch 88/1000\n",
            "540/540 [==============================] - 0s 42us/sample - loss: 0.2609 - accuracy: 0.3815 - val_loss: 0.2303 - val_accuracy: 0.8167\n",
            "Epoch 89/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2606 - accuracy: 0.3833 - val_loss: 0.2311 - val_accuracy: 0.8167\n",
            "Epoch 90/1000\n",
            "540/540 [==============================] - 0s 43us/sample - loss: 0.2604 - accuracy: 0.3870 - val_loss: 0.2318 - val_accuracy: 0.8167\n",
            "Epoch 91/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2602 - accuracy: 0.3907 - val_loss: 0.2326 - val_accuracy: 0.8167\n",
            "Epoch 92/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2600 - accuracy: 0.3870 - val_loss: 0.2333 - val_accuracy: 0.7667\n",
            "Epoch 93/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2598 - accuracy: 0.3926 - val_loss: 0.2341 - val_accuracy: 0.7500\n",
            "Epoch 94/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2597 - accuracy: 0.3981 - val_loss: 0.2349 - val_accuracy: 0.7333\n",
            "Epoch 95/1000\n",
            "540/540 [==============================] - 0s 56us/sample - loss: 0.2595 - accuracy: 0.4019 - val_loss: 0.2356 - val_accuracy: 0.7333\n",
            "Epoch 96/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2593 - accuracy: 0.4111 - val_loss: 0.2363 - val_accuracy: 0.7333\n",
            "Epoch 97/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2591 - accuracy: 0.4111 - val_loss: 0.2371 - val_accuracy: 0.7167\n",
            "Epoch 98/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2589 - accuracy: 0.4148 - val_loss: 0.2378 - val_accuracy: 0.7000\n",
            "Epoch 99/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2588 - accuracy: 0.4037 - val_loss: 0.2385 - val_accuracy: 0.6833\n",
            "Epoch 100/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2586 - accuracy: 0.3963 - val_loss: 0.2393 - val_accuracy: 0.6667\n",
            "Epoch 101/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2584 - accuracy: 0.3981 - val_loss: 0.2400 - val_accuracy: 0.6500\n",
            "Epoch 102/1000\n",
            "540/540 [==============================] - 0s 55us/sample - loss: 0.2582 - accuracy: 0.3963 - val_loss: 0.2407 - val_accuracy: 0.6333\n",
            "Epoch 103/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2581 - accuracy: 0.3926 - val_loss: 0.2414 - val_accuracy: 0.6333\n",
            "Epoch 104/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2579 - accuracy: 0.4000 - val_loss: 0.2421 - val_accuracy: 0.6333\n",
            "Epoch 105/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2578 - accuracy: 0.4056 - val_loss: 0.2428 - val_accuracy: 0.6000\n",
            "Epoch 106/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2576 - accuracy: 0.4056 - val_loss: 0.2435 - val_accuracy: 0.6000\n",
            "Epoch 107/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2575 - accuracy: 0.4074 - val_loss: 0.2442 - val_accuracy: 0.5833\n",
            "Epoch 108/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2573 - accuracy: 0.4111 - val_loss: 0.2449 - val_accuracy: 0.5667\n",
            "Epoch 109/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2572 - accuracy: 0.4241 - val_loss: 0.2455 - val_accuracy: 0.5500\n",
            "Epoch 110/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2570 - accuracy: 0.4278 - val_loss: 0.2462 - val_accuracy: 0.5333\n",
            "Epoch 111/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2569 - accuracy: 0.4259 - val_loss: 0.2469 - val_accuracy: 0.5333\n",
            "Epoch 112/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2567 - accuracy: 0.4315 - val_loss: 0.2475 - val_accuracy: 0.5333\n",
            "Epoch 113/1000\n",
            "540/540 [==============================] - 0s 41us/sample - loss: 0.2566 - accuracy: 0.4352 - val_loss: 0.2482 - val_accuracy: 0.5333\n",
            "Epoch 114/1000\n",
            "540/540 [==============================] - 0s 42us/sample - loss: 0.2565 - accuracy: 0.4333 - val_loss: 0.2489 - val_accuracy: 0.5333\n",
            "Epoch 115/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2563 - accuracy: 0.4407 - val_loss: 0.2495 - val_accuracy: 0.5333\n",
            "Epoch 116/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2562 - accuracy: 0.4426 - val_loss: 0.2501 - val_accuracy: 0.5333\n",
            "Epoch 117/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2561 - accuracy: 0.4463 - val_loss: 0.2508 - val_accuracy: 0.5000\n",
            "Epoch 118/1000\n",
            "540/540 [==============================] - 0s 42us/sample - loss: 0.2559 - accuracy: 0.4463 - val_loss: 0.2514 - val_accuracy: 0.5000\n",
            "Epoch 119/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2558 - accuracy: 0.4500 - val_loss: 0.2520 - val_accuracy: 0.5000\n",
            "Epoch 120/1000\n",
            "540/540 [==============================] - 0s 60us/sample - loss: 0.2557 - accuracy: 0.4556 - val_loss: 0.2527 - val_accuracy: 0.5000\n",
            "Epoch 121/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2556 - accuracy: 0.4611 - val_loss: 0.2533 - val_accuracy: 0.5000\n",
            "Epoch 122/1000\n",
            "540/540 [==============================] - 0s 43us/sample - loss: 0.2555 - accuracy: 0.4537 - val_loss: 0.2539 - val_accuracy: 0.4833\n",
            "Epoch 123/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2554 - accuracy: 0.4537 - val_loss: 0.2545 - val_accuracy: 0.4667\n",
            "Epoch 124/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2552 - accuracy: 0.4574 - val_loss: 0.2551 - val_accuracy: 0.4667\n",
            "Epoch 125/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2551 - accuracy: 0.4630 - val_loss: 0.2557 - val_accuracy: 0.4667\n",
            "Epoch 126/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2550 - accuracy: 0.4611 - val_loss: 0.2563 - val_accuracy: 0.4667\n",
            "Epoch 127/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2549 - accuracy: 0.4685 - val_loss: 0.2569 - val_accuracy: 0.4667\n",
            "Epoch 128/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2548 - accuracy: 0.4593 - val_loss: 0.2575 - val_accuracy: 0.4667\n",
            "Epoch 129/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2547 - accuracy: 0.4574 - val_loss: 0.2581 - val_accuracy: 0.4500\n",
            "Epoch 130/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2546 - accuracy: 0.4574 - val_loss: 0.2586 - val_accuracy: 0.4167\n",
            "Epoch 131/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2545 - accuracy: 0.4574 - val_loss: 0.2592 - val_accuracy: 0.4000\n",
            "Epoch 132/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2544 - accuracy: 0.4593 - val_loss: 0.2598 - val_accuracy: 0.3833\n",
            "Epoch 133/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2543 - accuracy: 0.4630 - val_loss: 0.2603 - val_accuracy: 0.3667\n",
            "Epoch 134/1000\n",
            "540/540 [==============================] - 0s 55us/sample - loss: 0.2542 - accuracy: 0.4611 - val_loss: 0.2609 - val_accuracy: 0.3667\n",
            "Epoch 135/1000\n",
            "540/540 [==============================] - 0s 58us/sample - loss: 0.2541 - accuracy: 0.4574 - val_loss: 0.2615 - val_accuracy: 0.3667\n",
            "Epoch 136/1000\n",
            "540/540 [==============================] - 0s 52us/sample - loss: 0.2540 - accuracy: 0.4556 - val_loss: 0.2620 - val_accuracy: 0.3500\n",
            "Epoch 137/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2539 - accuracy: 0.4481 - val_loss: 0.2625 - val_accuracy: 0.3500\n",
            "Epoch 138/1000\n",
            "540/540 [==============================] - 0s 51us/sample - loss: 0.2539 - accuracy: 0.4481 - val_loss: 0.2631 - val_accuracy: 0.3333\n",
            "Epoch 139/1000\n",
            "540/540 [==============================] - 0s 90us/sample - loss: 0.2538 - accuracy: 0.4444 - val_loss: 0.2636 - val_accuracy: 0.3333\n",
            "Epoch 140/1000\n",
            "540/540 [==============================] - 0s 51us/sample - loss: 0.2537 - accuracy: 0.4481 - val_loss: 0.2642 - val_accuracy: 0.3000\n",
            "Epoch 141/1000\n",
            "540/540 [==============================] - 0s 60us/sample - loss: 0.2536 - accuracy: 0.4389 - val_loss: 0.2647 - val_accuracy: 0.2833\n",
            "Epoch 142/1000\n",
            "540/540 [==============================] - 0s 56us/sample - loss: 0.2535 - accuracy: 0.4444 - val_loss: 0.2652 - val_accuracy: 0.2833\n",
            "Epoch 143/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2534 - accuracy: 0.4463 - val_loss: 0.2657 - val_accuracy: 0.2833\n",
            "Epoch 144/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2534 - accuracy: 0.4463 - val_loss: 0.2662 - val_accuracy: 0.2667\n",
            "Epoch 145/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2533 - accuracy: 0.4481 - val_loss: 0.2667 - val_accuracy: 0.2667\n",
            "Epoch 146/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2532 - accuracy: 0.4500 - val_loss: 0.2672 - val_accuracy: 0.2500\n",
            "Epoch 147/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2531 - accuracy: 0.4519 - val_loss: 0.2677 - val_accuracy: 0.2333\n",
            "Epoch 148/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2531 - accuracy: 0.4556 - val_loss: 0.2682 - val_accuracy: 0.2167\n",
            "Epoch 149/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2530 - accuracy: 0.4611 - val_loss: 0.2687 - val_accuracy: 0.2167\n",
            "Epoch 150/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2529 - accuracy: 0.4667 - val_loss: 0.2692 - val_accuracy: 0.1833\n",
            "Epoch 151/1000\n",
            "540/540 [==============================] - 0s 42us/sample - loss: 0.2529 - accuracy: 0.4704 - val_loss: 0.2697 - val_accuracy: 0.1500\n",
            "Epoch 152/1000\n",
            "540/540 [==============================] - 0s 53us/sample - loss: 0.2528 - accuracy: 0.4685 - val_loss: 0.2702 - val_accuracy: 0.1500\n",
            "Epoch 153/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2527 - accuracy: 0.4741 - val_loss: 0.2707 - val_accuracy: 0.1500\n",
            "Epoch 154/1000\n",
            "540/540 [==============================] - 0s 59us/sample - loss: 0.2527 - accuracy: 0.4889 - val_loss: 0.2711 - val_accuracy: 0.1500\n",
            "Epoch 155/1000\n",
            "540/540 [==============================] - 0s 67us/sample - loss: 0.2526 - accuracy: 0.4852 - val_loss: 0.2716 - val_accuracy: 0.1333\n",
            "Epoch 156/1000\n",
            "540/540 [==============================] - 0s 59us/sample - loss: 0.2525 - accuracy: 0.4833 - val_loss: 0.2721 - val_accuracy: 0.1333\n",
            "Epoch 157/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2525 - accuracy: 0.4759 - val_loss: 0.2725 - val_accuracy: 0.1000\n",
            "Epoch 158/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2524 - accuracy: 0.4685 - val_loss: 0.2730 - val_accuracy: 0.0500\n",
            "Epoch 159/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2523 - accuracy: 0.4685 - val_loss: 0.2734 - val_accuracy: 0.0500\n",
            "Epoch 160/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2523 - accuracy: 0.4667 - val_loss: 0.2739 - val_accuracy: 0.0500\n",
            "Epoch 161/1000\n",
            "540/540 [==============================] - 0s 54us/sample - loss: 0.2522 - accuracy: 0.4611 - val_loss: 0.2743 - val_accuracy: 0.0333\n",
            "Epoch 162/1000\n",
            "540/540 [==============================] - 0s 55us/sample - loss: 0.2522 - accuracy: 0.4593 - val_loss: 0.2748 - val_accuracy: 0.0333\n",
            "Epoch 163/1000\n",
            "540/540 [==============================] - 0s 53us/sample - loss: 0.2521 - accuracy: 0.4704 - val_loss: 0.2752 - val_accuracy: 0.0167\n",
            "Epoch 164/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2521 - accuracy: 0.4630 - val_loss: 0.2756 - val_accuracy: 0.0000e+00\n",
            "Epoch 165/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2520 - accuracy: 0.4593 - val_loss: 0.2760 - val_accuracy: 0.0000e+00\n",
            "Epoch 166/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2520 - accuracy: 0.4722 - val_loss: 0.2765 - val_accuracy: 0.0000e+00\n",
            "Epoch 167/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2519 - accuracy: 0.4815 - val_loss: 0.2769 - val_accuracy: 0.0000e+00\n",
            "Epoch 168/1000\n",
            "540/540 [==============================] - 0s 55us/sample - loss: 0.2519 - accuracy: 0.4833 - val_loss: 0.2773 - val_accuracy: 0.0000e+00\n",
            "Epoch 169/1000\n",
            "540/540 [==============================] - 0s 53us/sample - loss: 0.2518 - accuracy: 0.4926 - val_loss: 0.2777 - val_accuracy: 0.0000e+00\n",
            "Epoch 170/1000\n",
            "540/540 [==============================] - 0s 51us/sample - loss: 0.2518 - accuracy: 0.5000 - val_loss: 0.2781 - val_accuracy: 0.0000e+00\n",
            "Epoch 171/1000\n",
            "540/540 [==============================] - 0s 56us/sample - loss: 0.2517 - accuracy: 0.5130 - val_loss: 0.2785 - val_accuracy: 0.0000e+00\n",
            "Epoch 172/1000\n",
            "540/540 [==============================] - 0s 51us/sample - loss: 0.2517 - accuracy: 0.5259 - val_loss: 0.2789 - val_accuracy: 0.0000e+00\n",
            "Epoch 173/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2516 - accuracy: 0.5463 - val_loss: 0.2793 - val_accuracy: 0.0000e+00\n",
            "Epoch 174/1000\n",
            "540/540 [==============================] - 0s 65us/sample - loss: 0.2516 - accuracy: 0.5556 - val_loss: 0.2797 - val_accuracy: 0.0000e+00\n",
            "Epoch 175/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2515 - accuracy: 0.5556 - val_loss: 0.2801 - val_accuracy: 0.0000e+00\n",
            "Epoch 176/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2515 - accuracy: 0.5556 - val_loss: 0.2805 - val_accuracy: 0.0000e+00\n",
            "Epoch 177/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2514 - accuracy: 0.5556 - val_loss: 0.2809 - val_accuracy: 0.0000e+00\n",
            "Epoch 178/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2514 - accuracy: 0.5556 - val_loss: 0.2813 - val_accuracy: 0.0000e+00\n",
            "Epoch 179/1000\n",
            "540/540 [==============================] - 0s 54us/sample - loss: 0.2513 - accuracy: 0.5556 - val_loss: 0.2816 - val_accuracy: 0.0000e+00\n",
            "Epoch 180/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2513 - accuracy: 0.5556 - val_loss: 0.2820 - val_accuracy: 0.0000e+00\n",
            "Epoch 181/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2513 - accuracy: 0.5556 - val_loss: 0.2824 - val_accuracy: 0.0000e+00\n",
            "Epoch 182/1000\n",
            "540/540 [==============================] - 0s 43us/sample - loss: 0.2512 - accuracy: 0.5556 - val_loss: 0.2828 - val_accuracy: 0.0000e+00\n",
            "Epoch 183/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2512 - accuracy: 0.5556 - val_loss: 0.2831 - val_accuracy: 0.0000e+00\n",
            "Epoch 184/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2511 - accuracy: 0.5556 - val_loss: 0.2835 - val_accuracy: 0.0000e+00\n",
            "Epoch 185/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2511 - accuracy: 0.5556 - val_loss: 0.2838 - val_accuracy: 0.0000e+00\n",
            "Epoch 186/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2511 - accuracy: 0.5556 - val_loss: 0.2842 - val_accuracy: 0.0000e+00\n",
            "Epoch 187/1000\n",
            "540/540 [==============================] - 0s 52us/sample - loss: 0.2510 - accuracy: 0.5556 - val_loss: 0.2845 - val_accuracy: 0.0000e+00\n",
            "Epoch 188/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2510 - accuracy: 0.5556 - val_loss: 0.2849 - val_accuracy: 0.0000e+00\n",
            "Epoch 189/1000\n",
            "540/540 [==============================] - 0s 60us/sample - loss: 0.2510 - accuracy: 0.5556 - val_loss: 0.2852 - val_accuracy: 0.0000e+00\n",
            "Epoch 190/1000\n",
            "540/540 [==============================] - 0s 59us/sample - loss: 0.2509 - accuracy: 0.5556 - val_loss: 0.2856 - val_accuracy: 0.0000e+00\n",
            "Epoch 191/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2509 - accuracy: 0.5556 - val_loss: 0.2859 - val_accuracy: 0.0000e+00\n",
            "Epoch 192/1000\n",
            "540/540 [==============================] - 0s 58us/sample - loss: 0.2509 - accuracy: 0.5556 - val_loss: 0.2862 - val_accuracy: 0.0000e+00\n",
            "Epoch 193/1000\n",
            "540/540 [==============================] - 0s 55us/sample - loss: 0.2508 - accuracy: 0.5556 - val_loss: 0.2866 - val_accuracy: 0.0000e+00\n",
            "Epoch 194/1000\n",
            "540/540 [==============================] - 0s 54us/sample - loss: 0.2508 - accuracy: 0.5556 - val_loss: 0.2869 - val_accuracy: 0.0000e+00\n",
            "Epoch 195/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2508 - accuracy: 0.5556 - val_loss: 0.2872 - val_accuracy: 0.0000e+00\n",
            "Epoch 196/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2507 - accuracy: 0.5556 - val_loss: 0.2875 - val_accuracy: 0.0000e+00\n",
            "Epoch 197/1000\n",
            "540/540 [==============================] - 0s 52us/sample - loss: 0.2507 - accuracy: 0.5556 - val_loss: 0.2879 - val_accuracy: 0.0000e+00\n",
            "Epoch 198/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2507 - accuracy: 0.5556 - val_loss: 0.2882 - val_accuracy: 0.0000e+00\n",
            "Epoch 199/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2506 - accuracy: 0.5556 - val_loss: 0.2885 - val_accuracy: 0.0000e+00\n",
            "Epoch 200/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2506 - accuracy: 0.5556 - val_loss: 0.2888 - val_accuracy: 0.0000e+00\n",
            "Epoch 201/1000\n",
            "540/540 [==============================] - 0s 58us/sample - loss: 0.2506 - accuracy: 0.5556 - val_loss: 0.2891 - val_accuracy: 0.0000e+00\n",
            "Epoch 202/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2506 - accuracy: 0.5556 - val_loss: 0.2894 - val_accuracy: 0.0000e+00\n",
            "Epoch 203/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2505 - accuracy: 0.5556 - val_loss: 0.2897 - val_accuracy: 0.0000e+00\n",
            "Epoch 204/1000\n",
            "540/540 [==============================] - 0s 52us/sample - loss: 0.2505 - accuracy: 0.5556 - val_loss: 0.2900 - val_accuracy: 0.0000e+00\n",
            "Epoch 205/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2505 - accuracy: 0.5556 - val_loss: 0.2903 - val_accuracy: 0.0000e+00\n",
            "Epoch 206/1000\n",
            "540/540 [==============================] - 0s 52us/sample - loss: 0.2504 - accuracy: 0.5556 - val_loss: 0.2906 - val_accuracy: 0.0000e+00\n",
            "Epoch 207/1000\n",
            "540/540 [==============================] - 0s 51us/sample - loss: 0.2504 - accuracy: 0.5556 - val_loss: 0.2909 - val_accuracy: 0.0000e+00\n",
            "Epoch 208/1000\n",
            "540/540 [==============================] - 0s 53us/sample - loss: 0.2504 - accuracy: 0.5556 - val_loss: 0.2912 - val_accuracy: 0.0000e+00\n",
            "Epoch 209/1000\n",
            "540/540 [==============================] - 0s 69us/sample - loss: 0.2504 - accuracy: 0.5556 - val_loss: 0.2915 - val_accuracy: 0.0000e+00\n",
            "Epoch 210/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2503 - accuracy: 0.5556 - val_loss: 0.2918 - val_accuracy: 0.0000e+00\n",
            "Epoch 211/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2503 - accuracy: 0.5556 - val_loss: 0.2920 - val_accuracy: 0.0000e+00\n",
            "Epoch 212/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2503 - accuracy: 0.5556 - val_loss: 0.2923 - val_accuracy: 0.0000e+00\n",
            "Epoch 213/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2503 - accuracy: 0.5556 - val_loss: 0.2926 - val_accuracy: 0.0000e+00\n",
            "Epoch 214/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2502 - accuracy: 0.5556 - val_loss: 0.2929 - val_accuracy: 0.0000e+00\n",
            "Epoch 215/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2502 - accuracy: 0.5556 - val_loss: 0.2931 - val_accuracy: 0.0000e+00\n",
            "Epoch 216/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2502 - accuracy: 0.5556 - val_loss: 0.2934 - val_accuracy: 0.0000e+00\n",
            "Epoch 217/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2502 - accuracy: 0.5556 - val_loss: 0.2937 - val_accuracy: 0.0000e+00\n",
            "Epoch 218/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2502 - accuracy: 0.5556 - val_loss: 0.2939 - val_accuracy: 0.0000e+00\n",
            "Epoch 219/1000\n",
            "540/540 [==============================] - 0s 53us/sample - loss: 0.2501 - accuracy: 0.5556 - val_loss: 0.2942 - val_accuracy: 0.0000e+00\n",
            "Epoch 220/1000\n",
            "540/540 [==============================] - 0s 51us/sample - loss: 0.2501 - accuracy: 0.5556 - val_loss: 0.2944 - val_accuracy: 0.0000e+00\n",
            "Epoch 221/1000\n",
            "540/540 [==============================] - 0s 60us/sample - loss: 0.2501 - accuracy: 0.5556 - val_loss: 0.2947 - val_accuracy: 0.0000e+00\n",
            "Epoch 222/1000\n",
            "540/540 [==============================] - 0s 54us/sample - loss: 0.2501 - accuracy: 0.5556 - val_loss: 0.2949 - val_accuracy: 0.0000e+00\n",
            "Epoch 223/1000\n",
            "540/540 [==============================] - 0s 55us/sample - loss: 0.2501 - accuracy: 0.5556 - val_loss: 0.2952 - val_accuracy: 0.0000e+00\n",
            "Epoch 224/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2500 - accuracy: 0.5556 - val_loss: 0.2954 - val_accuracy: 0.0000e+00\n",
            "Epoch 225/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2500 - accuracy: 0.5556 - val_loss: 0.2957 - val_accuracy: 0.0000e+00\n",
            "Epoch 226/1000\n",
            "540/540 [==============================] - 0s 51us/sample - loss: 0.2500 - accuracy: 0.5556 - val_loss: 0.2959 - val_accuracy: 0.0000e+00\n",
            "Epoch 227/1000\n",
            "540/540 [==============================] - 0s 58us/sample - loss: 0.2500 - accuracy: 0.5556 - val_loss: 0.2962 - val_accuracy: 0.0000e+00\n",
            "Epoch 228/1000\n",
            "540/540 [==============================] - 0s 53us/sample - loss: 0.2500 - accuracy: 0.5556 - val_loss: 0.2964 - val_accuracy: 0.0000e+00\n",
            "Epoch 229/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2499 - accuracy: 0.5556 - val_loss: 0.2966 - val_accuracy: 0.0000e+00\n",
            "Epoch 230/1000\n",
            "540/540 [==============================] - 0s 51us/sample - loss: 0.2499 - accuracy: 0.5556 - val_loss: 0.2969 - val_accuracy: 0.0000e+00\n",
            "Epoch 231/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2499 - accuracy: 0.5556 - val_loss: 0.2971 - val_accuracy: 0.0000e+00\n",
            "Epoch 232/1000\n",
            "540/540 [==============================] - 0s 51us/sample - loss: 0.2499 - accuracy: 0.5556 - val_loss: 0.2973 - val_accuracy: 0.0000e+00\n",
            "Epoch 233/1000\n",
            "540/540 [==============================] - 0s 52us/sample - loss: 0.2499 - accuracy: 0.5556 - val_loss: 0.2976 - val_accuracy: 0.0000e+00\n",
            "Epoch 234/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2499 - accuracy: 0.5556 - val_loss: 0.2978 - val_accuracy: 0.0000e+00\n",
            "Epoch 235/1000\n",
            "540/540 [==============================] - 0s 52us/sample - loss: 0.2498 - accuracy: 0.5556 - val_loss: 0.2980 - val_accuracy: 0.0000e+00\n",
            "Epoch 236/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2498 - accuracy: 0.5556 - val_loss: 0.2982 - val_accuracy: 0.0000e+00\n",
            "Epoch 237/1000\n",
            "540/540 [==============================] - 0s 53us/sample - loss: 0.2498 - accuracy: 0.5556 - val_loss: 0.2984 - val_accuracy: 0.0000e+00\n",
            "Epoch 238/1000\n",
            "540/540 [==============================] - 0s 67us/sample - loss: 0.2498 - accuracy: 0.5556 - val_loss: 0.2987 - val_accuracy: 0.0000e+00\n",
            "Epoch 239/1000\n",
            "540/540 [==============================] - 0s 43us/sample - loss: 0.2498 - accuracy: 0.5556 - val_loss: 0.2989 - val_accuracy: 0.0000e+00\n",
            "Epoch 240/1000\n",
            "540/540 [==============================] - 0s 42us/sample - loss: 0.2498 - accuracy: 0.5556 - val_loss: 0.2991 - val_accuracy: 0.0000e+00\n",
            "Epoch 241/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2497 - accuracy: 0.5556 - val_loss: 0.2993 - val_accuracy: 0.0000e+00\n",
            "Epoch 242/1000\n",
            "540/540 [==============================] - 0s 51us/sample - loss: 0.2497 - accuracy: 0.5556 - val_loss: 0.2995 - val_accuracy: 0.0000e+00\n",
            "Epoch 243/1000\n",
            "540/540 [==============================] - 0s 57us/sample - loss: 0.2497 - accuracy: 0.5556 - val_loss: 0.2997 - val_accuracy: 0.0000e+00\n",
            "Epoch 244/1000\n",
            "540/540 [==============================] - 0s 56us/sample - loss: 0.2497 - accuracy: 0.5556 - val_loss: 0.2999 - val_accuracy: 0.0000e+00\n",
            "Epoch 245/1000\n",
            "540/540 [==============================] - 0s 65us/sample - loss: 0.2497 - accuracy: 0.5556 - val_loss: 0.3001 - val_accuracy: 0.0000e+00\n",
            "Epoch 246/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2497 - accuracy: 0.5556 - val_loss: 0.3003 - val_accuracy: 0.0000e+00\n",
            "Epoch 247/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2497 - accuracy: 0.5556 - val_loss: 0.3005 - val_accuracy: 0.0000e+00\n",
            "Epoch 248/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2496 - accuracy: 0.5556 - val_loss: 0.3007 - val_accuracy: 0.0000e+00\n",
            "Epoch 249/1000\n",
            "540/540 [==============================] - 0s 56us/sample - loss: 0.2496 - accuracy: 0.5556 - val_loss: 0.3009 - val_accuracy: 0.0000e+00\n",
            "Epoch 250/1000\n",
            "540/540 [==============================] - 0s 52us/sample - loss: 0.2496 - accuracy: 0.5556 - val_loss: 0.3011 - val_accuracy: 0.0000e+00\n",
            "Epoch 251/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2496 - accuracy: 0.5556 - val_loss: 0.3013 - val_accuracy: 0.0000e+00\n",
            "Epoch 252/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2496 - accuracy: 0.5556 - val_loss: 0.3015 - val_accuracy: 0.0000e+00\n",
            "Epoch 253/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2496 - accuracy: 0.5556 - val_loss: 0.3017 - val_accuracy: 0.0000e+00\n",
            "Epoch 254/1000\n",
            "540/540 [==============================] - 0s 51us/sample - loss: 0.2496 - accuracy: 0.5556 - val_loss: 0.3018 - val_accuracy: 0.0000e+00\n",
            "Epoch 255/1000\n",
            "540/540 [==============================] - 0s 52us/sample - loss: 0.2495 - accuracy: 0.5556 - val_loss: 0.3020 - val_accuracy: 0.0000e+00\n",
            "Epoch 256/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2495 - accuracy: 0.5556 - val_loss: 0.3022 - val_accuracy: 0.0000e+00\n",
            "Epoch 257/1000\n",
            "540/540 [==============================] - 0s 53us/sample - loss: 0.2495 - accuracy: 0.5556 - val_loss: 0.3024 - val_accuracy: 0.0000e+00\n",
            "Epoch 258/1000\n",
            "540/540 [==============================] - 0s 54us/sample - loss: 0.2495 - accuracy: 0.5556 - val_loss: 0.3026 - val_accuracy: 0.0000e+00\n",
            "Epoch 259/1000\n",
            "540/540 [==============================] - 0s 58us/sample - loss: 0.2495 - accuracy: 0.5556 - val_loss: 0.3027 - val_accuracy: 0.0000e+00\n",
            "Epoch 260/1000\n",
            "540/540 [==============================] - 0s 53us/sample - loss: 0.2495 - accuracy: 0.5556 - val_loss: 0.3029 - val_accuracy: 0.0000e+00\n",
            "Epoch 261/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2495 - accuracy: 0.5556 - val_loss: 0.3031 - val_accuracy: 0.0000e+00\n",
            "Epoch 262/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2495 - accuracy: 0.5556 - val_loss: 0.3033 - val_accuracy: 0.0000e+00\n",
            "Epoch 263/1000\n",
            "540/540 [==============================] - 0s 43us/sample - loss: 0.2495 - accuracy: 0.5556 - val_loss: 0.3034 - val_accuracy: 0.0000e+00\n",
            "Epoch 264/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2494 - accuracy: 0.5556 - val_loss: 0.3036 - val_accuracy: 0.0000e+00\n",
            "Epoch 265/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2494 - accuracy: 0.5556 - val_loss: 0.3038 - val_accuracy: 0.0000e+00\n",
            "Epoch 266/1000\n",
            "540/540 [==============================] - 0s 52us/sample - loss: 0.2494 - accuracy: 0.5556 - val_loss: 0.3039 - val_accuracy: 0.0000e+00\n",
            "Epoch 267/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2494 - accuracy: 0.5556 - val_loss: 0.3041 - val_accuracy: 0.0000e+00\n",
            "Epoch 268/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2494 - accuracy: 0.5556 - val_loss: 0.3042 - val_accuracy: 0.0000e+00\n",
            "Epoch 269/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2494 - accuracy: 0.5556 - val_loss: 0.3044 - val_accuracy: 0.0000e+00\n",
            "Epoch 270/1000\n",
            "540/540 [==============================] - 0s 43us/sample - loss: 0.2494 - accuracy: 0.5556 - val_loss: 0.3046 - val_accuracy: 0.0000e+00\n",
            "Epoch 271/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2494 - accuracy: 0.5556 - val_loss: 0.3047 - val_accuracy: 0.0000e+00\n",
            "Epoch 272/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2494 - accuracy: 0.5556 - val_loss: 0.3049 - val_accuracy: 0.0000e+00\n",
            "Epoch 273/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2493 - accuracy: 0.5556 - val_loss: 0.3050 - val_accuracy: 0.0000e+00\n",
            "Epoch 274/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2493 - accuracy: 0.5556 - val_loss: 0.3052 - val_accuracy: 0.0000e+00\n",
            "Epoch 275/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2493 - accuracy: 0.5556 - val_loss: 0.3053 - val_accuracy: 0.0000e+00\n",
            "Epoch 276/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2493 - accuracy: 0.5556 - val_loss: 0.3055 - val_accuracy: 0.0000e+00\n",
            "Epoch 277/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2493 - accuracy: 0.5556 - val_loss: 0.3056 - val_accuracy: 0.0000e+00\n",
            "Epoch 278/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2493 - accuracy: 0.5556 - val_loss: 0.3058 - val_accuracy: 0.0000e+00\n",
            "Epoch 279/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2493 - accuracy: 0.5556 - val_loss: 0.3059 - val_accuracy: 0.0000e+00\n",
            "Epoch 280/1000\n",
            "540/540 [==============================] - 0s 53us/sample - loss: 0.2493 - accuracy: 0.5556 - val_loss: 0.3061 - val_accuracy: 0.0000e+00\n",
            "Epoch 281/1000\n",
            "540/540 [==============================] - 0s 67us/sample - loss: 0.2493 - accuracy: 0.5556 - val_loss: 0.3062 - val_accuracy: 0.0000e+00\n",
            "Epoch 282/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2493 - accuracy: 0.5556 - val_loss: 0.3063 - val_accuracy: 0.0000e+00\n",
            "Epoch 283/1000\n",
            "540/540 [==============================] - 0s 57us/sample - loss: 0.2493 - accuracy: 0.5556 - val_loss: 0.3065 - val_accuracy: 0.0000e+00\n",
            "Epoch 284/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2492 - accuracy: 0.5556 - val_loss: 0.3066 - val_accuracy: 0.0000e+00\n",
            "Epoch 285/1000\n",
            "540/540 [==============================] - 0s 43us/sample - loss: 0.2492 - accuracy: 0.5556 - val_loss: 0.3068 - val_accuracy: 0.0000e+00\n",
            "Epoch 286/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2492 - accuracy: 0.5556 - val_loss: 0.3069 - val_accuracy: 0.0000e+00\n",
            "Epoch 287/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2492 - accuracy: 0.5556 - val_loss: 0.3070 - val_accuracy: 0.0000e+00\n",
            "Epoch 288/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2492 - accuracy: 0.5556 - val_loss: 0.3072 - val_accuracy: 0.0000e+00\n",
            "Epoch 289/1000\n",
            "540/540 [==============================] - 0s 53us/sample - loss: 0.2492 - accuracy: 0.5556 - val_loss: 0.3073 - val_accuracy: 0.0000e+00\n",
            "Epoch 290/1000\n",
            "540/540 [==============================] - 0s 43us/sample - loss: 0.2492 - accuracy: 0.5556 - val_loss: 0.3074 - val_accuracy: 0.0000e+00\n",
            "Epoch 291/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2492 - accuracy: 0.5556 - val_loss: 0.3075 - val_accuracy: 0.0000e+00\n",
            "Epoch 292/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2492 - accuracy: 0.5556 - val_loss: 0.3077 - val_accuracy: 0.0000e+00\n",
            "Epoch 293/1000\n",
            "540/540 [==============================] - 0s 41us/sample - loss: 0.2492 - accuracy: 0.5556 - val_loss: 0.3078 - val_accuracy: 0.0000e+00\n",
            "Epoch 294/1000\n",
            "540/540 [==============================] - 0s 43us/sample - loss: 0.2492 - accuracy: 0.5556 - val_loss: 0.3079 - val_accuracy: 0.0000e+00\n",
            "Epoch 295/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2492 - accuracy: 0.5556 - val_loss: 0.3080 - val_accuracy: 0.0000e+00\n",
            "Epoch 296/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2492 - accuracy: 0.5556 - val_loss: 0.3082 - val_accuracy: 0.0000e+00\n",
            "Epoch 297/1000\n",
            "540/540 [==============================] - 0s 41us/sample - loss: 0.2491 - accuracy: 0.5556 - val_loss: 0.3083 - val_accuracy: 0.0000e+00\n",
            "Epoch 298/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2491 - accuracy: 0.5556 - val_loss: 0.3084 - val_accuracy: 0.0000e+00\n",
            "Epoch 299/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2491 - accuracy: 0.5556 - val_loss: 0.3085 - val_accuracy: 0.0000e+00\n",
            "Epoch 300/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2491 - accuracy: 0.5556 - val_loss: 0.3086 - val_accuracy: 0.0000e+00\n",
            "Epoch 301/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2491 - accuracy: 0.5556 - val_loss: 0.3087 - val_accuracy: 0.0000e+00\n",
            "Epoch 302/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2491 - accuracy: 0.5556 - val_loss: 0.3089 - val_accuracy: 0.0000e+00\n",
            "Epoch 303/1000\n",
            "540/540 [==============================] - 0s 51us/sample - loss: 0.2491 - accuracy: 0.5556 - val_loss: 0.3090 - val_accuracy: 0.0000e+00\n",
            "Epoch 304/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2491 - accuracy: 0.5556 - val_loss: 0.3091 - val_accuracy: 0.0000e+00\n",
            "Epoch 305/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2491 - accuracy: 0.5556 - val_loss: 0.3092 - val_accuracy: 0.0000e+00\n",
            "Epoch 306/1000\n",
            "540/540 [==============================] - 0s 57us/sample - loss: 0.2491 - accuracy: 0.5556 - val_loss: 0.3093 - val_accuracy: 0.0000e+00\n",
            "Epoch 307/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2491 - accuracy: 0.5556 - val_loss: 0.3094 - val_accuracy: 0.0000e+00\n",
            "Epoch 308/1000\n",
            "540/540 [==============================] - 0s 42us/sample - loss: 0.2491 - accuracy: 0.5556 - val_loss: 0.3095 - val_accuracy: 0.0000e+00\n",
            "Epoch 309/1000\n",
            "540/540 [==============================] - 0s 56us/sample - loss: 0.2491 - accuracy: 0.5556 - val_loss: 0.3096 - val_accuracy: 0.0000e+00\n",
            "Epoch 310/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2491 - accuracy: 0.5556 - val_loss: 0.3097 - val_accuracy: 0.0000e+00\n",
            "Epoch 311/1000\n",
            "540/540 [==============================] - 0s 43us/sample - loss: 0.2490 - accuracy: 0.5556 - val_loss: 0.3098 - val_accuracy: 0.0000e+00\n",
            "Epoch 312/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2490 - accuracy: 0.5556 - val_loss: 0.3099 - val_accuracy: 0.0000e+00\n",
            "Epoch 313/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2490 - accuracy: 0.5556 - val_loss: 0.3101 - val_accuracy: 0.0000e+00\n",
            "Epoch 314/1000\n",
            "540/540 [==============================] - 0s 51us/sample - loss: 0.2490 - accuracy: 0.5556 - val_loss: 0.3102 - val_accuracy: 0.0000e+00\n",
            "Epoch 315/1000\n",
            "540/540 [==============================] - 0s 42us/sample - loss: 0.2490 - accuracy: 0.5556 - val_loss: 0.3103 - val_accuracy: 0.0000e+00\n",
            "Epoch 316/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2490 - accuracy: 0.5556 - val_loss: 0.3104 - val_accuracy: 0.0000e+00\n",
            "Epoch 317/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2490 - accuracy: 0.5556 - val_loss: 0.3105 - val_accuracy: 0.0000e+00\n",
            "Epoch 318/1000\n",
            "540/540 [==============================] - 0s 42us/sample - loss: 0.2490 - accuracy: 0.5556 - val_loss: 0.3105 - val_accuracy: 0.0000e+00\n",
            "Epoch 319/1000\n",
            "540/540 [==============================] - 0s 63us/sample - loss: 0.2490 - accuracy: 0.5556 - val_loss: 0.3106 - val_accuracy: 0.0000e+00\n",
            "Epoch 320/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2490 - accuracy: 0.5556 - val_loss: 0.3107 - val_accuracy: 0.0000e+00\n",
            "Epoch 321/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2490 - accuracy: 0.5556 - val_loss: 0.3108 - val_accuracy: 0.0000e+00\n",
            "Epoch 322/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2490 - accuracy: 0.5556 - val_loss: 0.3109 - val_accuracy: 0.0000e+00\n",
            "Epoch 323/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2490 - accuracy: 0.5556 - val_loss: 0.3110 - val_accuracy: 0.0000e+00\n",
            "Epoch 324/1000\n",
            "540/540 [==============================] - 0s 42us/sample - loss: 0.2490 - accuracy: 0.5556 - val_loss: 0.3111 - val_accuracy: 0.0000e+00\n",
            "Epoch 325/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2490 - accuracy: 0.5556 - val_loss: 0.3112 - val_accuracy: 0.0000e+00\n",
            "Epoch 326/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2489 - accuracy: 0.5556 - val_loss: 0.3113 - val_accuracy: 0.0000e+00\n",
            "Epoch 327/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2489 - accuracy: 0.5556 - val_loss: 0.3114 - val_accuracy: 0.0000e+00\n",
            "Epoch 328/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2489 - accuracy: 0.5556 - val_loss: 0.3115 - val_accuracy: 0.0000e+00\n",
            "Epoch 329/1000\n",
            "540/540 [==============================] - 0s 43us/sample - loss: 0.2489 - accuracy: 0.5556 - val_loss: 0.3116 - val_accuracy: 0.0000e+00\n",
            "Epoch 330/1000\n",
            "540/540 [==============================] - 0s 43us/sample - loss: 0.2489 - accuracy: 0.5556 - val_loss: 0.3116 - val_accuracy: 0.0000e+00\n",
            "Epoch 331/1000\n",
            "540/540 [==============================] - 0s 53us/sample - loss: 0.2489 - accuracy: 0.5556 - val_loss: 0.3117 - val_accuracy: 0.0000e+00\n",
            "Epoch 332/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2489 - accuracy: 0.5556 - val_loss: 0.3118 - val_accuracy: 0.0000e+00\n",
            "Epoch 333/1000\n",
            "540/540 [==============================] - 0s 54us/sample - loss: 0.2489 - accuracy: 0.5556 - val_loss: 0.3119 - val_accuracy: 0.0000e+00\n",
            "Epoch 334/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2489 - accuracy: 0.5556 - val_loss: 0.3120 - val_accuracy: 0.0000e+00\n",
            "Epoch 335/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2489 - accuracy: 0.5556 - val_loss: 0.3121 - val_accuracy: 0.0000e+00\n",
            "Epoch 336/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2489 - accuracy: 0.5556 - val_loss: 0.3121 - val_accuracy: 0.0000e+00\n",
            "Epoch 337/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2489 - accuracy: 0.5556 - val_loss: 0.3122 - val_accuracy: 0.0000e+00\n",
            "Epoch 338/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2489 - accuracy: 0.5556 - val_loss: 0.3123 - val_accuracy: 0.0000e+00\n",
            "Epoch 339/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2489 - accuracy: 0.5556 - val_loss: 0.3124 - val_accuracy: 0.0000e+00\n",
            "Epoch 340/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2489 - accuracy: 0.5556 - val_loss: 0.3125 - val_accuracy: 0.0000e+00\n",
            "Epoch 341/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2489 - accuracy: 0.5556 - val_loss: 0.3125 - val_accuracy: 0.0000e+00\n",
            "Epoch 342/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2489 - accuracy: 0.5556 - val_loss: 0.3126 - val_accuracy: 0.0000e+00\n",
            "Epoch 343/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2489 - accuracy: 0.5556 - val_loss: 0.3127 - val_accuracy: 0.0000e+00\n",
            "Epoch 344/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2489 - accuracy: 0.5556 - val_loss: 0.3128 - val_accuracy: 0.0000e+00\n",
            "Epoch 345/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2489 - accuracy: 0.5556 - val_loss: 0.3128 - val_accuracy: 0.0000e+00\n",
            "Epoch 346/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2488 - accuracy: 0.5556 - val_loss: 0.3129 - val_accuracy: 0.0000e+00\n",
            "Epoch 347/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2488 - accuracy: 0.5556 - val_loss: 0.3130 - val_accuracy: 0.0000e+00\n",
            "Epoch 348/1000\n",
            "540/540 [==============================] - 0s 52us/sample - loss: 0.2488 - accuracy: 0.5556 - val_loss: 0.3130 - val_accuracy: 0.0000e+00\n",
            "Epoch 349/1000\n",
            "540/540 [==============================] - 0s 63us/sample - loss: 0.2488 - accuracy: 0.5556 - val_loss: 0.3131 - val_accuracy: 0.0000e+00\n",
            "Epoch 350/1000\n",
            "540/540 [==============================] - 0s 51us/sample - loss: 0.2488 - accuracy: 0.5556 - val_loss: 0.3132 - val_accuracy: 0.0000e+00\n",
            "Epoch 351/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2488 - accuracy: 0.5556 - val_loss: 0.3133 - val_accuracy: 0.0000e+00\n",
            "Epoch 352/1000\n",
            "540/540 [==============================] - 0s 51us/sample - loss: 0.2488 - accuracy: 0.5556 - val_loss: 0.3133 - val_accuracy: 0.0000e+00\n",
            "Epoch 353/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2488 - accuracy: 0.5556 - val_loss: 0.3134 - val_accuracy: 0.0000e+00\n",
            "Epoch 354/1000\n",
            "540/540 [==============================] - 0s 59us/sample - loss: 0.2488 - accuracy: 0.5556 - val_loss: 0.3135 - val_accuracy: 0.0000e+00\n",
            "Epoch 355/1000\n",
            "540/540 [==============================] - 0s 58us/sample - loss: 0.2488 - accuracy: 0.5556 - val_loss: 0.3135 - val_accuracy: 0.0000e+00\n",
            "Epoch 356/1000\n",
            "540/540 [==============================] - 0s 60us/sample - loss: 0.2488 - accuracy: 0.5556 - val_loss: 0.3136 - val_accuracy: 0.0000e+00\n",
            "Epoch 357/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2488 - accuracy: 0.5556 - val_loss: 0.3137 - val_accuracy: 0.0000e+00\n",
            "Epoch 358/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2488 - accuracy: 0.5556 - val_loss: 0.3137 - val_accuracy: 0.0000e+00\n",
            "Epoch 359/1000\n",
            "540/540 [==============================] - 0s 59us/sample - loss: 0.2488 - accuracy: 0.5556 - val_loss: 0.3138 - val_accuracy: 0.0000e+00\n",
            "Epoch 360/1000\n",
            "540/540 [==============================] - 0s 55us/sample - loss: 0.2488 - accuracy: 0.5556 - val_loss: 0.3138 - val_accuracy: 0.0000e+00\n",
            "Epoch 361/1000\n",
            "540/540 [==============================] - 0s 52us/sample - loss: 0.2488 - accuracy: 0.5556 - val_loss: 0.3139 - val_accuracy: 0.0000e+00\n",
            "Epoch 362/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2488 - accuracy: 0.5556 - val_loss: 0.3140 - val_accuracy: 0.0000e+00\n",
            "Epoch 363/1000\n",
            "540/540 [==============================] - 0s 53us/sample - loss: 0.2488 - accuracy: 0.5556 - val_loss: 0.3140 - val_accuracy: 0.0000e+00\n",
            "Epoch 364/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2488 - accuracy: 0.5556 - val_loss: 0.3141 - val_accuracy: 0.0000e+00\n",
            "Epoch 365/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2488 - accuracy: 0.5556 - val_loss: 0.3141 - val_accuracy: 0.0000e+00\n",
            "Epoch 366/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2488 - accuracy: 0.5556 - val_loss: 0.3142 - val_accuracy: 0.0000e+00\n",
            "Epoch 367/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2487 - accuracy: 0.5556 - val_loss: 0.3143 - val_accuracy: 0.0000e+00\n",
            "Epoch 368/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2487 - accuracy: 0.5556 - val_loss: 0.3143 - val_accuracy: 0.0000e+00\n",
            "Epoch 369/1000\n",
            "540/540 [==============================] - 0s 51us/sample - loss: 0.2487 - accuracy: 0.5556 - val_loss: 0.3144 - val_accuracy: 0.0000e+00\n",
            "Epoch 370/1000\n",
            "540/540 [==============================] - 0s 51us/sample - loss: 0.2487 - accuracy: 0.5556 - val_loss: 0.3144 - val_accuracy: 0.0000e+00\n",
            "Epoch 371/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2487 - accuracy: 0.5556 - val_loss: 0.3145 - val_accuracy: 0.0000e+00\n",
            "Epoch 372/1000\n",
            "540/540 [==============================] - 0s 52us/sample - loss: 0.2487 - accuracy: 0.5556 - val_loss: 0.3145 - val_accuracy: 0.0000e+00\n",
            "Epoch 373/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2487 - accuracy: 0.5556 - val_loss: 0.3146 - val_accuracy: 0.0000e+00\n",
            "Epoch 374/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2487 - accuracy: 0.5556 - val_loss: 0.3147 - val_accuracy: 0.0000e+00\n",
            "Epoch 375/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2487 - accuracy: 0.5556 - val_loss: 0.3147 - val_accuracy: 0.0000e+00\n",
            "Epoch 376/1000\n",
            "540/540 [==============================] - 0s 51us/sample - loss: 0.2487 - accuracy: 0.5556 - val_loss: 0.3148 - val_accuracy: 0.0000e+00\n",
            "Epoch 377/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2487 - accuracy: 0.5556 - val_loss: 0.3148 - val_accuracy: 0.0000e+00\n",
            "Epoch 378/1000\n",
            "540/540 [==============================] - 0s 58us/sample - loss: 0.2487 - accuracy: 0.5556 - val_loss: 0.3149 - val_accuracy: 0.0000e+00\n",
            "Epoch 379/1000\n",
            "540/540 [==============================] - 0s 57us/sample - loss: 0.2487 - accuracy: 0.5556 - val_loss: 0.3149 - val_accuracy: 0.0000e+00\n",
            "Epoch 380/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2487 - accuracy: 0.5556 - val_loss: 0.3150 - val_accuracy: 0.0000e+00\n",
            "Epoch 381/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2487 - accuracy: 0.5556 - val_loss: 0.3150 - val_accuracy: 0.0000e+00\n",
            "Epoch 382/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2487 - accuracy: 0.5556 - val_loss: 0.3151 - val_accuracy: 0.0000e+00\n",
            "Epoch 383/1000\n",
            "540/540 [==============================] - 0s 51us/sample - loss: 0.2487 - accuracy: 0.5556 - val_loss: 0.3151 - val_accuracy: 0.0000e+00\n",
            "Epoch 384/1000\n",
            "540/540 [==============================] - 0s 62us/sample - loss: 0.2487 - accuracy: 0.5556 - val_loss: 0.3152 - val_accuracy: 0.0000e+00\n",
            "Epoch 385/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2487 - accuracy: 0.5556 - val_loss: 0.3152 - val_accuracy: 0.0000e+00\n",
            "Epoch 386/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2487 - accuracy: 0.5556 - val_loss: 0.3153 - val_accuracy: 0.0000e+00\n",
            "Epoch 387/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2487 - accuracy: 0.5556 - val_loss: 0.3153 - val_accuracy: 0.0000e+00\n",
            "Epoch 388/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2487 - accuracy: 0.5556 - val_loss: 0.3153 - val_accuracy: 0.0000e+00\n",
            "Epoch 389/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2487 - accuracy: 0.5556 - val_loss: 0.3154 - val_accuracy: 0.0000e+00\n",
            "Epoch 390/1000\n",
            "540/540 [==============================] - 0s 59us/sample - loss: 0.2487 - accuracy: 0.5556 - val_loss: 0.3154 - val_accuracy: 0.0000e+00\n",
            "Epoch 391/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2487 - accuracy: 0.5556 - val_loss: 0.3155 - val_accuracy: 0.0000e+00\n",
            "Epoch 392/1000\n",
            "540/540 [==============================] - 0s 71us/sample - loss: 0.2486 - accuracy: 0.5556 - val_loss: 0.3155 - val_accuracy: 0.0000e+00\n",
            "Epoch 393/1000\n",
            "540/540 [==============================] - 0s 51us/sample - loss: 0.2486 - accuracy: 0.5556 - val_loss: 0.3156 - val_accuracy: 0.0000e+00\n",
            "Epoch 394/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2486 - accuracy: 0.5556 - val_loss: 0.3156 - val_accuracy: 0.0000e+00\n",
            "Epoch 395/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2486 - accuracy: 0.5556 - val_loss: 0.3157 - val_accuracy: 0.0000e+00\n",
            "Epoch 396/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2486 - accuracy: 0.5556 - val_loss: 0.3157 - val_accuracy: 0.0000e+00\n",
            "Epoch 397/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2486 - accuracy: 0.5556 - val_loss: 0.3157 - val_accuracy: 0.0000e+00\n",
            "Epoch 398/1000\n",
            "540/540 [==============================] - 0s 62us/sample - loss: 0.2486 - accuracy: 0.5556 - val_loss: 0.3158 - val_accuracy: 0.0000e+00\n",
            "Epoch 399/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2486 - accuracy: 0.5556 - val_loss: 0.3158 - val_accuracy: 0.0000e+00\n",
            "Epoch 400/1000\n",
            "540/540 [==============================] - 0s 52us/sample - loss: 0.2486 - accuracy: 0.5556 - val_loss: 0.3159 - val_accuracy: 0.0000e+00\n",
            "Epoch 401/1000\n",
            "540/540 [==============================] - 0s 52us/sample - loss: 0.2486 - accuracy: 0.5556 - val_loss: 0.3159 - val_accuracy: 0.0000e+00\n",
            "Epoch 402/1000\n",
            "540/540 [==============================] - 0s 53us/sample - loss: 0.2486 - accuracy: 0.5556 - val_loss: 0.3159 - val_accuracy: 0.0000e+00\n",
            "Epoch 403/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2486 - accuracy: 0.5556 - val_loss: 0.3160 - val_accuracy: 0.0000e+00\n",
            "Epoch 404/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2486 - accuracy: 0.5556 - val_loss: 0.3160 - val_accuracy: 0.0000e+00\n",
            "Epoch 405/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2486 - accuracy: 0.5556 - val_loss: 0.3161 - val_accuracy: 0.0000e+00\n",
            "Epoch 406/1000\n",
            "540/540 [==============================] - 0s 55us/sample - loss: 0.2486 - accuracy: 0.5556 - val_loss: 0.3161 - val_accuracy: 0.0000e+00\n",
            "Epoch 407/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2486 - accuracy: 0.5556 - val_loss: 0.3161 - val_accuracy: 0.0000e+00\n",
            "Epoch 408/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2486 - accuracy: 0.5556 - val_loss: 0.3162 - val_accuracy: 0.0000e+00\n",
            "Epoch 409/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2486 - accuracy: 0.5556 - val_loss: 0.3162 - val_accuracy: 0.0000e+00\n",
            "Epoch 410/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2486 - accuracy: 0.5556 - val_loss: 0.3162 - val_accuracy: 0.0000e+00\n",
            "Epoch 411/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2486 - accuracy: 0.5556 - val_loss: 0.3163 - val_accuracy: 0.0000e+00\n",
            "Epoch 412/1000\n",
            "540/540 [==============================] - 0s 42us/sample - loss: 0.2486 - accuracy: 0.5556 - val_loss: 0.3163 - val_accuracy: 0.0000e+00\n",
            "Epoch 413/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2486 - accuracy: 0.5556 - val_loss: 0.3163 - val_accuracy: 0.0000e+00\n",
            "Epoch 414/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2486 - accuracy: 0.5556 - val_loss: 0.3164 - val_accuracy: 0.0000e+00\n",
            "Epoch 415/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2486 - accuracy: 0.5556 - val_loss: 0.3164 - val_accuracy: 0.0000e+00\n",
            "Epoch 416/1000\n",
            "540/540 [==============================] - 0s 51us/sample - loss: 0.2486 - accuracy: 0.5556 - val_loss: 0.3164 - val_accuracy: 0.0000e+00\n",
            "Epoch 417/1000\n",
            "540/540 [==============================] - 0s 52us/sample - loss: 0.2486 - accuracy: 0.5556 - val_loss: 0.3165 - val_accuracy: 0.0000e+00\n",
            "Epoch 418/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2486 - accuracy: 0.5556 - val_loss: 0.3165 - val_accuracy: 0.0000e+00\n",
            "Epoch 419/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2485 - accuracy: 0.5556 - val_loss: 0.3165 - val_accuracy: 0.0000e+00\n",
            "Epoch 420/1000\n",
            "540/540 [==============================] - 0s 51us/sample - loss: 0.2485 - accuracy: 0.5556 - val_loss: 0.3166 - val_accuracy: 0.0000e+00\n",
            "Epoch 421/1000\n",
            "540/540 [==============================] - 0s 52us/sample - loss: 0.2485 - accuracy: 0.5556 - val_loss: 0.3166 - val_accuracy: 0.0000e+00\n",
            "Epoch 422/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2485 - accuracy: 0.5556 - val_loss: 0.3166 - val_accuracy: 0.0000e+00\n",
            "Epoch 423/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2485 - accuracy: 0.5556 - val_loss: 0.3167 - val_accuracy: 0.0000e+00\n",
            "Epoch 424/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2485 - accuracy: 0.5556 - val_loss: 0.3167 - val_accuracy: 0.0000e+00\n",
            "Epoch 425/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2485 - accuracy: 0.5556 - val_loss: 0.3167 - val_accuracy: 0.0000e+00\n",
            "Epoch 426/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2485 - accuracy: 0.5556 - val_loss: 0.3168 - val_accuracy: 0.0000e+00\n",
            "Epoch 427/1000\n",
            "540/540 [==============================] - 0s 43us/sample - loss: 0.2485 - accuracy: 0.5556 - val_loss: 0.3168 - val_accuracy: 0.0000e+00\n",
            "Epoch 428/1000\n",
            "540/540 [==============================] - 0s 56us/sample - loss: 0.2485 - accuracy: 0.5556 - val_loss: 0.3168 - val_accuracy: 0.0000e+00\n",
            "Epoch 429/1000\n",
            "540/540 [==============================] - 0s 54us/sample - loss: 0.2485 - accuracy: 0.5556 - val_loss: 0.3168 - val_accuracy: 0.0000e+00\n",
            "Epoch 430/1000\n",
            "540/540 [==============================] - 0s 43us/sample - loss: 0.2485 - accuracy: 0.5556 - val_loss: 0.3169 - val_accuracy: 0.0000e+00\n",
            "Epoch 431/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2485 - accuracy: 0.5556 - val_loss: 0.3169 - val_accuracy: 0.0000e+00\n",
            "Epoch 432/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2485 - accuracy: 0.5556 - val_loss: 0.3169 - val_accuracy: 0.0000e+00\n",
            "Epoch 433/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2485 - accuracy: 0.5556 - val_loss: 0.3170 - val_accuracy: 0.0000e+00\n",
            "Epoch 434/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2485 - accuracy: 0.5556 - val_loss: 0.3170 - val_accuracy: 0.0000e+00\n",
            "Epoch 435/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2485 - accuracy: 0.5556 - val_loss: 0.3170 - val_accuracy: 0.0000e+00\n",
            "Epoch 436/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2485 - accuracy: 0.5556 - val_loss: 0.3170 - val_accuracy: 0.0000e+00\n",
            "Epoch 437/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2485 - accuracy: 0.5556 - val_loss: 0.3171 - val_accuracy: 0.0000e+00\n",
            "Epoch 438/1000\n",
            "540/540 [==============================] - 0s 57us/sample - loss: 0.2485 - accuracy: 0.5556 - val_loss: 0.3171 - val_accuracy: 0.0000e+00\n",
            "Epoch 439/1000\n",
            "540/540 [==============================] - 0s 54us/sample - loss: 0.2485 - accuracy: 0.5556 - val_loss: 0.3171 - val_accuracy: 0.0000e+00\n",
            "Epoch 440/1000\n",
            "540/540 [==============================] - 0s 55us/sample - loss: 0.2485 - accuracy: 0.5556 - val_loss: 0.3171 - val_accuracy: 0.0000e+00\n",
            "Epoch 441/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2485 - accuracy: 0.5556 - val_loss: 0.3172 - val_accuracy: 0.0000e+00\n",
            "Epoch 442/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2485 - accuracy: 0.5556 - val_loss: 0.3172 - val_accuracy: 0.0000e+00\n",
            "Epoch 443/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2485 - accuracy: 0.5556 - val_loss: 0.3172 - val_accuracy: 0.0000e+00\n",
            "Epoch 444/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2485 - accuracy: 0.5556 - val_loss: 0.3172 - val_accuracy: 0.0000e+00\n",
            "Epoch 445/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2485 - accuracy: 0.5556 - val_loss: 0.3173 - val_accuracy: 0.0000e+00\n",
            "Epoch 446/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2485 - accuracy: 0.5556 - val_loss: 0.3173 - val_accuracy: 0.0000e+00\n",
            "Epoch 447/1000\n",
            "540/540 [==============================] - 0s 51us/sample - loss: 0.2485 - accuracy: 0.5556 - val_loss: 0.3173 - val_accuracy: 0.0000e+00\n",
            "Epoch 448/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2485 - accuracy: 0.5556 - val_loss: 0.3173 - val_accuracy: 0.0000e+00\n",
            "Epoch 449/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2484 - accuracy: 0.5556 - val_loss: 0.3173 - val_accuracy: 0.0000e+00\n",
            "Epoch 450/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2484 - accuracy: 0.5556 - val_loss: 0.3174 - val_accuracy: 0.0000e+00\n",
            "Epoch 451/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2484 - accuracy: 0.5556 - val_loss: 0.3174 - val_accuracy: 0.0000e+00\n",
            "Epoch 452/1000\n",
            "540/540 [==============================] - 0s 43us/sample - loss: 0.2484 - accuracy: 0.5556 - val_loss: 0.3174 - val_accuracy: 0.0000e+00\n",
            "Epoch 453/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2484 - accuracy: 0.5556 - val_loss: 0.3174 - val_accuracy: 0.0000e+00\n",
            "Epoch 454/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2484 - accuracy: 0.5556 - val_loss: 0.3175 - val_accuracy: 0.0000e+00\n",
            "Epoch 455/1000\n",
            "540/540 [==============================] - 0s 59us/sample - loss: 0.2484 - accuracy: 0.5556 - val_loss: 0.3175 - val_accuracy: 0.0000e+00\n",
            "Epoch 456/1000\n",
            "540/540 [==============================] - 0s 55us/sample - loss: 0.2484 - accuracy: 0.5556 - val_loss: 0.3175 - val_accuracy: 0.0000e+00\n",
            "Epoch 457/1000\n",
            "540/540 [==============================] - 0s 55us/sample - loss: 0.2484 - accuracy: 0.5556 - val_loss: 0.3175 - val_accuracy: 0.0000e+00\n",
            "Epoch 458/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2484 - accuracy: 0.5556 - val_loss: 0.3175 - val_accuracy: 0.0000e+00\n",
            "Epoch 459/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2484 - accuracy: 0.5556 - val_loss: 0.3176 - val_accuracy: 0.0000e+00\n",
            "Epoch 460/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2484 - accuracy: 0.5556 - val_loss: 0.3176 - val_accuracy: 0.0000e+00\n",
            "Epoch 461/1000\n",
            "540/540 [==============================] - 0s 57us/sample - loss: 0.2484 - accuracy: 0.5556 - val_loss: 0.3176 - val_accuracy: 0.0000e+00\n",
            "Epoch 462/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2484 - accuracy: 0.5556 - val_loss: 0.3176 - val_accuracy: 0.0000e+00\n",
            "Epoch 463/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2484 - accuracy: 0.5556 - val_loss: 0.3176 - val_accuracy: 0.0000e+00\n",
            "Epoch 464/1000\n",
            "540/540 [==============================] - 0s 59us/sample - loss: 0.2484 - accuracy: 0.5556 - val_loss: 0.3176 - val_accuracy: 0.0000e+00\n",
            "Epoch 465/1000\n",
            "540/540 [==============================] - 0s 55us/sample - loss: 0.2484 - accuracy: 0.5556 - val_loss: 0.3177 - val_accuracy: 0.0000e+00\n",
            "Epoch 466/1000\n",
            "540/540 [==============================] - 0s 53us/sample - loss: 0.2484 - accuracy: 0.5556 - val_loss: 0.3177 - val_accuracy: 0.0000e+00\n",
            "Epoch 467/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2484 - accuracy: 0.5556 - val_loss: 0.3177 - val_accuracy: 0.0000e+00\n",
            "Epoch 468/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2484 - accuracy: 0.5556 - val_loss: 0.3177 - val_accuracy: 0.0000e+00\n",
            "Epoch 469/1000\n",
            "540/540 [==============================] - 0s 43us/sample - loss: 0.2484 - accuracy: 0.5556 - val_loss: 0.3177 - val_accuracy: 0.0000e+00\n",
            "Epoch 470/1000\n",
            "540/540 [==============================] - 0s 43us/sample - loss: 0.2484 - accuracy: 0.5556 - val_loss: 0.3178 - val_accuracy: 0.0000e+00\n",
            "Epoch 471/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2484 - accuracy: 0.5556 - val_loss: 0.3178 - val_accuracy: 0.0000e+00\n",
            "Epoch 472/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2484 - accuracy: 0.5556 - val_loss: 0.3178 - val_accuracy: 0.0000e+00\n",
            "Epoch 473/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2484 - accuracy: 0.5556 - val_loss: 0.3178 - val_accuracy: 0.0000e+00\n",
            "Epoch 474/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2484 - accuracy: 0.5556 - val_loss: 0.3178 - val_accuracy: 0.0000e+00\n",
            "Epoch 475/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2484 - accuracy: 0.5556 - val_loss: 0.3178 - val_accuracy: 0.0000e+00\n",
            "Epoch 476/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2484 - accuracy: 0.5556 - val_loss: 0.3178 - val_accuracy: 0.0000e+00\n",
            "Epoch 477/1000\n",
            "540/540 [==============================] - 0s 58us/sample - loss: 0.2484 - accuracy: 0.5556 - val_loss: 0.3179 - val_accuracy: 0.0000e+00\n",
            "Epoch 478/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2484 - accuracy: 0.5556 - val_loss: 0.3179 - val_accuracy: 0.0000e+00\n",
            "Epoch 479/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2484 - accuracy: 0.5556 - val_loss: 0.3179 - val_accuracy: 0.0000e+00\n",
            "Epoch 480/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2484 - accuracy: 0.5556 - val_loss: 0.3179 - val_accuracy: 0.0000e+00\n",
            "Epoch 481/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2483 - accuracy: 0.5556 - val_loss: 0.3179 - val_accuracy: 0.0000e+00\n",
            "Epoch 482/1000\n",
            "540/540 [==============================] - 0s 41us/sample - loss: 0.2483 - accuracy: 0.5556 - val_loss: 0.3179 - val_accuracy: 0.0000e+00\n",
            "Epoch 483/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2483 - accuracy: 0.5556 - val_loss: 0.3180 - val_accuracy: 0.0000e+00\n",
            "Epoch 484/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2483 - accuracy: 0.5556 - val_loss: 0.3180 - val_accuracy: 0.0000e+00\n",
            "Epoch 485/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2483 - accuracy: 0.5556 - val_loss: 0.3180 - val_accuracy: 0.0000e+00\n",
            "Epoch 486/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2483 - accuracy: 0.5556 - val_loss: 0.3180 - val_accuracy: 0.0000e+00\n",
            "Epoch 487/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2483 - accuracy: 0.5556 - val_loss: 0.3180 - val_accuracy: 0.0000e+00\n",
            "Epoch 488/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2483 - accuracy: 0.5556 - val_loss: 0.3180 - val_accuracy: 0.0000e+00\n",
            "Epoch 489/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2483 - accuracy: 0.5556 - val_loss: 0.3180 - val_accuracy: 0.0000e+00\n",
            "Epoch 490/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2483 - accuracy: 0.5556 - val_loss: 0.3180 - val_accuracy: 0.0000e+00\n",
            "Epoch 491/1000\n",
            "540/540 [==============================] - 0s 52us/sample - loss: 0.2483 - accuracy: 0.5556 - val_loss: 0.3181 - val_accuracy: 0.0000e+00\n",
            "Epoch 492/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2483 - accuracy: 0.5556 - val_loss: 0.3181 - val_accuracy: 0.0000e+00\n",
            "Epoch 493/1000\n",
            "540/540 [==============================] - 0s 56us/sample - loss: 0.2483 - accuracy: 0.5556 - val_loss: 0.3181 - val_accuracy: 0.0000e+00\n",
            "Epoch 494/1000\n",
            "540/540 [==============================] - 0s 65us/sample - loss: 0.2483 - accuracy: 0.5556 - val_loss: 0.3181 - val_accuracy: 0.0000e+00\n",
            "Epoch 495/1000\n",
            "540/540 [==============================] - 0s 59us/sample - loss: 0.2483 - accuracy: 0.5556 - val_loss: 0.3181 - val_accuracy: 0.0000e+00\n",
            "Epoch 496/1000\n",
            "540/540 [==============================] - 0s 51us/sample - loss: 0.2483 - accuracy: 0.5556 - val_loss: 0.3181 - val_accuracy: 0.0000e+00\n",
            "Epoch 497/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2483 - accuracy: 0.5556 - val_loss: 0.3181 - val_accuracy: 0.0000e+00\n",
            "Epoch 498/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2483 - accuracy: 0.5556 - val_loss: 0.3181 - val_accuracy: 0.0000e+00\n",
            "Epoch 499/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2483 - accuracy: 0.5556 - val_loss: 0.3182 - val_accuracy: 0.0000e+00\n",
            "Epoch 500/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2483 - accuracy: 0.5556 - val_loss: 0.3182 - val_accuracy: 0.0000e+00\n",
            "Epoch 501/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2483 - accuracy: 0.5556 - val_loss: 0.3182 - val_accuracy: 0.0000e+00\n",
            "Epoch 502/1000\n",
            "540/540 [==============================] - 0s 63us/sample - loss: 0.2483 - accuracy: 0.5556 - val_loss: 0.3182 - val_accuracy: 0.0000e+00\n",
            "Epoch 503/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2483 - accuracy: 0.5556 - val_loss: 0.3182 - val_accuracy: 0.0000e+00\n",
            "Epoch 504/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2483 - accuracy: 0.5556 - val_loss: 0.3182 - val_accuracy: 0.0000e+00\n",
            "Epoch 505/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2483 - accuracy: 0.5556 - val_loss: 0.3182 - val_accuracy: 0.0000e+00\n",
            "Epoch 506/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2483 - accuracy: 0.5556 - val_loss: 0.3182 - val_accuracy: 0.0000e+00\n",
            "Epoch 507/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2483 - accuracy: 0.5556 - val_loss: 0.3182 - val_accuracy: 0.0000e+00\n",
            "Epoch 508/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2483 - accuracy: 0.5556 - val_loss: 0.3182 - val_accuracy: 0.0000e+00\n",
            "Epoch 509/1000\n",
            "540/540 [==============================] - 0s 53us/sample - loss: 0.2483 - accuracy: 0.5556 - val_loss: 0.3182 - val_accuracy: 0.0000e+00\n",
            "Epoch 510/1000\n",
            "540/540 [==============================] - 0s 54us/sample - loss: 0.2483 - accuracy: 0.5556 - val_loss: 0.3183 - val_accuracy: 0.0000e+00\n",
            "Epoch 511/1000\n",
            "540/540 [==============================] - 0s 65us/sample - loss: 0.2483 - accuracy: 0.5556 - val_loss: 0.3183 - val_accuracy: 0.0000e+00\n",
            "Epoch 512/1000\n",
            "540/540 [==============================] - 0s 54us/sample - loss: 0.2483 - accuracy: 0.5556 - val_loss: 0.3183 - val_accuracy: 0.0000e+00\n",
            "Epoch 513/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2483 - accuracy: 0.5556 - val_loss: 0.3183 - val_accuracy: 0.0000e+00\n",
            "Epoch 514/1000\n",
            "540/540 [==============================] - 0s 51us/sample - loss: 0.2483 - accuracy: 0.5556 - val_loss: 0.3183 - val_accuracy: 0.0000e+00\n",
            "Epoch 515/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2482 - accuracy: 0.5556 - val_loss: 0.3183 - val_accuracy: 0.0000e+00\n",
            "Epoch 516/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2482 - accuracy: 0.5556 - val_loss: 0.3183 - val_accuracy: 0.0000e+00\n",
            "Epoch 517/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2482 - accuracy: 0.5556 - val_loss: 0.3183 - val_accuracy: 0.0000e+00\n",
            "Epoch 518/1000\n",
            "540/540 [==============================] - 0s 53us/sample - loss: 0.2482 - accuracy: 0.5556 - val_loss: 0.3183 - val_accuracy: 0.0000e+00\n",
            "Epoch 519/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2482 - accuracy: 0.5556 - val_loss: 0.3183 - val_accuracy: 0.0000e+00\n",
            "Epoch 520/1000\n",
            "540/540 [==============================] - 0s 56us/sample - loss: 0.2482 - accuracy: 0.5556 - val_loss: 0.3183 - val_accuracy: 0.0000e+00\n",
            "Epoch 521/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2482 - accuracy: 0.5556 - val_loss: 0.3184 - val_accuracy: 0.0000e+00\n",
            "Epoch 522/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2482 - accuracy: 0.5556 - val_loss: 0.3184 - val_accuracy: 0.0000e+00\n",
            "Epoch 523/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2482 - accuracy: 0.5556 - val_loss: 0.3184 - val_accuracy: 0.0000e+00\n",
            "Epoch 524/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2482 - accuracy: 0.5556 - val_loss: 0.3184 - val_accuracy: 0.0000e+00\n",
            "Epoch 525/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2482 - accuracy: 0.5556 - val_loss: 0.3184 - val_accuracy: 0.0000e+00\n",
            "Epoch 526/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2482 - accuracy: 0.5556 - val_loss: 0.3184 - val_accuracy: 0.0000e+00\n",
            "Epoch 527/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2482 - accuracy: 0.5556 - val_loss: 0.3184 - val_accuracy: 0.0000e+00\n",
            "Epoch 528/1000\n",
            "540/540 [==============================] - 0s 55us/sample - loss: 0.2482 - accuracy: 0.5556 - val_loss: 0.3184 - val_accuracy: 0.0000e+00\n",
            "Epoch 529/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2482 - accuracy: 0.5556 - val_loss: 0.3184 - val_accuracy: 0.0000e+00\n",
            "Epoch 530/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2482 - accuracy: 0.5556 - val_loss: 0.3184 - val_accuracy: 0.0000e+00\n",
            "Epoch 531/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2482 - accuracy: 0.5556 - val_loss: 0.3184 - val_accuracy: 0.0000e+00\n",
            "Epoch 532/1000\n",
            "540/540 [==============================] - 0s 55us/sample - loss: 0.2482 - accuracy: 0.5556 - val_loss: 0.3184 - val_accuracy: 0.0000e+00\n",
            "Epoch 533/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2482 - accuracy: 0.5556 - val_loss: 0.3184 - val_accuracy: 0.0000e+00\n",
            "Epoch 534/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2482 - accuracy: 0.5556 - val_loss: 0.3184 - val_accuracy: 0.0000e+00\n",
            "Epoch 535/1000\n",
            "540/540 [==============================] - 0s 43us/sample - loss: 0.2482 - accuracy: 0.5556 - val_loss: 0.3184 - val_accuracy: 0.0000e+00\n",
            "Epoch 536/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2482 - accuracy: 0.5556 - val_loss: 0.3184 - val_accuracy: 0.0000e+00\n",
            "Epoch 537/1000\n",
            "540/540 [==============================] - 0s 57us/sample - loss: 0.2482 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 538/1000\n",
            "540/540 [==============================] - 0s 62us/sample - loss: 0.2482 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 539/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2482 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 540/1000\n",
            "540/540 [==============================] - 0s 43us/sample - loss: 0.2482 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 541/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2482 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 542/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2482 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 543/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2482 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 544/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2482 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 545/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2482 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 546/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2482 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 547/1000\n",
            "540/540 [==============================] - 0s 54us/sample - loss: 0.2482 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 548/1000\n",
            "540/540 [==============================] - 0s 42us/sample - loss: 0.2482 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 549/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2482 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 550/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2481 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 551/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2481 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 552/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2481 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 553/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2481 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 554/1000\n",
            "540/540 [==============================] - 0s 57us/sample - loss: 0.2481 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 555/1000\n",
            "540/540 [==============================] - 0s 56us/sample - loss: 0.2481 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 556/1000\n",
            "540/540 [==============================] - 0s 52us/sample - loss: 0.2481 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 557/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2481 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 558/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2481 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 559/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2481 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 560/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2481 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 561/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2481 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 562/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2481 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 563/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2481 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 564/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2481 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 565/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2481 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 566/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2481 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 567/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2481 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 568/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2481 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 569/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2481 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 570/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2481 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 571/1000\n",
            "540/540 [==============================] - 0s 53us/sample - loss: 0.2481 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 572/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2481 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 573/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2481 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 574/1000\n",
            "540/540 [==============================] - 0s 54us/sample - loss: 0.2481 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 575/1000\n",
            "540/540 [==============================] - 0s 68us/sample - loss: 0.2481 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 576/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2481 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 577/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2481 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 578/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2481 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 579/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2481 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 580/1000\n",
            "540/540 [==============================] - 0s 51us/sample - loss: 0.2481 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 581/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2481 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 582/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2481 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 583/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2481 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 584/1000\n",
            "540/540 [==============================] - 0s 54us/sample - loss: 0.2481 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 585/1000\n",
            "540/540 [==============================] - 0s 52us/sample - loss: 0.2481 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 586/1000\n",
            "540/540 [==============================] - 0s 53us/sample - loss: 0.2481 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 587/1000\n",
            "540/540 [==============================] - 0s 57us/sample - loss: 0.2481 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 588/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2480 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 589/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2480 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 590/1000\n",
            "540/540 [==============================] - 0s 52us/sample - loss: 0.2480 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 591/1000\n",
            "540/540 [==============================] - 0s 52us/sample - loss: 0.2480 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 592/1000\n",
            "540/540 [==============================] - 0s 54us/sample - loss: 0.2480 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 593/1000\n",
            "540/540 [==============================] - 0s 53us/sample - loss: 0.2480 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 594/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2480 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 595/1000\n",
            "540/540 [==============================] - 0s 53us/sample - loss: 0.2480 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 596/1000\n",
            "540/540 [==============================] - 0s 52us/sample - loss: 0.2480 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 597/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2480 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 598/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2480 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 599/1000\n",
            "540/540 [==============================] - 0s 53us/sample - loss: 0.2480 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 600/1000\n",
            "540/540 [==============================] - 0s 54us/sample - loss: 0.2480 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 601/1000\n",
            "540/540 [==============================] - 0s 53us/sample - loss: 0.2480 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 602/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2480 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 603/1000\n",
            "540/540 [==============================] - 0s 56us/sample - loss: 0.2480 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 604/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2480 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 605/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2480 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 606/1000\n",
            "540/540 [==============================] - 0s 53us/sample - loss: 0.2480 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 607/1000\n",
            "540/540 [==============================] - 0s 54us/sample - loss: 0.2480 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 608/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2480 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 609/1000\n",
            "540/540 [==============================] - 0s 52us/sample - loss: 0.2480 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 610/1000\n",
            "540/540 [==============================] - 0s 60us/sample - loss: 0.2480 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 611/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2480 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 612/1000\n",
            "540/540 [==============================] - 0s 56us/sample - loss: 0.2480 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 613/1000\n",
            "540/540 [==============================] - 0s 54us/sample - loss: 0.2480 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 614/1000\n",
            "540/540 [==============================] - 0s 55us/sample - loss: 0.2480 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 615/1000\n",
            "540/540 [==============================] - 0s 52us/sample - loss: 0.2480 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 616/1000\n",
            "540/540 [==============================] - 0s 57us/sample - loss: 0.2480 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 617/1000\n",
            "540/540 [==============================] - 0s 58us/sample - loss: 0.2480 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 618/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2480 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 619/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2480 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 620/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2480 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 621/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2480 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 622/1000\n",
            "540/540 [==============================] - 0s 54us/sample - loss: 0.2480 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 623/1000\n",
            "540/540 [==============================] - 0s 57us/sample - loss: 0.2480 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 624/1000\n",
            "540/540 [==============================] - 0s 52us/sample - loss: 0.2480 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 625/1000\n",
            "540/540 [==============================] - 0s 53us/sample - loss: 0.2480 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 626/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2480 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 627/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2479 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 628/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2479 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 629/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2479 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 630/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2479 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 631/1000\n",
            "540/540 [==============================] - 0s 42us/sample - loss: 0.2479 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 632/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2479 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 633/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2479 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 634/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2479 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 635/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2479 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 636/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2479 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 637/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2479 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 638/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2479 - accuracy: 0.5556 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
            "Epoch 639/1000\n",
            "540/540 [==============================] - 0s 55us/sample - loss: 0.2479 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 640/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2479 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 641/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2479 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 642/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2479 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 643/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2479 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 644/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2479 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 645/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2479 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 646/1000\n",
            "540/540 [==============================] - 0s 62us/sample - loss: 0.2479 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 647/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2479 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 648/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2479 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 649/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2479 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 650/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2479 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 651/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2479 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 652/1000\n",
            "540/540 [==============================] - 0s 57us/sample - loss: 0.2479 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 653/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2479 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 654/1000\n",
            "540/540 [==============================] - 0s 51us/sample - loss: 0.2479 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 655/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2479 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 656/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2479 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 657/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2479 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 658/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2479 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 659/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2479 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 660/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2479 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 661/1000\n",
            "540/540 [==============================] - 0s 51us/sample - loss: 0.2479 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 662/1000\n",
            "540/540 [==============================] - 0s 59us/sample - loss: 0.2479 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 663/1000\n",
            "540/540 [==============================] - 0s 56us/sample - loss: 0.2479 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 664/1000\n",
            "540/540 [==============================] - 0s 57us/sample - loss: 0.2479 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 665/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2479 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 666/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2479 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 667/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2478 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 668/1000\n",
            "540/540 [==============================] - 0s 56us/sample - loss: 0.2478 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 669/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2478 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 670/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2478 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 671/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2478 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 672/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2478 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 673/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2478 - accuracy: 0.5556 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 674/1000\n",
            "540/540 [==============================] - 0s 51us/sample - loss: 0.2478 - accuracy: 0.5556 - val_loss: 0.3184 - val_accuracy: 0.0000e+00\n",
            "Epoch 675/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2478 - accuracy: 0.5556 - val_loss: 0.3184 - val_accuracy: 0.0000e+00\n",
            "Epoch 676/1000\n",
            "540/540 [==============================] - 0s 53us/sample - loss: 0.2478 - accuracy: 0.5556 - val_loss: 0.3184 - val_accuracy: 0.0000e+00\n",
            "Epoch 677/1000\n",
            "540/540 [==============================] - 0s 52us/sample - loss: 0.2478 - accuracy: 0.5556 - val_loss: 0.3184 - val_accuracy: 0.0000e+00\n",
            "Epoch 678/1000\n",
            "540/540 [==============================] - 0s 53us/sample - loss: 0.2478 - accuracy: 0.5556 - val_loss: 0.3184 - val_accuracy: 0.0000e+00\n",
            "Epoch 679/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2478 - accuracy: 0.5556 - val_loss: 0.3184 - val_accuracy: 0.0000e+00\n",
            "Epoch 680/1000\n",
            "540/540 [==============================] - 0s 51us/sample - loss: 0.2478 - accuracy: 0.5556 - val_loss: 0.3184 - val_accuracy: 0.0000e+00\n",
            "Epoch 681/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2478 - accuracy: 0.5556 - val_loss: 0.3184 - val_accuracy: 0.0000e+00\n",
            "Epoch 682/1000\n",
            "540/540 [==============================] - 0s 68us/sample - loss: 0.2478 - accuracy: 0.5556 - val_loss: 0.3184 - val_accuracy: 0.0000e+00\n",
            "Epoch 683/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2478 - accuracy: 0.5556 - val_loss: 0.3184 - val_accuracy: 0.0000e+00\n",
            "Epoch 684/1000\n",
            "540/540 [==============================] - 0s 56us/sample - loss: 0.2478 - accuracy: 0.5556 - val_loss: 0.3184 - val_accuracy: 0.0000e+00\n",
            "Epoch 685/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2478 - accuracy: 0.5556 - val_loss: 0.3184 - val_accuracy: 0.0000e+00\n",
            "Epoch 686/1000\n",
            "540/540 [==============================] - 0s 51us/sample - loss: 0.2478 - accuracy: 0.5556 - val_loss: 0.3184 - val_accuracy: 0.0000e+00\n",
            "Epoch 687/1000\n",
            "540/540 [==============================] - 0s 53us/sample - loss: 0.2478 - accuracy: 0.5556 - val_loss: 0.3184 - val_accuracy: 0.0000e+00\n",
            "Epoch 688/1000\n",
            "540/540 [==============================] - 0s 53us/sample - loss: 0.2478 - accuracy: 0.5556 - val_loss: 0.3184 - val_accuracy: 0.0000e+00\n",
            "Epoch 689/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2478 - accuracy: 0.5556 - val_loss: 0.3184 - val_accuracy: 0.0000e+00\n",
            "Epoch 690/1000\n",
            "540/540 [==============================] - 0s 52us/sample - loss: 0.2478 - accuracy: 0.5556 - val_loss: 0.3184 - val_accuracy: 0.0000e+00\n",
            "Epoch 691/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2478 - accuracy: 0.5556 - val_loss: 0.3184 - val_accuracy: 0.0000e+00\n",
            "Epoch 692/1000\n",
            "540/540 [==============================] - 0s 52us/sample - loss: 0.2478 - accuracy: 0.5556 - val_loss: 0.3184 - val_accuracy: 0.0000e+00\n",
            "Epoch 693/1000\n",
            "540/540 [==============================] - 0s 58us/sample - loss: 0.2478 - accuracy: 0.5556 - val_loss: 0.3184 - val_accuracy: 0.0000e+00\n",
            "Epoch 694/1000\n",
            "540/540 [==============================] - 0s 51us/sample - loss: 0.2478 - accuracy: 0.5556 - val_loss: 0.3184 - val_accuracy: 0.0000e+00\n",
            "Epoch 695/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2478 - accuracy: 0.5556 - val_loss: 0.3184 - val_accuracy: 0.0000e+00\n",
            "Epoch 696/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2478 - accuracy: 0.5556 - val_loss: 0.3184 - val_accuracy: 0.0000e+00\n",
            "Epoch 697/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2478 - accuracy: 0.5556 - val_loss: 0.3184 - val_accuracy: 0.0000e+00\n",
            "Epoch 698/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2478 - accuracy: 0.5556 - val_loss: 0.3184 - val_accuracy: 0.0000e+00\n",
            "Epoch 699/1000\n",
            "540/540 [==============================] - 0s 55us/sample - loss: 0.2478 - accuracy: 0.5556 - val_loss: 0.3184 - val_accuracy: 0.0000e+00\n",
            "Epoch 700/1000\n",
            "540/540 [==============================] - 0s 51us/sample - loss: 0.2478 - accuracy: 0.5556 - val_loss: 0.3184 - val_accuracy: 0.0000e+00\n",
            "Epoch 701/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2478 - accuracy: 0.5556 - val_loss: 0.3184 - val_accuracy: 0.0000e+00\n",
            "Epoch 702/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2478 - accuracy: 0.5556 - val_loss: 0.3183 - val_accuracy: 0.0000e+00\n",
            "Epoch 703/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2478 - accuracy: 0.5556 - val_loss: 0.3183 - val_accuracy: 0.0000e+00\n",
            "Epoch 704/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2478 - accuracy: 0.5556 - val_loss: 0.3183 - val_accuracy: 0.0000e+00\n",
            "Epoch 705/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2478 - accuracy: 0.5556 - val_loss: 0.3183 - val_accuracy: 0.0000e+00\n",
            "Epoch 706/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2478 - accuracy: 0.5556 - val_loss: 0.3183 - val_accuracy: 0.0000e+00\n",
            "Epoch 707/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2478 - accuracy: 0.5556 - val_loss: 0.3183 - val_accuracy: 0.0000e+00\n",
            "Epoch 708/1000\n",
            "540/540 [==============================] - 0s 52us/sample - loss: 0.2478 - accuracy: 0.5556 - val_loss: 0.3183 - val_accuracy: 0.0000e+00\n",
            "Epoch 709/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2477 - accuracy: 0.5556 - val_loss: 0.3183 - val_accuracy: 0.0000e+00\n",
            "Epoch 710/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2477 - accuracy: 0.5556 - val_loss: 0.3183 - val_accuracy: 0.0000e+00\n",
            "Epoch 711/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2477 - accuracy: 0.5556 - val_loss: 0.3183 - val_accuracy: 0.0000e+00\n",
            "Epoch 712/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2477 - accuracy: 0.5556 - val_loss: 0.3183 - val_accuracy: 0.0000e+00\n",
            "Epoch 713/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2477 - accuracy: 0.5556 - val_loss: 0.3183 - val_accuracy: 0.0000e+00\n",
            "Epoch 714/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2477 - accuracy: 0.5556 - val_loss: 0.3183 - val_accuracy: 0.0000e+00\n",
            "Epoch 715/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2477 - accuracy: 0.5556 - val_loss: 0.3183 - val_accuracy: 0.0000e+00\n",
            "Epoch 716/1000\n",
            "540/540 [==============================] - 0s 53us/sample - loss: 0.2477 - accuracy: 0.5556 - val_loss: 0.3183 - val_accuracy: 0.0000e+00\n",
            "Epoch 717/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2477 - accuracy: 0.5556 - val_loss: 0.3183 - val_accuracy: 0.0000e+00\n",
            "Epoch 718/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2477 - accuracy: 0.5556 - val_loss: 0.3183 - val_accuracy: 0.0000e+00\n",
            "Epoch 719/1000\n",
            "540/540 [==============================] - 0s 53us/sample - loss: 0.2477 - accuracy: 0.5556 - val_loss: 0.3183 - val_accuracy: 0.0000e+00\n",
            "Epoch 720/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2477 - accuracy: 0.5556 - val_loss: 0.3183 - val_accuracy: 0.0000e+00\n",
            "Epoch 721/1000\n",
            "540/540 [==============================] - 0s 42us/sample - loss: 0.2477 - accuracy: 0.5556 - val_loss: 0.3183 - val_accuracy: 0.0000e+00\n",
            "Epoch 722/1000\n",
            "540/540 [==============================] - 0s 40us/sample - loss: 0.2477 - accuracy: 0.5556 - val_loss: 0.3183 - val_accuracy: 0.0000e+00\n",
            "Epoch 723/1000\n",
            "540/540 [==============================] - 0s 41us/sample - loss: 0.2477 - accuracy: 0.5556 - val_loss: 0.3183 - val_accuracy: 0.0000e+00\n",
            "Epoch 724/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2477 - accuracy: 0.5556 - val_loss: 0.3183 - val_accuracy: 0.0000e+00\n",
            "Epoch 725/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2477 - accuracy: 0.5556 - val_loss: 0.3183 - val_accuracy: 0.0000e+00\n",
            "Epoch 726/1000\n",
            "540/540 [==============================] - 0s 66us/sample - loss: 0.2477 - accuracy: 0.5556 - val_loss: 0.3182 - val_accuracy: 0.0000e+00\n",
            "Epoch 727/1000\n",
            "540/540 [==============================] - 0s 51us/sample - loss: 0.2477 - accuracy: 0.5556 - val_loss: 0.3182 - val_accuracy: 0.0000e+00\n",
            "Epoch 728/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2477 - accuracy: 0.5556 - val_loss: 0.3182 - val_accuracy: 0.0000e+00\n",
            "Epoch 729/1000\n",
            "540/540 [==============================] - 0s 51us/sample - loss: 0.2477 - accuracy: 0.5556 - val_loss: 0.3182 - val_accuracy: 0.0000e+00\n",
            "Epoch 730/1000\n",
            "540/540 [==============================] - 0s 54us/sample - loss: 0.2477 - accuracy: 0.5556 - val_loss: 0.3182 - val_accuracy: 0.0000e+00\n",
            "Epoch 731/1000\n",
            "540/540 [==============================] - 0s 52us/sample - loss: 0.2477 - accuracy: 0.5556 - val_loss: 0.3182 - val_accuracy: 0.0000e+00\n",
            "Epoch 732/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2477 - accuracy: 0.5556 - val_loss: 0.3182 - val_accuracy: 0.0000e+00\n",
            "Epoch 733/1000\n",
            "540/540 [==============================] - 0s 41us/sample - loss: 0.2477 - accuracy: 0.5556 - val_loss: 0.3182 - val_accuracy: 0.0000e+00\n",
            "Epoch 734/1000\n",
            "540/540 [==============================] - 0s 56us/sample - loss: 0.2477 - accuracy: 0.5556 - val_loss: 0.3182 - val_accuracy: 0.0000e+00\n",
            "Epoch 735/1000\n",
            "540/540 [==============================] - 0s 62us/sample - loss: 0.2477 - accuracy: 0.5556 - val_loss: 0.3182 - val_accuracy: 0.0000e+00\n",
            "Epoch 736/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2477 - accuracy: 0.5556 - val_loss: 0.3182 - val_accuracy: 0.0000e+00\n",
            "Epoch 737/1000\n",
            "540/540 [==============================] - 0s 51us/sample - loss: 0.2477 - accuracy: 0.5556 - val_loss: 0.3182 - val_accuracy: 0.0000e+00\n",
            "Epoch 738/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2477 - accuracy: 0.5556 - val_loss: 0.3182 - val_accuracy: 0.0000e+00\n",
            "Epoch 739/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2477 - accuracy: 0.5556 - val_loss: 0.3182 - val_accuracy: 0.0000e+00\n",
            "Epoch 740/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2477 - accuracy: 0.5556 - val_loss: 0.3182 - val_accuracy: 0.0000e+00\n",
            "Epoch 741/1000\n",
            "540/540 [==============================] - 0s 56us/sample - loss: 0.2477 - accuracy: 0.5556 - val_loss: 0.3182 - val_accuracy: 0.0000e+00\n",
            "Epoch 742/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2477 - accuracy: 0.5556 - val_loss: 0.3182 - val_accuracy: 0.0000e+00\n",
            "Epoch 743/1000\n",
            "540/540 [==============================] - 0s 43us/sample - loss: 0.2477 - accuracy: 0.5556 - val_loss: 0.3182 - val_accuracy: 0.0000e+00\n",
            "Epoch 744/1000\n",
            "540/540 [==============================] - 0s 41us/sample - loss: 0.2477 - accuracy: 0.5556 - val_loss: 0.3182 - val_accuracy: 0.0000e+00\n",
            "Epoch 745/1000\n",
            "540/540 [==============================] - 0s 43us/sample - loss: 0.2477 - accuracy: 0.5556 - val_loss: 0.3182 - val_accuracy: 0.0000e+00\n",
            "Epoch 746/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2477 - accuracy: 0.5556 - val_loss: 0.3182 - val_accuracy: 0.0000e+00\n",
            "Epoch 747/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2477 - accuracy: 0.5556 - val_loss: 0.3181 - val_accuracy: 0.0000e+00\n",
            "Epoch 748/1000\n",
            "540/540 [==============================] - 0s 51us/sample - loss: 0.2477 - accuracy: 0.5556 - val_loss: 0.3181 - val_accuracy: 0.0000e+00\n",
            "Epoch 749/1000\n",
            "540/540 [==============================] - 0s 56us/sample - loss: 0.2477 - accuracy: 0.5556 - val_loss: 0.3181 - val_accuracy: 0.0000e+00\n",
            "Epoch 750/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2477 - accuracy: 0.5556 - val_loss: 0.3181 - val_accuracy: 0.0000e+00\n",
            "Epoch 751/1000\n",
            "540/540 [==============================] - 0s 53us/sample - loss: 0.2476 - accuracy: 0.5556 - val_loss: 0.3181 - val_accuracy: 0.0000e+00\n",
            "Epoch 752/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2476 - accuracy: 0.5556 - val_loss: 0.3181 - val_accuracy: 0.0000e+00\n",
            "Epoch 753/1000\n",
            "540/540 [==============================] - 0s 53us/sample - loss: 0.2476 - accuracy: 0.5556 - val_loss: 0.3181 - val_accuracy: 0.0000e+00\n",
            "Epoch 754/1000\n",
            "540/540 [==============================] - 0s 51us/sample - loss: 0.2476 - accuracy: 0.5556 - val_loss: 0.3181 - val_accuracy: 0.0000e+00\n",
            "Epoch 755/1000\n",
            "540/540 [==============================] - 0s 43us/sample - loss: 0.2476 - accuracy: 0.5556 - val_loss: 0.3181 - val_accuracy: 0.0000e+00\n",
            "Epoch 756/1000\n",
            "540/540 [==============================] - 0s 59us/sample - loss: 0.2476 - accuracy: 0.5556 - val_loss: 0.3181 - val_accuracy: 0.0000e+00\n",
            "Epoch 757/1000\n",
            "540/540 [==============================] - 0s 58us/sample - loss: 0.2476 - accuracy: 0.5556 - val_loss: 0.3181 - val_accuracy: 0.0000e+00\n",
            "Epoch 758/1000\n",
            "540/540 [==============================] - 0s 52us/sample - loss: 0.2476 - accuracy: 0.5556 - val_loss: 0.3181 - val_accuracy: 0.0000e+00\n",
            "Epoch 759/1000\n",
            "540/540 [==============================] - 0s 55us/sample - loss: 0.2476 - accuracy: 0.5556 - val_loss: 0.3181 - val_accuracy: 0.0000e+00\n",
            "Epoch 760/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2476 - accuracy: 0.5556 - val_loss: 0.3181 - val_accuracy: 0.0000e+00\n",
            "Epoch 761/1000\n",
            "540/540 [==============================] - 0s 55us/sample - loss: 0.2476 - accuracy: 0.5556 - val_loss: 0.3181 - val_accuracy: 0.0000e+00\n",
            "Epoch 762/1000\n",
            "540/540 [==============================] - 0s 52us/sample - loss: 0.2476 - accuracy: 0.5556 - val_loss: 0.3181 - val_accuracy: 0.0000e+00\n",
            "Epoch 763/1000\n",
            "540/540 [==============================] - 0s 43us/sample - loss: 0.2476 - accuracy: 0.5556 - val_loss: 0.3181 - val_accuracy: 0.0000e+00\n",
            "Epoch 764/1000\n",
            "540/540 [==============================] - 0s 54us/sample - loss: 0.2476 - accuracy: 0.5556 - val_loss: 0.3181 - val_accuracy: 0.0000e+00\n",
            "Epoch 765/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2476 - accuracy: 0.5556 - val_loss: 0.3181 - val_accuracy: 0.0000e+00\n",
            "Epoch 766/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2476 - accuracy: 0.5556 - val_loss: 0.3181 - val_accuracy: 0.0000e+00\n",
            "Epoch 767/1000\n",
            "540/540 [==============================] - 0s 53us/sample - loss: 0.2476 - accuracy: 0.5556 - val_loss: 0.3180 - val_accuracy: 0.0000e+00\n",
            "Epoch 768/1000\n",
            "540/540 [==============================] - 0s 60us/sample - loss: 0.2476 - accuracy: 0.5556 - val_loss: 0.3180 - val_accuracy: 0.0000e+00\n",
            "Epoch 769/1000\n",
            "540/540 [==============================] - 0s 51us/sample - loss: 0.2476 - accuracy: 0.5556 - val_loss: 0.3180 - val_accuracy: 0.0000e+00\n",
            "Epoch 770/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2476 - accuracy: 0.5556 - val_loss: 0.3180 - val_accuracy: 0.0000e+00\n",
            "Epoch 771/1000\n",
            "540/540 [==============================] - 0s 61us/sample - loss: 0.2476 - accuracy: 0.5556 - val_loss: 0.3180 - val_accuracy: 0.0000e+00\n",
            "Epoch 772/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2476 - accuracy: 0.5556 - val_loss: 0.3180 - val_accuracy: 0.0000e+00\n",
            "Epoch 773/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2476 - accuracy: 0.5556 - val_loss: 0.3180 - val_accuracy: 0.0000e+00\n",
            "Epoch 774/1000\n",
            "540/540 [==============================] - 0s 57us/sample - loss: 0.2476 - accuracy: 0.5556 - val_loss: 0.3180 - val_accuracy: 0.0000e+00\n",
            "Epoch 775/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2476 - accuracy: 0.5556 - val_loss: 0.3180 - val_accuracy: 0.0000e+00\n",
            "Epoch 776/1000\n",
            "540/540 [==============================] - 0s 59us/sample - loss: 0.2476 - accuracy: 0.5556 - val_loss: 0.3180 - val_accuracy: 0.0000e+00\n",
            "Epoch 777/1000\n",
            "540/540 [==============================] - 0s 51us/sample - loss: 0.2476 - accuracy: 0.5556 - val_loss: 0.3180 - val_accuracy: 0.0000e+00\n",
            "Epoch 778/1000\n",
            "540/540 [==============================] - 0s 54us/sample - loss: 0.2476 - accuracy: 0.5556 - val_loss: 0.3180 - val_accuracy: 0.0000e+00\n",
            "Epoch 779/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2476 - accuracy: 0.5556 - val_loss: 0.3180 - val_accuracy: 0.0000e+00\n",
            "Epoch 780/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2476 - accuracy: 0.5556 - val_loss: 0.3180 - val_accuracy: 0.0000e+00\n",
            "Epoch 781/1000\n",
            "540/540 [==============================] - 0s 56us/sample - loss: 0.2476 - accuracy: 0.5556 - val_loss: 0.3180 - val_accuracy: 0.0000e+00\n",
            "Epoch 782/1000\n",
            "540/540 [==============================] - 0s 52us/sample - loss: 0.2476 - accuracy: 0.5556 - val_loss: 0.3180 - val_accuracy: 0.0000e+00\n",
            "Epoch 783/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2476 - accuracy: 0.5556 - val_loss: 0.3180 - val_accuracy: 0.0000e+00\n",
            "Epoch 784/1000\n",
            "540/540 [==============================] - 0s 43us/sample - loss: 0.2476 - accuracy: 0.5556 - val_loss: 0.3180 - val_accuracy: 0.0000e+00\n",
            "Epoch 785/1000\n",
            "540/540 [==============================] - 0s 43us/sample - loss: 0.2476 - accuracy: 0.5556 - val_loss: 0.3180 - val_accuracy: 0.0000e+00\n",
            "Epoch 786/1000\n",
            "540/540 [==============================] - 0s 55us/sample - loss: 0.2476 - accuracy: 0.5556 - val_loss: 0.3180 - val_accuracy: 0.0000e+00\n",
            "Epoch 787/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2476 - accuracy: 0.5556 - val_loss: 0.3179 - val_accuracy: 0.0000e+00\n",
            "Epoch 788/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2476 - accuracy: 0.5556 - val_loss: 0.3179 - val_accuracy: 0.0000e+00\n",
            "Epoch 789/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2476 - accuracy: 0.5556 - val_loss: 0.3179 - val_accuracy: 0.0000e+00\n",
            "Epoch 790/1000\n",
            "540/540 [==============================] - 0s 66us/sample - loss: 0.2476 - accuracy: 0.5556 - val_loss: 0.3179 - val_accuracy: 0.0000e+00\n",
            "Epoch 791/1000\n",
            "540/540 [==============================] - 0s 52us/sample - loss: 0.2476 - accuracy: 0.5556 - val_loss: 0.3179 - val_accuracy: 0.0000e+00\n",
            "Epoch 792/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2476 - accuracy: 0.5556 - val_loss: 0.3179 - val_accuracy: 0.0000e+00\n",
            "Epoch 793/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2476 - accuracy: 0.5556 - val_loss: 0.3179 - val_accuracy: 0.0000e+00\n",
            "Epoch 794/1000\n",
            "540/540 [==============================] - 0s 57us/sample - loss: 0.2476 - accuracy: 0.5556 - val_loss: 0.3179 - val_accuracy: 0.0000e+00\n",
            "Epoch 795/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2475 - accuracy: 0.5556 - val_loss: 0.3179 - val_accuracy: 0.0000e+00\n",
            "Epoch 796/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2475 - accuracy: 0.5556 - val_loss: 0.3179 - val_accuracy: 0.0000e+00\n",
            "Epoch 797/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2475 - accuracy: 0.5556 - val_loss: 0.3179 - val_accuracy: 0.0000e+00\n",
            "Epoch 798/1000\n",
            "540/540 [==============================] - 0s 51us/sample - loss: 0.2475 - accuracy: 0.5556 - val_loss: 0.3179 - val_accuracy: 0.0000e+00\n",
            "Epoch 799/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2475 - accuracy: 0.5556 - val_loss: 0.3179 - val_accuracy: 0.0000e+00\n",
            "Epoch 800/1000\n",
            "540/540 [==============================] - 0s 52us/sample - loss: 0.2475 - accuracy: 0.5556 - val_loss: 0.3179 - val_accuracy: 0.0000e+00\n",
            "Epoch 801/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2475 - accuracy: 0.5556 - val_loss: 0.3179 - val_accuracy: 0.0000e+00\n",
            "Epoch 802/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2475 - accuracy: 0.5556 - val_loss: 0.3179 - val_accuracy: 0.0000e+00\n",
            "Epoch 803/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2475 - accuracy: 0.5556 - val_loss: 0.3179 - val_accuracy: 0.0000e+00\n",
            "Epoch 804/1000\n",
            "540/540 [==============================] - 0s 43us/sample - loss: 0.2475 - accuracy: 0.5556 - val_loss: 0.3179 - val_accuracy: 0.0000e+00\n",
            "Epoch 805/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2475 - accuracy: 0.5556 - val_loss: 0.3179 - val_accuracy: 0.0000e+00\n",
            "Epoch 806/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2475 - accuracy: 0.5556 - val_loss: 0.3178 - val_accuracy: 0.0000e+00\n",
            "Epoch 807/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2475 - accuracy: 0.5556 - val_loss: 0.3178 - val_accuracy: 0.0000e+00\n",
            "Epoch 808/1000\n",
            "540/540 [==============================] - 0s 43us/sample - loss: 0.2475 - accuracy: 0.5556 - val_loss: 0.3178 - val_accuracy: 0.0000e+00\n",
            "Epoch 809/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2475 - accuracy: 0.5556 - val_loss: 0.3178 - val_accuracy: 0.0000e+00\n",
            "Epoch 810/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2475 - accuracy: 0.5556 - val_loss: 0.3178 - val_accuracy: 0.0000e+00\n",
            "Epoch 811/1000\n",
            "540/540 [==============================] - 0s 42us/sample - loss: 0.2475 - accuracy: 0.5556 - val_loss: 0.3178 - val_accuracy: 0.0000e+00\n",
            "Epoch 812/1000\n",
            "540/540 [==============================] - 0s 52us/sample - loss: 0.2475 - accuracy: 0.5556 - val_loss: 0.3178 - val_accuracy: 0.0000e+00\n",
            "Epoch 813/1000\n",
            "540/540 [==============================] - 0s 57us/sample - loss: 0.2475 - accuracy: 0.5556 - val_loss: 0.3178 - val_accuracy: 0.0000e+00\n",
            "Epoch 814/1000\n",
            "540/540 [==============================] - 0s 43us/sample - loss: 0.2475 - accuracy: 0.5556 - val_loss: 0.3178 - val_accuracy: 0.0000e+00\n",
            "Epoch 815/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2475 - accuracy: 0.5556 - val_loss: 0.3178 - val_accuracy: 0.0000e+00\n",
            "Epoch 816/1000\n",
            "540/540 [==============================] - 0s 51us/sample - loss: 0.2475 - accuracy: 0.5556 - val_loss: 0.3178 - val_accuracy: 0.0000e+00\n",
            "Epoch 817/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2475 - accuracy: 0.5556 - val_loss: 0.3178 - val_accuracy: 0.0000e+00\n",
            "Epoch 818/1000\n",
            "540/540 [==============================] - 0s 53us/sample - loss: 0.2475 - accuracy: 0.5556 - val_loss: 0.3178 - val_accuracy: 0.0000e+00\n",
            "Epoch 819/1000\n",
            "540/540 [==============================] - 0s 57us/sample - loss: 0.2475 - accuracy: 0.5556 - val_loss: 0.3178 - val_accuracy: 0.0000e+00\n",
            "Epoch 820/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2475 - accuracy: 0.5556 - val_loss: 0.3178 - val_accuracy: 0.0000e+00\n",
            "Epoch 821/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2475 - accuracy: 0.5556 - val_loss: 0.3178 - val_accuracy: 0.0000e+00\n",
            "Epoch 822/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2475 - accuracy: 0.5556 - val_loss: 0.3178 - val_accuracy: 0.0000e+00\n",
            "Epoch 823/1000\n",
            "540/540 [==============================] - 0s 52us/sample - loss: 0.2475 - accuracy: 0.5556 - val_loss: 0.3178 - val_accuracy: 0.0000e+00\n",
            "Epoch 824/1000\n",
            "540/540 [==============================] - 0s 59us/sample - loss: 0.2475 - accuracy: 0.5556 - val_loss: 0.3178 - val_accuracy: 0.0000e+00\n",
            "Epoch 825/1000\n",
            "540/540 [==============================] - 0s 53us/sample - loss: 0.2475 - accuracy: 0.5556 - val_loss: 0.3177 - val_accuracy: 0.0000e+00\n",
            "Epoch 826/1000\n",
            "540/540 [==============================] - 0s 52us/sample - loss: 0.2475 - accuracy: 0.5556 - val_loss: 0.3177 - val_accuracy: 0.0000e+00\n",
            "Epoch 827/1000\n",
            "540/540 [==============================] - 0s 75us/sample - loss: 0.2475 - accuracy: 0.5556 - val_loss: 0.3177 - val_accuracy: 0.0000e+00\n",
            "Epoch 828/1000\n",
            "540/540 [==============================] - 0s 54us/sample - loss: 0.2475 - accuracy: 0.5556 - val_loss: 0.3177 - val_accuracy: 0.0000e+00\n",
            "Epoch 829/1000\n",
            "540/540 [==============================] - 0s 43us/sample - loss: 0.2475 - accuracy: 0.5556 - val_loss: 0.3177 - val_accuracy: 0.0000e+00\n",
            "Epoch 830/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2475 - accuracy: 0.5556 - val_loss: 0.3177 - val_accuracy: 0.0000e+00\n",
            "Epoch 831/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2475 - accuracy: 0.5556 - val_loss: 0.3177 - val_accuracy: 0.0000e+00\n",
            "Epoch 832/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2475 - accuracy: 0.5556 - val_loss: 0.3177 - val_accuracy: 0.0000e+00\n",
            "Epoch 833/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2475 - accuracy: 0.5556 - val_loss: 0.3177 - val_accuracy: 0.0000e+00\n",
            "Epoch 834/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2475 - accuracy: 0.5556 - val_loss: 0.3177 - val_accuracy: 0.0000e+00\n",
            "Epoch 835/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2475 - accuracy: 0.5556 - val_loss: 0.3177 - val_accuracy: 0.0000e+00\n",
            "Epoch 836/1000\n",
            "540/540 [==============================] - 0s 70us/sample - loss: 0.2475 - accuracy: 0.5556 - val_loss: 0.3177 - val_accuracy: 0.0000e+00\n",
            "Epoch 837/1000\n",
            "540/540 [==============================] - 0s 57us/sample - loss: 0.2474 - accuracy: 0.5556 - val_loss: 0.3177 - val_accuracy: 0.0000e+00\n",
            "Epoch 838/1000\n",
            "540/540 [==============================] - 0s 52us/sample - loss: 0.2474 - accuracy: 0.5556 - val_loss: 0.3177 - val_accuracy: 0.0000e+00\n",
            "Epoch 839/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2474 - accuracy: 0.5556 - val_loss: 0.3177 - val_accuracy: 0.0000e+00\n",
            "Epoch 840/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2474 - accuracy: 0.5556 - val_loss: 0.3177 - val_accuracy: 0.0000e+00\n",
            "Epoch 841/1000\n",
            "540/540 [==============================] - 0s 53us/sample - loss: 0.2474 - accuracy: 0.5556 - val_loss: 0.3177 - val_accuracy: 0.0000e+00\n",
            "Epoch 842/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2474 - accuracy: 0.5556 - val_loss: 0.3177 - val_accuracy: 0.0000e+00\n",
            "Epoch 843/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2474 - accuracy: 0.5556 - val_loss: 0.3177 - val_accuracy: 0.0000e+00\n",
            "Epoch 844/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2474 - accuracy: 0.5556 - val_loss: 0.3176 - val_accuracy: 0.0000e+00\n",
            "Epoch 845/1000\n",
            "540/540 [==============================] - 0s 54us/sample - loss: 0.2474 - accuracy: 0.5556 - val_loss: 0.3176 - val_accuracy: 0.0000e+00\n",
            "Epoch 846/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2474 - accuracy: 0.5556 - val_loss: 0.3176 - val_accuracy: 0.0000e+00\n",
            "Epoch 847/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2474 - accuracy: 0.5556 - val_loss: 0.3176 - val_accuracy: 0.0000e+00\n",
            "Epoch 848/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2474 - accuracy: 0.5556 - val_loss: 0.3176 - val_accuracy: 0.0000e+00\n",
            "Epoch 849/1000\n",
            "540/540 [==============================] - 0s 58us/sample - loss: 0.2474 - accuracy: 0.5556 - val_loss: 0.3176 - val_accuracy: 0.0000e+00\n",
            "Epoch 850/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2474 - accuracy: 0.5556 - val_loss: 0.3176 - val_accuracy: 0.0000e+00\n",
            "Epoch 851/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2474 - accuracy: 0.5556 - val_loss: 0.3176 - val_accuracy: 0.0000e+00\n",
            "Epoch 852/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2474 - accuracy: 0.5556 - val_loss: 0.3176 - val_accuracy: 0.0000e+00\n",
            "Epoch 853/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2474 - accuracy: 0.5556 - val_loss: 0.3176 - val_accuracy: 0.0000e+00\n",
            "Epoch 854/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2474 - accuracy: 0.5556 - val_loss: 0.3176 - val_accuracy: 0.0000e+00\n",
            "Epoch 855/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2474 - accuracy: 0.5556 - val_loss: 0.3176 - val_accuracy: 0.0000e+00\n",
            "Epoch 856/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2474 - accuracy: 0.5556 - val_loss: 0.3176 - val_accuracy: 0.0000e+00\n",
            "Epoch 857/1000\n",
            "540/540 [==============================] - 0s 42us/sample - loss: 0.2474 - accuracy: 0.5556 - val_loss: 0.3176 - val_accuracy: 0.0000e+00\n",
            "Epoch 858/1000\n",
            "540/540 [==============================] - 0s 42us/sample - loss: 0.2474 - accuracy: 0.5556 - val_loss: 0.3176 - val_accuracy: 0.0000e+00\n",
            "Epoch 859/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2474 - accuracy: 0.5556 - val_loss: 0.3176 - val_accuracy: 0.0000e+00\n",
            "Epoch 860/1000\n",
            "540/540 [==============================] - 0s 42us/sample - loss: 0.2474 - accuracy: 0.5556 - val_loss: 0.3176 - val_accuracy: 0.0000e+00\n",
            "Epoch 861/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2474 - accuracy: 0.5556 - val_loss: 0.3176 - val_accuracy: 0.0000e+00\n",
            "Epoch 862/1000\n",
            "540/540 [==============================] - 0s 53us/sample - loss: 0.2474 - accuracy: 0.5556 - val_loss: 0.3176 - val_accuracy: 0.0000e+00\n",
            "Epoch 863/1000\n",
            "540/540 [==============================] - 0s 62us/sample - loss: 0.2474 - accuracy: 0.5556 - val_loss: 0.3176 - val_accuracy: 0.0000e+00\n",
            "Epoch 864/1000\n",
            "540/540 [==============================] - 0s 53us/sample - loss: 0.2474 - accuracy: 0.5556 - val_loss: 0.3175 - val_accuracy: 0.0000e+00\n",
            "Epoch 865/1000\n",
            "540/540 [==============================] - 0s 51us/sample - loss: 0.2474 - accuracy: 0.5556 - val_loss: 0.3175 - val_accuracy: 0.0000e+00\n",
            "Epoch 866/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2474 - accuracy: 0.5556 - val_loss: 0.3175 - val_accuracy: 0.0000e+00\n",
            "Epoch 867/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2474 - accuracy: 0.5556 - val_loss: 0.3175 - val_accuracy: 0.0000e+00\n",
            "Epoch 868/1000\n",
            "540/540 [==============================] - 0s 43us/sample - loss: 0.2474 - accuracy: 0.5556 - val_loss: 0.3175 - val_accuracy: 0.0000e+00\n",
            "Epoch 869/1000\n",
            "540/540 [==============================] - 0s 43us/sample - loss: 0.2474 - accuracy: 0.5556 - val_loss: 0.3175 - val_accuracy: 0.0000e+00\n",
            "Epoch 870/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2474 - accuracy: 0.5556 - val_loss: 0.3175 - val_accuracy: 0.0000e+00\n",
            "Epoch 871/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2474 - accuracy: 0.5556 - val_loss: 0.3175 - val_accuracy: 0.0000e+00\n",
            "Epoch 872/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2474 - accuracy: 0.5556 - val_loss: 0.3175 - val_accuracy: 0.0000e+00\n",
            "Epoch 873/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2474 - accuracy: 0.5556 - val_loss: 0.3175 - val_accuracy: 0.0000e+00\n",
            "Epoch 874/1000\n",
            "540/540 [==============================] - 0s 42us/sample - loss: 0.2474 - accuracy: 0.5556 - val_loss: 0.3175 - val_accuracy: 0.0000e+00\n",
            "Epoch 875/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2474 - accuracy: 0.5556 - val_loss: 0.3175 - val_accuracy: 0.0000e+00\n",
            "Epoch 876/1000\n",
            "540/540 [==============================] - 0s 43us/sample - loss: 0.2474 - accuracy: 0.5556 - val_loss: 0.3175 - val_accuracy: 0.0000e+00\n",
            "Epoch 877/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2474 - accuracy: 0.5556 - val_loss: 0.3175 - val_accuracy: 0.0000e+00\n",
            "Epoch 878/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2474 - accuracy: 0.5556 - val_loss: 0.3175 - val_accuracy: 0.0000e+00\n",
            "Epoch 879/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2474 - accuracy: 0.5556 - val_loss: 0.3175 - val_accuracy: 0.0000e+00\n",
            "Epoch 880/1000\n",
            "540/540 [==============================] - 0s 43us/sample - loss: 0.2474 - accuracy: 0.5556 - val_loss: 0.3175 - val_accuracy: 0.0000e+00\n",
            "Epoch 881/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2474 - accuracy: 0.5556 - val_loss: 0.3175 - val_accuracy: 0.0000e+00\n",
            "Epoch 882/1000\n",
            "540/540 [==============================] - 0s 55us/sample - loss: 0.2473 - accuracy: 0.5556 - val_loss: 0.3174 - val_accuracy: 0.0000e+00\n",
            "Epoch 883/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2474 - accuracy: 0.5556 - val_loss: 0.3174 - val_accuracy: 0.0000e+00\n",
            "Epoch 884/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2473 - accuracy: 0.5556 - val_loss: 0.3174 - val_accuracy: 0.0000e+00\n",
            "Epoch 885/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2473 - accuracy: 0.5556 - val_loss: 0.3174 - val_accuracy: 0.0000e+00\n",
            "Epoch 886/1000\n",
            "540/540 [==============================] - 0s 42us/sample - loss: 0.2473 - accuracy: 0.5556 - val_loss: 0.3174 - val_accuracy: 0.0000e+00\n",
            "Epoch 887/1000\n",
            "540/540 [==============================] - 0s 43us/sample - loss: 0.2473 - accuracy: 0.5556 - val_loss: 0.3174 - val_accuracy: 0.0000e+00\n",
            "Epoch 888/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2473 - accuracy: 0.5556 - val_loss: 0.3174 - val_accuracy: 0.0000e+00\n",
            "Epoch 889/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2473 - accuracy: 0.5556 - val_loss: 0.3174 - val_accuracy: 0.0000e+00\n",
            "Epoch 890/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2473 - accuracy: 0.5556 - val_loss: 0.3174 - val_accuracy: 0.0000e+00\n",
            "Epoch 891/1000\n",
            "540/540 [==============================] - 0s 52us/sample - loss: 0.2473 - accuracy: 0.5556 - val_loss: 0.3174 - val_accuracy: 0.0000e+00\n",
            "Epoch 892/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2473 - accuracy: 0.5556 - val_loss: 0.3174 - val_accuracy: 0.0000e+00\n",
            "Epoch 893/1000\n",
            "540/540 [==============================] - 0s 41us/sample - loss: 0.2473 - accuracy: 0.5556 - val_loss: 0.3174 - val_accuracy: 0.0000e+00\n",
            "Epoch 894/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2473 - accuracy: 0.5556 - val_loss: 0.3174 - val_accuracy: 0.0000e+00\n",
            "Epoch 895/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2473 - accuracy: 0.5556 - val_loss: 0.3174 - val_accuracy: 0.0000e+00\n",
            "Epoch 896/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2473 - accuracy: 0.5556 - val_loss: 0.3174 - val_accuracy: 0.0000e+00\n",
            "Epoch 897/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2473 - accuracy: 0.5556 - val_loss: 0.3174 - val_accuracy: 0.0000e+00\n",
            "Epoch 898/1000\n",
            "540/540 [==============================] - 0s 43us/sample - loss: 0.2473 - accuracy: 0.5556 - val_loss: 0.3174 - val_accuracy: 0.0000e+00\n",
            "Epoch 899/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2473 - accuracy: 0.5556 - val_loss: 0.3174 - val_accuracy: 0.0000e+00\n",
            "Epoch 900/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2473 - accuracy: 0.5556 - val_loss: 0.3174 - val_accuracy: 0.0000e+00\n",
            "Epoch 901/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2473 - accuracy: 0.5556 - val_loss: 0.3173 - val_accuracy: 0.0000e+00\n",
            "Epoch 902/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2473 - accuracy: 0.5556 - val_loss: 0.3173 - val_accuracy: 0.0000e+00\n",
            "Epoch 903/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2473 - accuracy: 0.5556 - val_loss: 0.3173 - val_accuracy: 0.0000e+00\n",
            "Epoch 904/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2473 - accuracy: 0.5556 - val_loss: 0.3173 - val_accuracy: 0.0000e+00\n",
            "Epoch 905/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2473 - accuracy: 0.5556 - val_loss: 0.3173 - val_accuracy: 0.0000e+00\n",
            "Epoch 906/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2473 - accuracy: 0.5556 - val_loss: 0.3173 - val_accuracy: 0.0000e+00\n",
            "Epoch 907/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2473 - accuracy: 0.5556 - val_loss: 0.3173 - val_accuracy: 0.0000e+00\n",
            "Epoch 908/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2473 - accuracy: 0.5556 - val_loss: 0.3173 - val_accuracy: 0.0000e+00\n",
            "Epoch 909/1000\n",
            "540/540 [==============================] - 0s 51us/sample - loss: 0.2473 - accuracy: 0.5556 - val_loss: 0.3173 - val_accuracy: 0.0000e+00\n",
            "Epoch 910/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2473 - accuracy: 0.5556 - val_loss: 0.3173 - val_accuracy: 0.0000e+00\n",
            "Epoch 911/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2473 - accuracy: 0.5556 - val_loss: 0.3173 - val_accuracy: 0.0000e+00\n",
            "Epoch 912/1000\n",
            "540/540 [==============================] - 0s 42us/sample - loss: 0.2473 - accuracy: 0.5556 - val_loss: 0.3173 - val_accuracy: 0.0000e+00\n",
            "Epoch 913/1000\n",
            "540/540 [==============================] - 0s 43us/sample - loss: 0.2473 - accuracy: 0.5556 - val_loss: 0.3173 - val_accuracy: 0.0000e+00\n",
            "Epoch 914/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2473 - accuracy: 0.5556 - val_loss: 0.3173 - val_accuracy: 0.0000e+00\n",
            "Epoch 915/1000\n",
            "540/540 [==============================] - 0s 43us/sample - loss: 0.2473 - accuracy: 0.5556 - val_loss: 0.3173 - val_accuracy: 0.0000e+00\n",
            "Epoch 916/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2473 - accuracy: 0.5556 - val_loss: 0.3173 - val_accuracy: 0.0000e+00\n",
            "Epoch 917/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2473 - accuracy: 0.5556 - val_loss: 0.3173 - val_accuracy: 0.0000e+00\n",
            "Epoch 918/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2473 - accuracy: 0.5556 - val_loss: 0.3173 - val_accuracy: 0.0000e+00\n",
            "Epoch 919/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2473 - accuracy: 0.5556 - val_loss: 0.3173 - val_accuracy: 0.0000e+00\n",
            "Epoch 920/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2473 - accuracy: 0.5556 - val_loss: 0.3172 - val_accuracy: 0.0000e+00\n",
            "Epoch 921/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2473 - accuracy: 0.5556 - val_loss: 0.3172 - val_accuracy: 0.0000e+00\n",
            "Epoch 922/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2473 - accuracy: 0.5556 - val_loss: 0.3172 - val_accuracy: 0.0000e+00\n",
            "Epoch 923/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2473 - accuracy: 0.5556 - val_loss: 0.3172 - val_accuracy: 0.0000e+00\n",
            "Epoch 924/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2473 - accuracy: 0.5556 - val_loss: 0.3172 - val_accuracy: 0.0000e+00\n",
            "Epoch 925/1000\n",
            "540/540 [==============================] - 0s 43us/sample - loss: 0.2473 - accuracy: 0.5556 - val_loss: 0.3172 - val_accuracy: 0.0000e+00\n",
            "Epoch 926/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2473 - accuracy: 0.5556 - val_loss: 0.3172 - val_accuracy: 0.0000e+00\n",
            "Epoch 927/1000\n",
            "540/540 [==============================] - 0s 43us/sample - loss: 0.2473 - accuracy: 0.5556 - val_loss: 0.3172 - val_accuracy: 0.0000e+00\n",
            "Epoch 928/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2472 - accuracy: 0.5556 - val_loss: 0.3172 - val_accuracy: 0.0000e+00\n",
            "Epoch 929/1000\n",
            "540/540 [==============================] - 0s 51us/sample - loss: 0.2472 - accuracy: 0.5556 - val_loss: 0.3172 - val_accuracy: 0.0000e+00\n",
            "Epoch 930/1000\n",
            "540/540 [==============================] - 0s 43us/sample - loss: 0.2472 - accuracy: 0.5556 - val_loss: 0.3172 - val_accuracy: 0.0000e+00\n",
            "Epoch 931/1000\n",
            "540/540 [==============================] - 0s 42us/sample - loss: 0.2472 - accuracy: 0.5556 - val_loss: 0.3172 - val_accuracy: 0.0000e+00\n",
            "Epoch 932/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2472 - accuracy: 0.5556 - val_loss: 0.3172 - val_accuracy: 0.0000e+00\n",
            "Epoch 933/1000\n",
            "540/540 [==============================] - 0s 42us/sample - loss: 0.2472 - accuracy: 0.5556 - val_loss: 0.3172 - val_accuracy: 0.0000e+00\n",
            "Epoch 934/1000\n",
            "540/540 [==============================] - 0s 54us/sample - loss: 0.2472 - accuracy: 0.5556 - val_loss: 0.3172 - val_accuracy: 0.0000e+00\n",
            "Epoch 935/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2472 - accuracy: 0.5556 - val_loss: 0.3172 - val_accuracy: 0.0000e+00\n",
            "Epoch 936/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2472 - accuracy: 0.5556 - val_loss: 0.3172 - val_accuracy: 0.0000e+00\n",
            "Epoch 937/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2472 - accuracy: 0.5556 - val_loss: 0.3172 - val_accuracy: 0.0000e+00\n",
            "Epoch 938/1000\n",
            "540/540 [==============================] - 0s 41us/sample - loss: 0.2472 - accuracy: 0.5556 - val_loss: 0.3172 - val_accuracy: 0.0000e+00\n",
            "Epoch 939/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2472 - accuracy: 0.5556 - val_loss: 0.3171 - val_accuracy: 0.0000e+00\n",
            "Epoch 940/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2472 - accuracy: 0.5556 - val_loss: 0.3171 - val_accuracy: 0.0000e+00\n",
            "Epoch 941/1000\n",
            "540/540 [==============================] - 0s 52us/sample - loss: 0.2472 - accuracy: 0.5556 - val_loss: 0.3171 - val_accuracy: 0.0000e+00\n",
            "Epoch 942/1000\n",
            "540/540 [==============================] - 0s 56us/sample - loss: 0.2472 - accuracy: 0.5556 - val_loss: 0.3171 - val_accuracy: 0.0000e+00\n",
            "Epoch 943/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2472 - accuracy: 0.5556 - val_loss: 0.3171 - val_accuracy: 0.0000e+00\n",
            "Epoch 944/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2472 - accuracy: 0.5556 - val_loss: 0.3171 - val_accuracy: 0.0000e+00\n",
            "Epoch 945/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2472 - accuracy: 0.5556 - val_loss: 0.3171 - val_accuracy: 0.0000e+00\n",
            "Epoch 946/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2472 - accuracy: 0.5556 - val_loss: 0.3171 - val_accuracy: 0.0000e+00\n",
            "Epoch 947/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2472 - accuracy: 0.5556 - val_loss: 0.3171 - val_accuracy: 0.0000e+00\n",
            "Epoch 948/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2472 - accuracy: 0.5556 - val_loss: 0.3171 - val_accuracy: 0.0000e+00\n",
            "Epoch 949/1000\n",
            "540/540 [==============================] - 0s 56us/sample - loss: 0.2472 - accuracy: 0.5556 - val_loss: 0.3171 - val_accuracy: 0.0000e+00\n",
            "Epoch 950/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2472 - accuracy: 0.5556 - val_loss: 0.3171 - val_accuracy: 0.0000e+00\n",
            "Epoch 951/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2472 - accuracy: 0.5556 - val_loss: 0.3171 - val_accuracy: 0.0000e+00\n",
            "Epoch 952/1000\n",
            "540/540 [==============================] - 0s 43us/sample - loss: 0.2472 - accuracy: 0.5556 - val_loss: 0.3171 - val_accuracy: 0.0000e+00\n",
            "Epoch 953/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2472 - accuracy: 0.5556 - val_loss: 0.3171 - val_accuracy: 0.0000e+00\n",
            "Epoch 954/1000\n",
            "540/540 [==============================] - 0s 43us/sample - loss: 0.2472 - accuracy: 0.5556 - val_loss: 0.3171 - val_accuracy: 0.0000e+00\n",
            "Epoch 955/1000\n",
            "540/540 [==============================] - 0s 41us/sample - loss: 0.2472 - accuracy: 0.5556 - val_loss: 0.3171 - val_accuracy: 0.0000e+00\n",
            "Epoch 956/1000\n",
            "540/540 [==============================] - 0s 40us/sample - loss: 0.2472 - accuracy: 0.5556 - val_loss: 0.3171 - val_accuracy: 0.0000e+00\n",
            "Epoch 957/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2472 - accuracy: 0.5556 - val_loss: 0.3171 - val_accuracy: 0.0000e+00\n",
            "Epoch 958/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2472 - accuracy: 0.5556 - val_loss: 0.3170 - val_accuracy: 0.0000e+00\n",
            "Epoch 959/1000\n",
            "540/540 [==============================] - 0s 49us/sample - loss: 0.2472 - accuracy: 0.5556 - val_loss: 0.3170 - val_accuracy: 0.0000e+00\n",
            "Epoch 960/1000\n",
            "540/540 [==============================] - 0s 55us/sample - loss: 0.2472 - accuracy: 0.5556 - val_loss: 0.3170 - val_accuracy: 0.0000e+00\n",
            "Epoch 961/1000\n",
            "540/540 [==============================] - 0s 55us/sample - loss: 0.2472 - accuracy: 0.5556 - val_loss: 0.3170 - val_accuracy: 0.0000e+00\n",
            "Epoch 962/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2472 - accuracy: 0.5556 - val_loss: 0.3170 - val_accuracy: 0.0000e+00\n",
            "Epoch 963/1000\n",
            "540/540 [==============================] - 0s 51us/sample - loss: 0.2472 - accuracy: 0.5556 - val_loss: 0.3170 - val_accuracy: 0.0000e+00\n",
            "Epoch 964/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2472 - accuracy: 0.5556 - val_loss: 0.3170 - val_accuracy: 0.0000e+00\n",
            "Epoch 965/1000\n",
            "540/540 [==============================] - 0s 52us/sample - loss: 0.2472 - accuracy: 0.5556 - val_loss: 0.3170 - val_accuracy: 0.0000e+00\n",
            "Epoch 966/1000\n",
            "540/540 [==============================] - 0s 56us/sample - loss: 0.2472 - accuracy: 0.5556 - val_loss: 0.3170 - val_accuracy: 0.0000e+00\n",
            "Epoch 967/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2472 - accuracy: 0.5556 - val_loss: 0.3170 - val_accuracy: 0.0000e+00\n",
            "Epoch 968/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2472 - accuracy: 0.5556 - val_loss: 0.3170 - val_accuracy: 0.0000e+00\n",
            "Epoch 969/1000\n",
            "540/540 [==============================] - 0s 52us/sample - loss: 0.2472 - accuracy: 0.5556 - val_loss: 0.3170 - val_accuracy: 0.0000e+00\n",
            "Epoch 970/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2472 - accuracy: 0.5556 - val_loss: 0.3170 - val_accuracy: 0.0000e+00\n",
            "Epoch 971/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2472 - accuracy: 0.5556 - val_loss: 0.3170 - val_accuracy: 0.0000e+00\n",
            "Epoch 972/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2471 - accuracy: 0.5556 - val_loss: 0.3170 - val_accuracy: 0.0000e+00\n",
            "Epoch 973/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2471 - accuracy: 0.5556 - val_loss: 0.3170 - val_accuracy: 0.0000e+00\n",
            "Epoch 974/1000\n",
            "540/540 [==============================] - 0s 53us/sample - loss: 0.2471 - accuracy: 0.5556 - val_loss: 0.3170 - val_accuracy: 0.0000e+00\n",
            "Epoch 975/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2471 - accuracy: 0.5556 - val_loss: 0.3170 - val_accuracy: 0.0000e+00\n",
            "Epoch 976/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2471 - accuracy: 0.5556 - val_loss: 0.3170 - val_accuracy: 0.0000e+00\n",
            "Epoch 977/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2471 - accuracy: 0.5556 - val_loss: 0.3169 - val_accuracy: 0.0000e+00\n",
            "Epoch 978/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2471 - accuracy: 0.5556 - val_loss: 0.3169 - val_accuracy: 0.0000e+00\n",
            "Epoch 979/1000\n",
            "540/540 [==============================] - 0s 61us/sample - loss: 0.2471 - accuracy: 0.5556 - val_loss: 0.3169 - val_accuracy: 0.0000e+00\n",
            "Epoch 980/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2471 - accuracy: 0.5556 - val_loss: 0.3169 - val_accuracy: 0.0000e+00\n",
            "Epoch 981/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2471 - accuracy: 0.5556 - val_loss: 0.3169 - val_accuracy: 0.0000e+00\n",
            "Epoch 982/1000\n",
            "540/540 [==============================] - 0s 53us/sample - loss: 0.2471 - accuracy: 0.5556 - val_loss: 0.3169 - val_accuracy: 0.0000e+00\n",
            "Epoch 983/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2471 - accuracy: 0.5556 - val_loss: 0.3169 - val_accuracy: 0.0000e+00\n",
            "Epoch 984/1000\n",
            "540/540 [==============================] - 0s 50us/sample - loss: 0.2471 - accuracy: 0.5556 - val_loss: 0.3169 - val_accuracy: 0.0000e+00\n",
            "Epoch 985/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2471 - accuracy: 0.5556 - val_loss: 0.3169 - val_accuracy: 0.0000e+00\n",
            "Epoch 986/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2471 - accuracy: 0.5556 - val_loss: 0.3169 - val_accuracy: 0.0000e+00\n",
            "Epoch 987/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2471 - accuracy: 0.5556 - val_loss: 0.3169 - val_accuracy: 0.0000e+00\n",
            "Epoch 988/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2471 - accuracy: 0.5556 - val_loss: 0.3169 - val_accuracy: 0.0000e+00\n",
            "Epoch 989/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2471 - accuracy: 0.5556 - val_loss: 0.3169 - val_accuracy: 0.0000e+00\n",
            "Epoch 990/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2471 - accuracy: 0.5556 - val_loss: 0.3169 - val_accuracy: 0.0000e+00\n",
            "Epoch 991/1000\n",
            "540/540 [==============================] - 0s 53us/sample - loss: 0.2471 - accuracy: 0.5556 - val_loss: 0.3169 - val_accuracy: 0.0000e+00\n",
            "Epoch 992/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2471 - accuracy: 0.5556 - val_loss: 0.3169 - val_accuracy: 0.0000e+00\n",
            "Epoch 993/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2471 - accuracy: 0.5556 - val_loss: 0.3169 - val_accuracy: 0.0000e+00\n",
            "Epoch 994/1000\n",
            "540/540 [==============================] - 0s 44us/sample - loss: 0.2471 - accuracy: 0.5556 - val_loss: 0.3169 - val_accuracy: 0.0000e+00\n",
            "Epoch 995/1000\n",
            "540/540 [==============================] - 0s 45us/sample - loss: 0.2471 - accuracy: 0.5556 - val_loss: 0.3169 - val_accuracy: 0.0000e+00\n",
            "Epoch 996/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2471 - accuracy: 0.5556 - val_loss: 0.3168 - val_accuracy: 0.0000e+00\n",
            "Epoch 997/1000\n",
            "540/540 [==============================] - 0s 46us/sample - loss: 0.2471 - accuracy: 0.5556 - val_loss: 0.3168 - val_accuracy: 0.0000e+00\n",
            "Epoch 998/1000\n",
            "540/540 [==============================] - 0s 48us/sample - loss: 0.2471 - accuracy: 0.5556 - val_loss: 0.3168 - val_accuracy: 0.0000e+00\n",
            "Epoch 999/1000\n",
            "540/540 [==============================] - 0s 54us/sample - loss: 0.2471 - accuracy: 0.5556 - val_loss: 0.3168 - val_accuracy: 0.0000e+00\n",
            "Epoch 1000/1000\n",
            "540/540 [==============================] - 0s 47us/sample - loss: 0.2471 - accuracy: 0.5556 - val_loss: 0.3168 - val_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3e90053be0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhT6WtB3TBTp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "outputId": "91c69758-3fd5-454a-afe5-5704d1f95547"
      },
      "source": [
        "y_pred = mlp.predict(X)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
        "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n",
        "                     np.arange(y_min, y_max, 0.02))\n",
        "Z = None\n",
        "Z = mlp.predict(np.c_[xx.ravel(), yy.ravel()])[:,1]\n",
        "Z = Z.reshape(xx.shape)\n",
        "cm = plt.cm.bwr\n",
        "\n",
        "fig = plt.figure(figsize=(6,6))\n",
        "\n",
        "plt.contourf(xx, yy, Z, cmap=cm, alpha=.25)\n",
        "\n",
        "plt.plot(X[1,0],X[1,1],'+', color='#648fff', label='Positive Class')\n",
        "plt.plot(X[2,1],X[2,1],'_', color='#fe6100', label='Negative Class')\n",
        "\n",
        "for i in range(len(y)):\n",
        "  x1 = X[i,0]\n",
        "  x2 = X[i,1]\n",
        "  if y[i]==1: \n",
        "    if (y_pred[i] == 0):\n",
        "      plt.plot(x1,x2,'+', color='#648fff')\n",
        "    else:\n",
        "      plt.plot(x1,x2,'k.', alpha=0.25)\n",
        "  else:\n",
        "    if (y_pred[i] == 1):\n",
        "      plt.plot(x1,x2,'_', color='#fe6100')\n",
        "    else:\n",
        "      plt.plot(x1,x2,'k.', alpha=0.25)\n",
        "\n",
        "accuracy = np.sum(np.equal(y_pred,y_actual))/len(y_actual)\n",
        "\n",
        "plt.axis('tight')\n",
        "plt.xlim(min(X[:,0])-0.1, max(X[:,0])+0.1)\n",
        "plt.ylim(min(X[:,1])-0.1, max(X[:,1])+0.1)\n",
        "plt.xlabel('$x_1$')\n",
        "plt.ylabel('$x_2$')\n",
        "plt.legend()\n",
        "plt.title('Keras-based 3-neuron MLP on spiral dataset. Accuracy: {:04.3}'.format(accuracy))\n",
        "plt.savefig('ch.6.MLP.keras.spirals.png', dpi=350, bbox_inches='tight')\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZoAAAGFCAYAAADEhjUtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o57SP3Tzitav",
        "colab_type": "text"
      },
      "source": [
        "Experiments continued"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_APyN-XMktT7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "77d37e04-6b09-40b5-a61d-316302b3af2a"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "mlp = Sequential()\n",
        "mlp.add(Dense(16, input_dim=2, activation='sigmoid'))\n",
        "mlp.add(Dense(2, activation='sigmoid'))\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(factor=0.5, monitor='accuracy',\n",
        "                              patience=50, min_lr=0.00000001,\n",
        "                              verbose = 1)\n",
        "\n",
        "stop_save = EarlyStopping(patience=200, monitor='accuracy',\n",
        "                          verbose=1, \n",
        "                          restore_best_weights=True)\n",
        "\n",
        "# All parameter gradients will be clipped to\n",
        "# a maximum norm of 1.\n",
        "sgd = optimizers.SGD(lr=1., clipnorm=1.)\n",
        "\n",
        "mlp.compile(loss='binary_crossentropy',\n",
        "            optimizer=sgd,\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "# trains the model\n",
        "mlp.fit(X, yv, epochs=1000, batch_size=297,\n",
        "        verbose=1, callbacks=[reduce_lr, stop_save], \n",
        "        validation_split = 0.01)\n",
        "\n",
        "y_pred = mlp.predict(X)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
        "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n",
        "                     np.arange(y_min, y_max, 0.02))\n",
        "Z = None\n",
        "Z = mlp.predict(np.c_[xx.ravel(), yy.ravel()])[:,1]\n",
        "Z = Z.reshape(xx.shape)\n",
        "cm = plt.cm.bwr\n",
        "\n",
        "fig = plt.figure(figsize=(6,6))\n",
        "\n",
        "plt.contourf(xx, yy, Z, cmap=cm, alpha=.25)\n",
        "\n",
        "plt.plot(X[1,0],X[1,1],'+', color='#648fff', label='Positive Class')\n",
        "plt.plot(X[2,1],X[2,1],'_', color='#fe6100', label='Negative Class')\n",
        "\n",
        "for i in range(len(y)):\n",
        "  x1 = X[i,0]\n",
        "  x2 = X[i,1]\n",
        "  if y[i]==1: \n",
        "    if (y_pred[i] == 0):\n",
        "      plt.plot(x1,x2,'+', color='#648fff')\n",
        "    else:\n",
        "      plt.plot(x1,x2,'k.', alpha=0.25)\n",
        "  else:\n",
        "    if (y_pred[i] == 1):\n",
        "      plt.plot(x1,x2,'_', color='#fe6100')\n",
        "    else:\n",
        "      plt.plot(x1,x2,'k.', alpha=0.25)\n",
        "\n",
        "accuracy = np.sum(np.equal(y_pred,y_actual))/len(y_actual)\n",
        "\n",
        "plt.axis('tight')\n",
        "plt.xlim(min(X[:,0])-0.1, max(X[:,0])+0.1)\n",
        "plt.ylim(min(X[:,1])-0.1, max(X[:,1])+0.1)\n",
        "plt.xlabel('$x_1$')\n",
        "plt.ylabel('$x_2$')\n",
        "plt.legend()\n",
        "plt.title('Keras-based 4-layer MLP on spiral dataset. Accuracy: {:04.3}'.format(accuracy))\n",
        "plt.savefig('ch.6.MLP.keras.deep.a.spirals.png', dpi=350, bbox_inches='tight')\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 594 samples, validate on 6 samples\n",
            "Epoch 1/1000\n",
            "594/594 [==============================] - 0s 391us/sample - loss: 0.7374 - accuracy: 0.4798 - val_loss: 0.6502 - val_accuracy: 0.7500\n",
            "Epoch 2/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6991 - accuracy: 0.4815 - val_loss: 0.6931 - val_accuracy: 0.2500\n",
            "Epoch 3/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6937 - accuracy: 0.5059 - val_loss: 0.6898 - val_accuracy: 0.3333\n",
            "Epoch 4/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6906 - accuracy: 0.5404 - val_loss: 0.7308 - val_accuracy: 0.0833\n",
            "Epoch 5/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6853 - accuracy: 0.5623 - val_loss: 0.7228 - val_accuracy: 0.1667\n",
            "Epoch 6/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6809 - accuracy: 0.6010 - val_loss: 0.7091 - val_accuracy: 0.2500\n",
            "Epoch 7/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6774 - accuracy: 0.5918 - val_loss: 0.7233 - val_accuracy: 0.2500\n",
            "Epoch 8/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6747 - accuracy: 0.6044 - val_loss: 0.7019 - val_accuracy: 0.3333\n",
            "Epoch 9/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6709 - accuracy: 0.6035 - val_loss: 0.7158 - val_accuracy: 0.2500\n",
            "Epoch 10/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6697 - accuracy: 0.6002 - val_loss: 0.7544 - val_accuracy: 0.2500\n",
            "Epoch 11/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6653 - accuracy: 0.6178 - val_loss: 0.7369 - val_accuracy: 0.2500\n",
            "Epoch 12/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6628 - accuracy: 0.6204 - val_loss: 0.7217 - val_accuracy: 0.3333\n",
            "Epoch 13/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6601 - accuracy: 0.6069 - val_loss: 0.7456 - val_accuracy: 0.2500\n",
            "Epoch 14/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6577 - accuracy: 0.6086 - val_loss: 0.7454 - val_accuracy: 0.2500\n",
            "Epoch 15/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6561 - accuracy: 0.6077 - val_loss: 0.7598 - val_accuracy: 0.2500\n",
            "Epoch 16/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6545 - accuracy: 0.6069 - val_loss: 0.7674 - val_accuracy: 0.2500\n",
            "Epoch 17/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6528 - accuracy: 0.6094 - val_loss: 0.7733 - val_accuracy: 0.2500\n",
            "Epoch 18/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6511 - accuracy: 0.6136 - val_loss: 0.7759 - val_accuracy: 0.2500\n",
            "Epoch 19/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6489 - accuracy: 0.6187 - val_loss: 0.7509 - val_accuracy: 0.3333\n",
            "Epoch 20/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6473 - accuracy: 0.6128 - val_loss: 0.7659 - val_accuracy: 0.2500\n",
            "Epoch 21/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6480 - accuracy: 0.6153 - val_loss: 0.7370 - val_accuracy: 0.3333\n",
            "Epoch 22/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6455 - accuracy: 0.6128 - val_loss: 0.7819 - val_accuracy: 0.2500\n",
            "Epoch 23/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6439 - accuracy: 0.6128 - val_loss: 0.7803 - val_accuracy: 0.2500\n",
            "Epoch 24/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6435 - accuracy: 0.6162 - val_loss: 0.7622 - val_accuracy: 0.3333\n",
            "Epoch 25/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6429 - accuracy: 0.6187 - val_loss: 0.7600 - val_accuracy: 0.3333\n",
            "Epoch 26/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6434 - accuracy: 0.6136 - val_loss: 0.7519 - val_accuracy: 0.3333\n",
            "Epoch 27/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6413 - accuracy: 0.6069 - val_loss: 0.7692 - val_accuracy: 0.3333\n",
            "Epoch 28/1000\n",
            "594/594 [==============================] - 0s 44us/sample - loss: 0.6408 - accuracy: 0.6145 - val_loss: 0.7689 - val_accuracy: 0.3333\n",
            "Epoch 29/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6398 - accuracy: 0.6153 - val_loss: 0.7793 - val_accuracy: 0.3333\n",
            "Epoch 30/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6412 - accuracy: 0.6145 - val_loss: 0.7621 - val_accuracy: 0.3333\n",
            "Epoch 31/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6391 - accuracy: 0.6128 - val_loss: 0.8037 - val_accuracy: 0.2500\n",
            "Epoch 32/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6388 - accuracy: 0.6136 - val_loss: 0.7900 - val_accuracy: 0.3333\n",
            "Epoch 33/1000\n",
            "594/594 [==============================] - 0s 35us/sample - loss: 0.6392 - accuracy: 0.6153 - val_loss: 0.7764 - val_accuracy: 0.3333\n",
            "Epoch 34/1000\n",
            "594/594 [==============================] - 0s 34us/sample - loss: 0.6380 - accuracy: 0.6103 - val_loss: 0.7914 - val_accuracy: 0.3333\n",
            "Epoch 35/1000\n",
            "594/594 [==============================] - 0s 34us/sample - loss: 0.6376 - accuracy: 0.6187 - val_loss: 0.8124 - val_accuracy: 0.2500\n",
            "Epoch 36/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6373 - accuracy: 0.6145 - val_loss: 0.8025 - val_accuracy: 0.3333\n",
            "Epoch 37/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6393 - accuracy: 0.6103 - val_loss: 0.8388 - val_accuracy: 0.1667\n",
            "Epoch 38/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6378 - accuracy: 0.6229 - val_loss: 0.8302 - val_accuracy: 0.2500\n",
            "Epoch 39/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6369 - accuracy: 0.6145 - val_loss: 0.8155 - val_accuracy: 0.2500\n",
            "Epoch 40/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6393 - accuracy: 0.6136 - val_loss: 0.7790 - val_accuracy: 0.3333\n",
            "Epoch 41/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6367 - accuracy: 0.6170 - val_loss: 0.8122 - val_accuracy: 0.2500\n",
            "Epoch 42/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6366 - accuracy: 0.6128 - val_loss: 0.8242 - val_accuracy: 0.2500\n",
            "Epoch 43/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6365 - accuracy: 0.6162 - val_loss: 0.8068 - val_accuracy: 0.3333\n",
            "Epoch 44/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6364 - accuracy: 0.6170 - val_loss: 0.8261 - val_accuracy: 0.2500\n",
            "Epoch 45/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6363 - accuracy: 0.6153 - val_loss: 0.8132 - val_accuracy: 0.3333\n",
            "Epoch 46/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6363 - accuracy: 0.6178 - val_loss: 0.8078 - val_accuracy: 0.3333\n",
            "Epoch 47/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6362 - accuracy: 0.6162 - val_loss: 0.8289 - val_accuracy: 0.2500\n",
            "Epoch 48/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6361 - accuracy: 0.6195 - val_loss: 0.8292 - val_accuracy: 0.2500\n",
            "Epoch 49/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6375 - accuracy: 0.6136 - val_loss: 0.8000 - val_accuracy: 0.3333\n",
            "Epoch 50/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6368 - accuracy: 0.6111 - val_loss: 0.8401 - val_accuracy: 0.1667\n",
            "Epoch 51/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6359 - accuracy: 0.6187 - val_loss: 0.8221 - val_accuracy: 0.2500\n",
            "Epoch 52/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6359 - accuracy: 0.6170 - val_loss: 0.8271 - val_accuracy: 0.2500\n",
            "Epoch 53/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6397 - accuracy: 0.6111 - val_loss: 0.8664 - val_accuracy: 0.1667\n",
            "Epoch 54/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6363 - accuracy: 0.6162 - val_loss: 0.8405 - val_accuracy: 0.1667\n",
            "Epoch 55/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6359 - accuracy: 0.6204 - val_loss: 0.8345 - val_accuracy: 0.2500\n",
            "Epoch 56/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6357 - accuracy: 0.6128 - val_loss: 0.8233 - val_accuracy: 0.2500\n",
            "Epoch 57/1000\n",
            "594/594 [==============================] - 0s 20us/sample - loss: 0.6357 - accuracy: 0.6145 - val_loss: 0.8221 - val_accuracy: 0.2500\n",
            "Epoch 58/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6376 - accuracy: 0.6153 - val_loss: 0.7990 - val_accuracy: 0.3333\n",
            "Epoch 59/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6366 - accuracy: 0.6153 - val_loss: 0.8072 - val_accuracy: 0.3333\n",
            "Epoch 60/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6377 - accuracy: 0.6187 - val_loss: 0.8556 - val_accuracy: 0.1667\n",
            "Epoch 61/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6359 - accuracy: 0.6178 - val_loss: 0.8252 - val_accuracy: 0.2500\n",
            "Epoch 62/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6360 - accuracy: 0.6136 - val_loss: 0.8367 - val_accuracy: 0.1667\n",
            "Epoch 63/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6374 - accuracy: 0.6170 - val_loss: 0.8577 - val_accuracy: 0.1667\n",
            "Epoch 64/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6357 - accuracy: 0.6195 - val_loss: 0.8370 - val_accuracy: 0.1667\n",
            "Epoch 65/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6358 - accuracy: 0.6136 - val_loss: 0.8396 - val_accuracy: 0.1667\n",
            "Epoch 66/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6357 - accuracy: 0.6170 - val_loss: 0.8226 - val_accuracy: 0.3333\n",
            "Epoch 67/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6357 - accuracy: 0.6195 - val_loss: 0.8206 - val_accuracy: 0.3333\n",
            "Epoch 68/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6357 - accuracy: 0.6187 - val_loss: 0.8210 - val_accuracy: 0.3333\n",
            "Epoch 69/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6357 - accuracy: 0.6187 - val_loss: 0.8222 - val_accuracy: 0.3333\n",
            "Epoch 70/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6362 - accuracy: 0.6162 - val_loss: 0.8141 - val_accuracy: 0.3333\n",
            "Epoch 71/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6364 - accuracy: 0.6120 - val_loss: 0.8492 - val_accuracy: 0.1667\n",
            "Epoch 72/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6355 - accuracy: 0.6170 - val_loss: 0.8352 - val_accuracy: 0.2500\n",
            "Epoch 73/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6361 - accuracy: 0.6111 - val_loss: 0.8495 - val_accuracy: 0.1667\n",
            "Epoch 74/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6355 - accuracy: 0.6178 - val_loss: 0.8321 - val_accuracy: 0.2500\n",
            "Epoch 75/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6357 - accuracy: 0.6136 - val_loss: 0.8227 - val_accuracy: 0.3333\n",
            "Epoch 76/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6365 - accuracy: 0.6195 - val_loss: 0.8534 - val_accuracy: 0.1667\n",
            "Epoch 77/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6367 - accuracy: 0.6212 - val_loss: 0.8127 - val_accuracy: 0.3333\n",
            "Epoch 78/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6362 - accuracy: 0.6128 - val_loss: 0.8484 - val_accuracy: 0.1667\n",
            "Epoch 79/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6356 - accuracy: 0.6187 - val_loss: 0.8385 - val_accuracy: 0.1667\n",
            "Epoch 80/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6389 - accuracy: 0.6221 - val_loss: 0.7956 - val_accuracy: 0.3333\n",
            "Epoch 81/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6361 - accuracy: 0.6086 - val_loss: 0.8152 - val_accuracy: 0.3333\n",
            "Epoch 82/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6354 - accuracy: 0.6212 - val_loss: 0.8325 - val_accuracy: 0.2500\n",
            "Epoch 83/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6354 - accuracy: 0.6145 - val_loss: 0.8259 - val_accuracy: 0.3333\n",
            "Epoch 84/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6353 - accuracy: 0.6145 - val_loss: 0.8310 - val_accuracy: 0.2500\n",
            "Epoch 85/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6358 - accuracy: 0.6128 - val_loss: 0.8190 - val_accuracy: 0.3333\n",
            "Epoch 86/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6355 - accuracy: 0.6170 - val_loss: 0.8417 - val_accuracy: 0.1667\n",
            "Epoch 87/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6354 - accuracy: 0.6162 - val_loss: 0.8280 - val_accuracy: 0.2500\n",
            "Epoch 88/1000\n",
            "297/594 [==============>...............] - ETA: 0s - loss: 0.6260 - accuracy: 0.6296\n",
            "Epoch 00088: ReduceLROnPlateau reducing learning rate to 0.5.\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6355 - accuracy: 0.6204 - val_loss: 0.8216 - val_accuracy: 0.3333\n",
            "Epoch 89/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6356 - accuracy: 0.6170 - val_loss: 0.8314 - val_accuracy: 0.2500\n",
            "Epoch 90/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6353 - accuracy: 0.6136 - val_loss: 0.8337 - val_accuracy: 0.2500\n",
            "Epoch 91/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6355 - accuracy: 0.6128 - val_loss: 0.8293 - val_accuracy: 0.2500\n",
            "Epoch 92/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6352 - accuracy: 0.6153 - val_loss: 0.8306 - val_accuracy: 0.2500\n",
            "Epoch 93/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6354 - accuracy: 0.6170 - val_loss: 0.8341 - val_accuracy: 0.2500\n",
            "Epoch 94/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6353 - accuracy: 0.6111 - val_loss: 0.8313 - val_accuracy: 0.2500\n",
            "Epoch 95/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6354 - accuracy: 0.6162 - val_loss: 0.8350 - val_accuracy: 0.2500\n",
            "Epoch 96/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6362 - accuracy: 0.6136 - val_loss: 0.8417 - val_accuracy: 0.1667\n",
            "Epoch 97/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6353 - accuracy: 0.6145 - val_loss: 0.8357 - val_accuracy: 0.2500\n",
            "Epoch 98/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6356 - accuracy: 0.6153 - val_loss: 0.8298 - val_accuracy: 0.2500\n",
            "Epoch 99/1000\n",
            "594/594 [==============================] - 0s 40us/sample - loss: 0.6356 - accuracy: 0.6187 - val_loss: 0.8264 - val_accuracy: 0.3333\n",
            "Epoch 100/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6352 - accuracy: 0.6170 - val_loss: 0.8307 - val_accuracy: 0.2500\n",
            "Epoch 101/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6353 - accuracy: 0.6153 - val_loss: 0.8350 - val_accuracy: 0.2500\n",
            "Epoch 102/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6355 - accuracy: 0.6162 - val_loss: 0.8379 - val_accuracy: 0.1667\n",
            "Epoch 103/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6352 - accuracy: 0.6128 - val_loss: 0.8356 - val_accuracy: 0.2500\n",
            "Epoch 104/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6355 - accuracy: 0.6162 - val_loss: 0.8387 - val_accuracy: 0.1667\n",
            "Epoch 105/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6355 - accuracy: 0.6187 - val_loss: 0.8393 - val_accuracy: 0.1667\n",
            "Epoch 106/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6353 - accuracy: 0.6178 - val_loss: 0.8392 - val_accuracy: 0.1667\n",
            "Epoch 107/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6352 - accuracy: 0.6153 - val_loss: 0.8342 - val_accuracy: 0.2500\n",
            "Epoch 108/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6355 - accuracy: 0.6178 - val_loss: 0.8290 - val_accuracy: 0.2500\n",
            "Epoch 109/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6361 - accuracy: 0.6128 - val_loss: 0.8385 - val_accuracy: 0.1667\n",
            "Epoch 110/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6354 - accuracy: 0.6162 - val_loss: 0.8340 - val_accuracy: 0.2500\n",
            "Epoch 111/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6353 - accuracy: 0.6120 - val_loss: 0.8311 - val_accuracy: 0.2500\n",
            "Epoch 112/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6352 - accuracy: 0.6136 - val_loss: 0.8299 - val_accuracy: 0.2500\n",
            "Epoch 113/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6351 - accuracy: 0.6153 - val_loss: 0.8314 - val_accuracy: 0.2500\n",
            "Epoch 114/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6356 - accuracy: 0.6145 - val_loss: 0.8271 - val_accuracy: 0.3333\n",
            "Epoch 115/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6352 - accuracy: 0.6153 - val_loss: 0.8279 - val_accuracy: 0.3333\n",
            "Epoch 116/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6352 - accuracy: 0.6153 - val_loss: 0.8288 - val_accuracy: 0.2500\n",
            "Epoch 117/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6351 - accuracy: 0.6178 - val_loss: 0.8315 - val_accuracy: 0.2500\n",
            "Epoch 118/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6356 - accuracy: 0.6195 - val_loss: 0.8375 - val_accuracy: 0.1667\n",
            "Epoch 119/1000\n",
            "594/594 [==============================] - 0s 20us/sample - loss: 0.6352 - accuracy: 0.6128 - val_loss: 0.8361 - val_accuracy: 0.2500\n",
            "Epoch 120/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6351 - accuracy: 0.6111 - val_loss: 0.8343 - val_accuracy: 0.2500\n",
            "Epoch 121/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6355 - accuracy: 0.6128 - val_loss: 0.8385 - val_accuracy: 0.1667\n",
            "Epoch 122/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6353 - accuracy: 0.6170 - val_loss: 0.8329 - val_accuracy: 0.2500\n",
            "Epoch 123/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6361 - accuracy: 0.6153 - val_loss: 0.8409 - val_accuracy: 0.1667\n",
            "Epoch 124/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6351 - accuracy: 0.6145 - val_loss: 0.8363 - val_accuracy: 0.2500\n",
            "Epoch 125/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6352 - accuracy: 0.6145 - val_loss: 0.8322 - val_accuracy: 0.2500\n",
            "Epoch 126/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6355 - accuracy: 0.6120 - val_loss: 0.8275 - val_accuracy: 0.3333\n",
            "Epoch 127/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6352 - accuracy: 0.6204 - val_loss: 0.8278 - val_accuracy: 0.3333\n",
            "Epoch 128/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6351 - accuracy: 0.6136 - val_loss: 0.8294 - val_accuracy: 0.2500\n",
            "Epoch 129/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6354 - accuracy: 0.6162 - val_loss: 0.8270 - val_accuracy: 0.3333\n",
            "Epoch 130/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6351 - accuracy: 0.6145 - val_loss: 0.8295 - val_accuracy: 0.2500\n",
            "Epoch 131/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6358 - accuracy: 0.6120 - val_loss: 0.8382 - val_accuracy: 0.1667\n",
            "Epoch 132/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6351 - accuracy: 0.6145 - val_loss: 0.8371 - val_accuracy: 0.1667\n",
            "Epoch 133/1000\n",
            "594/594 [==============================] - 0s 20us/sample - loss: 0.6351 - accuracy: 0.6103 - val_loss: 0.8359 - val_accuracy: 0.2500\n",
            "Epoch 134/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6354 - accuracy: 0.6120 - val_loss: 0.8390 - val_accuracy: 0.1667\n",
            "Epoch 135/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6351 - accuracy: 0.6145 - val_loss: 0.8378 - val_accuracy: 0.1667\n",
            "Epoch 136/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6351 - accuracy: 0.6111 - val_loss: 0.8364 - val_accuracy: 0.2500\n",
            "Epoch 137/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6353 - accuracy: 0.6178 - val_loss: 0.8306 - val_accuracy: 0.2500\n",
            "Epoch 138/1000\n",
            "297/594 [==============>...............] - ETA: 0s - loss: 0.6231 - accuracy: 0.6128\n",
            "Epoch 00138: ReduceLROnPlateau reducing learning rate to 0.25.\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6359 - accuracy: 0.6170 - val_loss: 0.8249 - val_accuracy: 0.3333\n",
            "Epoch 139/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6358 - accuracy: 0.6178 - val_loss: 0.8247 - val_accuracy: 0.3333\n",
            "Epoch 140/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6351 - accuracy: 0.6170 - val_loss: 0.8262 - val_accuracy: 0.3333\n",
            "Epoch 141/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6350 - accuracy: 0.6170 - val_loss: 0.8281 - val_accuracy: 0.3333\n",
            "Epoch 142/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6351 - accuracy: 0.6170 - val_loss: 0.8299 - val_accuracy: 0.2500\n",
            "Epoch 143/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6350 - accuracy: 0.6128 - val_loss: 0.8306 - val_accuracy: 0.2500\n",
            "Epoch 144/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6350 - accuracy: 0.6145 - val_loss: 0.8315 - val_accuracy: 0.2500\n",
            "Epoch 145/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6351 - accuracy: 0.6162 - val_loss: 0.8326 - val_accuracy: 0.2500\n",
            "Epoch 146/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6351 - accuracy: 0.6136 - val_loss: 0.8334 - val_accuracy: 0.2500\n",
            "Epoch 147/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6351 - accuracy: 0.6153 - val_loss: 0.8342 - val_accuracy: 0.2500\n",
            "Epoch 148/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6361 - accuracy: 0.6170 - val_loss: 0.8369 - val_accuracy: 0.1667\n",
            "Epoch 149/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6351 - accuracy: 0.6128 - val_loss: 0.8349 - val_accuracy: 0.2500\n",
            "Epoch 150/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6352 - accuracy: 0.6103 - val_loss: 0.8357 - val_accuracy: 0.2500\n",
            "Epoch 151/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6351 - accuracy: 0.6111 - val_loss: 0.8350 - val_accuracy: 0.2500\n",
            "Epoch 152/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6352 - accuracy: 0.6128 - val_loss: 0.8332 - val_accuracy: 0.2500\n",
            "Epoch 153/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6350 - accuracy: 0.6128 - val_loss: 0.8335 - val_accuracy: 0.2500\n",
            "Epoch 154/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6351 - accuracy: 0.6136 - val_loss: 0.8327 - val_accuracy: 0.2500\n",
            "Epoch 155/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6351 - accuracy: 0.6136 - val_loss: 0.8336 - val_accuracy: 0.2500\n",
            "Epoch 156/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6353 - accuracy: 0.6145 - val_loss: 0.8318 - val_accuracy: 0.2500\n",
            "Epoch 157/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6350 - accuracy: 0.6120 - val_loss: 0.8316 - val_accuracy: 0.2500\n",
            "Epoch 158/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6351 - accuracy: 0.6120 - val_loss: 0.8325 - val_accuracy: 0.2500\n",
            "Epoch 159/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6350 - accuracy: 0.6120 - val_loss: 0.8325 - val_accuracy: 0.2500\n",
            "Epoch 160/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6351 - accuracy: 0.6136 - val_loss: 0.8332 - val_accuracy: 0.2500\n",
            "Epoch 161/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6350 - accuracy: 0.6111 - val_loss: 0.8332 - val_accuracy: 0.2500\n",
            "Epoch 162/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6352 - accuracy: 0.6128 - val_loss: 0.8318 - val_accuracy: 0.2500\n",
            "Epoch 163/1000\n",
            "594/594 [==============================] - 0s 41us/sample - loss: 0.6355 - accuracy: 0.6153 - val_loss: 0.8341 - val_accuracy: 0.2500\n",
            "Epoch 164/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6353 - accuracy: 0.6162 - val_loss: 0.8321 - val_accuracy: 0.2500\n",
            "Epoch 165/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6351 - accuracy: 0.6128 - val_loss: 0.8313 - val_accuracy: 0.2500\n",
            "Epoch 166/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6355 - accuracy: 0.6145 - val_loss: 0.8337 - val_accuracy: 0.2500\n",
            "Epoch 167/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6353 - accuracy: 0.6136 - val_loss: 0.8351 - val_accuracy: 0.2500\n",
            "Epoch 168/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6350 - accuracy: 0.6120 - val_loss: 0.8349 - val_accuracy: 0.2500\n",
            "Epoch 169/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6352 - accuracy: 0.6128 - val_loss: 0.8331 - val_accuracy: 0.2500\n",
            "Epoch 170/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6350 - accuracy: 0.6153 - val_loss: 0.8337 - val_accuracy: 0.2500\n",
            "Epoch 171/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6350 - accuracy: 0.6111 - val_loss: 0.8340 - val_accuracy: 0.2500\n",
            "Epoch 172/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6351 - accuracy: 0.6145 - val_loss: 0.8329 - val_accuracy: 0.2500\n",
            "Epoch 173/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6350 - accuracy: 0.6120 - val_loss: 0.8330 - val_accuracy: 0.2500\n",
            "Epoch 174/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6351 - accuracy: 0.6111 - val_loss: 0.8341 - val_accuracy: 0.2500\n",
            "Epoch 175/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6350 - accuracy: 0.6120 - val_loss: 0.8342 - val_accuracy: 0.2500\n",
            "Epoch 176/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6350 - accuracy: 0.6111 - val_loss: 0.8333 - val_accuracy: 0.2500\n",
            "Epoch 177/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6350 - accuracy: 0.6111 - val_loss: 0.8328 - val_accuracy: 0.2500\n",
            "Epoch 178/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6355 - accuracy: 0.6153 - val_loss: 0.8349 - val_accuracy: 0.2500\n",
            "Epoch 179/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6354 - accuracy: 0.6162 - val_loss: 0.8363 - val_accuracy: 0.2500\n",
            "Epoch 180/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6351 - accuracy: 0.6136 - val_loss: 0.8344 - val_accuracy: 0.2500\n",
            "Epoch 181/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6350 - accuracy: 0.6111 - val_loss: 0.8336 - val_accuracy: 0.2500\n",
            "Epoch 182/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6351 - accuracy: 0.6120 - val_loss: 0.8324 - val_accuracy: 0.2500\n",
            "Epoch 183/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6350 - accuracy: 0.6128 - val_loss: 0.8322 - val_accuracy: 0.2500\n",
            "Epoch 184/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6350 - accuracy: 0.6136 - val_loss: 0.8327 - val_accuracy: 0.2500\n",
            "Epoch 185/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6350 - accuracy: 0.6111 - val_loss: 0.8326 - val_accuracy: 0.2500\n",
            "Epoch 186/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6350 - accuracy: 0.6120 - val_loss: 0.8325 - val_accuracy: 0.2500\n",
            "Epoch 187/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6350 - accuracy: 0.6111 - val_loss: 0.8322 - val_accuracy: 0.2500\n",
            "Epoch 188/1000\n",
            "297/594 [==============>...............] - ETA: 0s - loss: 0.6189 - accuracy: 0.6195\n",
            "Epoch 00188: ReduceLROnPlateau reducing learning rate to 0.125.\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6349 - accuracy: 0.6128 - val_loss: 0.8325 - val_accuracy: 0.2500\n",
            "Epoch 189/1000\n",
            "594/594 [==============================] - 0s 20us/sample - loss: 0.6350 - accuracy: 0.6153 - val_loss: 0.8328 - val_accuracy: 0.2500\n",
            "Epoch 190/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6351 - accuracy: 0.6120 - val_loss: 0.8325 - val_accuracy: 0.2500\n",
            "Epoch 191/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6350 - accuracy: 0.6128 - val_loss: 0.8324 - val_accuracy: 0.2500\n",
            "Epoch 192/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6349 - accuracy: 0.6120 - val_loss: 0.8325 - val_accuracy: 0.2500\n",
            "Epoch 193/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6350 - accuracy: 0.6120 - val_loss: 0.8324 - val_accuracy: 0.2500\n",
            "Epoch 194/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6350 - accuracy: 0.6128 - val_loss: 0.8327 - val_accuracy: 0.2500\n",
            "Epoch 195/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6349 - accuracy: 0.6120 - val_loss: 0.8328 - val_accuracy: 0.2500\n",
            "Epoch 196/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6351 - accuracy: 0.6136 - val_loss: 0.8324 - val_accuracy: 0.2500\n",
            "Epoch 197/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6350 - accuracy: 0.6128 - val_loss: 0.8327 - val_accuracy: 0.2500\n",
            "Epoch 198/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6349 - accuracy: 0.6120 - val_loss: 0.8328 - val_accuracy: 0.2500\n",
            "Epoch 199/1000\n",
            "594/594 [==============================] - 0s 45us/sample - loss: 0.6353 - accuracy: 0.6145 - val_loss: 0.8322 - val_accuracy: 0.2500\n",
            "Epoch 200/1000\n",
            "594/594 [==============================] - 0s 33us/sample - loss: 0.6349 - accuracy: 0.6111 - val_loss: 0.8323 - val_accuracy: 0.2500\n",
            "Epoch 201/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6353 - accuracy: 0.6136 - val_loss: 0.8318 - val_accuracy: 0.2500\n",
            "Epoch 202/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6351 - accuracy: 0.6128 - val_loss: 0.8316 - val_accuracy: 0.2500\n",
            "Epoch 203/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6349 - accuracy: 0.6120 - val_loss: 0.8317 - val_accuracy: 0.2500\n",
            "Epoch 204/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6350 - accuracy: 0.6145 - val_loss: 0.8322 - val_accuracy: 0.2500\n",
            "Epoch 205/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6350 - accuracy: 0.6128 - val_loss: 0.8325 - val_accuracy: 0.2500\n",
            "Epoch 206/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6349 - accuracy: 0.6111 - val_loss: 0.8325 - val_accuracy: 0.2500\n",
            "Epoch 207/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6351 - accuracy: 0.6170 - val_loss: 0.8330 - val_accuracy: 0.2500\n",
            "Epoch 208/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6349 - accuracy: 0.6111 - val_loss: 0.8329 - val_accuracy: 0.2500\n",
            "Epoch 209/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6349 - accuracy: 0.6103 - val_loss: 0.8329 - val_accuracy: 0.2500\n",
            "Epoch 210/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6349 - accuracy: 0.6103 - val_loss: 0.8328 - val_accuracy: 0.2500\n",
            "Epoch 211/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6351 - accuracy: 0.6162 - val_loss: 0.8332 - val_accuracy: 0.2500\n",
            "Epoch 212/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6350 - accuracy: 0.6103 - val_loss: 0.8329 - val_accuracy: 0.2500\n",
            "Epoch 213/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6349 - accuracy: 0.6136 - val_loss: 0.8331 - val_accuracy: 0.2500\n",
            "Epoch 214/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6349 - accuracy: 0.6111 - val_loss: 0.8330 - val_accuracy: 0.2500\n",
            "Epoch 215/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6355 - accuracy: 0.6128 - val_loss: 0.8338 - val_accuracy: 0.2500\n",
            "Epoch 216/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6349 - accuracy: 0.6120 - val_loss: 0.8338 - val_accuracy: 0.2500\n",
            "Epoch 217/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6352 - accuracy: 0.6120 - val_loss: 0.8331 - val_accuracy: 0.2500\n",
            "Epoch 218/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6350 - accuracy: 0.6120 - val_loss: 0.8328 - val_accuracy: 0.2500\n",
            "Epoch 219/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6349 - accuracy: 0.6111 - val_loss: 0.8327 - val_accuracy: 0.2500\n",
            "Epoch 220/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6350 - accuracy: 0.6128 - val_loss: 0.8331 - val_accuracy: 0.2500\n",
            "Epoch 221/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6350 - accuracy: 0.6120 - val_loss: 0.8329 - val_accuracy: 0.2500\n",
            "Epoch 222/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6349 - accuracy: 0.6120 - val_loss: 0.8330 - val_accuracy: 0.2500\n",
            "Epoch 223/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6349 - accuracy: 0.6128 - val_loss: 0.8332 - val_accuracy: 0.2500\n",
            "Epoch 224/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6349 - accuracy: 0.6111 - val_loss: 0.8330 - val_accuracy: 0.2500\n",
            "Epoch 225/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6349 - accuracy: 0.6120 - val_loss: 0.8331 - val_accuracy: 0.2500\n",
            "Epoch 226/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6349 - accuracy: 0.6111 - val_loss: 0.8331 - val_accuracy: 0.2500\n",
            "Epoch 227/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6349 - accuracy: 0.6103 - val_loss: 0.8330 - val_accuracy: 0.2500\n",
            "Epoch 228/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6351 - accuracy: 0.6136 - val_loss: 0.8326 - val_accuracy: 0.2500\n",
            "Epoch 229/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6352 - accuracy: 0.6128 - val_loss: 0.8332 - val_accuracy: 0.2500\n",
            "Epoch 230/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6350 - accuracy: 0.6111 - val_loss: 0.8329 - val_accuracy: 0.2500\n",
            "Epoch 231/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6349 - accuracy: 0.6120 - val_loss: 0.8327 - val_accuracy: 0.2500\n",
            "Epoch 232/1000\n",
            "594/594 [==============================] - 0s 20us/sample - loss: 0.6349 - accuracy: 0.6120 - val_loss: 0.8326 - val_accuracy: 0.2500\n",
            "Epoch 233/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6349 - accuracy: 0.6128 - val_loss: 0.8328 - val_accuracy: 0.2500\n",
            "Epoch 234/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6349 - accuracy: 0.6111 - val_loss: 0.8328 - val_accuracy: 0.2500\n",
            "Epoch 235/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6349 - accuracy: 0.6120 - val_loss: 0.8329 - val_accuracy: 0.2500\n",
            "Epoch 236/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6349 - accuracy: 0.6120 - val_loss: 0.8330 - val_accuracy: 0.2500\n",
            "Epoch 237/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6349 - accuracy: 0.6111 - val_loss: 0.8329 - val_accuracy: 0.2500\n",
            "Epoch 238/1000\n",
            "297/594 [==============>...............] - ETA: 0s - loss: 0.6291 - accuracy: 0.6027\n",
            "Epoch 00238: ReduceLROnPlateau reducing learning rate to 0.0625.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6350 - accuracy: 0.6145 - val_loss: 0.8333 - val_accuracy: 0.2500\n",
            "Epoch 00238: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAGFCAYAAADAc+UQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nNBchfcluLo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7a771850-df0e-40cb-bfcf-234911dbb086"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "mlp = Sequential()\n",
        "mlp.add(Dense(16, input_dim=2, activation='relu'))\n",
        "mlp.add(Dense(2, activation='sigmoid'))\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(factor=0.5, monitor='accuracy',\n",
        "                              patience=50, min_lr=0.00000001,\n",
        "                              verbose = 1)\n",
        "\n",
        "stop_save = EarlyStopping(patience=200, monitor='accuracy',\n",
        "                          verbose=1, \n",
        "                          restore_best_weights=True)\n",
        "\n",
        "# All parameter gradients will be clipped to\n",
        "# a maximum norm of 1.\n",
        "sgd = optimizers.SGD(lr=1., clipnorm=1.)\n",
        "\n",
        "mlp.compile(loss='binary_crossentropy',\n",
        "            optimizer=sgd,\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "# trains the model\n",
        "mlp.fit(X, yv, epochs=1000, batch_size=297,\n",
        "        verbose=1, callbacks=[reduce_lr, stop_save], \n",
        "        validation_split = 0.01)\n",
        "\n",
        "y_pred = mlp.predict(X)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
        "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n",
        "                     np.arange(y_min, y_max, 0.02))\n",
        "Z = None\n",
        "Z = mlp.predict(np.c_[xx.ravel(), yy.ravel()])[:,1]\n",
        "Z = Z.reshape(xx.shape)\n",
        "cm = plt.cm.bwr\n",
        "\n",
        "fig = plt.figure(figsize=(6,6))\n",
        "\n",
        "plt.contourf(xx, yy, Z, cmap=cm, alpha=.25)\n",
        "\n",
        "plt.plot(X[1,0],X[1,1],'+', color='#648fff', label='Positive Class')\n",
        "plt.plot(X[2,1],X[2,1],'_', color='#fe6100', label='Negative Class')\n",
        "\n",
        "for i in range(len(y)):\n",
        "  x1 = X[i,0]\n",
        "  x2 = X[i,1]\n",
        "  if y[i]==1: \n",
        "    if (y_pred[i] == 0):\n",
        "      plt.plot(x1,x2,'+', color='#648fff')\n",
        "    else:\n",
        "      plt.plot(x1,x2,'k.', alpha=0.25)\n",
        "  else:\n",
        "    if (y_pred[i] == 1):\n",
        "      plt.plot(x1,x2,'_', color='#fe6100')\n",
        "    else:\n",
        "      plt.plot(x1,x2,'k.', alpha=0.25)\n",
        "\n",
        "accuracy = np.sum(np.equal(y_pred,y_actual))/len(y_actual)\n",
        "\n",
        "plt.axis('tight')\n",
        "plt.xlim(min(X[:,0])-0.1, max(X[:,0])+0.1)\n",
        "plt.ylim(min(X[:,1])-0.1, max(X[:,1])+0.1)\n",
        "plt.xlabel('$x_1$')\n",
        "plt.ylabel('$x_2$')\n",
        "plt.legend()\n",
        "plt.title('Keras-based 4-layer MLP on spiral dataset. Accuracy: {:04.3}'.format(accuracy))\n",
        "plt.savefig('ch.6.MLP.keras.deep.b.spirals.png', dpi=350, bbox_inches='tight')\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 594 samples, validate on 6 samples\n",
            "Epoch 1/1000\n",
            "594/594 [==============================] - 0s 414us/sample - loss: 0.6704 - accuracy: 0.5328 - val_loss: 0.6627 - val_accuracy: 0.5833\n",
            "Epoch 2/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6587 - accuracy: 0.5572 - val_loss: 0.6850 - val_accuracy: 0.4167\n",
            "Epoch 3/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6511 - accuracy: 0.5842 - val_loss: 0.7076 - val_accuracy: 0.3333\n",
            "Epoch 4/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6464 - accuracy: 0.5951 - val_loss: 0.7248 - val_accuracy: 0.3333\n",
            "Epoch 5/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6428 - accuracy: 0.6035 - val_loss: 0.7455 - val_accuracy: 0.3333\n",
            "Epoch 6/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6405 - accuracy: 0.6111 - val_loss: 0.7580 - val_accuracy: 0.3333\n",
            "Epoch 7/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6390 - accuracy: 0.6128 - val_loss: 0.7662 - val_accuracy: 0.3333\n",
            "Epoch 8/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6372 - accuracy: 0.6120 - val_loss: 0.7805 - val_accuracy: 0.3333\n",
            "Epoch 9/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6368 - accuracy: 0.6069 - val_loss: 0.7909 - val_accuracy: 0.2500\n",
            "Epoch 10/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6349 - accuracy: 0.6162 - val_loss: 0.7946 - val_accuracy: 0.2500\n",
            "Epoch 11/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6343 - accuracy: 0.6195 - val_loss: 0.8003 - val_accuracy: 0.2500\n",
            "Epoch 12/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6351 - accuracy: 0.6153 - val_loss: 0.7967 - val_accuracy: 0.2500\n",
            "Epoch 13/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.6328 - accuracy: 0.6204 - val_loss: 0.8001 - val_accuracy: 0.2500\n",
            "Epoch 14/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6323 - accuracy: 0.6187 - val_loss: 0.8031 - val_accuracy: 0.2500\n",
            "Epoch 15/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6318 - accuracy: 0.6237 - val_loss: 0.8095 - val_accuracy: 0.2500\n",
            "Epoch 16/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6313 - accuracy: 0.6221 - val_loss: 0.8115 - val_accuracy: 0.2500\n",
            "Epoch 17/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6303 - accuracy: 0.6254 - val_loss: 0.8115 - val_accuracy: 0.2500\n",
            "Epoch 18/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6300 - accuracy: 0.6279 - val_loss: 0.8084 - val_accuracy: 0.2500\n",
            "Epoch 19/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6298 - accuracy: 0.6254 - val_loss: 0.8090 - val_accuracy: 0.2500\n",
            "Epoch 20/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6288 - accuracy: 0.6271 - val_loss: 0.8066 - val_accuracy: 0.2500\n",
            "Epoch 21/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6290 - accuracy: 0.6237 - val_loss: 0.8123 - val_accuracy: 0.2500\n",
            "Epoch 22/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6281 - accuracy: 0.6204 - val_loss: 0.8130 - val_accuracy: 0.2500\n",
            "Epoch 23/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6271 - accuracy: 0.6338 - val_loss: 0.8086 - val_accuracy: 0.2500\n",
            "Epoch 24/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6266 - accuracy: 0.6347 - val_loss: 0.8058 - val_accuracy: 0.2500\n",
            "Epoch 25/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6261 - accuracy: 0.6296 - val_loss: 0.8046 - val_accuracy: 0.3333\n",
            "Epoch 26/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6256 - accuracy: 0.6355 - val_loss: 0.8026 - val_accuracy: 0.3333\n",
            "Epoch 27/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6254 - accuracy: 0.6330 - val_loss: 0.8046 - val_accuracy: 0.3333\n",
            "Epoch 28/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6256 - accuracy: 0.6448 - val_loss: 0.7954 - val_accuracy: 0.3333\n",
            "Epoch 29/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6242 - accuracy: 0.6423 - val_loss: 0.7944 - val_accuracy: 0.3333\n",
            "Epoch 30/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6244 - accuracy: 0.6389 - val_loss: 0.8008 - val_accuracy: 0.3333\n",
            "Epoch 31/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6230 - accuracy: 0.6456 - val_loss: 0.7997 - val_accuracy: 0.3333\n",
            "Epoch 32/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6230 - accuracy: 0.6532 - val_loss: 0.7958 - val_accuracy: 0.3333\n",
            "Epoch 33/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6221 - accuracy: 0.6507 - val_loss: 0.7947 - val_accuracy: 0.3333\n",
            "Epoch 34/1000\n",
            "594/594 [==============================] - 0s 41us/sample - loss: 0.6217 - accuracy: 0.6490 - val_loss: 0.7980 - val_accuracy: 0.3333\n",
            "Epoch 35/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6215 - accuracy: 0.6448 - val_loss: 0.8007 - val_accuracy: 0.3333\n",
            "Epoch 36/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6208 - accuracy: 0.6566 - val_loss: 0.8010 - val_accuracy: 0.3333\n",
            "Epoch 37/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6205 - accuracy: 0.6582 - val_loss: 0.7956 - val_accuracy: 0.3333\n",
            "Epoch 38/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6200 - accuracy: 0.6515 - val_loss: 0.7985 - val_accuracy: 0.3333\n",
            "Epoch 39/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6208 - accuracy: 0.6557 - val_loss: 0.7929 - val_accuracy: 0.3333\n",
            "Epoch 40/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6196 - accuracy: 0.6566 - val_loss: 0.7929 - val_accuracy: 0.3333\n",
            "Epoch 41/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6195 - accuracy: 0.6532 - val_loss: 0.7927 - val_accuracy: 0.3333\n",
            "Epoch 42/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6187 - accuracy: 0.6498 - val_loss: 0.7972 - val_accuracy: 0.3333\n",
            "Epoch 43/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6203 - accuracy: 0.6532 - val_loss: 0.8071 - val_accuracy: 0.3333\n",
            "Epoch 44/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6181 - accuracy: 0.6599 - val_loss: 0.8044 - val_accuracy: 0.3333\n",
            "Epoch 45/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6179 - accuracy: 0.6557 - val_loss: 0.8077 - val_accuracy: 0.3333\n",
            "Epoch 46/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6173 - accuracy: 0.6633 - val_loss: 0.8046 - val_accuracy: 0.3333\n",
            "Epoch 47/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6174 - accuracy: 0.6582 - val_loss: 0.8031 - val_accuracy: 0.3333\n",
            "Epoch 48/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6167 - accuracy: 0.6557 - val_loss: 0.8071 - val_accuracy: 0.3333\n",
            "Epoch 49/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6162 - accuracy: 0.6616 - val_loss: 0.8064 - val_accuracy: 0.3333\n",
            "Epoch 50/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6162 - accuracy: 0.6608 - val_loss: 0.8046 - val_accuracy: 0.3333\n",
            "Epoch 51/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6159 - accuracy: 0.6532 - val_loss: 0.8104 - val_accuracy: 0.3333\n",
            "Epoch 52/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6154 - accuracy: 0.6599 - val_loss: 0.8071 - val_accuracy: 0.3333\n",
            "Epoch 53/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6159 - accuracy: 0.6608 - val_loss: 0.8053 - val_accuracy: 0.3333\n",
            "Epoch 54/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6148 - accuracy: 0.6625 - val_loss: 0.8090 - val_accuracy: 0.3333\n",
            "Epoch 55/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6152 - accuracy: 0.6574 - val_loss: 0.8102 - val_accuracy: 0.3333\n",
            "Epoch 56/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6141 - accuracy: 0.6582 - val_loss: 0.8104 - val_accuracy: 0.3333\n",
            "Epoch 57/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6141 - accuracy: 0.6608 - val_loss: 0.8081 - val_accuracy: 0.3333\n",
            "Epoch 58/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6151 - accuracy: 0.6582 - val_loss: 0.8154 - val_accuracy: 0.3333\n",
            "Epoch 59/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6133 - accuracy: 0.6616 - val_loss: 0.8113 - val_accuracy: 0.3333\n",
            "Epoch 60/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6132 - accuracy: 0.6566 - val_loss: 0.8113 - val_accuracy: 0.3333\n",
            "Epoch 61/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6130 - accuracy: 0.6591 - val_loss: 0.8141 - val_accuracy: 0.3333\n",
            "Epoch 62/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6125 - accuracy: 0.6566 - val_loss: 0.8090 - val_accuracy: 0.3333\n",
            "Epoch 63/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6121 - accuracy: 0.6599 - val_loss: 0.8079 - val_accuracy: 0.3333\n",
            "Epoch 64/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6127 - accuracy: 0.6532 - val_loss: 0.8157 - val_accuracy: 0.3333\n",
            "Epoch 65/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6115 - accuracy: 0.6616 - val_loss: 0.8106 - val_accuracy: 0.3333\n",
            "Epoch 66/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6114 - accuracy: 0.6582 - val_loss: 0.8088 - val_accuracy: 0.3333\n",
            "Epoch 67/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6106 - accuracy: 0.6591 - val_loss: 0.8103 - val_accuracy: 0.3333\n",
            "Epoch 68/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6104 - accuracy: 0.6591 - val_loss: 0.8107 - val_accuracy: 0.3333\n",
            "Epoch 69/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6100 - accuracy: 0.6599 - val_loss: 0.8126 - val_accuracy: 0.3333\n",
            "Epoch 70/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6099 - accuracy: 0.6608 - val_loss: 0.8092 - val_accuracy: 0.3333\n",
            "Epoch 71/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6098 - accuracy: 0.6582 - val_loss: 0.8092 - val_accuracy: 0.3333\n",
            "Epoch 72/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6089 - accuracy: 0.6599 - val_loss: 0.8116 - val_accuracy: 0.3333\n",
            "Epoch 73/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6084 - accuracy: 0.6641 - val_loss: 0.8172 - val_accuracy: 0.2500\n",
            "Epoch 74/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6081 - accuracy: 0.6616 - val_loss: 0.8168 - val_accuracy: 0.2500\n",
            "Epoch 75/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6081 - accuracy: 0.6650 - val_loss: 0.8241 - val_accuracy: 0.2500\n",
            "Epoch 76/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6074 - accuracy: 0.6599 - val_loss: 0.8199 - val_accuracy: 0.2500\n",
            "Epoch 77/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6083 - accuracy: 0.6641 - val_loss: 0.8277 - val_accuracy: 0.2500\n",
            "Epoch 78/1000\n",
            "594/594 [==============================] - 0s 39us/sample - loss: 0.6073 - accuracy: 0.6667 - val_loss: 0.8311 - val_accuracy: 0.1667\n",
            "Epoch 79/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6061 - accuracy: 0.6658 - val_loss: 0.8305 - val_accuracy: 0.1667\n",
            "Epoch 80/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6055 - accuracy: 0.6641 - val_loss: 0.8232 - val_accuracy: 0.2500\n",
            "Epoch 81/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6047 - accuracy: 0.6726 - val_loss: 0.8234 - val_accuracy: 0.2500\n",
            "Epoch 82/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6045 - accuracy: 0.6700 - val_loss: 0.8200 - val_accuracy: 0.2500\n",
            "Epoch 83/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6037 - accuracy: 0.6717 - val_loss: 0.8226 - val_accuracy: 0.2500\n",
            "Epoch 84/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6034 - accuracy: 0.6700 - val_loss: 0.8214 - val_accuracy: 0.2500\n",
            "Epoch 85/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6037 - accuracy: 0.6759 - val_loss: 0.8292 - val_accuracy: 0.2500\n",
            "Epoch 86/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6027 - accuracy: 0.6742 - val_loss: 0.8334 - val_accuracy: 0.2500\n",
            "Epoch 87/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6023 - accuracy: 0.6641 - val_loss: 0.8287 - val_accuracy: 0.2500\n",
            "Epoch 88/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6015 - accuracy: 0.6751 - val_loss: 0.8335 - val_accuracy: 0.2500\n",
            "Epoch 89/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6005 - accuracy: 0.6759 - val_loss: 0.8316 - val_accuracy: 0.2500\n",
            "Epoch 90/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5997 - accuracy: 0.6759 - val_loss: 0.8341 - val_accuracy: 0.2500\n",
            "Epoch 91/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6004 - accuracy: 0.6793 - val_loss: 0.8386 - val_accuracy: 0.2500\n",
            "Epoch 92/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5991 - accuracy: 0.6734 - val_loss: 0.8368 - val_accuracy: 0.2500\n",
            "Epoch 93/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.5983 - accuracy: 0.6726 - val_loss: 0.8354 - val_accuracy: 0.2500\n",
            "Epoch 94/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5978 - accuracy: 0.6785 - val_loss: 0.8378 - val_accuracy: 0.2500\n",
            "Epoch 95/1000\n",
            "594/594 [==============================] - 0s 38us/sample - loss: 0.5978 - accuracy: 0.6801 - val_loss: 0.8441 - val_accuracy: 0.2500\n",
            "Epoch 96/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5976 - accuracy: 0.6700 - val_loss: 0.8352 - val_accuracy: 0.2500\n",
            "Epoch 97/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.5965 - accuracy: 0.6776 - val_loss: 0.8395 - val_accuracy: 0.2500\n",
            "Epoch 98/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5965 - accuracy: 0.6734 - val_loss: 0.8385 - val_accuracy: 0.2500\n",
            "Epoch 99/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5957 - accuracy: 0.6776 - val_loss: 0.8393 - val_accuracy: 0.2500\n",
            "Epoch 100/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5948 - accuracy: 0.6801 - val_loss: 0.8391 - val_accuracy: 0.2500\n",
            "Epoch 101/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5945 - accuracy: 0.6785 - val_loss: 0.8381 - val_accuracy: 0.2500\n",
            "Epoch 102/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5951 - accuracy: 0.6768 - val_loss: 0.8466 - val_accuracy: 0.1667\n",
            "Epoch 103/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5946 - accuracy: 0.6709 - val_loss: 0.8376 - val_accuracy: 0.2500\n",
            "Epoch 104/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.5928 - accuracy: 0.6768 - val_loss: 0.8399 - val_accuracy: 0.2500\n",
            "Epoch 105/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5925 - accuracy: 0.6709 - val_loss: 0.8397 - val_accuracy: 0.1667\n",
            "Epoch 106/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5917 - accuracy: 0.6692 - val_loss: 0.8412 - val_accuracy: 0.1667\n",
            "Epoch 107/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5912 - accuracy: 0.6684 - val_loss: 0.8384 - val_accuracy: 0.1667\n",
            "Epoch 108/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5900 - accuracy: 0.6726 - val_loss: 0.8452 - val_accuracy: 0.1667\n",
            "Epoch 109/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5893 - accuracy: 0.6726 - val_loss: 0.8508 - val_accuracy: 0.1667\n",
            "Epoch 110/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5887 - accuracy: 0.6692 - val_loss: 0.8456 - val_accuracy: 0.1667\n",
            "Epoch 111/1000\n",
            "594/594 [==============================] - 0s 20us/sample - loss: 0.5886 - accuracy: 0.6709 - val_loss: 0.8415 - val_accuracy: 0.1667\n",
            "Epoch 112/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.5882 - accuracy: 0.6793 - val_loss: 0.8526 - val_accuracy: 0.1667\n",
            "Epoch 113/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5869 - accuracy: 0.6759 - val_loss: 0.8530 - val_accuracy: 0.1667\n",
            "Epoch 114/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5861 - accuracy: 0.6759 - val_loss: 0.8451 - val_accuracy: 0.1667\n",
            "Epoch 115/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5856 - accuracy: 0.6717 - val_loss: 0.8440 - val_accuracy: 0.1667\n",
            "Epoch 116/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5855 - accuracy: 0.6700 - val_loss: 0.8486 - val_accuracy: 0.1667\n",
            "Epoch 117/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5849 - accuracy: 0.6776 - val_loss: 0.8394 - val_accuracy: 0.1667\n",
            "Epoch 118/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5840 - accuracy: 0.6776 - val_loss: 0.8378 - val_accuracy: 0.1667\n",
            "Epoch 119/1000\n",
            "594/594 [==============================] - 0s 34us/sample - loss: 0.5837 - accuracy: 0.6751 - val_loss: 0.8394 - val_accuracy: 0.2500\n",
            "Epoch 120/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.5863 - accuracy: 0.6633 - val_loss: 0.8299 - val_accuracy: 0.2500\n",
            "Epoch 121/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.5823 - accuracy: 0.6726 - val_loss: 0.8353 - val_accuracy: 0.2500\n",
            "Epoch 122/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.5815 - accuracy: 0.6751 - val_loss: 0.8388 - val_accuracy: 0.2500\n",
            "Epoch 123/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5812 - accuracy: 0.6709 - val_loss: 0.8351 - val_accuracy: 0.2500\n",
            "Epoch 124/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.5802 - accuracy: 0.6751 - val_loss: 0.8385 - val_accuracy: 0.2500\n",
            "Epoch 125/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5802 - accuracy: 0.6759 - val_loss: 0.8379 - val_accuracy: 0.2500\n",
            "Epoch 126/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5795 - accuracy: 0.6709 - val_loss: 0.8468 - val_accuracy: 0.1667\n",
            "Epoch 127/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5792 - accuracy: 0.6759 - val_loss: 0.8506 - val_accuracy: 0.1667\n",
            "Epoch 128/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5783 - accuracy: 0.6726 - val_loss: 0.8508 - val_accuracy: 0.1667\n",
            "Epoch 129/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5777 - accuracy: 0.6734 - val_loss: 0.8441 - val_accuracy: 0.1667\n",
            "Epoch 130/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5808 - accuracy: 0.6726 - val_loss: 0.8564 - val_accuracy: 0.1667\n",
            "Epoch 131/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5769 - accuracy: 0.6776 - val_loss: 0.8519 - val_accuracy: 0.1667\n",
            "Epoch 132/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5755 - accuracy: 0.6734 - val_loss: 0.8440 - val_accuracy: 0.2500\n",
            "Epoch 133/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5763 - accuracy: 0.6692 - val_loss: 0.8487 - val_accuracy: 0.1667\n",
            "Epoch 134/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5745 - accuracy: 0.6700 - val_loss: 0.8428 - val_accuracy: 0.3333\n",
            "Epoch 135/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5762 - accuracy: 0.6684 - val_loss: 0.8348 - val_accuracy: 0.3333\n",
            "Epoch 136/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5750 - accuracy: 0.6751 - val_loss: 0.8406 - val_accuracy: 0.3333\n",
            "Epoch 137/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5726 - accuracy: 0.6650 - val_loss: 0.8436 - val_accuracy: 0.3333\n",
            "Epoch 138/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5722 - accuracy: 0.6684 - val_loss: 0.8388 - val_accuracy: 0.3333\n",
            "Epoch 139/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5722 - accuracy: 0.6717 - val_loss: 0.8521 - val_accuracy: 0.2500\n",
            "Epoch 140/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5708 - accuracy: 0.6667 - val_loss: 0.8446 - val_accuracy: 0.3333\n",
            "Epoch 141/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5732 - accuracy: 0.6742 - val_loss: 0.8635 - val_accuracy: 0.1667\n",
            "Epoch 142/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5700 - accuracy: 0.6667 - val_loss: 0.8490 - val_accuracy: 0.3333\n",
            "Epoch 143/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5705 - accuracy: 0.6684 - val_loss: 0.8456 - val_accuracy: 0.3333\n",
            "Epoch 144/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5692 - accuracy: 0.6684 - val_loss: 0.8542 - val_accuracy: 0.2500\n",
            "Epoch 145/1000\n",
            "297/594 [==============>...............] - ETA: 0s - loss: 0.5600 - accuracy: 0.6869\n",
            "Epoch 00145: ReduceLROnPlateau reducing learning rate to 0.5.\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5695 - accuracy: 0.6742 - val_loss: 0.8562 - val_accuracy: 0.2500\n",
            "Epoch 146/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5675 - accuracy: 0.6658 - val_loss: 0.8507 - val_accuracy: 0.3333\n",
            "Epoch 147/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5670 - accuracy: 0.6658 - val_loss: 0.8481 - val_accuracy: 0.3333\n",
            "Epoch 148/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5669 - accuracy: 0.6616 - val_loss: 0.8500 - val_accuracy: 0.3333\n",
            "Epoch 149/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5663 - accuracy: 0.6641 - val_loss: 0.8471 - val_accuracy: 0.3333\n",
            "Epoch 150/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5661 - accuracy: 0.6641 - val_loss: 0.8475 - val_accuracy: 0.3333\n",
            "Epoch 151/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.5659 - accuracy: 0.6616 - val_loss: 0.8441 - val_accuracy: 0.3333\n",
            "Epoch 152/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.5653 - accuracy: 0.6658 - val_loss: 0.8424 - val_accuracy: 0.3333\n",
            "Epoch 153/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5654 - accuracy: 0.6658 - val_loss: 0.8392 - val_accuracy: 0.3333\n",
            "Epoch 154/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5651 - accuracy: 0.6658 - val_loss: 0.8417 - val_accuracy: 0.3333\n",
            "Epoch 155/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5648 - accuracy: 0.6785 - val_loss: 0.8438 - val_accuracy: 0.3333\n",
            "Epoch 156/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5641 - accuracy: 0.6658 - val_loss: 0.8419 - val_accuracy: 0.3333\n",
            "Epoch 157/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.5637 - accuracy: 0.6633 - val_loss: 0.8417 - val_accuracy: 0.3333\n",
            "Epoch 158/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5635 - accuracy: 0.6734 - val_loss: 0.8424 - val_accuracy: 0.3333\n",
            "Epoch 159/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5630 - accuracy: 0.6667 - val_loss: 0.8427 - val_accuracy: 0.3333\n",
            "Epoch 160/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5634 - accuracy: 0.6684 - val_loss: 0.8405 - val_accuracy: 0.3333\n",
            "Epoch 161/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5626 - accuracy: 0.6684 - val_loss: 0.8425 - val_accuracy: 0.3333\n",
            "Epoch 162/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5625 - accuracy: 0.6675 - val_loss: 0.8391 - val_accuracy: 0.3333\n",
            "Epoch 163/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5619 - accuracy: 0.6717 - val_loss: 0.8390 - val_accuracy: 0.3333\n",
            "Epoch 164/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5615 - accuracy: 0.6726 - val_loss: 0.8399 - val_accuracy: 0.3333\n",
            "Epoch 165/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5621 - accuracy: 0.6709 - val_loss: 0.8366 - val_accuracy: 0.3333\n",
            "Epoch 166/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5610 - accuracy: 0.6726 - val_loss: 0.8363 - val_accuracy: 0.3333\n",
            "Epoch 167/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5607 - accuracy: 0.6759 - val_loss: 0.8394 - val_accuracy: 0.3333\n",
            "Epoch 168/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5607 - accuracy: 0.6751 - val_loss: 0.8368 - val_accuracy: 0.3333\n",
            "Epoch 169/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5609 - accuracy: 0.6700 - val_loss: 0.8353 - val_accuracy: 0.3333\n",
            "Epoch 170/1000\n",
            "594/594 [==============================] - 0s 20us/sample - loss: 0.5597 - accuracy: 0.6785 - val_loss: 0.8378 - val_accuracy: 0.3333\n",
            "Epoch 171/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5595 - accuracy: 0.6776 - val_loss: 0.8391 - val_accuracy: 0.3333\n",
            "Epoch 172/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5599 - accuracy: 0.6684 - val_loss: 0.8368 - val_accuracy: 0.3333\n",
            "Epoch 173/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5593 - accuracy: 0.6869 - val_loss: 0.8371 - val_accuracy: 0.3333\n",
            "Epoch 174/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5588 - accuracy: 0.6751 - val_loss: 0.8361 - val_accuracy: 0.3333\n",
            "Epoch 175/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5587 - accuracy: 0.6827 - val_loss: 0.8364 - val_accuracy: 0.3333\n",
            "Epoch 176/1000\n",
            "594/594 [==============================] - 0s 20us/sample - loss: 0.5582 - accuracy: 0.6768 - val_loss: 0.8359 - val_accuracy: 0.3333\n",
            "Epoch 177/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5581 - accuracy: 0.6818 - val_loss: 0.8388 - val_accuracy: 0.3333\n",
            "Epoch 178/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5576 - accuracy: 0.6827 - val_loss: 0.8369 - val_accuracy: 0.3333\n",
            "Epoch 179/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.5574 - accuracy: 0.6843 - val_loss: 0.8384 - val_accuracy: 0.3333\n",
            "Epoch 180/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5570 - accuracy: 0.6886 - val_loss: 0.8405 - val_accuracy: 0.3333\n",
            "Epoch 181/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5575 - accuracy: 0.6877 - val_loss: 0.8444 - val_accuracy: 0.3333\n",
            "Epoch 182/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.5566 - accuracy: 0.6886 - val_loss: 0.8429 - val_accuracy: 0.3333\n",
            "Epoch 183/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5562 - accuracy: 0.6818 - val_loss: 0.8409 - val_accuracy: 0.3333\n",
            "Epoch 184/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5562 - accuracy: 0.6860 - val_loss: 0.8423 - val_accuracy: 0.3333\n",
            "Epoch 185/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5562 - accuracy: 0.6835 - val_loss: 0.8371 - val_accuracy: 0.3333\n",
            "Epoch 186/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5559 - accuracy: 0.6852 - val_loss: 0.8385 - val_accuracy: 0.3333\n",
            "Epoch 187/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.5557 - accuracy: 0.6843 - val_loss: 0.8385 - val_accuracy: 0.4167\n",
            "Epoch 188/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5548 - accuracy: 0.6877 - val_loss: 0.8391 - val_accuracy: 0.4167\n",
            "Epoch 189/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5549 - accuracy: 0.6843 - val_loss: 0.8376 - val_accuracy: 0.4167\n",
            "Epoch 190/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5544 - accuracy: 0.6869 - val_loss: 0.8402 - val_accuracy: 0.4167\n",
            "Epoch 191/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5540 - accuracy: 0.6860 - val_loss: 0.8386 - val_accuracy: 0.4167\n",
            "Epoch 192/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5539 - accuracy: 0.6843 - val_loss: 0.8378 - val_accuracy: 0.4167\n",
            "Epoch 193/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5537 - accuracy: 0.6860 - val_loss: 0.8369 - val_accuracy: 0.4167\n",
            "Epoch 194/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5536 - accuracy: 0.6843 - val_loss: 0.8406 - val_accuracy: 0.4167\n",
            "Epoch 195/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5530 - accuracy: 0.6843 - val_loss: 0.8395 - val_accuracy: 0.4167\n",
            "Epoch 196/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5528 - accuracy: 0.6852 - val_loss: 0.8368 - val_accuracy: 0.4167\n",
            "Epoch 197/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5526 - accuracy: 0.6835 - val_loss: 0.8356 - val_accuracy: 0.4167\n",
            "Epoch 198/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.5523 - accuracy: 0.6894 - val_loss: 0.8402 - val_accuracy: 0.4167\n",
            "Epoch 199/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5519 - accuracy: 0.6827 - val_loss: 0.8413 - val_accuracy: 0.4167\n",
            "Epoch 200/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.5518 - accuracy: 0.6835 - val_loss: 0.8394 - val_accuracy: 0.4167\n",
            "Epoch 201/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5513 - accuracy: 0.6827 - val_loss: 0.8400 - val_accuracy: 0.4167\n",
            "Epoch 202/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5524 - accuracy: 0.6759 - val_loss: 0.8403 - val_accuracy: 0.4167\n",
            "Epoch 203/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.5507 - accuracy: 0.6843 - val_loss: 0.8405 - val_accuracy: 0.4167\n",
            "Epoch 204/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5507 - accuracy: 0.6852 - val_loss: 0.8396 - val_accuracy: 0.4167\n",
            "Epoch 205/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5503 - accuracy: 0.6801 - val_loss: 0.8381 - val_accuracy: 0.4167\n",
            "Epoch 206/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5502 - accuracy: 0.6843 - val_loss: 0.8380 - val_accuracy: 0.4167\n",
            "Epoch 207/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5499 - accuracy: 0.6835 - val_loss: 0.8364 - val_accuracy: 0.4167\n",
            "Epoch 208/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5492 - accuracy: 0.6827 - val_loss: 0.8380 - val_accuracy: 0.4167\n",
            "Epoch 209/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5495 - accuracy: 0.6843 - val_loss: 0.8417 - val_accuracy: 0.4167\n",
            "Epoch 210/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5488 - accuracy: 0.6835 - val_loss: 0.8373 - val_accuracy: 0.4167\n",
            "Epoch 211/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5491 - accuracy: 0.6843 - val_loss: 0.8388 - val_accuracy: 0.3333\n",
            "Epoch 212/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5483 - accuracy: 0.6801 - val_loss: 0.8371 - val_accuracy: 0.3333\n",
            "Epoch 213/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5481 - accuracy: 0.6801 - val_loss: 0.8375 - val_accuracy: 0.4167\n",
            "Epoch 214/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5482 - accuracy: 0.6860 - val_loss: 0.8369 - val_accuracy: 0.3333\n",
            "Epoch 215/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5476 - accuracy: 0.6835 - val_loss: 0.8351 - val_accuracy: 0.3333\n",
            "Epoch 216/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5478 - accuracy: 0.6843 - val_loss: 0.8369 - val_accuracy: 0.3333\n",
            "Epoch 217/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5472 - accuracy: 0.6843 - val_loss: 0.8374 - val_accuracy: 0.3333\n",
            "Epoch 218/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5470 - accuracy: 0.6860 - val_loss: 0.8389 - val_accuracy: 0.3333\n",
            "Epoch 219/1000\n",
            "594/594 [==============================] - 0s 35us/sample - loss: 0.5464 - accuracy: 0.6852 - val_loss: 0.8360 - val_accuracy: 0.3333\n",
            "Epoch 220/1000\n",
            "594/594 [==============================] - 0s 33us/sample - loss: 0.5469 - accuracy: 0.6877 - val_loss: 0.8391 - val_accuracy: 0.3333\n",
            "Epoch 221/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5465 - accuracy: 0.6860 - val_loss: 0.8341 - val_accuracy: 0.3333\n",
            "Epoch 222/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5458 - accuracy: 0.6835 - val_loss: 0.8333 - val_accuracy: 0.3333\n",
            "Epoch 223/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5456 - accuracy: 0.6894 - val_loss: 0.8323 - val_accuracy: 0.3333\n",
            "Epoch 224/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5452 - accuracy: 0.6894 - val_loss: 0.8366 - val_accuracy: 0.3333\n",
            "Epoch 225/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5449 - accuracy: 0.6894 - val_loss: 0.8358 - val_accuracy: 0.3333\n",
            "Epoch 226/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.5452 - accuracy: 0.6902 - val_loss: 0.8367 - val_accuracy: 0.3333\n",
            "Epoch 227/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.5443 - accuracy: 0.6894 - val_loss: 0.8350 - val_accuracy: 0.3333\n",
            "Epoch 228/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5449 - accuracy: 0.6911 - val_loss: 0.8362 - val_accuracy: 0.3333\n",
            "Epoch 229/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5441 - accuracy: 0.6911 - val_loss: 0.8378 - val_accuracy: 0.3333\n",
            "Epoch 230/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5442 - accuracy: 0.6928 - val_loss: 0.8389 - val_accuracy: 0.3333\n",
            "Epoch 231/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5433 - accuracy: 0.6894 - val_loss: 0.8350 - val_accuracy: 0.4167\n",
            "Epoch 232/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5433 - accuracy: 0.6919 - val_loss: 0.8351 - val_accuracy: 0.4167\n",
            "Epoch 233/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5448 - accuracy: 0.6919 - val_loss: 0.8417 - val_accuracy: 0.4167\n",
            "Epoch 234/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5426 - accuracy: 0.6894 - val_loss: 0.8361 - val_accuracy: 0.4167\n",
            "Epoch 235/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5424 - accuracy: 0.6919 - val_loss: 0.8340 - val_accuracy: 0.4167\n",
            "Epoch 236/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5425 - accuracy: 0.6902 - val_loss: 0.8300 - val_accuracy: 0.4167\n",
            "Epoch 237/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5429 - accuracy: 0.6894 - val_loss: 0.8372 - val_accuracy: 0.4167\n",
            "Epoch 238/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.5424 - accuracy: 0.6902 - val_loss: 0.8324 - val_accuracy: 0.4167\n",
            "Epoch 239/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5416 - accuracy: 0.6894 - val_loss: 0.8321 - val_accuracy: 0.4167\n",
            "Epoch 240/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5417 - accuracy: 0.6911 - val_loss: 0.8326 - val_accuracy: 0.4167\n",
            "Epoch 241/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5409 - accuracy: 0.6902 - val_loss: 0.8299 - val_accuracy: 0.4167\n",
            "Epoch 242/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5406 - accuracy: 0.6953 - val_loss: 0.8310 - val_accuracy: 0.4167\n",
            "Epoch 243/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5407 - accuracy: 0.6919 - val_loss: 0.8316 - val_accuracy: 0.4167\n",
            "Epoch 244/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5400 - accuracy: 0.6936 - val_loss: 0.8302 - val_accuracy: 0.4167\n",
            "Epoch 245/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.5426 - accuracy: 0.6911 - val_loss: 0.8216 - val_accuracy: 0.5000\n",
            "Epoch 246/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5396 - accuracy: 0.6970 - val_loss: 0.8265 - val_accuracy: 0.5000\n",
            "Epoch 247/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5394 - accuracy: 0.6987 - val_loss: 0.8289 - val_accuracy: 0.5000\n",
            "Epoch 248/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5396 - accuracy: 0.6995 - val_loss: 0.8307 - val_accuracy: 0.3333\n",
            "Epoch 249/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.5390 - accuracy: 0.6970 - val_loss: 0.8297 - val_accuracy: 0.3333\n",
            "Epoch 250/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5394 - accuracy: 0.6928 - val_loss: 0.8259 - val_accuracy: 0.5000\n",
            "Epoch 251/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5390 - accuracy: 0.6911 - val_loss: 0.8246 - val_accuracy: 0.5000\n",
            "Epoch 252/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5393 - accuracy: 0.6936 - val_loss: 0.8324 - val_accuracy: 0.4167\n",
            "Epoch 253/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.5381 - accuracy: 0.6944 - val_loss: 0.8303 - val_accuracy: 0.5000\n",
            "Epoch 254/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5391 - accuracy: 0.6919 - val_loss: 0.8356 - val_accuracy: 0.4167\n",
            "Epoch 255/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5383 - accuracy: 0.6928 - val_loss: 0.8334 - val_accuracy: 0.4167\n",
            "Epoch 256/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5374 - accuracy: 0.6944 - val_loss: 0.8285 - val_accuracy: 0.4167\n",
            "Epoch 257/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5378 - accuracy: 0.6944 - val_loss: 0.8274 - val_accuracy: 0.4167\n",
            "Epoch 258/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.5375 - accuracy: 0.6944 - val_loss: 0.8314 - val_accuracy: 0.4167\n",
            "Epoch 259/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5368 - accuracy: 0.6970 - val_loss: 0.8319 - val_accuracy: 0.4167\n",
            "Epoch 260/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5364 - accuracy: 0.6953 - val_loss: 0.8280 - val_accuracy: 0.4167\n",
            "Epoch 261/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5361 - accuracy: 0.6978 - val_loss: 0.8282 - val_accuracy: 0.4167\n",
            "Epoch 262/1000\n",
            "594/594 [==============================] - 0s 33us/sample - loss: 0.5359 - accuracy: 0.6936 - val_loss: 0.8295 - val_accuracy: 0.5000\n",
            "Epoch 263/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5359 - accuracy: 0.6978 - val_loss: 0.8325 - val_accuracy: 0.5000\n",
            "Epoch 264/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5368 - accuracy: 0.6919 - val_loss: 0.8255 - val_accuracy: 0.5000\n",
            "Epoch 265/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.5358 - accuracy: 0.6995 - val_loss: 0.8321 - val_accuracy: 0.5000\n",
            "Epoch 266/1000\n",
            "594/594 [==============================] - 0s 34us/sample - loss: 0.5354 - accuracy: 0.6970 - val_loss: 0.8279 - val_accuracy: 0.5000\n",
            "Epoch 267/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5350 - accuracy: 0.6944 - val_loss: 0.8272 - val_accuracy: 0.5000\n",
            "Epoch 268/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.5356 - accuracy: 0.6961 - val_loss: 0.8251 - val_accuracy: 0.5000\n",
            "Epoch 269/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.5362 - accuracy: 0.6919 - val_loss: 0.8332 - val_accuracy: 0.5000\n",
            "Epoch 270/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5349 - accuracy: 0.6944 - val_loss: 0.8349 - val_accuracy: 0.5000\n",
            "Epoch 271/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5342 - accuracy: 0.6944 - val_loss: 0.8289 - val_accuracy: 0.5000\n",
            "Epoch 272/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5339 - accuracy: 0.6970 - val_loss: 0.8268 - val_accuracy: 0.5000\n",
            "Epoch 273/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5335 - accuracy: 0.6970 - val_loss: 0.8252 - val_accuracy: 0.5000\n",
            "Epoch 274/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5333 - accuracy: 0.6995 - val_loss: 0.8239 - val_accuracy: 0.5000\n",
            "Epoch 275/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5332 - accuracy: 0.6978 - val_loss: 0.8256 - val_accuracy: 0.5000\n",
            "Epoch 276/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5331 - accuracy: 0.6970 - val_loss: 0.8234 - val_accuracy: 0.5000\n",
            "Epoch 277/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5335 - accuracy: 0.6987 - val_loss: 0.8226 - val_accuracy: 0.5000\n",
            "Epoch 278/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.5327 - accuracy: 0.6995 - val_loss: 0.8259 - val_accuracy: 0.5000\n",
            "Epoch 279/1000\n",
            "594/594 [==============================] - 0s 33us/sample - loss: 0.5332 - accuracy: 0.6928 - val_loss: 0.8239 - val_accuracy: 0.5000\n",
            "Epoch 280/1000\n",
            "594/594 [==============================] - 0s 33us/sample - loss: 0.5323 - accuracy: 0.6987 - val_loss: 0.8274 - val_accuracy: 0.5000\n",
            "Epoch 281/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.5317 - accuracy: 0.6978 - val_loss: 0.8257 - val_accuracy: 0.5000\n",
            "Epoch 282/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.5320 - accuracy: 0.6995 - val_loss: 0.8270 - val_accuracy: 0.5000\n",
            "Epoch 283/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.5318 - accuracy: 0.6978 - val_loss: 0.8227 - val_accuracy: 0.5000\n",
            "Epoch 284/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5321 - accuracy: 0.6987 - val_loss: 0.8286 - val_accuracy: 0.5000\n",
            "Epoch 285/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5308 - accuracy: 0.6987 - val_loss: 0.8277 - val_accuracy: 0.5000\n",
            "Epoch 286/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5309 - accuracy: 0.7012 - val_loss: 0.8268 - val_accuracy: 0.5000\n",
            "Epoch 287/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5320 - accuracy: 0.7012 - val_loss: 0.8322 - val_accuracy: 0.5000\n",
            "Epoch 288/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5305 - accuracy: 0.6961 - val_loss: 0.8267 - val_accuracy: 0.5000\n",
            "Epoch 289/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.5304 - accuracy: 0.7012 - val_loss: 0.8282 - val_accuracy: 0.5000\n",
            "Epoch 290/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.5298 - accuracy: 0.6987 - val_loss: 0.8291 - val_accuracy: 0.5000\n",
            "Epoch 291/1000\n",
            "594/594 [==============================] - 0s 33us/sample - loss: 0.5305 - accuracy: 0.6995 - val_loss: 0.8237 - val_accuracy: 0.5000\n",
            "Epoch 292/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.5298 - accuracy: 0.6961 - val_loss: 0.8288 - val_accuracy: 0.5000\n",
            "Epoch 293/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.5301 - accuracy: 0.6970 - val_loss: 0.8261 - val_accuracy: 0.5000\n",
            "Epoch 294/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5290 - accuracy: 0.7012 - val_loss: 0.8259 - val_accuracy: 0.5000\n",
            "Epoch 295/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5288 - accuracy: 0.6995 - val_loss: 0.8280 - val_accuracy: 0.5000\n",
            "Epoch 296/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5289 - accuracy: 0.6978 - val_loss: 0.8241 - val_accuracy: 0.5000\n",
            "Epoch 297/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5287 - accuracy: 0.6978 - val_loss: 0.8266 - val_accuracy: 0.5000\n",
            "Epoch 298/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.5283 - accuracy: 0.6995 - val_loss: 0.8260 - val_accuracy: 0.5000\n",
            "Epoch 299/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.5290 - accuracy: 0.6987 - val_loss: 0.8242 - val_accuracy: 0.5000\n",
            "Epoch 300/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5280 - accuracy: 0.6970 - val_loss: 0.8253 - val_accuracy: 0.5000\n",
            "Epoch 301/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5276 - accuracy: 0.7012 - val_loss: 0.8251 - val_accuracy: 0.5000\n",
            "Epoch 302/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.5288 - accuracy: 0.6970 - val_loss: 0.8267 - val_accuracy: 0.5000\n",
            "Epoch 303/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5283 - accuracy: 0.6961 - val_loss: 0.8253 - val_accuracy: 0.5000\n",
            "Epoch 304/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5271 - accuracy: 0.6970 - val_loss: 0.8238 - val_accuracy: 0.5000\n",
            "Epoch 305/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5270 - accuracy: 0.6995 - val_loss: 0.8288 - val_accuracy: 0.5000\n",
            "Epoch 306/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.5273 - accuracy: 0.6944 - val_loss: 0.8240 - val_accuracy: 0.5000\n",
            "Epoch 307/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5266 - accuracy: 0.6987 - val_loss: 0.8274 - val_accuracy: 0.5000\n",
            "Epoch 308/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5264 - accuracy: 0.7020 - val_loss: 0.8313 - val_accuracy: 0.5000\n",
            "Epoch 309/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5269 - accuracy: 0.6987 - val_loss: 0.8310 - val_accuracy: 0.5000\n",
            "Epoch 310/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5261 - accuracy: 0.6995 - val_loss: 0.8318 - val_accuracy: 0.5000\n",
            "Epoch 311/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5257 - accuracy: 0.6970 - val_loss: 0.8319 - val_accuracy: 0.5000\n",
            "Epoch 312/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5252 - accuracy: 0.6987 - val_loss: 0.8304 - val_accuracy: 0.5000\n",
            "Epoch 313/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5251 - accuracy: 0.7003 - val_loss: 0.8317 - val_accuracy: 0.5000\n",
            "Epoch 314/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5256 - accuracy: 0.6970 - val_loss: 0.8301 - val_accuracy: 0.5000\n",
            "Epoch 315/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.5247 - accuracy: 0.7045 - val_loss: 0.8277 - val_accuracy: 0.5000\n",
            "Epoch 316/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5247 - accuracy: 0.6987 - val_loss: 0.8318 - val_accuracy: 0.5000\n",
            "Epoch 317/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.5247 - accuracy: 0.6978 - val_loss: 0.8343 - val_accuracy: 0.5000\n",
            "Epoch 318/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5241 - accuracy: 0.7029 - val_loss: 0.8300 - val_accuracy: 0.5000\n",
            "Epoch 319/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5247 - accuracy: 0.7045 - val_loss: 0.8287 - val_accuracy: 0.5000\n",
            "Epoch 320/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5238 - accuracy: 0.6970 - val_loss: 0.8274 - val_accuracy: 0.5000\n",
            "Epoch 321/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.5251 - accuracy: 0.6911 - val_loss: 0.8273 - val_accuracy: 0.5000\n",
            "Epoch 322/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5239 - accuracy: 0.6995 - val_loss: 0.8232 - val_accuracy: 0.5000\n",
            "Epoch 323/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5237 - accuracy: 0.7029 - val_loss: 0.8229 - val_accuracy: 0.5000\n",
            "Epoch 324/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5229 - accuracy: 0.7037 - val_loss: 0.8293 - val_accuracy: 0.5000\n",
            "Epoch 325/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5229 - accuracy: 0.6928 - val_loss: 0.8297 - val_accuracy: 0.5000\n",
            "Epoch 326/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5232 - accuracy: 0.7037 - val_loss: 0.8350 - val_accuracy: 0.5000\n",
            "Epoch 327/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5224 - accuracy: 0.7045 - val_loss: 0.8304 - val_accuracy: 0.5000\n",
            "Epoch 328/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5221 - accuracy: 0.7029 - val_loss: 0.8308 - val_accuracy: 0.5000\n",
            "Epoch 329/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.5219 - accuracy: 0.6970 - val_loss: 0.8297 - val_accuracy: 0.5000\n",
            "Epoch 330/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5217 - accuracy: 0.6995 - val_loss: 0.8260 - val_accuracy: 0.5000\n",
            "Epoch 331/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.5222 - accuracy: 0.6944 - val_loss: 0.8225 - val_accuracy: 0.5000\n",
            "Epoch 332/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5215 - accuracy: 0.7020 - val_loss: 0.8208 - val_accuracy: 0.5000\n",
            "Epoch 333/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5215 - accuracy: 0.7003 - val_loss: 0.8304 - val_accuracy: 0.5000\n",
            "Epoch 334/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5213 - accuracy: 0.6987 - val_loss: 0.8247 - val_accuracy: 0.5000\n",
            "Epoch 335/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5206 - accuracy: 0.7012 - val_loss: 0.8306 - val_accuracy: 0.5000\n",
            "Epoch 336/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5205 - accuracy: 0.6987 - val_loss: 0.8265 - val_accuracy: 0.5000\n",
            "Epoch 337/1000\n",
            "594/594 [==============================] - 0s 40us/sample - loss: 0.5202 - accuracy: 0.7003 - val_loss: 0.8270 - val_accuracy: 0.5000\n",
            "Epoch 338/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5202 - accuracy: 0.7012 - val_loss: 0.8298 - val_accuracy: 0.5000\n",
            "Epoch 339/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5198 - accuracy: 0.7020 - val_loss: 0.8266 - val_accuracy: 0.5000\n",
            "Epoch 340/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.5195 - accuracy: 0.7003 - val_loss: 0.8262 - val_accuracy: 0.5000\n",
            "Epoch 341/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5197 - accuracy: 0.6970 - val_loss: 0.8276 - val_accuracy: 0.5000\n",
            "Epoch 342/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5192 - accuracy: 0.7045 - val_loss: 0.8300 - val_accuracy: 0.5000\n",
            "Epoch 343/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5198 - accuracy: 0.7012 - val_loss: 0.8219 - val_accuracy: 0.5000\n",
            "Epoch 344/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.5207 - accuracy: 0.7045 - val_loss: 0.8329 - val_accuracy: 0.5000\n",
            "Epoch 345/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5194 - accuracy: 0.7037 - val_loss: 0.8320 - val_accuracy: 0.5000\n",
            "Epoch 346/1000\n",
            "594/594 [==============================] - 0s 34us/sample - loss: 0.5183 - accuracy: 0.6995 - val_loss: 0.8317 - val_accuracy: 0.5000\n",
            "Epoch 347/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5192 - accuracy: 0.6961 - val_loss: 0.8268 - val_accuracy: 0.5000\n",
            "Epoch 348/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5180 - accuracy: 0.7054 - val_loss: 0.8270 - val_accuracy: 0.5000\n",
            "Epoch 349/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5179 - accuracy: 0.7045 - val_loss: 0.8225 - val_accuracy: 0.5000\n",
            "Epoch 350/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.5178 - accuracy: 0.7071 - val_loss: 0.8236 - val_accuracy: 0.5000\n",
            "Epoch 351/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5178 - accuracy: 0.7045 - val_loss: 0.8240 - val_accuracy: 0.5000\n",
            "Epoch 352/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5175 - accuracy: 0.7045 - val_loss: 0.8290 - val_accuracy: 0.5000\n",
            "Epoch 353/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5185 - accuracy: 0.7029 - val_loss: 0.8339 - val_accuracy: 0.5000\n",
            "Epoch 354/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5171 - accuracy: 0.7003 - val_loss: 0.8324 - val_accuracy: 0.5000\n",
            "Epoch 355/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5176 - accuracy: 0.6978 - val_loss: 0.8226 - val_accuracy: 0.5000\n",
            "Epoch 356/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5171 - accuracy: 0.7054 - val_loss: 0.8168 - val_accuracy: 0.5000\n",
            "Epoch 357/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5167 - accuracy: 0.7020 - val_loss: 0.8252 - val_accuracy: 0.5000\n",
            "Epoch 358/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5172 - accuracy: 0.6978 - val_loss: 0.8233 - val_accuracy: 0.5000\n",
            "Epoch 359/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5166 - accuracy: 0.7062 - val_loss: 0.8229 - val_accuracy: 0.5000\n",
            "Epoch 360/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5166 - accuracy: 0.7045 - val_loss: 0.8325 - val_accuracy: 0.5000\n",
            "Epoch 361/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5162 - accuracy: 0.6995 - val_loss: 0.8338 - val_accuracy: 0.5000\n",
            "Epoch 362/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5152 - accuracy: 0.7045 - val_loss: 0.8244 - val_accuracy: 0.5000\n",
            "Epoch 363/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5150 - accuracy: 0.7130 - val_loss: 0.8269 - val_accuracy: 0.5000\n",
            "Epoch 364/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5162 - accuracy: 0.7079 - val_loss: 0.8367 - val_accuracy: 0.5000\n",
            "Epoch 365/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5145 - accuracy: 0.7045 - val_loss: 0.8295 - val_accuracy: 0.5000\n",
            "Epoch 366/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5145 - accuracy: 0.7029 - val_loss: 0.8221 - val_accuracy: 0.5000\n",
            "Epoch 367/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5141 - accuracy: 0.7130 - val_loss: 0.8259 - val_accuracy: 0.5000\n",
            "Epoch 368/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5139 - accuracy: 0.7037 - val_loss: 0.8250 - val_accuracy: 0.5000\n",
            "Epoch 369/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.5139 - accuracy: 0.7045 - val_loss: 0.8195 - val_accuracy: 0.5000\n",
            "Epoch 370/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.5141 - accuracy: 0.7054 - val_loss: 0.8186 - val_accuracy: 0.5000\n",
            "Epoch 371/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5134 - accuracy: 0.7088 - val_loss: 0.8235 - val_accuracy: 0.5000\n",
            "Epoch 372/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.5131 - accuracy: 0.7088 - val_loss: 0.8229 - val_accuracy: 0.5000\n",
            "Epoch 373/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5134 - accuracy: 0.7054 - val_loss: 0.8206 - val_accuracy: 0.5000\n",
            "Epoch 374/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5144 - accuracy: 0.7071 - val_loss: 0.8171 - val_accuracy: 0.5000\n",
            "Epoch 375/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5129 - accuracy: 0.7146 - val_loss: 0.8187 - val_accuracy: 0.5000\n",
            "Epoch 376/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5126 - accuracy: 0.7062 - val_loss: 0.8205 - val_accuracy: 0.5000\n",
            "Epoch 377/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5122 - accuracy: 0.7121 - val_loss: 0.8250 - val_accuracy: 0.5000\n",
            "Epoch 378/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5129 - accuracy: 0.7062 - val_loss: 0.8175 - val_accuracy: 0.5000\n",
            "Epoch 379/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5120 - accuracy: 0.7163 - val_loss: 0.8243 - val_accuracy: 0.5000\n",
            "Epoch 380/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5126 - accuracy: 0.7003 - val_loss: 0.8287 - val_accuracy: 0.5000\n",
            "Epoch 381/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.5116 - accuracy: 0.7172 - val_loss: 0.8262 - val_accuracy: 0.5000\n",
            "Epoch 382/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5118 - accuracy: 0.7096 - val_loss: 0.8199 - val_accuracy: 0.5000\n",
            "Epoch 383/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5113 - accuracy: 0.7146 - val_loss: 0.8235 - val_accuracy: 0.5000\n",
            "Epoch 384/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5113 - accuracy: 0.7121 - val_loss: 0.8270 - val_accuracy: 0.5000\n",
            "Epoch 385/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5114 - accuracy: 0.7062 - val_loss: 0.8260 - val_accuracy: 0.5000\n",
            "Epoch 386/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.5116 - accuracy: 0.7138 - val_loss: 0.8226 - val_accuracy: 0.5000\n",
            "Epoch 387/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5106 - accuracy: 0.7113 - val_loss: 0.8206 - val_accuracy: 0.5000\n",
            "Epoch 388/1000\n",
            "594/594 [==============================] - 0s 33us/sample - loss: 0.5102 - accuracy: 0.7163 - val_loss: 0.8216 - val_accuracy: 0.5000\n",
            "Epoch 389/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5111 - accuracy: 0.7096 - val_loss: 0.8212 - val_accuracy: 0.5000\n",
            "Epoch 390/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5110 - accuracy: 0.7121 - val_loss: 0.8273 - val_accuracy: 0.5000\n",
            "Epoch 391/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5100 - accuracy: 0.7146 - val_loss: 0.8222 - val_accuracy: 0.5000\n",
            "Epoch 392/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5106 - accuracy: 0.7138 - val_loss: 0.8218 - val_accuracy: 0.5000\n",
            "Epoch 393/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5099 - accuracy: 0.7163 - val_loss: 0.8209 - val_accuracy: 0.5000\n",
            "Epoch 394/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5097 - accuracy: 0.7155 - val_loss: 0.8206 - val_accuracy: 0.5000\n",
            "Epoch 395/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5091 - accuracy: 0.7146 - val_loss: 0.8226 - val_accuracy: 0.5000\n",
            "Epoch 396/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5121 - accuracy: 0.7155 - val_loss: 0.8348 - val_accuracy: 0.5000\n",
            "Epoch 397/1000\n",
            "594/594 [==============================] - 0s 38us/sample - loss: 0.5090 - accuracy: 0.7146 - val_loss: 0.8266 - val_accuracy: 0.5000\n",
            "Epoch 398/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5088 - accuracy: 0.7197 - val_loss: 0.8224 - val_accuracy: 0.5000\n",
            "Epoch 399/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5091 - accuracy: 0.7138 - val_loss: 0.8212 - val_accuracy: 0.5000\n",
            "Epoch 400/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5091 - accuracy: 0.7138 - val_loss: 0.8231 - val_accuracy: 0.5000\n",
            "Epoch 401/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5086 - accuracy: 0.7130 - val_loss: 0.8164 - val_accuracy: 0.5000\n",
            "Epoch 402/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.5082 - accuracy: 0.7155 - val_loss: 0.8196 - val_accuracy: 0.5000\n",
            "Epoch 403/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5079 - accuracy: 0.7180 - val_loss: 0.8218 - val_accuracy: 0.5000\n",
            "Epoch 404/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5085 - accuracy: 0.7130 - val_loss: 0.8282 - val_accuracy: 0.5000\n",
            "Epoch 405/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.5081 - accuracy: 0.7163 - val_loss: 0.8271 - val_accuracy: 0.5000\n",
            "Epoch 406/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5080 - accuracy: 0.7096 - val_loss: 0.8233 - val_accuracy: 0.5000\n",
            "Epoch 407/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.5074 - accuracy: 0.7197 - val_loss: 0.8204 - val_accuracy: 0.5000\n",
            "Epoch 408/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5069 - accuracy: 0.7155 - val_loss: 0.8214 - val_accuracy: 0.5000\n",
            "Epoch 409/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5069 - accuracy: 0.7197 - val_loss: 0.8199 - val_accuracy: 0.5000\n",
            "Epoch 410/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5071 - accuracy: 0.7138 - val_loss: 0.8238 - val_accuracy: 0.5000\n",
            "Epoch 411/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5074 - accuracy: 0.7163 - val_loss: 0.8177 - val_accuracy: 0.5000\n",
            "Epoch 412/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5064 - accuracy: 0.7214 - val_loss: 0.8202 - val_accuracy: 0.5000\n",
            "Epoch 413/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5061 - accuracy: 0.7163 - val_loss: 0.8197 - val_accuracy: 0.5000\n",
            "Epoch 414/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5061 - accuracy: 0.7172 - val_loss: 0.8235 - val_accuracy: 0.5000\n",
            "Epoch 415/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5067 - accuracy: 0.7189 - val_loss: 0.8264 - val_accuracy: 0.5000\n",
            "Epoch 416/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5069 - accuracy: 0.7155 - val_loss: 0.8166 - val_accuracy: 0.5000\n",
            "Epoch 417/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5059 - accuracy: 0.7155 - val_loss: 0.8190 - val_accuracy: 0.5000\n",
            "Epoch 418/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5062 - accuracy: 0.7189 - val_loss: 0.8266 - val_accuracy: 0.5000\n",
            "Epoch 419/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5063 - accuracy: 0.7256 - val_loss: 0.8178 - val_accuracy: 0.5000\n",
            "Epoch 420/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5065 - accuracy: 0.7138 - val_loss: 0.8297 - val_accuracy: 0.5000\n",
            "Epoch 421/1000\n",
            "594/594 [==============================] - 0s 20us/sample - loss: 0.5053 - accuracy: 0.7222 - val_loss: 0.8253 - val_accuracy: 0.5000\n",
            "Epoch 422/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5066 - accuracy: 0.7222 - val_loss: 0.8294 - val_accuracy: 0.5000\n",
            "Epoch 423/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5053 - accuracy: 0.7222 - val_loss: 0.8205 - val_accuracy: 0.5000\n",
            "Epoch 424/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5047 - accuracy: 0.7163 - val_loss: 0.8192 - val_accuracy: 0.5000\n",
            "Epoch 425/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5051 - accuracy: 0.7163 - val_loss: 0.8147 - val_accuracy: 0.5000\n",
            "Epoch 426/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5042 - accuracy: 0.7172 - val_loss: 0.8182 - val_accuracy: 0.5000\n",
            "Epoch 427/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.5042 - accuracy: 0.7205 - val_loss: 0.8175 - val_accuracy: 0.5000\n",
            "Epoch 428/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5042 - accuracy: 0.7130 - val_loss: 0.8227 - val_accuracy: 0.5000\n",
            "Epoch 429/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.5056 - accuracy: 0.7247 - val_loss: 0.8263 - val_accuracy: 0.5000\n",
            "Epoch 430/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5044 - accuracy: 0.7155 - val_loss: 0.8143 - val_accuracy: 0.5000\n",
            "Epoch 431/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5034 - accuracy: 0.7180 - val_loss: 0.8183 - val_accuracy: 0.5000\n",
            "Epoch 432/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5034 - accuracy: 0.7163 - val_loss: 0.8226 - val_accuracy: 0.5000\n",
            "Epoch 433/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5035 - accuracy: 0.7231 - val_loss: 0.8190 - val_accuracy: 0.5000\n",
            "Epoch 434/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5041 - accuracy: 0.7172 - val_loss: 0.8286 - val_accuracy: 0.5000\n",
            "Epoch 435/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5030 - accuracy: 0.7264 - val_loss: 0.8200 - val_accuracy: 0.5000\n",
            "Epoch 436/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5033 - accuracy: 0.7239 - val_loss: 0.8206 - val_accuracy: 0.5000\n",
            "Epoch 437/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5029 - accuracy: 0.7222 - val_loss: 0.8174 - val_accuracy: 0.5000\n",
            "Epoch 438/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5027 - accuracy: 0.7239 - val_loss: 0.8150 - val_accuracy: 0.5000\n",
            "Epoch 439/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5027 - accuracy: 0.7180 - val_loss: 0.8145 - val_accuracy: 0.5000\n",
            "Epoch 440/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5025 - accuracy: 0.7163 - val_loss: 0.8199 - val_accuracy: 0.5000\n",
            "Epoch 441/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5022 - accuracy: 0.7180 - val_loss: 0.8174 - val_accuracy: 0.5000\n",
            "Epoch 442/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5020 - accuracy: 0.7222 - val_loss: 0.8180 - val_accuracy: 0.5000\n",
            "Epoch 443/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5017 - accuracy: 0.7256 - val_loss: 0.8154 - val_accuracy: 0.5000\n",
            "Epoch 444/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5019 - accuracy: 0.7239 - val_loss: 0.8164 - val_accuracy: 0.5000\n",
            "Epoch 445/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5018 - accuracy: 0.7231 - val_loss: 0.8209 - val_accuracy: 0.5000\n",
            "Epoch 446/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.5024 - accuracy: 0.7205 - val_loss: 0.8125 - val_accuracy: 0.5000\n",
            "Epoch 447/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.5016 - accuracy: 0.7205 - val_loss: 0.8146 - val_accuracy: 0.5000\n",
            "Epoch 448/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5020 - accuracy: 0.7180 - val_loss: 0.8195 - val_accuracy: 0.5000\n",
            "Epoch 449/1000\n",
            "594/594 [==============================] - 0s 33us/sample - loss: 0.5011 - accuracy: 0.7239 - val_loss: 0.8212 - val_accuracy: 0.5000\n",
            "Epoch 450/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5015 - accuracy: 0.7264 - val_loss: 0.8124 - val_accuracy: 0.5000\n",
            "Epoch 451/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5015 - accuracy: 0.7247 - val_loss: 0.8095 - val_accuracy: 0.5000\n",
            "Epoch 452/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5008 - accuracy: 0.7222 - val_loss: 0.8146 - val_accuracy: 0.5000\n",
            "Epoch 453/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5006 - accuracy: 0.7239 - val_loss: 0.8165 - val_accuracy: 0.5000\n",
            "Epoch 454/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5011 - accuracy: 0.7247 - val_loss: 0.8084 - val_accuracy: 0.5000\n",
            "Epoch 455/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.5004 - accuracy: 0.7197 - val_loss: 0.8169 - val_accuracy: 0.5000\n",
            "Epoch 456/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5008 - accuracy: 0.7222 - val_loss: 0.8227 - val_accuracy: 0.5000\n",
            "Epoch 457/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5008 - accuracy: 0.7281 - val_loss: 0.8148 - val_accuracy: 0.5000\n",
            "Epoch 458/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5003 - accuracy: 0.7138 - val_loss: 0.8226 - val_accuracy: 0.5000\n",
            "Epoch 459/1000\n",
            "594/594 [==============================] - 0s 20us/sample - loss: 0.5006 - accuracy: 0.7273 - val_loss: 0.8131 - val_accuracy: 0.5000\n",
            "Epoch 460/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.5002 - accuracy: 0.7205 - val_loss: 0.8187 - val_accuracy: 0.5000\n",
            "Epoch 461/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4995 - accuracy: 0.7256 - val_loss: 0.8156 - val_accuracy: 0.5000\n",
            "Epoch 462/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5001 - accuracy: 0.7155 - val_loss: 0.8185 - val_accuracy: 0.5000\n",
            "Epoch 463/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4995 - accuracy: 0.7323 - val_loss: 0.8163 - val_accuracy: 0.5000\n",
            "Epoch 464/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.4993 - accuracy: 0.7239 - val_loss: 0.8206 - val_accuracy: 0.5000\n",
            "Epoch 465/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5001 - accuracy: 0.7273 - val_loss: 0.8078 - val_accuracy: 0.5000\n",
            "Epoch 466/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4988 - accuracy: 0.7239 - val_loss: 0.8113 - val_accuracy: 0.5000\n",
            "Epoch 467/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.4990 - accuracy: 0.7239 - val_loss: 0.8107 - val_accuracy: 0.5000\n",
            "Epoch 468/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4998 - accuracy: 0.7214 - val_loss: 0.8217 - val_accuracy: 0.5000\n",
            "Epoch 469/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.4992 - accuracy: 0.7273 - val_loss: 0.8203 - val_accuracy: 0.5000\n",
            "Epoch 470/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5018 - accuracy: 0.7273 - val_loss: 0.8264 - val_accuracy: 0.5000\n",
            "Epoch 471/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4993 - accuracy: 0.7264 - val_loss: 0.8196 - val_accuracy: 0.5000\n",
            "Epoch 472/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4995 - accuracy: 0.7222 - val_loss: 0.8180 - val_accuracy: 0.5000\n",
            "Epoch 473/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4987 - accuracy: 0.7264 - val_loss: 0.8082 - val_accuracy: 0.5000\n",
            "Epoch 474/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4983 - accuracy: 0.7222 - val_loss: 0.8103 - val_accuracy: 0.5000\n",
            "Epoch 475/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5012 - accuracy: 0.7138 - val_loss: 0.8328 - val_accuracy: 0.5000\n",
            "Epoch 476/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4979 - accuracy: 0.7281 - val_loss: 0.8204 - val_accuracy: 0.5000\n",
            "Epoch 477/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.4974 - accuracy: 0.7264 - val_loss: 0.8162 - val_accuracy: 0.5000\n",
            "Epoch 478/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4980 - accuracy: 0.7264 - val_loss: 0.8171 - val_accuracy: 0.5000\n",
            "Epoch 479/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4973 - accuracy: 0.7281 - val_loss: 0.8123 - val_accuracy: 0.5000\n",
            "Epoch 480/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.4980 - accuracy: 0.7172 - val_loss: 0.8176 - val_accuracy: 0.5000\n",
            "Epoch 481/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4973 - accuracy: 0.7332 - val_loss: 0.8119 - val_accuracy: 0.5000\n",
            "Epoch 482/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4970 - accuracy: 0.7256 - val_loss: 0.8152 - val_accuracy: 0.5000\n",
            "Epoch 483/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4970 - accuracy: 0.7273 - val_loss: 0.8103 - val_accuracy: 0.5000\n",
            "Epoch 484/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.4973 - accuracy: 0.7256 - val_loss: 0.8116 - val_accuracy: 0.5000\n",
            "Epoch 485/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4985 - accuracy: 0.7247 - val_loss: 0.7998 - val_accuracy: 0.5000\n",
            "Epoch 486/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4987 - accuracy: 0.7231 - val_loss: 0.8148 - val_accuracy: 0.5000\n",
            "Epoch 487/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.4971 - accuracy: 0.7239 - val_loss: 0.8120 - val_accuracy: 0.5000\n",
            "Epoch 488/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4964 - accuracy: 0.7256 - val_loss: 0.8092 - val_accuracy: 0.5000\n",
            "Epoch 489/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.4974 - accuracy: 0.7172 - val_loss: 0.8123 - val_accuracy: 0.5000\n",
            "Epoch 490/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4968 - accuracy: 0.7306 - val_loss: 0.8128 - val_accuracy: 0.5000\n",
            "Epoch 491/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.4965 - accuracy: 0.7273 - val_loss: 0.8058 - val_accuracy: 0.5000\n",
            "Epoch 492/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4968 - accuracy: 0.7146 - val_loss: 0.8203 - val_accuracy: 0.5000\n",
            "Epoch 493/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4965 - accuracy: 0.7189 - val_loss: 0.8199 - val_accuracy: 0.5000\n",
            "Epoch 494/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4958 - accuracy: 0.7281 - val_loss: 0.8163 - val_accuracy: 0.5000\n",
            "Epoch 495/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4956 - accuracy: 0.7290 - val_loss: 0.8151 - val_accuracy: 0.5000\n",
            "Epoch 496/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.4960 - accuracy: 0.7222 - val_loss: 0.8072 - val_accuracy: 0.5000\n",
            "Epoch 497/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.4966 - accuracy: 0.7239 - val_loss: 0.8025 - val_accuracy: 0.5000\n",
            "Epoch 498/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4966 - accuracy: 0.7247 - val_loss: 0.8165 - val_accuracy: 0.5000\n",
            "Epoch 499/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4953 - accuracy: 0.7222 - val_loss: 0.8158 - val_accuracy: 0.5000\n",
            "Epoch 500/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4952 - accuracy: 0.7306 - val_loss: 0.8083 - val_accuracy: 0.5000\n",
            "Epoch 501/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.4967 - accuracy: 0.7180 - val_loss: 0.8177 - val_accuracy: 0.5000\n",
            "Epoch 502/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.4950 - accuracy: 0.7281 - val_loss: 0.8094 - val_accuracy: 0.5000\n",
            "Epoch 503/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4958 - accuracy: 0.7180 - val_loss: 0.8030 - val_accuracy: 0.5000\n",
            "Epoch 504/1000\n",
            "594/594 [==============================] - 0s 34us/sample - loss: 0.4954 - accuracy: 0.7205 - val_loss: 0.8164 - val_accuracy: 0.5000\n",
            "Epoch 505/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4946 - accuracy: 0.7256 - val_loss: 0.8100 - val_accuracy: 0.5000\n",
            "Epoch 506/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.4947 - accuracy: 0.7205 - val_loss: 0.8107 - val_accuracy: 0.5000\n",
            "Epoch 507/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4941 - accuracy: 0.7281 - val_loss: 0.8123 - val_accuracy: 0.5000\n",
            "Epoch 508/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4941 - accuracy: 0.7239 - val_loss: 0.8089 - val_accuracy: 0.5000\n",
            "Epoch 509/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.4939 - accuracy: 0.7273 - val_loss: 0.8098 - val_accuracy: 0.5000\n",
            "Epoch 510/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4941 - accuracy: 0.7256 - val_loss: 0.8087 - val_accuracy: 0.5000\n",
            "Epoch 511/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4937 - accuracy: 0.7231 - val_loss: 0.8078 - val_accuracy: 0.5000\n",
            "Epoch 512/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4942 - accuracy: 0.7214 - val_loss: 0.8142 - val_accuracy: 0.5000\n",
            "Epoch 513/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4940 - accuracy: 0.7290 - val_loss: 0.8164 - val_accuracy: 0.5000\n",
            "Epoch 514/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4940 - accuracy: 0.7172 - val_loss: 0.8215 - val_accuracy: 0.5000\n",
            "Epoch 515/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4953 - accuracy: 0.7189 - val_loss: 0.8076 - val_accuracy: 0.5000\n",
            "Epoch 516/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4933 - accuracy: 0.7273 - val_loss: 0.8083 - val_accuracy: 0.5000\n",
            "Epoch 517/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.4934 - accuracy: 0.7214 - val_loss: 0.8079 - val_accuracy: 0.5000\n",
            "Epoch 518/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.4934 - accuracy: 0.7281 - val_loss: 0.8052 - val_accuracy: 0.5000\n",
            "Epoch 519/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.4931 - accuracy: 0.7205 - val_loss: 0.8089 - val_accuracy: 0.5000\n",
            "Epoch 520/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4928 - accuracy: 0.7231 - val_loss: 0.8080 - val_accuracy: 0.5000\n",
            "Epoch 521/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4935 - accuracy: 0.7264 - val_loss: 0.8054 - val_accuracy: 0.5000\n",
            "Epoch 522/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.4927 - accuracy: 0.7189 - val_loss: 0.8145 - val_accuracy: 0.5000\n",
            "Epoch 523/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.4931 - accuracy: 0.7197 - val_loss: 0.8119 - val_accuracy: 0.5000\n",
            "Epoch 524/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.4925 - accuracy: 0.7247 - val_loss: 0.8064 - val_accuracy: 0.5000\n",
            "Epoch 525/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.4922 - accuracy: 0.7273 - val_loss: 0.8072 - val_accuracy: 0.5000\n",
            "Epoch 526/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4927 - accuracy: 0.7222 - val_loss: 0.7990 - val_accuracy: 0.5000\n",
            "Epoch 527/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4926 - accuracy: 0.7222 - val_loss: 0.8074 - val_accuracy: 0.5000\n",
            "Epoch 528/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4923 - accuracy: 0.7189 - val_loss: 0.8118 - val_accuracy: 0.5000\n",
            "Epoch 529/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.4921 - accuracy: 0.7256 - val_loss: 0.8057 - val_accuracy: 0.5000\n",
            "Epoch 530/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.4917 - accuracy: 0.7197 - val_loss: 0.8077 - val_accuracy: 0.5000\n",
            "Epoch 531/1000\n",
            "297/594 [==============>...............] - ETA: 0s - loss: 0.5096 - accuracy: 0.7104\n",
            "Epoch 00531: ReduceLROnPlateau reducing learning rate to 0.25.\n",
            "594/594 [==============================] - 0s 20us/sample - loss: 0.4916 - accuracy: 0.7222 - val_loss: 0.8046 - val_accuracy: 0.5000\n",
            "Epoch 532/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4916 - accuracy: 0.7197 - val_loss: 0.8081 - val_accuracy: 0.5000\n",
            "Epoch 533/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.4913 - accuracy: 0.7247 - val_loss: 0.8093 - val_accuracy: 0.5000\n",
            "Epoch 534/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4922 - accuracy: 0.7247 - val_loss: 0.8051 - val_accuracy: 0.5000\n",
            "Epoch 535/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4915 - accuracy: 0.7222 - val_loss: 0.8043 - val_accuracy: 0.5000\n",
            "Epoch 536/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.4912 - accuracy: 0.7239 - val_loss: 0.8052 - val_accuracy: 0.5000\n",
            "Epoch 537/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4910 - accuracy: 0.7231 - val_loss: 0.8052 - val_accuracy: 0.5000\n",
            "Epoch 538/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4909 - accuracy: 0.7214 - val_loss: 0.8059 - val_accuracy: 0.5000\n",
            "Epoch 539/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4909 - accuracy: 0.7231 - val_loss: 0.8065 - val_accuracy: 0.5000\n",
            "Epoch 540/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.4909 - accuracy: 0.7239 - val_loss: 0.8063 - val_accuracy: 0.5000\n",
            "Epoch 541/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4908 - accuracy: 0.7247 - val_loss: 0.8080 - val_accuracy: 0.5000\n",
            "Epoch 542/1000\n",
            "594/594 [==============================] - 0s 37us/sample - loss: 0.4906 - accuracy: 0.7247 - val_loss: 0.8068 - val_accuracy: 0.5000\n",
            "Epoch 543/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4905 - accuracy: 0.7231 - val_loss: 0.8067 - val_accuracy: 0.5000\n",
            "Epoch 544/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.4907 - accuracy: 0.7247 - val_loss: 0.8063 - val_accuracy: 0.5000\n",
            "Epoch 545/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4910 - accuracy: 0.7222 - val_loss: 0.8090 - val_accuracy: 0.5000\n",
            "Epoch 546/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4904 - accuracy: 0.7222 - val_loss: 0.8078 - val_accuracy: 0.5000\n",
            "Epoch 547/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.4905 - accuracy: 0.7231 - val_loss: 0.8071 - val_accuracy: 0.5000\n",
            "Epoch 548/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.4903 - accuracy: 0.7239 - val_loss: 0.8076 - val_accuracy: 0.5000\n",
            "Epoch 549/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4906 - accuracy: 0.7222 - val_loss: 0.8091 - val_accuracy: 0.5000\n",
            "Epoch 550/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4908 - accuracy: 0.7239 - val_loss: 0.8095 - val_accuracy: 0.5000\n",
            "Epoch 551/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.4905 - accuracy: 0.7222 - val_loss: 0.8100 - val_accuracy: 0.5000\n",
            "Epoch 552/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4901 - accuracy: 0.7247 - val_loss: 0.8067 - val_accuracy: 0.5000\n",
            "Epoch 553/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4900 - accuracy: 0.7222 - val_loss: 0.8061 - val_accuracy: 0.5000\n",
            "Epoch 554/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.4899 - accuracy: 0.7214 - val_loss: 0.8067 - val_accuracy: 0.5000\n",
            "Epoch 555/1000\n",
            "594/594 [==============================] - 0s 36us/sample - loss: 0.4901 - accuracy: 0.7239 - val_loss: 0.8046 - val_accuracy: 0.5000\n",
            "Epoch 556/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.4902 - accuracy: 0.7239 - val_loss: 0.8059 - val_accuracy: 0.5000\n",
            "Epoch 557/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.4900 - accuracy: 0.7256 - val_loss: 0.8049 - val_accuracy: 0.5000\n",
            "Epoch 558/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4902 - accuracy: 0.7189 - val_loss: 0.8034 - val_accuracy: 0.5000\n",
            "Epoch 559/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.4897 - accuracy: 0.7231 - val_loss: 0.8040 - val_accuracy: 0.5000\n",
            "Epoch 560/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.4903 - accuracy: 0.7205 - val_loss: 0.8047 - val_accuracy: 0.5000\n",
            "Epoch 561/1000\n",
            "594/594 [==============================] - 0s 33us/sample - loss: 0.4897 - accuracy: 0.7222 - val_loss: 0.8046 - val_accuracy: 0.5000\n",
            "Epoch 562/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.4895 - accuracy: 0.7214 - val_loss: 0.8060 - val_accuracy: 0.5000\n",
            "Epoch 563/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4895 - accuracy: 0.7231 - val_loss: 0.8049 - val_accuracy: 0.5000\n",
            "Epoch 564/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4894 - accuracy: 0.7214 - val_loss: 0.8060 - val_accuracy: 0.5000\n",
            "Epoch 565/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.4894 - accuracy: 0.7247 - val_loss: 0.8070 - val_accuracy: 0.5000\n",
            "Epoch 566/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.4899 - accuracy: 0.7231 - val_loss: 0.8090 - val_accuracy: 0.5000\n",
            "Epoch 567/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4893 - accuracy: 0.7231 - val_loss: 0.8064 - val_accuracy: 0.5000\n",
            "Epoch 568/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4891 - accuracy: 0.7239 - val_loss: 0.8056 - val_accuracy: 0.5000\n",
            "Epoch 569/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4893 - accuracy: 0.7197 - val_loss: 0.8079 - val_accuracy: 0.5000\n",
            "Epoch 570/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.4890 - accuracy: 0.7231 - val_loss: 0.8066 - val_accuracy: 0.5000\n",
            "Epoch 571/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4890 - accuracy: 0.7231 - val_loss: 0.8066 - val_accuracy: 0.5000\n",
            "Epoch 572/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4894 - accuracy: 0.7222 - val_loss: 0.8048 - val_accuracy: 0.5000\n",
            "Epoch 573/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4894 - accuracy: 0.7239 - val_loss: 0.8041 - val_accuracy: 0.5000\n",
            "Epoch 574/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4889 - accuracy: 0.7214 - val_loss: 0.8054 - val_accuracy: 0.5000\n",
            "Epoch 575/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4890 - accuracy: 0.7231 - val_loss: 0.8030 - val_accuracy: 0.5000\n",
            "Epoch 576/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.4890 - accuracy: 0.7222 - val_loss: 0.8051 - val_accuracy: 0.5000\n",
            "Epoch 577/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.4893 - accuracy: 0.7214 - val_loss: 0.8029 - val_accuracy: 0.5000\n",
            "Epoch 578/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.4889 - accuracy: 0.7231 - val_loss: 0.8035 - val_accuracy: 0.5000\n",
            "Epoch 579/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4890 - accuracy: 0.7239 - val_loss: 0.8031 - val_accuracy: 0.5000\n",
            "Epoch 580/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.4887 - accuracy: 0.7222 - val_loss: 0.8036 - val_accuracy: 0.5000\n",
            "Epoch 581/1000\n",
            "297/594 [==============>...............] - ETA: 0s - loss: 0.4714 - accuracy: 0.7441\n",
            "Epoch 00581: ReduceLROnPlateau reducing learning rate to 0.125.\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.4889 - accuracy: 0.7231 - val_loss: 0.8019 - val_accuracy: 0.5000\n",
            "Epoch 582/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.4885 - accuracy: 0.7222 - val_loss: 0.8031 - val_accuracy: 0.5000\n",
            "Epoch 583/1000\n",
            "594/594 [==============================] - 0s 33us/sample - loss: 0.4885 - accuracy: 0.7214 - val_loss: 0.8044 - val_accuracy: 0.5000\n",
            "Epoch 584/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4885 - accuracy: 0.7231 - val_loss: 0.8050 - val_accuracy: 0.5000\n",
            "Epoch 585/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4885 - accuracy: 0.7231 - val_loss: 0.8058 - val_accuracy: 0.5000\n",
            "Epoch 586/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.4886 - accuracy: 0.7214 - val_loss: 0.8064 - val_accuracy: 0.5000\n",
            "Epoch 587/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4884 - accuracy: 0.7231 - val_loss: 0.8056 - val_accuracy: 0.5000\n",
            "Epoch 588/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.4885 - accuracy: 0.7222 - val_loss: 0.8060 - val_accuracy: 0.5000\n",
            "Epoch 589/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4882 - accuracy: 0.7231 - val_loss: 0.8061 - val_accuracy: 0.5000\n",
            "Epoch 590/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4886 - accuracy: 0.7231 - val_loss: 0.8064 - val_accuracy: 0.5000\n",
            "Epoch 591/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4885 - accuracy: 0.7239 - val_loss: 0.8057 - val_accuracy: 0.5000\n",
            "Epoch 592/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4883 - accuracy: 0.7222 - val_loss: 0.8060 - val_accuracy: 0.5000\n",
            "Epoch 593/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.4882 - accuracy: 0.7231 - val_loss: 0.8056 - val_accuracy: 0.5000\n",
            "Epoch 594/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.4881 - accuracy: 0.7239 - val_loss: 0.8055 - val_accuracy: 0.5000\n",
            "Epoch 595/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4882 - accuracy: 0.7222 - val_loss: 0.8058 - val_accuracy: 0.5000\n",
            "Epoch 596/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.4882 - accuracy: 0.7239 - val_loss: 0.8056 - val_accuracy: 0.5000\n",
            "Epoch 597/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4881 - accuracy: 0.7231 - val_loss: 0.8055 - val_accuracy: 0.5000\n",
            "Epoch 598/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.4881 - accuracy: 0.7239 - val_loss: 0.8054 - val_accuracy: 0.5000\n",
            "Epoch 599/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4888 - accuracy: 0.7205 - val_loss: 0.8042 - val_accuracy: 0.5000\n",
            "Epoch 600/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4881 - accuracy: 0.7231 - val_loss: 0.8042 - val_accuracy: 0.5000\n",
            "Epoch 601/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.4888 - accuracy: 0.7214 - val_loss: 0.8053 - val_accuracy: 0.5000\n",
            "Epoch 602/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4880 - accuracy: 0.7222 - val_loss: 0.8057 - val_accuracy: 0.5000\n",
            "Epoch 603/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4880 - accuracy: 0.7231 - val_loss: 0.8055 - val_accuracy: 0.5000\n",
            "Epoch 604/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4885 - accuracy: 0.7214 - val_loss: 0.8067 - val_accuracy: 0.5000\n",
            "Epoch 605/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4879 - accuracy: 0.7239 - val_loss: 0.8060 - val_accuracy: 0.5000\n",
            "Epoch 606/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4880 - accuracy: 0.7231 - val_loss: 0.8056 - val_accuracy: 0.5000\n",
            "Epoch 607/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.4883 - accuracy: 0.7222 - val_loss: 0.8067 - val_accuracy: 0.5000\n",
            "Epoch 608/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4878 - accuracy: 0.7222 - val_loss: 0.8065 - val_accuracy: 0.5000\n",
            "Epoch 609/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4879 - accuracy: 0.7222 - val_loss: 0.8062 - val_accuracy: 0.5000\n",
            "Epoch 610/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.4879 - accuracy: 0.7222 - val_loss: 0.8064 - val_accuracy: 0.5000\n",
            "Epoch 611/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4879 - accuracy: 0.7222 - val_loss: 0.8070 - val_accuracy: 0.5000\n",
            "Epoch 612/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.4878 - accuracy: 0.7222 - val_loss: 0.8063 - val_accuracy: 0.5000\n",
            "Epoch 613/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4880 - accuracy: 0.7214 - val_loss: 0.8068 - val_accuracy: 0.5000\n",
            "Epoch 614/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4878 - accuracy: 0.7231 - val_loss: 0.8056 - val_accuracy: 0.5000\n",
            "Epoch 615/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4877 - accuracy: 0.7222 - val_loss: 0.8050 - val_accuracy: 0.5000\n",
            "Epoch 616/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4876 - accuracy: 0.7222 - val_loss: 0.8051 - val_accuracy: 0.5000\n",
            "Epoch 617/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4876 - accuracy: 0.7222 - val_loss: 0.8050 - val_accuracy: 0.5000\n",
            "Epoch 618/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4878 - accuracy: 0.7214 - val_loss: 0.8057 - val_accuracy: 0.5000\n",
            "Epoch 619/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4876 - accuracy: 0.7214 - val_loss: 0.8059 - val_accuracy: 0.5000\n",
            "Epoch 620/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4876 - accuracy: 0.7214 - val_loss: 0.8057 - val_accuracy: 0.5000\n",
            "Epoch 621/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4876 - accuracy: 0.7214 - val_loss: 0.8058 - val_accuracy: 0.5000\n",
            "Epoch 622/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.4875 - accuracy: 0.7222 - val_loss: 0.8063 - val_accuracy: 0.5000\n",
            "Epoch 623/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.4878 - accuracy: 0.7231 - val_loss: 0.8050 - val_accuracy: 0.5000\n",
            "Epoch 624/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4876 - accuracy: 0.7231 - val_loss: 0.8050 - val_accuracy: 0.5000\n",
            "Epoch 625/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.4875 - accuracy: 0.7231 - val_loss: 0.8049 - val_accuracy: 0.5000\n",
            "Epoch 626/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.4876 - accuracy: 0.7231 - val_loss: 0.8046 - val_accuracy: 0.5000\n",
            "Epoch 627/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.4874 - accuracy: 0.7222 - val_loss: 0.8045 - val_accuracy: 0.5000\n",
            "Epoch 628/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.4874 - accuracy: 0.7214 - val_loss: 0.8046 - val_accuracy: 0.5000\n",
            "Epoch 629/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4873 - accuracy: 0.7222 - val_loss: 0.8049 - val_accuracy: 0.5000\n",
            "Epoch 630/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.4874 - accuracy: 0.7222 - val_loss: 0.8047 - val_accuracy: 0.5000\n",
            "Epoch 631/1000\n",
            "297/594 [==============>...............] - ETA: 0s - loss: 0.4782 - accuracy: 0.7525\n",
            "Epoch 00631: ReduceLROnPlateau reducing learning rate to 0.0625.\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4873 - accuracy: 0.7222 - val_loss: 0.8050 - val_accuracy: 0.5000\n",
            "Epoch 632/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4872 - accuracy: 0.7222 - val_loss: 0.8050 - val_accuracy: 0.5000\n",
            "Epoch 633/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4873 - accuracy: 0.7222 - val_loss: 0.8048 - val_accuracy: 0.5000\n",
            "Epoch 634/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.4872 - accuracy: 0.7231 - val_loss: 0.8048 - val_accuracy: 0.5000\n",
            "Epoch 635/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.4872 - accuracy: 0.7222 - val_loss: 0.8049 - val_accuracy: 0.5000\n",
            "Epoch 636/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.4872 - accuracy: 0.7222 - val_loss: 0.8048 - val_accuracy: 0.5000\n",
            "Epoch 637/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.4872 - accuracy: 0.7222 - val_loss: 0.8050 - val_accuracy: 0.5000\n",
            "Epoch 638/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4871 - accuracy: 0.7222 - val_loss: 0.8051 - val_accuracy: 0.5000\n",
            "Epoch 639/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.4871 - accuracy: 0.7222 - val_loss: 0.8050 - val_accuracy: 0.5000\n",
            "Epoch 640/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.4873 - accuracy: 0.7214 - val_loss: 0.8052 - val_accuracy: 0.5000\n",
            "Epoch 641/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.4871 - accuracy: 0.7222 - val_loss: 0.8051 - val_accuracy: 0.5000\n",
            "Epoch 642/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4871 - accuracy: 0.7222 - val_loss: 0.8050 - val_accuracy: 0.5000\n",
            "Epoch 643/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4871 - accuracy: 0.7222 - val_loss: 0.8050 - val_accuracy: 0.5000\n",
            "Epoch 644/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.4871 - accuracy: 0.7222 - val_loss: 0.8051 - val_accuracy: 0.5000\n",
            "Epoch 645/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.4871 - accuracy: 0.7222 - val_loss: 0.8053 - val_accuracy: 0.5000\n",
            "Epoch 646/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.4871 - accuracy: 0.7222 - val_loss: 0.8053 - val_accuracy: 0.5000\n",
            "Epoch 647/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4871 - accuracy: 0.7231 - val_loss: 0.8052 - val_accuracy: 0.5000\n",
            "Epoch 648/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4871 - accuracy: 0.7222 - val_loss: 0.8054 - val_accuracy: 0.5000\n",
            "Epoch 649/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4872 - accuracy: 0.7231 - val_loss: 0.8056 - val_accuracy: 0.5000\n",
            "Epoch 650/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.4870 - accuracy: 0.7222 - val_loss: 0.8056 - val_accuracy: 0.5000\n",
            "Epoch 651/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4871 - accuracy: 0.7222 - val_loss: 0.8053 - val_accuracy: 0.5000\n",
            "Epoch 652/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4870 - accuracy: 0.7222 - val_loss: 0.8054 - val_accuracy: 0.5000\n",
            "Epoch 653/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4870 - accuracy: 0.7222 - val_loss: 0.8054 - val_accuracy: 0.5000\n",
            "Epoch 654/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4871 - accuracy: 0.7222 - val_loss: 0.8052 - val_accuracy: 0.5000\n",
            "Epoch 655/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4869 - accuracy: 0.7214 - val_loss: 0.8052 - val_accuracy: 0.5000\n",
            "Epoch 656/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4870 - accuracy: 0.7214 - val_loss: 0.8052 - val_accuracy: 0.5000\n",
            "Epoch 657/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4869 - accuracy: 0.7222 - val_loss: 0.8052 - val_accuracy: 0.5000\n",
            "Epoch 658/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.4871 - accuracy: 0.7231 - val_loss: 0.8049 - val_accuracy: 0.5000\n",
            "Epoch 659/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.4870 - accuracy: 0.7214 - val_loss: 0.8050 - val_accuracy: 0.5000\n",
            "Epoch 660/1000\n",
            "594/594 [==============================] - 0s 35us/sample - loss: 0.4872 - accuracy: 0.7222 - val_loss: 0.8053 - val_accuracy: 0.5000\n",
            "Epoch 661/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4869 - accuracy: 0.7214 - val_loss: 0.8052 - val_accuracy: 0.5000\n",
            "Epoch 662/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4871 - accuracy: 0.7205 - val_loss: 0.8054 - val_accuracy: 0.5000\n",
            "Epoch 663/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4869 - accuracy: 0.7222 - val_loss: 0.8054 - val_accuracy: 0.5000\n",
            "Epoch 664/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.4869 - accuracy: 0.7222 - val_loss: 0.8052 - val_accuracy: 0.5000\n",
            "Epoch 665/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4869 - accuracy: 0.7222 - val_loss: 0.8050 - val_accuracy: 0.5000\n",
            "Epoch 666/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4869 - accuracy: 0.7222 - val_loss: 0.8049 - val_accuracy: 0.5000\n",
            "Epoch 667/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4868 - accuracy: 0.7214 - val_loss: 0.8050 - val_accuracy: 0.5000\n",
            "Epoch 668/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.4868 - accuracy: 0.7214 - val_loss: 0.8051 - val_accuracy: 0.5000\n",
            "Epoch 669/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4869 - accuracy: 0.7222 - val_loss: 0.8050 - val_accuracy: 0.5000\n",
            "Epoch 670/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4868 - accuracy: 0.7222 - val_loss: 0.8051 - val_accuracy: 0.5000\n",
            "Epoch 671/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.4868 - accuracy: 0.7214 - val_loss: 0.8050 - val_accuracy: 0.5000\n",
            "Epoch 672/1000\n",
            "594/594 [==============================] - 0s 19us/sample - loss: 0.4868 - accuracy: 0.7222 - val_loss: 0.8049 - val_accuracy: 0.5000\n",
            "Epoch 673/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4868 - accuracy: 0.7222 - val_loss: 0.8049 - val_accuracy: 0.5000\n",
            "Epoch 674/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.4867 - accuracy: 0.7222 - val_loss: 0.8048 - val_accuracy: 0.5000\n",
            "Epoch 675/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.4867 - accuracy: 0.7222 - val_loss: 0.8047 - val_accuracy: 0.5000\n",
            "Epoch 676/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.4867 - accuracy: 0.7222 - val_loss: 0.8048 - val_accuracy: 0.5000\n",
            "Epoch 677/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4868 - accuracy: 0.7222 - val_loss: 0.8050 - val_accuracy: 0.5000\n",
            "Epoch 678/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4867 - accuracy: 0.7222 - val_loss: 0.8049 - val_accuracy: 0.5000\n",
            "Epoch 679/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.4867 - accuracy: 0.7222 - val_loss: 0.8048 - val_accuracy: 0.5000\n",
            "Epoch 680/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4868 - accuracy: 0.7214 - val_loss: 0.8050 - val_accuracy: 0.5000\n",
            "Epoch 681/1000\n",
            "297/594 [==============>...............] - ETA: 0s - loss: 0.4993 - accuracy: 0.7037\n",
            "Epoch 00681: ReduceLROnPlateau reducing learning rate to 0.03125.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "594/594 [==============================] - 0s 35us/sample - loss: 0.4867 - accuracy: 0.7214 - val_loss: 0.8051 - val_accuracy: 0.5000\n",
            "Epoch 00681: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAGFCAYAAADAc+UQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYydU3kdl7OT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b09a1ad4-7f48-4f9c-a547-05830e648c11"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "mlp = Sequential()\n",
        "mlp.add(Dense(16, input_dim=2, activation='sigmoid'))\n",
        "mlp.add(Dense(16, activation='sigmoid'))\n",
        "mlp.add(Dense(2, activation='sigmoid'))\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(factor=0.5, monitor='accuracy',\n",
        "                              patience=50, min_lr=0.00000001,\n",
        "                              verbose = 1)\n",
        "\n",
        "stop_save = EarlyStopping(patience=200, monitor='accuracy',\n",
        "                          verbose=1, \n",
        "                          restore_best_weights=True)\n",
        "\n",
        "# All parameter gradients will be clipped to\n",
        "# a maximum norm of 1.\n",
        "sgd = optimizers.SGD(lr=1., clipnorm=1.)\n",
        "\n",
        "mlp.compile(loss='binary_crossentropy',\n",
        "            optimizer=sgd,\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "# trains the model\n",
        "mlp.fit(X, yv, epochs=1000, batch_size=297,\n",
        "        verbose=1, callbacks=[reduce_lr, stop_save], \n",
        "        validation_split = 0.01)\n",
        "\n",
        "y_pred = mlp.predict(X)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
        "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n",
        "                     np.arange(y_min, y_max, 0.02))\n",
        "Z = None\n",
        "Z = mlp.predict(np.c_[xx.ravel(), yy.ravel()])[:,1]\n",
        "Z = Z.reshape(xx.shape)\n",
        "cm = plt.cm.bwr\n",
        "\n",
        "fig = plt.figure(figsize=(6,6))\n",
        "\n",
        "plt.contourf(xx, yy, Z, cmap=cm, alpha=.25)\n",
        "\n",
        "plt.plot(X[1,0],X[1,1],'+', color='#648fff', label='Positive Class')\n",
        "plt.plot(X[2,1],X[2,1],'_', color='#fe6100', label='Negative Class')\n",
        "\n",
        "for i in range(len(y)):\n",
        "  x1 = X[i,0]\n",
        "  x2 = X[i,1]\n",
        "  if y[i]==1: \n",
        "    if (y_pred[i] == 0):\n",
        "      plt.plot(x1,x2,'+', color='#648fff')\n",
        "    else:\n",
        "      plt.plot(x1,x2,'k.', alpha=0.25)\n",
        "  else:\n",
        "    if (y_pred[i] == 1):\n",
        "      plt.plot(x1,x2,'_', color='#fe6100')\n",
        "    else:\n",
        "      plt.plot(x1,x2,'k.', alpha=0.25)\n",
        "\n",
        "accuracy = np.sum(np.equal(y_pred,y_actual))/len(y_actual)\n",
        "\n",
        "plt.axis('tight')\n",
        "plt.xlim(min(X[:,0])-0.1, max(X[:,0])+0.1)\n",
        "plt.ylim(min(X[:,1])-0.1, max(X[:,1])+0.1)\n",
        "plt.xlabel('$x_1$')\n",
        "plt.ylabel('$x_2$')\n",
        "plt.legend()\n",
        "plt.title('Keras-based 4-layer MLP on spiral dataset. Accuracy: {:04.3}'.format(accuracy))\n",
        "plt.savefig('ch.6.MLP.keras.deep.c.spirals.png', dpi=350, bbox_inches='tight')\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 594 samples, validate on 6 samples\n",
            "Epoch 1/1000\n",
            "594/594 [==============================] - 0s 433us/sample - loss: 0.7409 - accuracy: 0.5000 - val_loss: 0.7555 - val_accuracy: 0.2500\n",
            "Epoch 2/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6915 - accuracy: 0.5370 - val_loss: 0.7271 - val_accuracy: 0.0833\n",
            "Epoch 3/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6880 - accuracy: 0.5303 - val_loss: 0.6933 - val_accuracy: 0.4167\n",
            "Epoch 4/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6872 - accuracy: 0.5673 - val_loss: 0.6938 - val_accuracy: 0.4167\n",
            "Epoch 5/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6872 - accuracy: 0.5614 - val_loss: 0.7137 - val_accuracy: 0.0833\n",
            "Epoch 6/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6867 - accuracy: 0.5505 - val_loss: 0.6866 - val_accuracy: 0.4167\n",
            "Epoch 7/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6874 - accuracy: 0.5177 - val_loss: 0.6751 - val_accuracy: 0.7500\n",
            "Epoch 8/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6870 - accuracy: 0.5446 - val_loss: 0.6746 - val_accuracy: 0.7500\n",
            "Epoch 9/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6856 - accuracy: 0.5774 - val_loss: 0.7182 - val_accuracy: 0.1667\n",
            "Epoch 10/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6840 - accuracy: 0.5791 - val_loss: 0.7070 - val_accuracy: 0.3333\n",
            "Epoch 11/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6836 - accuracy: 0.5909 - val_loss: 0.7118 - val_accuracy: 0.3333\n",
            "Epoch 12/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6830 - accuracy: 0.5867 - val_loss: 0.6945 - val_accuracy: 0.3333\n",
            "Epoch 13/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6834 - accuracy: 0.5833 - val_loss: 0.6814 - val_accuracy: 0.4167\n",
            "Epoch 14/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6821 - accuracy: 0.5875 - val_loss: 0.7158 - val_accuracy: 0.3333\n",
            "Epoch 15/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6834 - accuracy: 0.5816 - val_loss: 0.7357 - val_accuracy: 0.1667\n",
            "Epoch 16/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6808 - accuracy: 0.5816 - val_loss: 0.6963 - val_accuracy: 0.3333\n",
            "Epoch 17/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6804 - accuracy: 0.5960 - val_loss: 0.7233 - val_accuracy: 0.2500\n",
            "Epoch 18/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6791 - accuracy: 0.6044 - val_loss: 0.7002 - val_accuracy: 0.3333\n",
            "Epoch 19/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6790 - accuracy: 0.5968 - val_loss: 0.7242 - val_accuracy: 0.3333\n",
            "Epoch 20/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6781 - accuracy: 0.5960 - val_loss: 0.7233 - val_accuracy: 0.3333\n",
            "Epoch 21/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6771 - accuracy: 0.5859 - val_loss: 0.7211 - val_accuracy: 0.3333\n",
            "Epoch 22/1000\n",
            "594/594 [==============================] - 0s 36us/sample - loss: 0.6764 - accuracy: 0.6162 - val_loss: 0.6953 - val_accuracy: 0.3333\n",
            "Epoch 23/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6754 - accuracy: 0.5892 - val_loss: 0.7189 - val_accuracy: 0.3333\n",
            "Epoch 24/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6744 - accuracy: 0.5976 - val_loss: 0.7113 - val_accuracy: 0.3333\n",
            "Epoch 25/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6735 - accuracy: 0.5875 - val_loss: 0.7135 - val_accuracy: 0.3333\n",
            "Epoch 26/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6726 - accuracy: 0.5867 - val_loss: 0.7128 - val_accuracy: 0.3333\n",
            "Epoch 27/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6721 - accuracy: 0.5892 - val_loss: 0.7254 - val_accuracy: 0.3333\n",
            "Epoch 28/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6709 - accuracy: 0.6044 - val_loss: 0.7127 - val_accuracy: 0.3333\n",
            "Epoch 29/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6710 - accuracy: 0.5993 - val_loss: 0.6928 - val_accuracy: 0.3333\n",
            "Epoch 30/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6691 - accuracy: 0.5943 - val_loss: 0.7171 - val_accuracy: 0.3333\n",
            "Epoch 31/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6688 - accuracy: 0.5976 - val_loss: 0.7350 - val_accuracy: 0.3333\n",
            "Epoch 32/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6673 - accuracy: 0.6077 - val_loss: 0.7108 - val_accuracy: 0.3333\n",
            "Epoch 33/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6662 - accuracy: 0.5892 - val_loss: 0.7205 - val_accuracy: 0.3333\n",
            "Epoch 34/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6667 - accuracy: 0.5918 - val_loss: 0.7476 - val_accuracy: 0.3333\n",
            "Epoch 35/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6658 - accuracy: 0.6128 - val_loss: 0.6948 - val_accuracy: 0.3333\n",
            "Epoch 36/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6656 - accuracy: 0.5993 - val_loss: 0.6898 - val_accuracy: 0.3333\n",
            "Epoch 37/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6647 - accuracy: 0.6153 - val_loss: 0.6906 - val_accuracy: 0.3333\n",
            "Epoch 38/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6619 - accuracy: 0.6069 - val_loss: 0.7415 - val_accuracy: 0.3333\n",
            "Epoch 39/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6602 - accuracy: 0.5993 - val_loss: 0.7305 - val_accuracy: 0.3333\n",
            "Epoch 40/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6619 - accuracy: 0.5951 - val_loss: 0.6909 - val_accuracy: 0.3333\n",
            "Epoch 41/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6585 - accuracy: 0.5985 - val_loss: 0.7252 - val_accuracy: 0.3333\n",
            "Epoch 42/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6572 - accuracy: 0.6019 - val_loss: 0.7326 - val_accuracy: 0.3333\n",
            "Epoch 43/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6566 - accuracy: 0.6052 - val_loss: 0.7170 - val_accuracy: 0.3333\n",
            "Epoch 44/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6559 - accuracy: 0.6027 - val_loss: 0.7555 - val_accuracy: 0.3333\n",
            "Epoch 45/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6552 - accuracy: 0.6002 - val_loss: 0.7593 - val_accuracy: 0.3333\n",
            "Epoch 46/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6535 - accuracy: 0.6044 - val_loss: 0.7456 - val_accuracy: 0.3333\n",
            "Epoch 47/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6524 - accuracy: 0.6035 - val_loss: 0.7411 - val_accuracy: 0.3333\n",
            "Epoch 48/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6523 - accuracy: 0.6052 - val_loss: 0.7651 - val_accuracy: 0.3333\n",
            "Epoch 49/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6508 - accuracy: 0.6061 - val_loss: 0.7534 - val_accuracy: 0.3333\n",
            "Epoch 50/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6498 - accuracy: 0.6035 - val_loss: 0.7503 - val_accuracy: 0.3333\n",
            "Epoch 51/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6495 - accuracy: 0.6086 - val_loss: 0.7681 - val_accuracy: 0.3333\n",
            "Epoch 52/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6525 - accuracy: 0.6128 - val_loss: 0.6983 - val_accuracy: 0.3333\n",
            "Epoch 53/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6486 - accuracy: 0.6061 - val_loss: 0.7368 - val_accuracy: 0.3333\n",
            "Epoch 54/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6478 - accuracy: 0.6103 - val_loss: 0.7833 - val_accuracy: 0.3333\n",
            "Epoch 55/1000\n",
            "594/594 [==============================] - 0s 38us/sample - loss: 0.6468 - accuracy: 0.6035 - val_loss: 0.7774 - val_accuracy: 0.3333\n",
            "Epoch 56/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6454 - accuracy: 0.6069 - val_loss: 0.7565 - val_accuracy: 0.3333\n",
            "Epoch 57/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6448 - accuracy: 0.6153 - val_loss: 0.7703 - val_accuracy: 0.3333\n",
            "Epoch 58/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6441 - accuracy: 0.6069 - val_loss: 0.7621 - val_accuracy: 0.3333\n",
            "Epoch 59/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6484 - accuracy: 0.6128 - val_loss: 0.8275 - val_accuracy: 0.2500\n",
            "Epoch 60/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6493 - accuracy: 0.6204 - val_loss: 0.7030 - val_accuracy: 0.4167\n",
            "Epoch 61/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6439 - accuracy: 0.6128 - val_loss: 0.7953 - val_accuracy: 0.3333\n",
            "Epoch 62/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6422 - accuracy: 0.6086 - val_loss: 0.7640 - val_accuracy: 0.3333\n",
            "Epoch 63/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6417 - accuracy: 0.6136 - val_loss: 0.7760 - val_accuracy: 0.3333\n",
            "Epoch 64/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6421 - accuracy: 0.6103 - val_loss: 0.7518 - val_accuracy: 0.3333\n",
            "Epoch 65/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6412 - accuracy: 0.6136 - val_loss: 0.7709 - val_accuracy: 0.3333\n",
            "Epoch 66/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6406 - accuracy: 0.6120 - val_loss: 0.7776 - val_accuracy: 0.3333\n",
            "Epoch 67/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6412 - accuracy: 0.6086 - val_loss: 0.7569 - val_accuracy: 0.3333\n",
            "Epoch 68/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6408 - accuracy: 0.6111 - val_loss: 0.8129 - val_accuracy: 0.3333\n",
            "Epoch 69/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6401 - accuracy: 0.6111 - val_loss: 0.7690 - val_accuracy: 0.3333\n",
            "Epoch 70/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6402 - accuracy: 0.6111 - val_loss: 0.8171 - val_accuracy: 0.3333\n",
            "Epoch 71/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6398 - accuracy: 0.6103 - val_loss: 0.7672 - val_accuracy: 0.3333\n",
            "Epoch 72/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6398 - accuracy: 0.6103 - val_loss: 0.8216 - val_accuracy: 0.3333\n",
            "Epoch 73/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6440 - accuracy: 0.6153 - val_loss: 0.7297 - val_accuracy: 0.3333\n",
            "Epoch 74/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6404 - accuracy: 0.6111 - val_loss: 0.7734 - val_accuracy: 0.3333\n",
            "Epoch 75/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6393 - accuracy: 0.6086 - val_loss: 0.8246 - val_accuracy: 0.3333\n",
            "Epoch 76/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6385 - accuracy: 0.6178 - val_loss: 0.8086 - val_accuracy: 0.3333\n",
            "Epoch 77/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6385 - accuracy: 0.6162 - val_loss: 0.8144 - val_accuracy: 0.3333\n",
            "Epoch 78/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6394 - accuracy: 0.6094 - val_loss: 0.7673 - val_accuracy: 0.3333\n",
            "Epoch 79/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6381 - accuracy: 0.6120 - val_loss: 0.8110 - val_accuracy: 0.3333\n",
            "Epoch 80/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6379 - accuracy: 0.6136 - val_loss: 0.7944 - val_accuracy: 0.3333\n",
            "Epoch 81/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6386 - accuracy: 0.6052 - val_loss: 0.7803 - val_accuracy: 0.3333\n",
            "Epoch 82/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6380 - accuracy: 0.6145 - val_loss: 0.7936 - val_accuracy: 0.3333\n",
            "Epoch 83/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6375 - accuracy: 0.6128 - val_loss: 0.8042 - val_accuracy: 0.3333\n",
            "Epoch 84/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6383 - accuracy: 0.6178 - val_loss: 0.7838 - val_accuracy: 0.3333\n",
            "Epoch 85/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6376 - accuracy: 0.6120 - val_loss: 0.8026 - val_accuracy: 0.3333\n",
            "Epoch 86/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6377 - accuracy: 0.6111 - val_loss: 0.8337 - val_accuracy: 0.2500\n",
            "Epoch 87/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6392 - accuracy: 0.6111 - val_loss: 0.8538 - val_accuracy: 0.1667\n",
            "Epoch 88/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6385 - accuracy: 0.6094 - val_loss: 0.8427 - val_accuracy: 0.2500\n",
            "Epoch 89/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6380 - accuracy: 0.6136 - val_loss: 0.7889 - val_accuracy: 0.3333\n",
            "Epoch 90/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6377 - accuracy: 0.6128 - val_loss: 0.8418 - val_accuracy: 0.2500\n",
            "Epoch 91/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6379 - accuracy: 0.6162 - val_loss: 0.7895 - val_accuracy: 0.3333\n",
            "Epoch 92/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6391 - accuracy: 0.6153 - val_loss: 0.7806 - val_accuracy: 0.3333\n",
            "Epoch 93/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6380 - accuracy: 0.6044 - val_loss: 0.7977 - val_accuracy: 0.3333\n",
            "Epoch 94/1000\n",
            "594/594 [==============================] - 0s 19us/sample - loss: 0.6372 - accuracy: 0.6103 - val_loss: 0.8091 - val_accuracy: 0.3333\n",
            "Epoch 95/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6385 - accuracy: 0.6153 - val_loss: 0.8586 - val_accuracy: 0.1667\n",
            "Epoch 96/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6379 - accuracy: 0.6094 - val_loss: 0.8436 - val_accuracy: 0.2500\n",
            "Epoch 97/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6380 - accuracy: 0.6052 - val_loss: 0.8520 - val_accuracy: 0.1667\n",
            "Epoch 98/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6370 - accuracy: 0.6145 - val_loss: 0.8220 - val_accuracy: 0.3333\n",
            "Epoch 99/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6371 - accuracy: 0.6136 - val_loss: 0.8087 - val_accuracy: 0.3333\n",
            "Epoch 100/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6370 - accuracy: 0.6170 - val_loss: 0.8104 - val_accuracy: 0.3333\n",
            "Epoch 101/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6369 - accuracy: 0.6178 - val_loss: 0.8377 - val_accuracy: 0.2500\n",
            "Epoch 102/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6379 - accuracy: 0.6086 - val_loss: 0.8548 - val_accuracy: 0.1667\n",
            "Epoch 103/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6369 - accuracy: 0.6195 - val_loss: 0.8110 - val_accuracy: 0.3333\n",
            "Epoch 104/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6375 - accuracy: 0.6187 - val_loss: 0.8005 - val_accuracy: 0.3333\n",
            "Epoch 105/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6382 - accuracy: 0.6120 - val_loss: 0.7931 - val_accuracy: 0.3333\n",
            "Epoch 106/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6376 - accuracy: 0.6136 - val_loss: 0.8041 - val_accuracy: 0.3333\n",
            "Epoch 107/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6380 - accuracy: 0.6136 - val_loss: 0.8647 - val_accuracy: 0.1667\n",
            "Epoch 108/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6378 - accuracy: 0.6136 - val_loss: 0.8508 - val_accuracy: 0.1667\n",
            "Epoch 109/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6372 - accuracy: 0.6170 - val_loss: 0.8051 - val_accuracy: 0.3333\n",
            "Epoch 110/1000\n",
            "297/594 [==============>...............] - ETA: 0s - loss: 0.6634 - accuracy: 0.5657\n",
            "Epoch 00110: ReduceLROnPlateau reducing learning rate to 0.5.\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6376 - accuracy: 0.6128 - val_loss: 0.8021 - val_accuracy: 0.3333\n",
            "Epoch 111/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6368 - accuracy: 0.6178 - val_loss: 0.8151 - val_accuracy: 0.3333\n",
            "Epoch 112/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6366 - accuracy: 0.6178 - val_loss: 0.8252 - val_accuracy: 0.3333\n",
            "Epoch 113/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6370 - accuracy: 0.6153 - val_loss: 0.8192 - val_accuracy: 0.3333\n",
            "Epoch 114/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6368 - accuracy: 0.6195 - val_loss: 0.8201 - val_accuracy: 0.3333\n",
            "Epoch 115/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.6366 - accuracy: 0.6204 - val_loss: 0.8266 - val_accuracy: 0.3333\n",
            "Epoch 116/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6366 - accuracy: 0.6162 - val_loss: 0.8253 - val_accuracy: 0.3333\n",
            "Epoch 117/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6365 - accuracy: 0.6162 - val_loss: 0.8251 - val_accuracy: 0.3333\n",
            "Epoch 118/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6365 - accuracy: 0.6195 - val_loss: 0.8261 - val_accuracy: 0.3333\n",
            "Epoch 119/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6374 - accuracy: 0.6128 - val_loss: 0.8394 - val_accuracy: 0.2500\n",
            "Epoch 120/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6366 - accuracy: 0.6178 - val_loss: 0.8362 - val_accuracy: 0.2500\n",
            "Epoch 121/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6370 - accuracy: 0.6136 - val_loss: 0.8402 - val_accuracy: 0.2500\n",
            "Epoch 122/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6366 - accuracy: 0.6136 - val_loss: 0.8364 - val_accuracy: 0.2500\n",
            "Epoch 123/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6366 - accuracy: 0.6136 - val_loss: 0.8281 - val_accuracy: 0.2500\n",
            "Epoch 124/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6371 - accuracy: 0.6145 - val_loss: 0.8204 - val_accuracy: 0.3333\n",
            "Epoch 125/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6367 - accuracy: 0.6162 - val_loss: 0.8215 - val_accuracy: 0.3333\n",
            "Epoch 126/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6365 - accuracy: 0.6204 - val_loss: 0.8241 - val_accuracy: 0.3333\n",
            "Epoch 127/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6368 - accuracy: 0.6128 - val_loss: 0.8346 - val_accuracy: 0.2500\n",
            "Epoch 128/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6366 - accuracy: 0.6178 - val_loss: 0.8353 - val_accuracy: 0.2500\n",
            "Epoch 129/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6366 - accuracy: 0.6178 - val_loss: 0.8370 - val_accuracy: 0.2500\n",
            "Epoch 130/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6374 - accuracy: 0.6094 - val_loss: 0.8439 - val_accuracy: 0.1667\n",
            "Epoch 131/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6392 - accuracy: 0.6094 - val_loss: 0.8544 - val_accuracy: 0.1667\n",
            "Epoch 132/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6368 - accuracy: 0.6178 - val_loss: 0.8439 - val_accuracy: 0.1667\n",
            "Epoch 133/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6365 - accuracy: 0.6136 - val_loss: 0.8325 - val_accuracy: 0.2500\n",
            "Epoch 134/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6364 - accuracy: 0.6187 - val_loss: 0.8329 - val_accuracy: 0.2500\n",
            "Epoch 135/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6369 - accuracy: 0.6195 - val_loss: 0.8230 - val_accuracy: 0.3333\n",
            "Epoch 136/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6365 - accuracy: 0.6212 - val_loss: 0.8320 - val_accuracy: 0.2500\n",
            "Epoch 137/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6364 - accuracy: 0.6162 - val_loss: 0.8298 - val_accuracy: 0.2500\n",
            "Epoch 138/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6369 - accuracy: 0.6195 - val_loss: 0.8224 - val_accuracy: 0.3333\n",
            "Epoch 139/1000\n",
            "594/594 [==============================] - 0s 20us/sample - loss: 0.6364 - accuracy: 0.6195 - val_loss: 0.8301 - val_accuracy: 0.2500\n",
            "Epoch 140/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6365 - accuracy: 0.6178 - val_loss: 0.8353 - val_accuracy: 0.2500\n",
            "Epoch 141/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6368 - accuracy: 0.6145 - val_loss: 0.8404 - val_accuracy: 0.2500\n",
            "Epoch 142/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6366 - accuracy: 0.6153 - val_loss: 0.8389 - val_accuracy: 0.2500\n",
            "Epoch 143/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6378 - accuracy: 0.6195 - val_loss: 0.8199 - val_accuracy: 0.3333\n",
            "Epoch 144/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6364 - accuracy: 0.6204 - val_loss: 0.8287 - val_accuracy: 0.2500\n",
            "Epoch 145/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6364 - accuracy: 0.6187 - val_loss: 0.8295 - val_accuracy: 0.2500\n",
            "Epoch 146/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6370 - accuracy: 0.6204 - val_loss: 0.8216 - val_accuracy: 0.3333\n",
            "Epoch 147/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6364 - accuracy: 0.6212 - val_loss: 0.8261 - val_accuracy: 0.3333\n",
            "Epoch 148/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6365 - accuracy: 0.6204 - val_loss: 0.8329 - val_accuracy: 0.2500\n",
            "Epoch 149/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6370 - accuracy: 0.6094 - val_loss: 0.8412 - val_accuracy: 0.1667\n",
            "Epoch 150/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6365 - accuracy: 0.6187 - val_loss: 0.8394 - val_accuracy: 0.2500\n",
            "Epoch 151/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6365 - accuracy: 0.6204 - val_loss: 0.8378 - val_accuracy: 0.2500\n",
            "Epoch 152/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6365 - accuracy: 0.6145 - val_loss: 0.8390 - val_accuracy: 0.2500\n",
            "Epoch 153/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6368 - accuracy: 0.6128 - val_loss: 0.8424 - val_accuracy: 0.1667\n",
            "Epoch 154/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6364 - accuracy: 0.6128 - val_loss: 0.8346 - val_accuracy: 0.2500\n",
            "Epoch 155/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6368 - accuracy: 0.6162 - val_loss: 0.8250 - val_accuracy: 0.3333\n",
            "Epoch 156/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6365 - accuracy: 0.6187 - val_loss: 0.8338 - val_accuracy: 0.2500\n",
            "Epoch 157/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6363 - accuracy: 0.6162 - val_loss: 0.8305 - val_accuracy: 0.2500\n",
            "Epoch 158/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6364 - accuracy: 0.6178 - val_loss: 0.8285 - val_accuracy: 0.2500\n",
            "Epoch 159/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6367 - accuracy: 0.6195 - val_loss: 0.8237 - val_accuracy: 0.3333\n",
            "Epoch 160/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6368 - accuracy: 0.6229 - val_loss: 0.8211 - val_accuracy: 0.3333\n",
            "Epoch 161/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6369 - accuracy: 0.6111 - val_loss: 0.8375 - val_accuracy: 0.2500\n",
            "Epoch 162/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6365 - accuracy: 0.6178 - val_loss: 0.8386 - val_accuracy: 0.2500\n",
            "Epoch 163/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6363 - accuracy: 0.6187 - val_loss: 0.8369 - val_accuracy: 0.2500\n",
            "Epoch 164/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6367 - accuracy: 0.6136 - val_loss: 0.8411 - val_accuracy: 0.1667\n",
            "Epoch 165/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6363 - accuracy: 0.6120 - val_loss: 0.8326 - val_accuracy: 0.2500\n",
            "Epoch 166/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6363 - accuracy: 0.6178 - val_loss: 0.8343 - val_accuracy: 0.2500\n",
            "Epoch 167/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6367 - accuracy: 0.6178 - val_loss: 0.8401 - val_accuracy: 0.1667\n",
            "Epoch 168/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6369 - accuracy: 0.6094 - val_loss: 0.8441 - val_accuracy: 0.1667\n",
            "Epoch 169/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6366 - accuracy: 0.6162 - val_loss: 0.8430 - val_accuracy: 0.1667\n",
            "Epoch 170/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6368 - accuracy: 0.6136 - val_loss: 0.8446 - val_accuracy: 0.1667\n",
            "Epoch 171/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6365 - accuracy: 0.6145 - val_loss: 0.8307 - val_accuracy: 0.2500\n",
            "Epoch 172/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6363 - accuracy: 0.6204 - val_loss: 0.8307 - val_accuracy: 0.2500\n",
            "Epoch 173/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6362 - accuracy: 0.6221 - val_loss: 0.8322 - val_accuracy: 0.2500\n",
            "Epoch 174/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6363 - accuracy: 0.6153 - val_loss: 0.8303 - val_accuracy: 0.2500\n",
            "Epoch 175/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6364 - accuracy: 0.6170 - val_loss: 0.8269 - val_accuracy: 0.3333\n",
            "Epoch 176/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6378 - accuracy: 0.6136 - val_loss: 0.8453 - val_accuracy: 0.1667\n",
            "Epoch 177/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6363 - accuracy: 0.6162 - val_loss: 0.8404 - val_accuracy: 0.1667\n",
            "Epoch 178/1000\n",
            "594/594 [==============================] - 0s 19us/sample - loss: 0.6362 - accuracy: 0.6170 - val_loss: 0.8359 - val_accuracy: 0.2500\n",
            "Epoch 179/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6363 - accuracy: 0.6204 - val_loss: 0.8368 - val_accuracy: 0.2500\n",
            "Epoch 180/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6369 - accuracy: 0.6153 - val_loss: 0.8244 - val_accuracy: 0.3333\n",
            "Epoch 181/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6363 - accuracy: 0.6204 - val_loss: 0.8272 - val_accuracy: 0.3333\n",
            "Epoch 182/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6362 - accuracy: 0.6212 - val_loss: 0.8317 - val_accuracy: 0.2500\n",
            "Epoch 183/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6368 - accuracy: 0.6153 - val_loss: 0.8240 - val_accuracy: 0.3333\n",
            "Epoch 184/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6363 - accuracy: 0.6212 - val_loss: 0.8325 - val_accuracy: 0.2500\n",
            "Epoch 185/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6363 - accuracy: 0.6170 - val_loss: 0.8283 - val_accuracy: 0.2500\n",
            "Epoch 186/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6376 - accuracy: 0.6187 - val_loss: 0.8453 - val_accuracy: 0.1667\n",
            "Epoch 187/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6363 - accuracy: 0.6187 - val_loss: 0.8407 - val_accuracy: 0.1667\n",
            "Epoch 188/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6375 - accuracy: 0.6111 - val_loss: 0.8221 - val_accuracy: 0.3333\n",
            "Epoch 189/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6369 - accuracy: 0.6120 - val_loss: 0.8193 - val_accuracy: 0.3333\n",
            "Epoch 190/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6371 - accuracy: 0.6204 - val_loss: 0.8391 - val_accuracy: 0.1667\n",
            "Epoch 191/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6365 - accuracy: 0.6153 - val_loss: 0.8282 - val_accuracy: 0.2500\n",
            "Epoch 192/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6384 - accuracy: 0.6221 - val_loss: 0.8136 - val_accuracy: 0.3333\n",
            "Epoch 193/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6363 - accuracy: 0.6170 - val_loss: 0.8280 - val_accuracy: 0.2500\n",
            "Epoch 194/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6367 - accuracy: 0.6170 - val_loss: 0.8226 - val_accuracy: 0.3333\n",
            "Epoch 195/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6371 - accuracy: 0.6229 - val_loss: 0.8175 - val_accuracy: 0.3333\n",
            "Epoch 196/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6364 - accuracy: 0.6120 - val_loss: 0.8327 - val_accuracy: 0.2500\n",
            "Epoch 197/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6362 - accuracy: 0.6178 - val_loss: 0.8308 - val_accuracy: 0.2500\n",
            "Epoch 198/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6361 - accuracy: 0.6204 - val_loss: 0.8318 - val_accuracy: 0.2500\n",
            "Epoch 199/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6366 - accuracy: 0.6162 - val_loss: 0.8402 - val_accuracy: 0.1667\n",
            "Epoch 200/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6372 - accuracy: 0.6187 - val_loss: 0.8231 - val_accuracy: 0.3333\n",
            "Epoch 201/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6362 - accuracy: 0.6212 - val_loss: 0.8312 - val_accuracy: 0.2500\n",
            "Epoch 202/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6377 - accuracy: 0.6145 - val_loss: 0.8474 - val_accuracy: 0.1667\n",
            "Epoch 203/1000\n",
            "594/594 [==============================] - 0s 20us/sample - loss: 0.6362 - accuracy: 0.6128 - val_loss: 0.8384 - val_accuracy: 0.1667\n",
            "Epoch 204/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6361 - accuracy: 0.6153 - val_loss: 0.8351 - val_accuracy: 0.2500\n",
            "Epoch 205/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6363 - accuracy: 0.6136 - val_loss: 0.8283 - val_accuracy: 0.2500\n",
            "Epoch 206/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6362 - accuracy: 0.6221 - val_loss: 0.8345 - val_accuracy: 0.2500\n",
            "Epoch 207/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6365 - accuracy: 0.6187 - val_loss: 0.8268 - val_accuracy: 0.3333\n",
            "Epoch 208/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6361 - accuracy: 0.6221 - val_loss: 0.8305 - val_accuracy: 0.2500\n",
            "Epoch 209/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6361 - accuracy: 0.6204 - val_loss: 0.8314 - val_accuracy: 0.2500\n",
            "Epoch 210/1000\n",
            "297/594 [==============>...............] - ETA: 0s - loss: 0.6405 - accuracy: 0.6380\n",
            "Epoch 00210: ReduceLROnPlateau reducing learning rate to 0.25.\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6367 - accuracy: 0.6221 - val_loss: 0.8235 - val_accuracy: 0.3333\n",
            "Epoch 211/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.6365 - accuracy: 0.6136 - val_loss: 0.8240 - val_accuracy: 0.3333\n",
            "Epoch 212/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.6378 - accuracy: 0.6187 - val_loss: 0.8328 - val_accuracy: 0.2500\n",
            "Epoch 213/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6361 - accuracy: 0.6195 - val_loss: 0.8327 - val_accuracy: 0.2500\n",
            "Epoch 214/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6362 - accuracy: 0.6153 - val_loss: 0.8317 - val_accuracy: 0.2500\n",
            "Epoch 215/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6363 - accuracy: 0.6212 - val_loss: 0.8340 - val_accuracy: 0.2500\n",
            "Epoch 216/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6363 - accuracy: 0.6187 - val_loss: 0.8358 - val_accuracy: 0.2500\n",
            "Epoch 217/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6361 - accuracy: 0.6195 - val_loss: 0.8357 - val_accuracy: 0.2500\n",
            "Epoch 218/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6361 - accuracy: 0.6170 - val_loss: 0.8347 - val_accuracy: 0.2500\n",
            "Epoch 219/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6366 - accuracy: 0.6153 - val_loss: 0.8309 - val_accuracy: 0.2500\n",
            "Epoch 220/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6367 - accuracy: 0.6162 - val_loss: 0.8350 - val_accuracy: 0.2500\n",
            "Epoch 221/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6361 - accuracy: 0.6204 - val_loss: 0.8348 - val_accuracy: 0.2500\n",
            "Epoch 222/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6362 - accuracy: 0.6204 - val_loss: 0.8355 - val_accuracy: 0.2500\n",
            "Epoch 223/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6361 - accuracy: 0.6170 - val_loss: 0.8347 - val_accuracy: 0.2500\n",
            "Epoch 224/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6361 - accuracy: 0.6212 - val_loss: 0.8349 - val_accuracy: 0.2500\n",
            "Epoch 225/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6362 - accuracy: 0.6136 - val_loss: 0.8323 - val_accuracy: 0.2500\n",
            "Epoch 226/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6361 - accuracy: 0.6187 - val_loss: 0.8316 - val_accuracy: 0.2500\n",
            "Epoch 227/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6361 - accuracy: 0.6204 - val_loss: 0.8328 - val_accuracy: 0.2500\n",
            "Epoch 228/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6365 - accuracy: 0.6145 - val_loss: 0.8298 - val_accuracy: 0.2500\n",
            "Epoch 229/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6366 - accuracy: 0.6162 - val_loss: 0.8275 - val_accuracy: 0.3333\n",
            "Epoch 230/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6361 - accuracy: 0.6221 - val_loss: 0.8294 - val_accuracy: 0.2500\n",
            "Epoch 231/1000\n",
            "594/594 [==============================] - 0s 20us/sample - loss: 0.6361 - accuracy: 0.6221 - val_loss: 0.8311 - val_accuracy: 0.2500\n",
            "Epoch 232/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6376 - accuracy: 0.6187 - val_loss: 0.8261 - val_accuracy: 0.3333\n",
            "Epoch 233/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6363 - accuracy: 0.6178 - val_loss: 0.8266 - val_accuracy: 0.3333\n",
            "Epoch 234/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6362 - accuracy: 0.6221 - val_loss: 0.8307 - val_accuracy: 0.2500\n",
            "Epoch 235/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6360 - accuracy: 0.6221 - val_loss: 0.8312 - val_accuracy: 0.2500\n",
            "Epoch 236/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6361 - accuracy: 0.6162 - val_loss: 0.8305 - val_accuracy: 0.2500\n",
            "Epoch 237/1000\n",
            "594/594 [==============================] - 0s 33us/sample - loss: 0.6360 - accuracy: 0.6212 - val_loss: 0.8312 - val_accuracy: 0.2500\n",
            "Epoch 238/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6362 - accuracy: 0.6212 - val_loss: 0.8333 - val_accuracy: 0.2500\n",
            "Epoch 239/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6360 - accuracy: 0.6195 - val_loss: 0.8331 - val_accuracy: 0.2500\n",
            "Epoch 240/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6362 - accuracy: 0.6187 - val_loss: 0.8348 - val_accuracy: 0.2500\n",
            "Epoch 241/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6361 - accuracy: 0.6136 - val_loss: 0.8333 - val_accuracy: 0.2500\n",
            "Epoch 242/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6361 - accuracy: 0.6187 - val_loss: 0.8327 - val_accuracy: 0.2500\n",
            "Epoch 243/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6363 - accuracy: 0.6204 - val_loss: 0.8352 - val_accuracy: 0.2500\n",
            "Epoch 244/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6363 - accuracy: 0.6145 - val_loss: 0.8321 - val_accuracy: 0.2500\n",
            "Epoch 245/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6360 - accuracy: 0.6195 - val_loss: 0.8327 - val_accuracy: 0.2500\n",
            "Epoch 246/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6360 - accuracy: 0.6195 - val_loss: 0.8335 - val_accuracy: 0.2500\n",
            "Epoch 247/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6367 - accuracy: 0.6128 - val_loss: 0.8295 - val_accuracy: 0.2500\n",
            "Epoch 248/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6361 - accuracy: 0.6212 - val_loss: 0.8298 - val_accuracy: 0.2500\n",
            "Epoch 249/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6361 - accuracy: 0.6229 - val_loss: 0.8319 - val_accuracy: 0.2500\n",
            "Epoch 250/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6366 - accuracy: 0.6178 - val_loss: 0.8290 - val_accuracy: 0.2500\n",
            "Epoch 251/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6365 - accuracy: 0.6145 - val_loss: 0.8275 - val_accuracy: 0.3333\n",
            "Epoch 252/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6362 - accuracy: 0.6229 - val_loss: 0.8315 - val_accuracy: 0.2500\n",
            "Epoch 253/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6360 - accuracy: 0.6204 - val_loss: 0.8320 - val_accuracy: 0.2500\n",
            "Epoch 254/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6363 - accuracy: 0.6187 - val_loss: 0.8301 - val_accuracy: 0.2500\n",
            "Epoch 255/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6360 - accuracy: 0.6212 - val_loss: 0.8313 - val_accuracy: 0.2500\n",
            "Epoch 256/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6363 - accuracy: 0.6195 - val_loss: 0.8343 - val_accuracy: 0.2500\n",
            "Epoch 257/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6363 - accuracy: 0.6187 - val_loss: 0.8364 - val_accuracy: 0.2500\n",
            "Epoch 258/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6370 - accuracy: 0.6128 - val_loss: 0.8307 - val_accuracy: 0.2500\n",
            "Epoch 259/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6362 - accuracy: 0.6229 - val_loss: 0.8333 - val_accuracy: 0.2500\n",
            "Epoch 260/1000\n",
            "297/594 [==============>...............] - ETA: 0s - loss: 0.6352 - accuracy: 0.6145\n",
            "Epoch 00260: ReduceLROnPlateau reducing learning rate to 0.125.\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6361 - accuracy: 0.6145 - val_loss: 0.8321 - val_accuracy: 0.2500\n",
            "Epoch 261/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6363 - accuracy: 0.6195 - val_loss: 0.8331 - val_accuracy: 0.2500\n",
            "Epoch 262/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6361 - accuracy: 0.6204 - val_loss: 0.8335 - val_accuracy: 0.2500\n",
            "Epoch 263/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6360 - accuracy: 0.6187 - val_loss: 0.8335 - val_accuracy: 0.2500\n",
            "Epoch 264/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6360 - accuracy: 0.6187 - val_loss: 0.8333 - val_accuracy: 0.2500\n",
            "Epoch 265/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6362 - accuracy: 0.6162 - val_loss: 0.8326 - val_accuracy: 0.2500\n",
            "Epoch 266/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6361 - accuracy: 0.6195 - val_loss: 0.8332 - val_accuracy: 0.2500\n",
            "Epoch 267/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6363 - accuracy: 0.6128 - val_loss: 0.8323 - val_accuracy: 0.2500\n",
            "Epoch 268/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6360 - accuracy: 0.6195 - val_loss: 0.8322 - val_accuracy: 0.2500\n",
            "Epoch 269/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6365 - accuracy: 0.6204 - val_loss: 0.8335 - val_accuracy: 0.2500\n",
            "Epoch 270/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6360 - accuracy: 0.6187 - val_loss: 0.8333 - val_accuracy: 0.2500\n",
            "Epoch 271/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6360 - accuracy: 0.6195 - val_loss: 0.8332 - val_accuracy: 0.2500\n",
            "Epoch 272/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6361 - accuracy: 0.6212 - val_loss: 0.8337 - val_accuracy: 0.2500\n",
            "Epoch 273/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6361 - accuracy: 0.6212 - val_loss: 0.8341 - val_accuracy: 0.2500\n",
            "Epoch 274/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6360 - accuracy: 0.6170 - val_loss: 0.8336 - val_accuracy: 0.2500\n",
            "Epoch 275/1000\n",
            "594/594 [==============================] - 0s 40us/sample - loss: 0.6365 - accuracy: 0.6187 - val_loss: 0.8347 - val_accuracy: 0.2500\n",
            "Epoch 276/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6360 - accuracy: 0.6187 - val_loss: 0.8341 - val_accuracy: 0.2500\n",
            "Epoch 277/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6360 - accuracy: 0.6187 - val_loss: 0.8342 - val_accuracy: 0.2500\n",
            "Epoch 278/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6360 - accuracy: 0.6170 - val_loss: 0.8335 - val_accuracy: 0.2500\n",
            "Epoch 279/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6360 - accuracy: 0.6187 - val_loss: 0.8337 - val_accuracy: 0.2500\n",
            "Epoch 280/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6361 - accuracy: 0.6212 - val_loss: 0.8340 - val_accuracy: 0.2500\n",
            "Epoch 281/1000\n",
            "594/594 [==============================] - 0s 20us/sample - loss: 0.6360 - accuracy: 0.6195 - val_loss: 0.8341 - val_accuracy: 0.2500\n",
            "Epoch 282/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6360 - accuracy: 0.6187 - val_loss: 0.8339 - val_accuracy: 0.2500\n",
            "Epoch 283/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6360 - accuracy: 0.6195 - val_loss: 0.8341 - val_accuracy: 0.2500\n",
            "Epoch 284/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6360 - accuracy: 0.6187 - val_loss: 0.8339 - val_accuracy: 0.2500\n",
            "Epoch 285/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6361 - accuracy: 0.6212 - val_loss: 0.8342 - val_accuracy: 0.2500\n",
            "Epoch 286/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6360 - accuracy: 0.6170 - val_loss: 0.8337 - val_accuracy: 0.2500\n",
            "Epoch 287/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6360 - accuracy: 0.6195 - val_loss: 0.8337 - val_accuracy: 0.2500\n",
            "Epoch 288/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6361 - accuracy: 0.6212 - val_loss: 0.8341 - val_accuracy: 0.2500\n",
            "Epoch 289/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6361 - accuracy: 0.6187 - val_loss: 0.8334 - val_accuracy: 0.2500\n",
            "Epoch 290/1000\n",
            "594/594 [==============================] - 0s 35us/sample - loss: 0.6361 - accuracy: 0.6178 - val_loss: 0.8328 - val_accuracy: 0.2500\n",
            "Epoch 291/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6360 - accuracy: 0.6204 - val_loss: 0.8329 - val_accuracy: 0.2500\n",
            "Epoch 292/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6361 - accuracy: 0.6153 - val_loss: 0.8324 - val_accuracy: 0.2500\n",
            "Epoch 293/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6360 - accuracy: 0.6195 - val_loss: 0.8327 - val_accuracy: 0.2500\n",
            "Epoch 294/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6360 - accuracy: 0.6195 - val_loss: 0.8326 - val_accuracy: 0.2500\n",
            "Epoch 295/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6360 - accuracy: 0.6178 - val_loss: 0.8324 - val_accuracy: 0.2500\n",
            "Epoch 296/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6360 - accuracy: 0.6195 - val_loss: 0.8327 - val_accuracy: 0.2500\n",
            "Epoch 297/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6360 - accuracy: 0.6162 - val_loss: 0.8323 - val_accuracy: 0.2500\n",
            "Epoch 298/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6360 - accuracy: 0.6212 - val_loss: 0.8326 - val_accuracy: 0.2500\n",
            "Epoch 299/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6363 - accuracy: 0.6178 - val_loss: 0.8336 - val_accuracy: 0.2500\n",
            "Epoch 300/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6360 - accuracy: 0.6170 - val_loss: 0.8332 - val_accuracy: 0.2500\n",
            "Epoch 301/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6360 - accuracy: 0.6195 - val_loss: 0.8331 - val_accuracy: 0.2500\n",
            "Epoch 302/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6359 - accuracy: 0.6195 - val_loss: 0.8331 - val_accuracy: 0.2500\n",
            "Epoch 303/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6359 - accuracy: 0.6204 - val_loss: 0.8332 - val_accuracy: 0.2500\n",
            "Epoch 304/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6364 - accuracy: 0.6229 - val_loss: 0.8342 - val_accuracy: 0.2500\n",
            "Epoch 305/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6360 - accuracy: 0.6178 - val_loss: 0.8336 - val_accuracy: 0.2500\n",
            "Epoch 306/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6362 - accuracy: 0.6221 - val_loss: 0.8342 - val_accuracy: 0.2500\n",
            "Epoch 307/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6360 - accuracy: 0.6187 - val_loss: 0.8338 - val_accuracy: 0.2500\n",
            "Epoch 308/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6360 - accuracy: 0.6170 - val_loss: 0.8335 - val_accuracy: 0.2500\n",
            "Epoch 309/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6361 - accuracy: 0.6204 - val_loss: 0.8340 - val_accuracy: 0.2500\n",
            "Epoch 310/1000\n",
            "297/594 [==============>...............] - ETA: 0s - loss: 0.6300 - accuracy: 0.6162\n",
            "Epoch 00310: ReduceLROnPlateau reducing learning rate to 0.0625.\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6359 - accuracy: 0.6187 - val_loss: 0.8338 - val_accuracy: 0.2500\n",
            "Epoch 311/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6359 - accuracy: 0.6187 - val_loss: 0.8336 - val_accuracy: 0.2500\n",
            "Epoch 312/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6360 - accuracy: 0.6187 - val_loss: 0.8335 - val_accuracy: 0.2500\n",
            "Epoch 313/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6361 - accuracy: 0.6153 - val_loss: 0.8333 - val_accuracy: 0.2500\n",
            "Epoch 314/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6359 - accuracy: 0.6187 - val_loss: 0.8332 - val_accuracy: 0.2500\n",
            "Epoch 315/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6360 - accuracy: 0.6204 - val_loss: 0.8334 - val_accuracy: 0.2500\n",
            "Epoch 316/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6362 - accuracy: 0.6178 - val_loss: 0.8337 - val_accuracy: 0.2500\n",
            "Epoch 317/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6359 - accuracy: 0.6187 - val_loss: 0.8336 - val_accuracy: 0.2500\n",
            "Epoch 318/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6359 - accuracy: 0.6187 - val_loss: 0.8335 - val_accuracy: 0.2500\n",
            "Epoch 319/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6359 - accuracy: 0.6187 - val_loss: 0.8334 - val_accuracy: 0.2500\n",
            "Epoch 320/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6360 - accuracy: 0.6187 - val_loss: 0.8335 - val_accuracy: 0.2500\n",
            "Epoch 321/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6361 - accuracy: 0.6195 - val_loss: 0.8337 - val_accuracy: 0.2500\n",
            "Epoch 322/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6361 - accuracy: 0.6145 - val_loss: 0.8334 - val_accuracy: 0.2500\n",
            "Epoch 323/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6360 - accuracy: 0.6187 - val_loss: 0.8335 - val_accuracy: 0.2500\n",
            "Epoch 324/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6359 - accuracy: 0.6195 - val_loss: 0.8335 - val_accuracy: 0.2500\n",
            "Epoch 325/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6360 - accuracy: 0.6178 - val_loss: 0.8335 - val_accuracy: 0.2500\n",
            "Epoch 326/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6359 - accuracy: 0.6187 - val_loss: 0.8335 - val_accuracy: 0.2500\n",
            "Epoch 327/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6360 - accuracy: 0.6170 - val_loss: 0.8333 - val_accuracy: 0.2500\n",
            "Epoch 328/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6360 - accuracy: 0.6178 - val_loss: 0.8332 - val_accuracy: 0.2500\n",
            "Epoch 329/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6359 - accuracy: 0.6195 - val_loss: 0.8332 - val_accuracy: 0.2500\n",
            "Epoch 330/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6360 - accuracy: 0.6187 - val_loss: 0.8331 - val_accuracy: 0.2500\n",
            "Epoch 331/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6361 - accuracy: 0.6229 - val_loss: 0.8333 - val_accuracy: 0.2500\n",
            "Epoch 332/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6360 - accuracy: 0.6195 - val_loss: 0.8334 - val_accuracy: 0.2500\n",
            "Epoch 333/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6360 - accuracy: 0.6153 - val_loss: 0.8332 - val_accuracy: 0.2500\n",
            "Epoch 334/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6359 - accuracy: 0.6195 - val_loss: 0.8332 - val_accuracy: 0.2500\n",
            "Epoch 335/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6360 - accuracy: 0.6187 - val_loss: 0.8334 - val_accuracy: 0.2500\n",
            "Epoch 336/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6359 - accuracy: 0.6187 - val_loss: 0.8333 - val_accuracy: 0.2500\n",
            "Epoch 337/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6359 - accuracy: 0.6195 - val_loss: 0.8333 - val_accuracy: 0.2500\n",
            "Epoch 338/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6360 - accuracy: 0.6170 - val_loss: 0.8332 - val_accuracy: 0.2500\n",
            "Epoch 339/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6359 - accuracy: 0.6187 - val_loss: 0.8331 - val_accuracy: 0.2500\n",
            "Epoch 340/1000\n",
            "594/594 [==============================] - 0s 43us/sample - loss: 0.6360 - accuracy: 0.6195 - val_loss: 0.8330 - val_accuracy: 0.2500\n",
            "Epoch 341/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6359 - accuracy: 0.6195 - val_loss: 0.8330 - val_accuracy: 0.2500\n",
            "Epoch 342/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6360 - accuracy: 0.6187 - val_loss: 0.8331 - val_accuracy: 0.2500\n",
            "Epoch 343/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6359 - accuracy: 0.6195 - val_loss: 0.8331 - val_accuracy: 0.2500\n",
            "Epoch 344/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6363 - accuracy: 0.6178 - val_loss: 0.8335 - val_accuracy: 0.2500\n",
            "Epoch 345/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6360 - accuracy: 0.6221 - val_loss: 0.8335 - val_accuracy: 0.2500\n",
            "Epoch 346/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6359 - accuracy: 0.6204 - val_loss: 0.8336 - val_accuracy: 0.2500\n",
            "Epoch 347/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6359 - accuracy: 0.6187 - val_loss: 0.8335 - val_accuracy: 0.2500\n",
            "Epoch 348/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6359 - accuracy: 0.6187 - val_loss: 0.8334 - val_accuracy: 0.2500\n",
            "Epoch 349/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6359 - accuracy: 0.6195 - val_loss: 0.8334 - val_accuracy: 0.2500\n",
            "Epoch 350/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6359 - accuracy: 0.6187 - val_loss: 0.8334 - val_accuracy: 0.2500\n",
            "Epoch 351/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6359 - accuracy: 0.6187 - val_loss: 0.8333 - val_accuracy: 0.2500\n",
            "Epoch 352/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6359 - accuracy: 0.6195 - val_loss: 0.8333 - val_accuracy: 0.2500\n",
            "Epoch 353/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6359 - accuracy: 0.6187 - val_loss: 0.8332 - val_accuracy: 0.2500\n",
            "Epoch 354/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6359 - accuracy: 0.6195 - val_loss: 0.8332 - val_accuracy: 0.2500\n",
            "Epoch 355/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6359 - accuracy: 0.6195 - val_loss: 0.8331 - val_accuracy: 0.2500\n",
            "Epoch 356/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6359 - accuracy: 0.6195 - val_loss: 0.8331 - val_accuracy: 0.2500\n",
            "Epoch 357/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6359 - accuracy: 0.6187 - val_loss: 0.8331 - val_accuracy: 0.2500\n",
            "Epoch 358/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6359 - accuracy: 0.6204 - val_loss: 0.8331 - val_accuracy: 0.2500\n",
            "Epoch 359/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6359 - accuracy: 0.6195 - val_loss: 0.8331 - val_accuracy: 0.2500\n",
            "Epoch 360/1000\n",
            "297/594 [==============>...............] - ETA: 0s - loss: 0.6414 - accuracy: 0.6027\n",
            "Epoch 00360: ReduceLROnPlateau reducing learning rate to 0.03125.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6359 - accuracy: 0.6187 - val_loss: 0.8331 - val_accuracy: 0.2500\n",
            "Epoch 00360: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAGFCAYAAADAc+UQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNOjRvOpmYvs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cb3ea76d-5e4b-4482-ccab-d4b3ef66c86d"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "mlp = Sequential()\n",
        "mlp.add(Dense(16, input_dim=2, activation='relu'))\n",
        "mlp.add(Dense(16, activation='sigmoid'))\n",
        "mlp.add(Dense(2, activation='sigmoid'))\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(factor=0.5, monitor='accuracy',\n",
        "                              patience=50, min_lr=0.00000001,\n",
        "                              verbose = 1)\n",
        "\n",
        "stop_save = EarlyStopping(patience=200, monitor='accuracy',\n",
        "                          verbose=1, \n",
        "                          restore_best_weights=True)\n",
        "\n",
        "# All parameter gradients will be clipped to\n",
        "# a maximum norm of 1.\n",
        "sgd = optimizers.SGD(lr=1., clipnorm=1.)\n",
        "\n",
        "mlp.compile(loss='binary_crossentropy',\n",
        "            optimizer=sgd,\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "# trains the model\n",
        "mlp.fit(X, yv, epochs=1000, batch_size=297,\n",
        "        verbose=1, callbacks=[reduce_lr, stop_save], \n",
        "        validation_split = 0.01)\n",
        "\n",
        "y_pred = mlp.predict(X)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
        "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n",
        "                     np.arange(y_min, y_max, 0.02))\n",
        "Z = None\n",
        "Z = mlp.predict(np.c_[xx.ravel(), yy.ravel()])[:,1]\n",
        "Z = Z.reshape(xx.shape)\n",
        "cm = plt.cm.bwr\n",
        "\n",
        "fig = plt.figure(figsize=(6,6))\n",
        "\n",
        "plt.contourf(xx, yy, Z, cmap=cm, alpha=.25)\n",
        "\n",
        "plt.plot(X[1,0],X[1,1],'+', color='#648fff', label='Positive Class')\n",
        "plt.plot(X[2,1],X[2,1],'_', color='#fe6100', label='Negative Class')\n",
        "\n",
        "for i in range(len(y)):\n",
        "  x1 = X[i,0]\n",
        "  x2 = X[i,1]\n",
        "  if y[i]==1: \n",
        "    if (y_pred[i] == 0):\n",
        "      plt.plot(x1,x2,'+', color='#648fff')\n",
        "    else:\n",
        "      plt.plot(x1,x2,'k.', alpha=0.25)\n",
        "  else:\n",
        "    if (y_pred[i] == 1):\n",
        "      plt.plot(x1,x2,'_', color='#fe6100')\n",
        "    else:\n",
        "      plt.plot(x1,x2,'k.', alpha=0.25)\n",
        "\n",
        "accuracy = np.sum(np.equal(y_pred,y_actual))/len(y_actual)\n",
        "\n",
        "plt.axis('tight')\n",
        "plt.xlim(min(X[:,0])-0.1, max(X[:,0])+0.1)\n",
        "plt.ylim(min(X[:,1])-0.1, max(X[:,1])+0.1)\n",
        "plt.xlabel('$x_1$')\n",
        "plt.ylabel('$x_2$')\n",
        "plt.legend()\n",
        "plt.title('Keras-based 4-layer MLP on spiral dataset. Accuracy: {:04.3}'.format(accuracy))\n",
        "plt.savefig('ch.6.MLP.keras.deep.d.spirals.png', dpi=350, bbox_inches='tight')\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 594 samples, validate on 6 samples\n",
            "Epoch 1/1000\n",
            "594/594 [==============================] - 0s 438us/sample - loss: 0.7359 - accuracy: 0.5000 - val_loss: 0.7219 - val_accuracy: 0.5000\n",
            "Epoch 2/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6928 - accuracy: 0.5320 - val_loss: 0.7328 - val_accuracy: 0.0833\n",
            "Epoch 3/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6893 - accuracy: 0.5210 - val_loss: 0.7202 - val_accuracy: 0.0833\n",
            "Epoch 4/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6887 - accuracy: 0.5261 - val_loss: 0.7358 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6861 - accuracy: 0.5732 - val_loss: 0.7215 - val_accuracy: 0.1667\n",
            "Epoch 6/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6844 - accuracy: 0.5556 - val_loss: 0.7138 - val_accuracy: 0.2500\n",
            "Epoch 7/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6836 - accuracy: 0.5968 - val_loss: 0.7013 - val_accuracy: 0.3333\n",
            "Epoch 8/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6818 - accuracy: 0.5724 - val_loss: 0.7397 - val_accuracy: 0.1667\n",
            "Epoch 9/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6799 - accuracy: 0.5918 - val_loss: 0.7435 - val_accuracy: 0.1667\n",
            "Epoch 10/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6775 - accuracy: 0.6338 - val_loss: 0.7240 - val_accuracy: 0.2500\n",
            "Epoch 11/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6761 - accuracy: 0.6313 - val_loss: 0.7161 - val_accuracy: 0.2500\n",
            "Epoch 12/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6739 - accuracy: 0.6044 - val_loss: 0.7487 - val_accuracy: 0.1667\n",
            "Epoch 13/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6714 - accuracy: 0.6364 - val_loss: 0.7394 - val_accuracy: 0.1667\n",
            "Epoch 14/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6697 - accuracy: 0.6406 - val_loss: 0.7304 - val_accuracy: 0.2500\n",
            "Epoch 15/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6707 - accuracy: 0.6035 - val_loss: 0.7100 - val_accuracy: 0.3333\n",
            "Epoch 16/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6654 - accuracy: 0.6187 - val_loss: 0.7433 - val_accuracy: 0.1667\n",
            "Epoch 17/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6628 - accuracy: 0.6204 - val_loss: 0.7544 - val_accuracy: 0.1667\n",
            "Epoch 18/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6607 - accuracy: 0.6254 - val_loss: 0.7752 - val_accuracy: 0.1667\n",
            "Epoch 19/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6590 - accuracy: 0.6322 - val_loss: 0.7534 - val_accuracy: 0.1667\n",
            "Epoch 20/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6572 - accuracy: 0.6136 - val_loss: 0.7579 - val_accuracy: 0.1667\n",
            "Epoch 21/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6585 - accuracy: 0.6305 - val_loss: 0.7383 - val_accuracy: 0.3333\n",
            "Epoch 22/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6532 - accuracy: 0.6136 - val_loss: 0.7811 - val_accuracy: 0.1667\n",
            "Epoch 23/1000\n",
            "594/594 [==============================] - 0s 46us/sample - loss: 0.6527 - accuracy: 0.6111 - val_loss: 0.8225 - val_accuracy: 0.1667\n",
            "Epoch 24/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6512 - accuracy: 0.6153 - val_loss: 0.8286 - val_accuracy: 0.1667\n",
            "Epoch 25/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6490 - accuracy: 0.6136 - val_loss: 0.8266 - val_accuracy: 0.1667\n",
            "Epoch 26/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6478 - accuracy: 0.6271 - val_loss: 0.7886 - val_accuracy: 0.1667\n",
            "Epoch 27/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6464 - accuracy: 0.6162 - val_loss: 0.8328 - val_accuracy: 0.1667\n",
            "Epoch 28/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6450 - accuracy: 0.6246 - val_loss: 0.8079 - val_accuracy: 0.1667\n",
            "Epoch 29/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.6440 - accuracy: 0.6229 - val_loss: 0.8127 - val_accuracy: 0.1667\n",
            "Epoch 30/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6433 - accuracy: 0.6170 - val_loss: 0.8390 - val_accuracy: 0.1667\n",
            "Epoch 31/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6438 - accuracy: 0.6195 - val_loss: 0.8587 - val_accuracy: 0.1667\n",
            "Epoch 32/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6423 - accuracy: 0.6195 - val_loss: 0.8506 - val_accuracy: 0.1667\n",
            "Epoch 33/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6414 - accuracy: 0.6254 - val_loss: 0.8399 - val_accuracy: 0.1667\n",
            "Epoch 34/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6420 - accuracy: 0.6204 - val_loss: 0.8167 - val_accuracy: 0.2500\n",
            "Epoch 35/1000\n",
            "594/594 [==============================] - 0s 34us/sample - loss: 0.6410 - accuracy: 0.6178 - val_loss: 0.8569 - val_accuracy: 0.1667\n",
            "Epoch 36/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6406 - accuracy: 0.6254 - val_loss: 0.8387 - val_accuracy: 0.1667\n",
            "Epoch 37/1000\n",
            "594/594 [==============================] - 0s 35us/sample - loss: 0.6403 - accuracy: 0.6187 - val_loss: 0.8580 - val_accuracy: 0.1667\n",
            "Epoch 38/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6397 - accuracy: 0.6212 - val_loss: 0.8502 - val_accuracy: 0.1667\n",
            "Epoch 39/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6398 - accuracy: 0.6187 - val_loss: 0.8461 - val_accuracy: 0.1667\n",
            "Epoch 40/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6395 - accuracy: 0.6178 - val_loss: 0.8623 - val_accuracy: 0.1667\n",
            "Epoch 41/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6395 - accuracy: 0.6187 - val_loss: 0.8604 - val_accuracy: 0.1667\n",
            "Epoch 42/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6388 - accuracy: 0.6204 - val_loss: 0.8537 - val_accuracy: 0.1667\n",
            "Epoch 43/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6387 - accuracy: 0.6212 - val_loss: 0.8451 - val_accuracy: 0.2500\n",
            "Epoch 44/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6405 - accuracy: 0.6145 - val_loss: 0.8865 - val_accuracy: 0.1667\n",
            "Epoch 45/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6388 - accuracy: 0.6195 - val_loss: 0.8672 - val_accuracy: 0.1667\n",
            "Epoch 46/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6392 - accuracy: 0.6254 - val_loss: 0.8297 - val_accuracy: 0.3333\n",
            "Epoch 47/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6382 - accuracy: 0.6178 - val_loss: 0.8454 - val_accuracy: 0.2500\n",
            "Epoch 48/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6384 - accuracy: 0.6229 - val_loss: 0.8343 - val_accuracy: 0.2500\n",
            "Epoch 49/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6387 - accuracy: 0.6279 - val_loss: 0.8293 - val_accuracy: 0.3333\n",
            "Epoch 50/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6399 - accuracy: 0.6221 - val_loss: 0.8180 - val_accuracy: 0.3333\n",
            "Epoch 51/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6403 - accuracy: 0.6162 - val_loss: 0.8917 - val_accuracy: 0.1667\n",
            "Epoch 52/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6376 - accuracy: 0.6313 - val_loss: 0.8415 - val_accuracy: 0.2500\n",
            "Epoch 53/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6372 - accuracy: 0.6195 - val_loss: 0.8642 - val_accuracy: 0.1667\n",
            "Epoch 54/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6367 - accuracy: 0.6162 - val_loss: 0.8549 - val_accuracy: 0.2500\n",
            "Epoch 55/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6368 - accuracy: 0.6170 - val_loss: 0.8444 - val_accuracy: 0.2500\n",
            "Epoch 56/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6378 - accuracy: 0.6162 - val_loss: 0.8796 - val_accuracy: 0.1667\n",
            "Epoch 57/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6379 - accuracy: 0.6305 - val_loss: 0.8257 - val_accuracy: 0.3333\n",
            "Epoch 58/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6368 - accuracy: 0.6136 - val_loss: 0.8689 - val_accuracy: 0.1667\n",
            "Epoch 59/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6360 - accuracy: 0.6170 - val_loss: 0.8544 - val_accuracy: 0.2500\n",
            "Epoch 60/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6358 - accuracy: 0.6178 - val_loss: 0.8484 - val_accuracy: 0.2500\n",
            "Epoch 61/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6357 - accuracy: 0.6170 - val_loss: 0.8433 - val_accuracy: 0.2500\n",
            "Epoch 62/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6369 - accuracy: 0.6221 - val_loss: 0.8230 - val_accuracy: 0.3333\n",
            "Epoch 63/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6368 - accuracy: 0.6162 - val_loss: 0.8748 - val_accuracy: 0.1667\n",
            "Epoch 64/1000\n",
            "297/594 [==============>...............] - ETA: 0s - loss: 0.6579 - accuracy: 0.5875\n",
            "Epoch 00064: ReduceLROnPlateau reducing learning rate to 0.5.\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6356 - accuracy: 0.6221 - val_loss: 0.8576 - val_accuracy: 0.2500\n",
            "Epoch 65/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6350 - accuracy: 0.6221 - val_loss: 0.8537 - val_accuracy: 0.2500\n",
            "Epoch 66/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6349 - accuracy: 0.6212 - val_loss: 0.8500 - val_accuracy: 0.2500\n",
            "Epoch 67/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6348 - accuracy: 0.6162 - val_loss: 0.8501 - val_accuracy: 0.2500\n",
            "Epoch 68/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6353 - accuracy: 0.6204 - val_loss: 0.8548 - val_accuracy: 0.2500\n",
            "Epoch 69/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6354 - accuracy: 0.6170 - val_loss: 0.8579 - val_accuracy: 0.2500\n",
            "Epoch 70/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6348 - accuracy: 0.6229 - val_loss: 0.8502 - val_accuracy: 0.2500\n",
            "Epoch 71/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6348 - accuracy: 0.6246 - val_loss: 0.8440 - val_accuracy: 0.2500\n",
            "Epoch 72/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6349 - accuracy: 0.6212 - val_loss: 0.8393 - val_accuracy: 0.2500\n",
            "Epoch 73/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6349 - accuracy: 0.6237 - val_loss: 0.8359 - val_accuracy: 0.2500\n",
            "Epoch 74/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6345 - accuracy: 0.6178 - val_loss: 0.8402 - val_accuracy: 0.2500\n",
            "Epoch 75/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6345 - accuracy: 0.6170 - val_loss: 0.8467 - val_accuracy: 0.2500\n",
            "Epoch 76/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6345 - accuracy: 0.6237 - val_loss: 0.8405 - val_accuracy: 0.2500\n",
            "Epoch 77/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6350 - accuracy: 0.6162 - val_loss: 0.8507 - val_accuracy: 0.2500\n",
            "Epoch 78/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6343 - accuracy: 0.6170 - val_loss: 0.8511 - val_accuracy: 0.2500\n",
            "Epoch 79/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6340 - accuracy: 0.6279 - val_loss: 0.8427 - val_accuracy: 0.2500\n",
            "Epoch 80/1000\n",
            "594/594 [==============================] - 0s 34us/sample - loss: 0.6338 - accuracy: 0.6229 - val_loss: 0.8406 - val_accuracy: 0.2500\n",
            "Epoch 81/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.6337 - accuracy: 0.6204 - val_loss: 0.8427 - val_accuracy: 0.2500\n",
            "Epoch 82/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6336 - accuracy: 0.6246 - val_loss: 0.8419 - val_accuracy: 0.2500\n",
            "Epoch 83/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6337 - accuracy: 0.6237 - val_loss: 0.8438 - val_accuracy: 0.2500\n",
            "Epoch 84/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6334 - accuracy: 0.6246 - val_loss: 0.8447 - val_accuracy: 0.2500\n",
            "Epoch 85/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6333 - accuracy: 0.6279 - val_loss: 0.8395 - val_accuracy: 0.2500\n",
            "Epoch 86/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6333 - accuracy: 0.6254 - val_loss: 0.8378 - val_accuracy: 0.2500\n",
            "Epoch 87/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6331 - accuracy: 0.6229 - val_loss: 0.8411 - val_accuracy: 0.2500\n",
            "Epoch 88/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6330 - accuracy: 0.6271 - val_loss: 0.8376 - val_accuracy: 0.2500\n",
            "Epoch 89/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6328 - accuracy: 0.6263 - val_loss: 0.8368 - val_accuracy: 0.2500\n",
            "Epoch 90/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6328 - accuracy: 0.6288 - val_loss: 0.8358 - val_accuracy: 0.2500\n",
            "Epoch 91/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6330 - accuracy: 0.6288 - val_loss: 0.8316 - val_accuracy: 0.2500\n",
            "Epoch 92/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6328 - accuracy: 0.6204 - val_loss: 0.8377 - val_accuracy: 0.2500\n",
            "Epoch 93/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6331 - accuracy: 0.6145 - val_loss: 0.8431 - val_accuracy: 0.2500\n",
            "Epoch 94/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6332 - accuracy: 0.6246 - val_loss: 0.8465 - val_accuracy: 0.2500\n",
            "Epoch 95/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6324 - accuracy: 0.6338 - val_loss: 0.8381 - val_accuracy: 0.2500\n",
            "Epoch 96/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6324 - accuracy: 0.6279 - val_loss: 0.8393 - val_accuracy: 0.2500\n",
            "Epoch 97/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6331 - accuracy: 0.6178 - val_loss: 0.8449 - val_accuracy: 0.2500\n",
            "Epoch 98/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6329 - accuracy: 0.6364 - val_loss: 0.8299 - val_accuracy: 0.2500\n",
            "Epoch 99/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6327 - accuracy: 0.6178 - val_loss: 0.8390 - val_accuracy: 0.2500\n",
            "Epoch 100/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6324 - accuracy: 0.6212 - val_loss: 0.8412 - val_accuracy: 0.2500\n",
            "Epoch 101/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6325 - accuracy: 0.6254 - val_loss: 0.8433 - val_accuracy: 0.2500\n",
            "Epoch 102/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6320 - accuracy: 0.6229 - val_loss: 0.8416 - val_accuracy: 0.2500\n",
            "Epoch 103/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6319 - accuracy: 0.6330 - val_loss: 0.8297 - val_accuracy: 0.2500\n",
            "Epoch 104/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6315 - accuracy: 0.6322 - val_loss: 0.8282 - val_accuracy: 0.2500\n",
            "Epoch 105/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6313 - accuracy: 0.6296 - val_loss: 0.8289 - val_accuracy: 0.2500\n",
            "Epoch 106/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6317 - accuracy: 0.6263 - val_loss: 0.8349 - val_accuracy: 0.2500\n",
            "Epoch 107/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6312 - accuracy: 0.6313 - val_loss: 0.8329 - val_accuracy: 0.2500\n",
            "Epoch 108/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6312 - accuracy: 0.6313 - val_loss: 0.8274 - val_accuracy: 0.2500\n",
            "Epoch 109/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6310 - accuracy: 0.6305 - val_loss: 0.8249 - val_accuracy: 0.2500\n",
            "Epoch 110/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6314 - accuracy: 0.6313 - val_loss: 0.8199 - val_accuracy: 0.2500\n",
            "Epoch 111/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6308 - accuracy: 0.6271 - val_loss: 0.8228 - val_accuracy: 0.2500\n",
            "Epoch 112/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6308 - accuracy: 0.6271 - val_loss: 0.8250 - val_accuracy: 0.2500\n",
            "Epoch 113/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6317 - accuracy: 0.6313 - val_loss: 0.8169 - val_accuracy: 0.2500\n",
            "Epoch 114/1000\n",
            "297/594 [==============>...............] - ETA: 0s - loss: 0.6242 - accuracy: 0.6498\n",
            "Epoch 00114: ReduceLROnPlateau reducing learning rate to 0.25.\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.6306 - accuracy: 0.6263 - val_loss: 0.8222 - val_accuracy: 0.2500\n",
            "Epoch 115/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6305 - accuracy: 0.6263 - val_loss: 0.8229 - val_accuracy: 0.2500\n",
            "Epoch 116/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6305 - accuracy: 0.6254 - val_loss: 0.8238 - val_accuracy: 0.2500\n",
            "Epoch 117/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6304 - accuracy: 0.6305 - val_loss: 0.8229 - val_accuracy: 0.2500\n",
            "Epoch 118/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6306 - accuracy: 0.6263 - val_loss: 0.8244 - val_accuracy: 0.2500\n",
            "Epoch 119/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6303 - accuracy: 0.6347 - val_loss: 0.8231 - val_accuracy: 0.2500\n",
            "Epoch 120/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6304 - accuracy: 0.6271 - val_loss: 0.8239 - val_accuracy: 0.2500\n",
            "Epoch 121/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6304 - accuracy: 0.6279 - val_loss: 0.8249 - val_accuracy: 0.2500\n",
            "Epoch 122/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6302 - accuracy: 0.6288 - val_loss: 0.8247 - val_accuracy: 0.2500\n",
            "Epoch 123/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6303 - accuracy: 0.6263 - val_loss: 0.8248 - val_accuracy: 0.2500\n",
            "Epoch 124/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6305 - accuracy: 0.6313 - val_loss: 0.8259 - val_accuracy: 0.2500\n",
            "Epoch 125/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6300 - accuracy: 0.6372 - val_loss: 0.8239 - val_accuracy: 0.2500\n",
            "Epoch 126/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6300 - accuracy: 0.6288 - val_loss: 0.8239 - val_accuracy: 0.2500\n",
            "Epoch 127/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6299 - accuracy: 0.6338 - val_loss: 0.8232 - val_accuracy: 0.2500\n",
            "Epoch 128/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6299 - accuracy: 0.6313 - val_loss: 0.8228 - val_accuracy: 0.2500\n",
            "Epoch 129/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6299 - accuracy: 0.6355 - val_loss: 0.8210 - val_accuracy: 0.2500\n",
            "Epoch 130/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6298 - accuracy: 0.6330 - val_loss: 0.8202 - val_accuracy: 0.2500\n",
            "Epoch 131/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6298 - accuracy: 0.6322 - val_loss: 0.8196 - val_accuracy: 0.2500\n",
            "Epoch 132/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6305 - accuracy: 0.6397 - val_loss: 0.8166 - val_accuracy: 0.2500\n",
            "Epoch 133/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6300 - accuracy: 0.6296 - val_loss: 0.8192 - val_accuracy: 0.2500\n",
            "Epoch 134/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6297 - accuracy: 0.6313 - val_loss: 0.8194 - val_accuracy: 0.2500\n",
            "Epoch 135/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6296 - accuracy: 0.6322 - val_loss: 0.8193 - val_accuracy: 0.2500\n",
            "Epoch 136/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6296 - accuracy: 0.6313 - val_loss: 0.8198 - val_accuracy: 0.2500\n",
            "Epoch 137/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6296 - accuracy: 0.6347 - val_loss: 0.8184 - val_accuracy: 0.2500\n",
            "Epoch 138/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6295 - accuracy: 0.6322 - val_loss: 0.8189 - val_accuracy: 0.2500\n",
            "Epoch 139/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6294 - accuracy: 0.6338 - val_loss: 0.8189 - val_accuracy: 0.2500\n",
            "Epoch 140/1000\n",
            "594/594 [==============================] - 0s 33us/sample - loss: 0.6295 - accuracy: 0.6364 - val_loss: 0.8177 - val_accuracy: 0.2500\n",
            "Epoch 141/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6294 - accuracy: 0.6355 - val_loss: 0.8169 - val_accuracy: 0.2500\n",
            "Epoch 142/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6297 - accuracy: 0.6372 - val_loss: 0.8151 - val_accuracy: 0.3333\n",
            "Epoch 143/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6293 - accuracy: 0.6322 - val_loss: 0.8158 - val_accuracy: 0.2500\n",
            "Epoch 144/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6295 - accuracy: 0.6347 - val_loss: 0.8144 - val_accuracy: 0.3333\n",
            "Epoch 145/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6292 - accuracy: 0.6330 - val_loss: 0.8151 - val_accuracy: 0.3333\n",
            "Epoch 146/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6292 - accuracy: 0.6330 - val_loss: 0.8152 - val_accuracy: 0.3333\n",
            "Epoch 147/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6292 - accuracy: 0.6347 - val_loss: 0.8145 - val_accuracy: 0.3333\n",
            "Epoch 148/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6293 - accuracy: 0.6330 - val_loss: 0.8164 - val_accuracy: 0.2500\n",
            "Epoch 149/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6300 - accuracy: 0.6372 - val_loss: 0.8131 - val_accuracy: 0.3333\n",
            "Epoch 150/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6292 - accuracy: 0.6347 - val_loss: 0.8128 - val_accuracy: 0.3333\n",
            "Epoch 151/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6291 - accuracy: 0.6347 - val_loss: 0.8128 - val_accuracy: 0.3333\n",
            "Epoch 152/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6289 - accuracy: 0.6330 - val_loss: 0.8138 - val_accuracy: 0.3333\n",
            "Epoch 153/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6292 - accuracy: 0.6389 - val_loss: 0.8125 - val_accuracy: 0.3333\n",
            "Epoch 154/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6289 - accuracy: 0.6313 - val_loss: 0.8143 - val_accuracy: 0.3333\n",
            "Epoch 155/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6288 - accuracy: 0.6347 - val_loss: 0.8144 - val_accuracy: 0.3333\n",
            "Epoch 156/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6291 - accuracy: 0.6389 - val_loss: 0.8130 - val_accuracy: 0.3333\n",
            "Epoch 157/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6289 - accuracy: 0.6330 - val_loss: 0.8148 - val_accuracy: 0.3333\n",
            "Epoch 158/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6287 - accuracy: 0.6347 - val_loss: 0.8153 - val_accuracy: 0.3333\n",
            "Epoch 159/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6287 - accuracy: 0.6338 - val_loss: 0.8155 - val_accuracy: 0.3333\n",
            "Epoch 160/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6288 - accuracy: 0.6439 - val_loss: 0.8140 - val_accuracy: 0.3333\n",
            "Epoch 161/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6286 - accuracy: 0.6347 - val_loss: 0.8143 - val_accuracy: 0.3333\n",
            "Epoch 162/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6294 - accuracy: 0.6338 - val_loss: 0.8170 - val_accuracy: 0.2500\n",
            "Epoch 163/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6287 - accuracy: 0.6414 - val_loss: 0.8147 - val_accuracy: 0.3333\n",
            "Epoch 164/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6285 - accuracy: 0.6372 - val_loss: 0.8148 - val_accuracy: 0.3333\n",
            "Epoch 165/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6287 - accuracy: 0.6364 - val_loss: 0.8159 - val_accuracy: 0.2500\n",
            "Epoch 166/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6287 - accuracy: 0.6423 - val_loss: 0.8133 - val_accuracy: 0.3333\n",
            "Epoch 167/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6286 - accuracy: 0.6322 - val_loss: 0.8145 - val_accuracy: 0.3333\n",
            "Epoch 168/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6283 - accuracy: 0.6364 - val_loss: 0.8145 - val_accuracy: 0.3333\n",
            "Epoch 169/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6283 - accuracy: 0.6364 - val_loss: 0.8146 - val_accuracy: 0.3333\n",
            "Epoch 170/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6284 - accuracy: 0.6380 - val_loss: 0.8151 - val_accuracy: 0.3333\n",
            "Epoch 171/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6285 - accuracy: 0.6380 - val_loss: 0.8158 - val_accuracy: 0.2500\n",
            "Epoch 172/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6283 - accuracy: 0.6397 - val_loss: 0.8136 - val_accuracy: 0.3333\n",
            "Epoch 173/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6284 - accuracy: 0.6397 - val_loss: 0.8115 - val_accuracy: 0.3333\n",
            "Epoch 174/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6281 - accuracy: 0.6397 - val_loss: 0.8119 - val_accuracy: 0.3333\n",
            "Epoch 175/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6281 - accuracy: 0.6380 - val_loss: 0.8119 - val_accuracy: 0.3333\n",
            "Epoch 176/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6281 - accuracy: 0.6423 - val_loss: 0.8107 - val_accuracy: 0.3333\n",
            "Epoch 177/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6281 - accuracy: 0.6406 - val_loss: 0.8099 - val_accuracy: 0.3333\n",
            "Epoch 178/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6281 - accuracy: 0.6406 - val_loss: 0.8092 - val_accuracy: 0.3333\n",
            "Epoch 179/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6280 - accuracy: 0.6397 - val_loss: 0.8105 - val_accuracy: 0.3333\n",
            "Epoch 180/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6284 - accuracy: 0.6364 - val_loss: 0.8126 - val_accuracy: 0.3333\n",
            "Epoch 181/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6283 - accuracy: 0.6439 - val_loss: 0.8100 - val_accuracy: 0.3333\n",
            "Epoch 182/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6278 - accuracy: 0.6414 - val_loss: 0.8102 - val_accuracy: 0.3333\n",
            "Epoch 183/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6279 - accuracy: 0.6397 - val_loss: 0.8112 - val_accuracy: 0.3333\n",
            "Epoch 184/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6278 - accuracy: 0.6439 - val_loss: 0.8114 - val_accuracy: 0.3333\n",
            "Epoch 185/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6278 - accuracy: 0.6431 - val_loss: 0.8114 - val_accuracy: 0.3333\n",
            "Epoch 186/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6277 - accuracy: 0.6439 - val_loss: 0.8103 - val_accuracy: 0.3333\n",
            "Epoch 187/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6279 - accuracy: 0.6423 - val_loss: 0.8113 - val_accuracy: 0.3333\n",
            "Epoch 188/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6278 - accuracy: 0.6456 - val_loss: 0.8094 - val_accuracy: 0.3333\n",
            "Epoch 189/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6276 - accuracy: 0.6439 - val_loss: 0.8087 - val_accuracy: 0.3333\n",
            "Epoch 190/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6276 - accuracy: 0.6448 - val_loss: 0.8088 - val_accuracy: 0.3333\n",
            "Epoch 191/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6275 - accuracy: 0.6439 - val_loss: 0.8092 - val_accuracy: 0.3333\n",
            "Epoch 192/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6275 - accuracy: 0.6481 - val_loss: 0.8086 - val_accuracy: 0.3333\n",
            "Epoch 193/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6275 - accuracy: 0.6448 - val_loss: 0.8077 - val_accuracy: 0.3333\n",
            "Epoch 194/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6278 - accuracy: 0.6439 - val_loss: 0.8059 - val_accuracy: 0.3333\n",
            "Epoch 195/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6275 - accuracy: 0.6423 - val_loss: 0.8079 - val_accuracy: 0.3333\n",
            "Epoch 196/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6274 - accuracy: 0.6439 - val_loss: 0.8088 - val_accuracy: 0.2500\n",
            "Epoch 197/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6277 - accuracy: 0.6406 - val_loss: 0.8105 - val_accuracy: 0.2500\n",
            "Epoch 198/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6273 - accuracy: 0.6481 - val_loss: 0.8093 - val_accuracy: 0.2500\n",
            "Epoch 199/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6274 - accuracy: 0.6481 - val_loss: 0.8072 - val_accuracy: 0.2500\n",
            "Epoch 200/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6272 - accuracy: 0.6481 - val_loss: 0.8068 - val_accuracy: 0.2500\n",
            "Epoch 201/1000\n",
            "594/594 [==============================] - 0s 41us/sample - loss: 0.6272 - accuracy: 0.6473 - val_loss: 0.8068 - val_accuracy: 0.2500\n",
            "Epoch 202/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6271 - accuracy: 0.6481 - val_loss: 0.8061 - val_accuracy: 0.2500\n",
            "Epoch 203/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6271 - accuracy: 0.6490 - val_loss: 0.8059 - val_accuracy: 0.2500\n",
            "Epoch 204/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6271 - accuracy: 0.6473 - val_loss: 0.8059 - val_accuracy: 0.2500\n",
            "Epoch 205/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6274 - accuracy: 0.6448 - val_loss: 0.8041 - val_accuracy: 0.2500\n",
            "Epoch 206/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6271 - accuracy: 0.6481 - val_loss: 0.8037 - val_accuracy: 0.2500\n",
            "Epoch 207/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6269 - accuracy: 0.6473 - val_loss: 0.8041 - val_accuracy: 0.2500\n",
            "Epoch 208/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6271 - accuracy: 0.6473 - val_loss: 0.8059 - val_accuracy: 0.2500\n",
            "Epoch 209/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6270 - accuracy: 0.6507 - val_loss: 0.8046 - val_accuracy: 0.2500\n",
            "Epoch 210/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6268 - accuracy: 0.6490 - val_loss: 0.8050 - val_accuracy: 0.2500\n",
            "Epoch 211/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6269 - accuracy: 0.6507 - val_loss: 0.8041 - val_accuracy: 0.2500\n",
            "Epoch 212/1000\n",
            "594/594 [==============================] - 0s 42us/sample - loss: 0.6269 - accuracy: 0.6507 - val_loss: 0.8030 - val_accuracy: 0.2500\n",
            "Epoch 213/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6267 - accuracy: 0.6507 - val_loss: 0.8033 - val_accuracy: 0.2500\n",
            "Epoch 214/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6267 - accuracy: 0.6490 - val_loss: 0.8039 - val_accuracy: 0.2500\n",
            "Epoch 215/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6266 - accuracy: 0.6507 - val_loss: 0.8034 - val_accuracy: 0.2500\n",
            "Epoch 216/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6267 - accuracy: 0.6498 - val_loss: 0.8042 - val_accuracy: 0.2500\n",
            "Epoch 217/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6267 - accuracy: 0.6490 - val_loss: 0.8039 - val_accuracy: 0.2500\n",
            "Epoch 218/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6265 - accuracy: 0.6515 - val_loss: 0.8031 - val_accuracy: 0.2500\n",
            "Epoch 219/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6267 - accuracy: 0.6448 - val_loss: 0.8047 - val_accuracy: 0.2500\n",
            "Epoch 220/1000\n",
            "594/594 [==============================] - 0s 34us/sample - loss: 0.6265 - accuracy: 0.6540 - val_loss: 0.8031 - val_accuracy: 0.2500\n",
            "Epoch 221/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6273 - accuracy: 0.6465 - val_loss: 0.8059 - val_accuracy: 0.2500\n",
            "Epoch 222/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6263 - accuracy: 0.6524 - val_loss: 0.8046 - val_accuracy: 0.2500\n",
            "Epoch 223/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6263 - accuracy: 0.6490 - val_loss: 0.8043 - val_accuracy: 0.2500\n",
            "Epoch 224/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6263 - accuracy: 0.6507 - val_loss: 0.8037 - val_accuracy: 0.2500\n",
            "Epoch 225/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6263 - accuracy: 0.6524 - val_loss: 0.8040 - val_accuracy: 0.2500\n",
            "Epoch 226/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6262 - accuracy: 0.6515 - val_loss: 0.8030 - val_accuracy: 0.2500\n",
            "Epoch 227/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6264 - accuracy: 0.6498 - val_loss: 0.8040 - val_accuracy: 0.2500\n",
            "Epoch 228/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6264 - accuracy: 0.6540 - val_loss: 0.8011 - val_accuracy: 0.2500\n",
            "Epoch 229/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6260 - accuracy: 0.6515 - val_loss: 0.8004 - val_accuracy: 0.2500\n",
            "Epoch 230/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6262 - accuracy: 0.6566 - val_loss: 0.7987 - val_accuracy: 0.2500\n",
            "Epoch 231/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6260 - accuracy: 0.6540 - val_loss: 0.8002 - val_accuracy: 0.2500\n",
            "Epoch 232/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6260 - accuracy: 0.6515 - val_loss: 0.8011 - val_accuracy: 0.2500\n",
            "Epoch 233/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6259 - accuracy: 0.6515 - val_loss: 0.7994 - val_accuracy: 0.2500\n",
            "Epoch 234/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6257 - accuracy: 0.6532 - val_loss: 0.7993 - val_accuracy: 0.2500\n",
            "Epoch 235/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6257 - accuracy: 0.6549 - val_loss: 0.7997 - val_accuracy: 0.2500\n",
            "Epoch 236/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6260 - accuracy: 0.6507 - val_loss: 0.7973 - val_accuracy: 0.2500\n",
            "Epoch 237/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6256 - accuracy: 0.6515 - val_loss: 0.7980 - val_accuracy: 0.2500\n",
            "Epoch 238/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6258 - accuracy: 0.6557 - val_loss: 0.7995 - val_accuracy: 0.2500\n",
            "Epoch 239/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6258 - accuracy: 0.6540 - val_loss: 0.7969 - val_accuracy: 0.2500\n",
            "Epoch 240/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6257 - accuracy: 0.6557 - val_loss: 0.7953 - val_accuracy: 0.2500\n",
            "Epoch 241/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6254 - accuracy: 0.6540 - val_loss: 0.7954 - val_accuracy: 0.2500\n",
            "Epoch 242/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6254 - accuracy: 0.6532 - val_loss: 0.7956 - val_accuracy: 0.2500\n",
            "Epoch 243/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6253 - accuracy: 0.6532 - val_loss: 0.7967 - val_accuracy: 0.2500\n",
            "Epoch 244/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6257 - accuracy: 0.6549 - val_loss: 0.7941 - val_accuracy: 0.2500\n",
            "Epoch 245/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6252 - accuracy: 0.6532 - val_loss: 0.7942 - val_accuracy: 0.2500\n",
            "Epoch 246/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6252 - accuracy: 0.6524 - val_loss: 0.7953 - val_accuracy: 0.2500\n",
            "Epoch 247/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6251 - accuracy: 0.6532 - val_loss: 0.7954 - val_accuracy: 0.2500\n",
            "Epoch 248/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6250 - accuracy: 0.6549 - val_loss: 0.7951 - val_accuracy: 0.2500\n",
            "Epoch 249/1000\n",
            "594/594 [==============================] - 0s 34us/sample - loss: 0.6250 - accuracy: 0.6566 - val_loss: 0.7944 - val_accuracy: 0.2500\n",
            "Epoch 250/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6250 - accuracy: 0.6507 - val_loss: 0.7954 - val_accuracy: 0.2500\n",
            "Epoch 251/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6250 - accuracy: 0.6549 - val_loss: 0.7951 - val_accuracy: 0.2500\n",
            "Epoch 252/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6254 - accuracy: 0.6515 - val_loss: 0.7972 - val_accuracy: 0.2500\n",
            "Epoch 253/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6249 - accuracy: 0.6549 - val_loss: 0.7957 - val_accuracy: 0.2500\n",
            "Epoch 254/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6251 - accuracy: 0.6566 - val_loss: 0.7970 - val_accuracy: 0.2500\n",
            "Epoch 255/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6248 - accuracy: 0.6540 - val_loss: 0.7953 - val_accuracy: 0.2500\n",
            "Epoch 256/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6247 - accuracy: 0.6549 - val_loss: 0.7950 - val_accuracy: 0.2500\n",
            "Epoch 257/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6247 - accuracy: 0.6574 - val_loss: 0.7954 - val_accuracy: 0.2500\n",
            "Epoch 258/1000\n",
            "594/594 [==============================] - 0s 36us/sample - loss: 0.6247 - accuracy: 0.6566 - val_loss: 0.7959 - val_accuracy: 0.2500\n",
            "Epoch 259/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6249 - accuracy: 0.6507 - val_loss: 0.7969 - val_accuracy: 0.2500\n",
            "Epoch 260/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6253 - accuracy: 0.6532 - val_loss: 0.7928 - val_accuracy: 0.2500\n",
            "Epoch 261/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6245 - accuracy: 0.6557 - val_loss: 0.7926 - val_accuracy: 0.2500\n",
            "Epoch 262/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6247 - accuracy: 0.6515 - val_loss: 0.7944 - val_accuracy: 0.2500\n",
            "Epoch 263/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6243 - accuracy: 0.6549 - val_loss: 0.7932 - val_accuracy: 0.2500\n",
            "Epoch 264/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6246 - accuracy: 0.6524 - val_loss: 0.7909 - val_accuracy: 0.2500\n",
            "Epoch 265/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6243 - accuracy: 0.6524 - val_loss: 0.7901 - val_accuracy: 0.2500\n",
            "Epoch 266/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6245 - accuracy: 0.6532 - val_loss: 0.7923 - val_accuracy: 0.2500\n",
            "Epoch 267/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6242 - accuracy: 0.6540 - val_loss: 0.7908 - val_accuracy: 0.2500\n",
            "Epoch 268/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6242 - accuracy: 0.6540 - val_loss: 0.7900 - val_accuracy: 0.2500\n",
            "Epoch 269/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6241 - accuracy: 0.6549 - val_loss: 0.7906 - val_accuracy: 0.2500\n",
            "Epoch 270/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6240 - accuracy: 0.6549 - val_loss: 0.7905 - val_accuracy: 0.2500\n",
            "Epoch 271/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6240 - accuracy: 0.6532 - val_loss: 0.7911 - val_accuracy: 0.2500\n",
            "Epoch 272/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6239 - accuracy: 0.6557 - val_loss: 0.7905 - val_accuracy: 0.2500\n",
            "Epoch 273/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6239 - accuracy: 0.6540 - val_loss: 0.7903 - val_accuracy: 0.2500\n",
            "Epoch 274/1000\n",
            "594/594 [==============================] - 0s 33us/sample - loss: 0.6238 - accuracy: 0.6557 - val_loss: 0.7899 - val_accuracy: 0.2500\n",
            "Epoch 275/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6239 - accuracy: 0.6532 - val_loss: 0.7889 - val_accuracy: 0.2500\n",
            "Epoch 276/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6238 - accuracy: 0.6540 - val_loss: 0.7898 - val_accuracy: 0.2500\n",
            "Epoch 277/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6239 - accuracy: 0.6532 - val_loss: 0.7914 - val_accuracy: 0.2500\n",
            "Epoch 278/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6237 - accuracy: 0.6549 - val_loss: 0.7908 - val_accuracy: 0.2500\n",
            "Epoch 279/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6238 - accuracy: 0.6557 - val_loss: 0.7894 - val_accuracy: 0.2500\n",
            "Epoch 280/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6236 - accuracy: 0.6557 - val_loss: 0.7900 - val_accuracy: 0.2500\n",
            "Epoch 281/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6236 - accuracy: 0.6540 - val_loss: 0.7905 - val_accuracy: 0.2500\n",
            "Epoch 282/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6235 - accuracy: 0.6549 - val_loss: 0.7900 - val_accuracy: 0.2500\n",
            "Epoch 283/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6236 - accuracy: 0.6557 - val_loss: 0.7886 - val_accuracy: 0.2500\n",
            "Epoch 284/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6234 - accuracy: 0.6557 - val_loss: 0.7889 - val_accuracy: 0.2500\n",
            "Epoch 285/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6238 - accuracy: 0.6507 - val_loss: 0.7869 - val_accuracy: 0.2500\n",
            "Epoch 286/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.6248 - accuracy: 0.6515 - val_loss: 0.7916 - val_accuracy: 0.2500\n",
            "Epoch 287/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6234 - accuracy: 0.6557 - val_loss: 0.7918 - val_accuracy: 0.2500\n",
            "Epoch 288/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6232 - accuracy: 0.6549 - val_loss: 0.7905 - val_accuracy: 0.2500\n",
            "Epoch 289/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6234 - accuracy: 0.6557 - val_loss: 0.7913 - val_accuracy: 0.2500\n",
            "Epoch 290/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6232 - accuracy: 0.6557 - val_loss: 0.7902 - val_accuracy: 0.2500\n",
            "Epoch 291/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6234 - accuracy: 0.6566 - val_loss: 0.7880 - val_accuracy: 0.2500\n",
            "Epoch 292/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6233 - accuracy: 0.6532 - val_loss: 0.7871 - val_accuracy: 0.2500\n",
            "Epoch 293/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6234 - accuracy: 0.6532 - val_loss: 0.7858 - val_accuracy: 0.2500\n",
            "Epoch 294/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6231 - accuracy: 0.6566 - val_loss: 0.7875 - val_accuracy: 0.2500\n",
            "Epoch 295/1000\n",
            "594/594 [==============================] - 0s 33us/sample - loss: 0.6232 - accuracy: 0.6582 - val_loss: 0.7890 - val_accuracy: 0.2500\n",
            "Epoch 296/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6230 - accuracy: 0.6566 - val_loss: 0.7881 - val_accuracy: 0.2500\n",
            "Epoch 297/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6229 - accuracy: 0.6549 - val_loss: 0.7887 - val_accuracy: 0.2500\n",
            "Epoch 298/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6229 - accuracy: 0.6566 - val_loss: 0.7879 - val_accuracy: 0.2500\n",
            "Epoch 299/1000\n",
            "594/594 [==============================] - 0s 34us/sample - loss: 0.6232 - accuracy: 0.6574 - val_loss: 0.7896 - val_accuracy: 0.2500\n",
            "Epoch 300/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.6228 - accuracy: 0.6557 - val_loss: 0.7885 - val_accuracy: 0.2500\n",
            "Epoch 301/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6228 - accuracy: 0.6566 - val_loss: 0.7885 - val_accuracy: 0.2500\n",
            "Epoch 302/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6227 - accuracy: 0.6566 - val_loss: 0.7877 - val_accuracy: 0.2500\n",
            "Epoch 303/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6227 - accuracy: 0.6557 - val_loss: 0.7865 - val_accuracy: 0.2500\n",
            "Epoch 304/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6226 - accuracy: 0.6566 - val_loss: 0.7867 - val_accuracy: 0.2500\n",
            "Epoch 305/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6227 - accuracy: 0.6582 - val_loss: 0.7858 - val_accuracy: 0.2500\n",
            "Epoch 306/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6225 - accuracy: 0.6566 - val_loss: 0.7858 - val_accuracy: 0.2500\n",
            "Epoch 307/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6234 - accuracy: 0.6507 - val_loss: 0.7891 - val_accuracy: 0.2500\n",
            "Epoch 308/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6227 - accuracy: 0.6574 - val_loss: 0.7897 - val_accuracy: 0.2500\n",
            "Epoch 309/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6226 - accuracy: 0.6549 - val_loss: 0.7868 - val_accuracy: 0.2500\n",
            "Epoch 310/1000\n",
            "594/594 [==============================] - 0s 33us/sample - loss: 0.6225 - accuracy: 0.6582 - val_loss: 0.7875 - val_accuracy: 0.2500\n",
            "Epoch 311/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6223 - accuracy: 0.6557 - val_loss: 0.7865 - val_accuracy: 0.2500\n",
            "Epoch 312/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6223 - accuracy: 0.6574 - val_loss: 0.7852 - val_accuracy: 0.2500\n",
            "Epoch 313/1000\n",
            "594/594 [==============================] - 0s 38us/sample - loss: 0.6222 - accuracy: 0.6574 - val_loss: 0.7849 - val_accuracy: 0.2500\n",
            "Epoch 314/1000\n",
            "594/594 [==============================] - 0s 35us/sample - loss: 0.6222 - accuracy: 0.6591 - val_loss: 0.7846 - val_accuracy: 0.2500\n",
            "Epoch 315/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6222 - accuracy: 0.6599 - val_loss: 0.7854 - val_accuracy: 0.2500\n",
            "Epoch 316/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6225 - accuracy: 0.6557 - val_loss: 0.7825 - val_accuracy: 0.2500\n",
            "Epoch 317/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6220 - accuracy: 0.6582 - val_loss: 0.7827 - val_accuracy: 0.2500\n",
            "Epoch 318/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6220 - accuracy: 0.6582 - val_loss: 0.7837 - val_accuracy: 0.2500\n",
            "Epoch 319/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6220 - accuracy: 0.6557 - val_loss: 0.7823 - val_accuracy: 0.2500\n",
            "Epoch 320/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6219 - accuracy: 0.6566 - val_loss: 0.7817 - val_accuracy: 0.2500\n",
            "Epoch 321/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6218 - accuracy: 0.6582 - val_loss: 0.7816 - val_accuracy: 0.2500\n",
            "Epoch 322/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6217 - accuracy: 0.6582 - val_loss: 0.7821 - val_accuracy: 0.2500\n",
            "Epoch 323/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6217 - accuracy: 0.6591 - val_loss: 0.7823 - val_accuracy: 0.2500\n",
            "Epoch 324/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.6217 - accuracy: 0.6591 - val_loss: 0.7813 - val_accuracy: 0.2500\n",
            "Epoch 325/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6217 - accuracy: 0.6574 - val_loss: 0.7796 - val_accuracy: 0.2500\n",
            "Epoch 326/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6215 - accuracy: 0.6599 - val_loss: 0.7802 - val_accuracy: 0.2500\n",
            "Epoch 327/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6215 - accuracy: 0.6599 - val_loss: 0.7807 - val_accuracy: 0.2500\n",
            "Epoch 328/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6214 - accuracy: 0.6574 - val_loss: 0.7799 - val_accuracy: 0.2500\n",
            "Epoch 329/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6213 - accuracy: 0.6591 - val_loss: 0.7796 - val_accuracy: 0.2500\n",
            "Epoch 330/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6212 - accuracy: 0.6591 - val_loss: 0.7794 - val_accuracy: 0.2500\n",
            "Epoch 331/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6216 - accuracy: 0.6625 - val_loss: 0.7770 - val_accuracy: 0.2500\n",
            "Epoch 332/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6215 - accuracy: 0.6625 - val_loss: 0.7757 - val_accuracy: 0.2500\n",
            "Epoch 333/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6212 - accuracy: 0.6574 - val_loss: 0.7778 - val_accuracy: 0.2500\n",
            "Epoch 334/1000\n",
            "594/594 [==============================] - 0s 35us/sample - loss: 0.6211 - accuracy: 0.6633 - val_loss: 0.7765 - val_accuracy: 0.2500\n",
            "Epoch 335/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6211 - accuracy: 0.6608 - val_loss: 0.7780 - val_accuracy: 0.2500\n",
            "Epoch 336/1000\n",
            "594/594 [==============================] - 0s 36us/sample - loss: 0.6210 - accuracy: 0.6641 - val_loss: 0.7770 - val_accuracy: 0.2500\n",
            "Epoch 337/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6216 - accuracy: 0.6524 - val_loss: 0.7794 - val_accuracy: 0.2500\n",
            "Epoch 338/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6208 - accuracy: 0.6641 - val_loss: 0.7788 - val_accuracy: 0.2500\n",
            "Epoch 339/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6207 - accuracy: 0.6650 - val_loss: 0.7770 - val_accuracy: 0.2500\n",
            "Epoch 340/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6207 - accuracy: 0.6641 - val_loss: 0.7753 - val_accuracy: 0.2500\n",
            "Epoch 341/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6206 - accuracy: 0.6667 - val_loss: 0.7750 - val_accuracy: 0.2500\n",
            "Epoch 342/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6208 - accuracy: 0.6633 - val_loss: 0.7730 - val_accuracy: 0.3333\n",
            "Epoch 343/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6209 - accuracy: 0.6616 - val_loss: 0.7754 - val_accuracy: 0.2500\n",
            "Epoch 344/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6203 - accuracy: 0.6667 - val_loss: 0.7743 - val_accuracy: 0.2500\n",
            "Epoch 345/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6203 - accuracy: 0.6658 - val_loss: 0.7730 - val_accuracy: 0.2500\n",
            "Epoch 346/1000\n",
            "594/594 [==============================] - 0s 36us/sample - loss: 0.6202 - accuracy: 0.6675 - val_loss: 0.7728 - val_accuracy: 0.2500\n",
            "Epoch 347/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6201 - accuracy: 0.6667 - val_loss: 0.7722 - val_accuracy: 0.3333\n",
            "Epoch 348/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6204 - accuracy: 0.6641 - val_loss: 0.7700 - val_accuracy: 0.3333\n",
            "Epoch 349/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6201 - accuracy: 0.6684 - val_loss: 0.7716 - val_accuracy: 0.3333\n",
            "Epoch 350/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6200 - accuracy: 0.6684 - val_loss: 0.7726 - val_accuracy: 0.2500\n",
            "Epoch 351/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6199 - accuracy: 0.6675 - val_loss: 0.7708 - val_accuracy: 0.3333\n",
            "Epoch 352/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6201 - accuracy: 0.6641 - val_loss: 0.7727 - val_accuracy: 0.2500\n",
            "Epoch 353/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6197 - accuracy: 0.6675 - val_loss: 0.7724 - val_accuracy: 0.3333\n",
            "Epoch 354/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6196 - accuracy: 0.6675 - val_loss: 0.7712 - val_accuracy: 0.3333\n",
            "Epoch 355/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6195 - accuracy: 0.6675 - val_loss: 0.7703 - val_accuracy: 0.3333\n",
            "Epoch 356/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6196 - accuracy: 0.6684 - val_loss: 0.7689 - val_accuracy: 0.3333\n",
            "Epoch 357/1000\n",
            "594/594 [==============================] - 0s 38us/sample - loss: 0.6200 - accuracy: 0.6658 - val_loss: 0.7713 - val_accuracy: 0.3333\n",
            "Epoch 358/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6196 - accuracy: 0.6667 - val_loss: 0.7689 - val_accuracy: 0.3333\n",
            "Epoch 359/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6193 - accuracy: 0.6700 - val_loss: 0.7686 - val_accuracy: 0.3333\n",
            "Epoch 360/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6192 - accuracy: 0.6700 - val_loss: 0.7674 - val_accuracy: 0.3333\n",
            "Epoch 361/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6192 - accuracy: 0.6684 - val_loss: 0.7665 - val_accuracy: 0.4167\n",
            "Epoch 362/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6191 - accuracy: 0.6700 - val_loss: 0.7673 - val_accuracy: 0.3333\n",
            "Epoch 363/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6190 - accuracy: 0.6700 - val_loss: 0.7671 - val_accuracy: 0.3333\n",
            "Epoch 364/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6189 - accuracy: 0.6684 - val_loss: 0.7662 - val_accuracy: 0.4167\n",
            "Epoch 365/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6190 - accuracy: 0.6717 - val_loss: 0.7677 - val_accuracy: 0.3333\n",
            "Epoch 366/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6189 - accuracy: 0.6692 - val_loss: 0.7662 - val_accuracy: 0.4167\n",
            "Epoch 367/1000\n",
            "594/594 [==============================] - 0s 34us/sample - loss: 0.6187 - accuracy: 0.6742 - val_loss: 0.7668 - val_accuracy: 0.4167\n",
            "Epoch 368/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.6188 - accuracy: 0.6726 - val_loss: 0.7680 - val_accuracy: 0.3333\n",
            "Epoch 369/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6187 - accuracy: 0.6734 - val_loss: 0.7689 - val_accuracy: 0.3333\n",
            "Epoch 370/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6187 - accuracy: 0.6667 - val_loss: 0.7659 - val_accuracy: 0.4167\n",
            "Epoch 371/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6183 - accuracy: 0.6709 - val_loss: 0.7659 - val_accuracy: 0.4167\n",
            "Epoch 372/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6183 - accuracy: 0.6726 - val_loss: 0.7648 - val_accuracy: 0.4167\n",
            "Epoch 373/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6183 - accuracy: 0.6692 - val_loss: 0.7636 - val_accuracy: 0.4167\n",
            "Epoch 374/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6182 - accuracy: 0.6726 - val_loss: 0.7637 - val_accuracy: 0.4167\n",
            "Epoch 375/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6182 - accuracy: 0.6717 - val_loss: 0.7626 - val_accuracy: 0.5000\n",
            "Epoch 376/1000\n",
            "594/594 [==============================] - 0s 37us/sample - loss: 0.6180 - accuracy: 0.6751 - val_loss: 0.7630 - val_accuracy: 0.4167\n",
            "Epoch 377/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6180 - accuracy: 0.6742 - val_loss: 0.7637 - val_accuracy: 0.4167\n",
            "Epoch 378/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6178 - accuracy: 0.6751 - val_loss: 0.7640 - val_accuracy: 0.4167\n",
            "Epoch 379/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6177 - accuracy: 0.6734 - val_loss: 0.7634 - val_accuracy: 0.4167\n",
            "Epoch 380/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6177 - accuracy: 0.6734 - val_loss: 0.7621 - val_accuracy: 0.5000\n",
            "Epoch 381/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6176 - accuracy: 0.6751 - val_loss: 0.7621 - val_accuracy: 0.5000\n",
            "Epoch 382/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6176 - accuracy: 0.6726 - val_loss: 0.7612 - val_accuracy: 0.5000\n",
            "Epoch 383/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6175 - accuracy: 0.6742 - val_loss: 0.7613 - val_accuracy: 0.5000\n",
            "Epoch 384/1000\n",
            "594/594 [==============================] - 0s 35us/sample - loss: 0.6175 - accuracy: 0.6776 - val_loss: 0.7634 - val_accuracy: 0.5000\n",
            "Epoch 385/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6173 - accuracy: 0.6785 - val_loss: 0.7641 - val_accuracy: 0.4167\n",
            "Epoch 386/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6181 - accuracy: 0.6717 - val_loss: 0.7669 - val_accuracy: 0.4167\n",
            "Epoch 387/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6175 - accuracy: 0.6751 - val_loss: 0.7676 - val_accuracy: 0.4167\n",
            "Epoch 388/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6170 - accuracy: 0.6692 - val_loss: 0.7652 - val_accuracy: 0.4167\n",
            "Epoch 389/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6172 - accuracy: 0.6734 - val_loss: 0.7622 - val_accuracy: 0.5000\n",
            "Epoch 390/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6167 - accuracy: 0.6751 - val_loss: 0.7619 - val_accuracy: 0.5000\n",
            "Epoch 391/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6169 - accuracy: 0.6751 - val_loss: 0.7635 - val_accuracy: 0.5000\n",
            "Epoch 392/1000\n",
            "594/594 [==============================] - 0s 35us/sample - loss: 0.6166 - accuracy: 0.6742 - val_loss: 0.7630 - val_accuracy: 0.5000\n",
            "Epoch 393/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6165 - accuracy: 0.6751 - val_loss: 0.7619 - val_accuracy: 0.5000\n",
            "Epoch 394/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6164 - accuracy: 0.6768 - val_loss: 0.7611 - val_accuracy: 0.5000\n",
            "Epoch 395/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6164 - accuracy: 0.6785 - val_loss: 0.7614 - val_accuracy: 0.5000\n",
            "Epoch 396/1000\n",
            "594/594 [==============================] - 0s 36us/sample - loss: 0.6162 - accuracy: 0.6785 - val_loss: 0.7607 - val_accuracy: 0.5833\n",
            "Epoch 397/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6164 - accuracy: 0.6793 - val_loss: 0.7620 - val_accuracy: 0.5000\n",
            "Epoch 398/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6163 - accuracy: 0.6785 - val_loss: 0.7628 - val_accuracy: 0.5000\n",
            "Epoch 399/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6160 - accuracy: 0.6776 - val_loss: 0.7612 - val_accuracy: 0.5833\n",
            "Epoch 400/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6161 - accuracy: 0.6768 - val_loss: 0.7622 - val_accuracy: 0.5000\n",
            "Epoch 401/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6161 - accuracy: 0.6734 - val_loss: 0.7591 - val_accuracy: 0.5833\n",
            "Epoch 402/1000\n",
            "594/594 [==============================] - 0s 37us/sample - loss: 0.6158 - accuracy: 0.6810 - val_loss: 0.7594 - val_accuracy: 0.5833\n",
            "Epoch 403/1000\n",
            "594/594 [==============================] - 0s 37us/sample - loss: 0.6160 - accuracy: 0.6692 - val_loss: 0.7610 - val_accuracy: 0.5833\n",
            "Epoch 404/1000\n",
            "594/594 [==============================] - 0s 42us/sample - loss: 0.6156 - accuracy: 0.6818 - val_loss: 0.7606 - val_accuracy: 0.5833\n",
            "Epoch 405/1000\n",
            "594/594 [==============================] - 0s 35us/sample - loss: 0.6154 - accuracy: 0.6801 - val_loss: 0.7595 - val_accuracy: 0.5833\n",
            "Epoch 406/1000\n",
            "594/594 [==============================] - 0s 33us/sample - loss: 0.6154 - accuracy: 0.6818 - val_loss: 0.7588 - val_accuracy: 0.5833\n",
            "Epoch 407/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6155 - accuracy: 0.6818 - val_loss: 0.7597 - val_accuracy: 0.5833\n",
            "Epoch 408/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6152 - accuracy: 0.6801 - val_loss: 0.7581 - val_accuracy: 0.5833\n",
            "Epoch 409/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6151 - accuracy: 0.6818 - val_loss: 0.7578 - val_accuracy: 0.5833\n",
            "Epoch 410/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6152 - accuracy: 0.6818 - val_loss: 0.7584 - val_accuracy: 0.5833\n",
            "Epoch 411/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6153 - accuracy: 0.6776 - val_loss: 0.7559 - val_accuracy: 0.5833\n",
            "Epoch 412/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6149 - accuracy: 0.6843 - val_loss: 0.7553 - val_accuracy: 0.5833\n",
            "Epoch 413/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6148 - accuracy: 0.6835 - val_loss: 0.7553 - val_accuracy: 0.5833\n",
            "Epoch 414/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6149 - accuracy: 0.6801 - val_loss: 0.7559 - val_accuracy: 0.5833\n",
            "Epoch 415/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6147 - accuracy: 0.6818 - val_loss: 0.7553 - val_accuracy: 0.5833\n",
            "Epoch 416/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6146 - accuracy: 0.6852 - val_loss: 0.7559 - val_accuracy: 0.5833\n",
            "Epoch 417/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6154 - accuracy: 0.6785 - val_loss: 0.7525 - val_accuracy: 0.5833\n",
            "Epoch 418/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6144 - accuracy: 0.6843 - val_loss: 0.7530 - val_accuracy: 0.5833\n",
            "Epoch 419/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6144 - accuracy: 0.6843 - val_loss: 0.7541 - val_accuracy: 0.5833\n",
            "Epoch 420/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6144 - accuracy: 0.6835 - val_loss: 0.7533 - val_accuracy: 0.5833\n",
            "Epoch 421/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6142 - accuracy: 0.6827 - val_loss: 0.7533 - val_accuracy: 0.5833\n",
            "Epoch 422/1000\n",
            "594/594 [==============================] - 0s 48us/sample - loss: 0.6141 - accuracy: 0.6835 - val_loss: 0.7536 - val_accuracy: 0.5833\n",
            "Epoch 423/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6144 - accuracy: 0.6785 - val_loss: 0.7514 - val_accuracy: 0.5833\n",
            "Epoch 424/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6143 - accuracy: 0.6793 - val_loss: 0.7502 - val_accuracy: 0.5833\n",
            "Epoch 425/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6139 - accuracy: 0.6860 - val_loss: 0.7503 - val_accuracy: 0.5833\n",
            "Epoch 426/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6139 - accuracy: 0.6843 - val_loss: 0.7506 - val_accuracy: 0.5833\n",
            "Epoch 427/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6139 - accuracy: 0.6860 - val_loss: 0.7529 - val_accuracy: 0.5833\n",
            "Epoch 428/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6137 - accuracy: 0.6785 - val_loss: 0.7515 - val_accuracy: 0.5833\n",
            "Epoch 429/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6137 - accuracy: 0.6869 - val_loss: 0.7535 - val_accuracy: 0.5000\n",
            "Epoch 430/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6136 - accuracy: 0.6818 - val_loss: 0.7522 - val_accuracy: 0.5833\n",
            "Epoch 431/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6134 - accuracy: 0.6877 - val_loss: 0.7530 - val_accuracy: 0.5000\n",
            "Epoch 432/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6134 - accuracy: 0.6835 - val_loss: 0.7524 - val_accuracy: 0.5000\n",
            "Epoch 433/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6132 - accuracy: 0.6852 - val_loss: 0.7521 - val_accuracy: 0.5000\n",
            "Epoch 434/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6138 - accuracy: 0.6818 - val_loss: 0.7499 - val_accuracy: 0.5833\n",
            "Epoch 435/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6132 - accuracy: 0.6902 - val_loss: 0.7519 - val_accuracy: 0.5000\n",
            "Epoch 436/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6132 - accuracy: 0.6860 - val_loss: 0.7533 - val_accuracy: 0.5000\n",
            "Epoch 437/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6132 - accuracy: 0.6869 - val_loss: 0.7552 - val_accuracy: 0.5000\n",
            "Epoch 438/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6128 - accuracy: 0.6835 - val_loss: 0.7551 - val_accuracy: 0.5000\n",
            "Epoch 439/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6128 - accuracy: 0.6827 - val_loss: 0.7540 - val_accuracy: 0.5000\n",
            "Epoch 440/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6127 - accuracy: 0.6835 - val_loss: 0.7548 - val_accuracy: 0.5000\n",
            "Epoch 441/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6130 - accuracy: 0.6843 - val_loss: 0.7566 - val_accuracy: 0.5000\n",
            "Epoch 442/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6127 - accuracy: 0.6852 - val_loss: 0.7563 - val_accuracy: 0.5000\n",
            "Epoch 443/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6140 - accuracy: 0.6726 - val_loss: 0.7514 - val_accuracy: 0.5000\n",
            "Epoch 444/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6125 - accuracy: 0.6843 - val_loss: 0.7516 - val_accuracy: 0.5000\n",
            "Epoch 445/1000\n",
            "594/594 [==============================] - 0s 34us/sample - loss: 0.6124 - accuracy: 0.6818 - val_loss: 0.7514 - val_accuracy: 0.5000\n",
            "Epoch 446/1000\n",
            "594/594 [==============================] - 0s 41us/sample - loss: 0.6122 - accuracy: 0.6877 - val_loss: 0.7527 - val_accuracy: 0.5000\n",
            "Epoch 447/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6121 - accuracy: 0.6852 - val_loss: 0.7531 - val_accuracy: 0.5000\n",
            "Epoch 448/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6122 - accuracy: 0.6827 - val_loss: 0.7524 - val_accuracy: 0.5000\n",
            "Epoch 449/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6119 - accuracy: 0.6843 - val_loss: 0.7531 - val_accuracy: 0.5000\n",
            "Epoch 450/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6122 - accuracy: 0.6801 - val_loss: 0.7516 - val_accuracy: 0.5000\n",
            "Epoch 451/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6121 - accuracy: 0.6869 - val_loss: 0.7544 - val_accuracy: 0.5000\n",
            "Epoch 452/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6117 - accuracy: 0.6835 - val_loss: 0.7544 - val_accuracy: 0.5000\n",
            "Epoch 453/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6117 - accuracy: 0.6835 - val_loss: 0.7553 - val_accuracy: 0.5000\n",
            "Epoch 454/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6119 - accuracy: 0.6810 - val_loss: 0.7562 - val_accuracy: 0.5000\n",
            "Epoch 455/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6116 - accuracy: 0.6827 - val_loss: 0.7569 - val_accuracy: 0.5000\n",
            "Epoch 456/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6114 - accuracy: 0.6827 - val_loss: 0.7561 - val_accuracy: 0.5000\n",
            "Epoch 457/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6116 - accuracy: 0.6860 - val_loss: 0.7581 - val_accuracy: 0.5000\n",
            "Epoch 458/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6116 - accuracy: 0.6877 - val_loss: 0.7595 - val_accuracy: 0.5000\n",
            "Epoch 459/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6112 - accuracy: 0.6801 - val_loss: 0.7579 - val_accuracy: 0.5000\n",
            "Epoch 460/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6116 - accuracy: 0.6810 - val_loss: 0.7604 - val_accuracy: 0.5000\n",
            "Epoch 461/1000\n",
            "594/594 [==============================] - 0s 36us/sample - loss: 0.6111 - accuracy: 0.6818 - val_loss: 0.7586 - val_accuracy: 0.5000\n",
            "Epoch 462/1000\n",
            "594/594 [==============================] - 0s 34us/sample - loss: 0.6114 - accuracy: 0.6827 - val_loss: 0.7609 - val_accuracy: 0.5000\n",
            "Epoch 463/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6109 - accuracy: 0.6818 - val_loss: 0.7596 - val_accuracy: 0.5000\n",
            "Epoch 464/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6108 - accuracy: 0.6835 - val_loss: 0.7599 - val_accuracy: 0.5000\n",
            "Epoch 465/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.6109 - accuracy: 0.6793 - val_loss: 0.7573 - val_accuracy: 0.5000\n",
            "Epoch 466/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6105 - accuracy: 0.6835 - val_loss: 0.7575 - val_accuracy: 0.5000\n",
            "Epoch 467/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6105 - accuracy: 0.6827 - val_loss: 0.7574 - val_accuracy: 0.5000\n",
            "Epoch 468/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6104 - accuracy: 0.6801 - val_loss: 0.7571 - val_accuracy: 0.5000\n",
            "Epoch 469/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6105 - accuracy: 0.6776 - val_loss: 0.7558 - val_accuracy: 0.5000\n",
            "Epoch 470/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6105 - accuracy: 0.6810 - val_loss: 0.7547 - val_accuracy: 0.5833\n",
            "Epoch 471/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6101 - accuracy: 0.6843 - val_loss: 0.7571 - val_accuracy: 0.5000\n",
            "Epoch 472/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6099 - accuracy: 0.6843 - val_loss: 0.7586 - val_accuracy: 0.5000\n",
            "Epoch 473/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6098 - accuracy: 0.6818 - val_loss: 0.7589 - val_accuracy: 0.5000\n",
            "Epoch 474/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6098 - accuracy: 0.6818 - val_loss: 0.7599 - val_accuracy: 0.5000\n",
            "Epoch 475/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6097 - accuracy: 0.6827 - val_loss: 0.7612 - val_accuracy: 0.5000\n",
            "Epoch 476/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6096 - accuracy: 0.6818 - val_loss: 0.7610 - val_accuracy: 0.5000\n",
            "Epoch 477/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6095 - accuracy: 0.6810 - val_loss: 0.7605 - val_accuracy: 0.5000\n",
            "Epoch 478/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6094 - accuracy: 0.6818 - val_loss: 0.7602 - val_accuracy: 0.5833\n",
            "Epoch 479/1000\n",
            "594/594 [==============================] - 0s 41us/sample - loss: 0.6093 - accuracy: 0.6818 - val_loss: 0.7606 - val_accuracy: 0.5833\n",
            "Epoch 480/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6092 - accuracy: 0.6818 - val_loss: 0.7609 - val_accuracy: 0.5833\n",
            "Epoch 481/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6096 - accuracy: 0.6835 - val_loss: 0.7638 - val_accuracy: 0.5000\n",
            "Epoch 482/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6090 - accuracy: 0.6818 - val_loss: 0.7639 - val_accuracy: 0.5000\n",
            "Epoch 483/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6089 - accuracy: 0.6818 - val_loss: 0.7638 - val_accuracy: 0.5833\n",
            "Epoch 484/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6088 - accuracy: 0.6818 - val_loss: 0.7633 - val_accuracy: 0.5833\n",
            "Epoch 485/1000\n",
            "297/594 [==============>...............] - ETA: 0s - loss: 0.6228 - accuracy: 0.6751\n",
            "Epoch 00485: ReduceLROnPlateau reducing learning rate to 0.125.\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6089 - accuracy: 0.6793 - val_loss: 0.7617 - val_accuracy: 0.5833\n",
            "Epoch 486/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6086 - accuracy: 0.6818 - val_loss: 0.7623 - val_accuracy: 0.5833\n",
            "Epoch 487/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6085 - accuracy: 0.6810 - val_loss: 0.7624 - val_accuracy: 0.5833\n",
            "Epoch 488/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6085 - accuracy: 0.6810 - val_loss: 0.7629 - val_accuracy: 0.5833\n",
            "Epoch 489/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6085 - accuracy: 0.6810 - val_loss: 0.7631 - val_accuracy: 0.5833\n",
            "Epoch 490/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6084 - accuracy: 0.6810 - val_loss: 0.7631 - val_accuracy: 0.5833\n",
            "Epoch 491/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6085 - accuracy: 0.6827 - val_loss: 0.7635 - val_accuracy: 0.5833\n",
            "Epoch 492/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6084 - accuracy: 0.6818 - val_loss: 0.7639 - val_accuracy: 0.5833\n",
            "Epoch 493/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6083 - accuracy: 0.6810 - val_loss: 0.7637 - val_accuracy: 0.5833\n",
            "Epoch 494/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6082 - accuracy: 0.6818 - val_loss: 0.7640 - val_accuracy: 0.5833\n",
            "Epoch 495/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6083 - accuracy: 0.6818 - val_loss: 0.7645 - val_accuracy: 0.5833\n",
            "Epoch 496/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6081 - accuracy: 0.6810 - val_loss: 0.7647 - val_accuracy: 0.5833\n",
            "Epoch 497/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6083 - accuracy: 0.6827 - val_loss: 0.7654 - val_accuracy: 0.5833\n",
            "Epoch 498/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6083 - accuracy: 0.6835 - val_loss: 0.7659 - val_accuracy: 0.5833\n",
            "Epoch 499/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6081 - accuracy: 0.6810 - val_loss: 0.7662 - val_accuracy: 0.5833\n",
            "Epoch 500/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6079 - accuracy: 0.6818 - val_loss: 0.7659 - val_accuracy: 0.5833\n",
            "Epoch 501/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6080 - accuracy: 0.6818 - val_loss: 0.7654 - val_accuracy: 0.5833\n",
            "Epoch 502/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6081 - accuracy: 0.6835 - val_loss: 0.7660 - val_accuracy: 0.5833\n",
            "Epoch 503/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6078 - accuracy: 0.6810 - val_loss: 0.7662 - val_accuracy: 0.5833\n",
            "Epoch 504/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6079 - accuracy: 0.6793 - val_loss: 0.7654 - val_accuracy: 0.5833\n",
            "Epoch 505/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6076 - accuracy: 0.6827 - val_loss: 0.7656 - val_accuracy: 0.5833\n",
            "Epoch 506/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6076 - accuracy: 0.6843 - val_loss: 0.7655 - val_accuracy: 0.5833\n",
            "Epoch 507/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6076 - accuracy: 0.6835 - val_loss: 0.7651 - val_accuracy: 0.5833\n",
            "Epoch 508/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6075 - accuracy: 0.6843 - val_loss: 0.7652 - val_accuracy: 0.5833\n",
            "Epoch 509/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6075 - accuracy: 0.6843 - val_loss: 0.7652 - val_accuracy: 0.5833\n",
            "Epoch 510/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6075 - accuracy: 0.6835 - val_loss: 0.7650 - val_accuracy: 0.5833\n",
            "Epoch 511/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6075 - accuracy: 0.6843 - val_loss: 0.7657 - val_accuracy: 0.5833\n",
            "Epoch 512/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6073 - accuracy: 0.6843 - val_loss: 0.7657 - val_accuracy: 0.5833\n",
            "Epoch 513/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6074 - accuracy: 0.6835 - val_loss: 0.7651 - val_accuracy: 0.5833\n",
            "Epoch 514/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6073 - accuracy: 0.6843 - val_loss: 0.7654 - val_accuracy: 0.5833\n",
            "Epoch 515/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6071 - accuracy: 0.6835 - val_loss: 0.7657 - val_accuracy: 0.5833\n",
            "Epoch 516/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6071 - accuracy: 0.6843 - val_loss: 0.7659 - val_accuracy: 0.5833\n",
            "Epoch 517/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6071 - accuracy: 0.6835 - val_loss: 0.7656 - val_accuracy: 0.5833\n",
            "Epoch 518/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6069 - accuracy: 0.6843 - val_loss: 0.7658 - val_accuracy: 0.5833\n",
            "Epoch 519/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6069 - accuracy: 0.6843 - val_loss: 0.7658 - val_accuracy: 0.5833\n",
            "Epoch 520/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6068 - accuracy: 0.6835 - val_loss: 0.7660 - val_accuracy: 0.5833\n",
            "Epoch 521/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6067 - accuracy: 0.6843 - val_loss: 0.7664 - val_accuracy: 0.5833\n",
            "Epoch 522/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6068 - accuracy: 0.6835 - val_loss: 0.7670 - val_accuracy: 0.5833\n",
            "Epoch 523/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6067 - accuracy: 0.6852 - val_loss: 0.7668 - val_accuracy: 0.5833\n",
            "Epoch 524/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6066 - accuracy: 0.6852 - val_loss: 0.7669 - val_accuracy: 0.5833\n",
            "Epoch 525/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6066 - accuracy: 0.6860 - val_loss: 0.7674 - val_accuracy: 0.5833\n",
            "Epoch 526/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6065 - accuracy: 0.6843 - val_loss: 0.7672 - val_accuracy: 0.5833\n",
            "Epoch 527/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.6064 - accuracy: 0.6843 - val_loss: 0.7675 - val_accuracy: 0.5833\n",
            "Epoch 528/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6065 - accuracy: 0.6843 - val_loss: 0.7670 - val_accuracy: 0.5833\n",
            "Epoch 529/1000\n",
            "594/594 [==============================] - 0s 35us/sample - loss: 0.6063 - accuracy: 0.6843 - val_loss: 0.7675 - val_accuracy: 0.5833\n",
            "Epoch 530/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6062 - accuracy: 0.6852 - val_loss: 0.7675 - val_accuracy: 0.5833\n",
            "Epoch 531/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6062 - accuracy: 0.6852 - val_loss: 0.7679 - val_accuracy: 0.5833\n",
            "Epoch 532/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6061 - accuracy: 0.6843 - val_loss: 0.7681 - val_accuracy: 0.5833\n",
            "Epoch 533/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6060 - accuracy: 0.6843 - val_loss: 0.7683 - val_accuracy: 0.5833\n",
            "Epoch 534/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6060 - accuracy: 0.6843 - val_loss: 0.7680 - val_accuracy: 0.5833\n",
            "Epoch 535/1000\n",
            "297/594 [==============>...............] - ETA: 0s - loss: 0.6150 - accuracy: 0.6869\n",
            "Epoch 00535: ReduceLROnPlateau reducing learning rate to 0.0625.\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6059 - accuracy: 0.6860 - val_loss: 0.7683 - val_accuracy: 0.5833\n",
            "Epoch 536/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6059 - accuracy: 0.6852 - val_loss: 0.7683 - val_accuracy: 0.5833\n",
            "Epoch 537/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6058 - accuracy: 0.6860 - val_loss: 0.7684 - val_accuracy: 0.5833\n",
            "Epoch 538/1000\n",
            "594/594 [==============================] - 0s 36us/sample - loss: 0.6057 - accuracy: 0.6869 - val_loss: 0.7685 - val_accuracy: 0.5833\n",
            "Epoch 539/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6058 - accuracy: 0.6869 - val_loss: 0.7687 - val_accuracy: 0.5833\n",
            "Epoch 540/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6057 - accuracy: 0.6860 - val_loss: 0.7687 - val_accuracy: 0.5833\n",
            "Epoch 541/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6057 - accuracy: 0.6869 - val_loss: 0.7688 - val_accuracy: 0.5833\n",
            "Epoch 542/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6058 - accuracy: 0.6852 - val_loss: 0.7687 - val_accuracy: 0.5833\n",
            "Epoch 543/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6056 - accuracy: 0.6869 - val_loss: 0.7688 - val_accuracy: 0.5833\n",
            "Epoch 544/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6056 - accuracy: 0.6869 - val_loss: 0.7689 - val_accuracy: 0.5833\n",
            "Epoch 545/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6057 - accuracy: 0.6869 - val_loss: 0.7692 - val_accuracy: 0.5833\n",
            "Epoch 546/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6056 - accuracy: 0.6877 - val_loss: 0.7694 - val_accuracy: 0.5833\n",
            "Epoch 547/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6055 - accuracy: 0.6869 - val_loss: 0.7695 - val_accuracy: 0.5833\n",
            "Epoch 548/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6055 - accuracy: 0.6869 - val_loss: 0.7694 - val_accuracy: 0.5833\n",
            "Epoch 549/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6055 - accuracy: 0.6860 - val_loss: 0.7694 - val_accuracy: 0.5833\n",
            "Epoch 550/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6054 - accuracy: 0.6869 - val_loss: 0.7694 - val_accuracy: 0.5833\n",
            "Epoch 551/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6054 - accuracy: 0.6869 - val_loss: 0.7695 - val_accuracy: 0.5833\n",
            "Epoch 552/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6054 - accuracy: 0.6869 - val_loss: 0.7696 - val_accuracy: 0.5833\n",
            "Epoch 553/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6054 - accuracy: 0.6877 - val_loss: 0.7697 - val_accuracy: 0.5833\n",
            "Epoch 554/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6053 - accuracy: 0.6869 - val_loss: 0.7698 - val_accuracy: 0.5833\n",
            "Epoch 555/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6053 - accuracy: 0.6869 - val_loss: 0.7699 - val_accuracy: 0.5833\n",
            "Epoch 556/1000\n",
            "594/594 [==============================] - 0s 33us/sample - loss: 0.6053 - accuracy: 0.6869 - val_loss: 0.7700 - val_accuracy: 0.5833\n",
            "Epoch 557/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6052 - accuracy: 0.6869 - val_loss: 0.7699 - val_accuracy: 0.5833\n",
            "Epoch 558/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6052 - accuracy: 0.6869 - val_loss: 0.7699 - val_accuracy: 0.5833\n",
            "Epoch 559/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6052 - accuracy: 0.6869 - val_loss: 0.7700 - val_accuracy: 0.5833\n",
            "Epoch 560/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6051 - accuracy: 0.6869 - val_loss: 0.7700 - val_accuracy: 0.5833\n",
            "Epoch 561/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6051 - accuracy: 0.6869 - val_loss: 0.7701 - val_accuracy: 0.5833\n",
            "Epoch 562/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6053 - accuracy: 0.6852 - val_loss: 0.7699 - val_accuracy: 0.5833\n",
            "Epoch 563/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6051 - accuracy: 0.6886 - val_loss: 0.7699 - val_accuracy: 0.5833\n",
            "Epoch 564/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6051 - accuracy: 0.6869 - val_loss: 0.7700 - val_accuracy: 0.5833\n",
            "Epoch 565/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6050 - accuracy: 0.6869 - val_loss: 0.7701 - val_accuracy: 0.5833\n",
            "Epoch 566/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6051 - accuracy: 0.6869 - val_loss: 0.7700 - val_accuracy: 0.5833\n",
            "Epoch 567/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6050 - accuracy: 0.6869 - val_loss: 0.7700 - val_accuracy: 0.5833\n",
            "Epoch 568/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6049 - accuracy: 0.6869 - val_loss: 0.7701 - val_accuracy: 0.5833\n",
            "Epoch 569/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6050 - accuracy: 0.6886 - val_loss: 0.7703 - val_accuracy: 0.5833\n",
            "Epoch 570/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6049 - accuracy: 0.6877 - val_loss: 0.7703 - val_accuracy: 0.5833\n",
            "Epoch 571/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6048 - accuracy: 0.6869 - val_loss: 0.7704 - val_accuracy: 0.6667\n",
            "Epoch 572/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6048 - accuracy: 0.6869 - val_loss: 0.7704 - val_accuracy: 0.6667\n",
            "Epoch 573/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6048 - accuracy: 0.6869 - val_loss: 0.7703 - val_accuracy: 0.6667\n",
            "Epoch 574/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6048 - accuracy: 0.6869 - val_loss: 0.7703 - val_accuracy: 0.6667\n",
            "Epoch 575/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.6048 - accuracy: 0.6869 - val_loss: 0.7703 - val_accuracy: 0.6667\n",
            "Epoch 576/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6047 - accuracy: 0.6869 - val_loss: 0.7702 - val_accuracy: 0.6667\n",
            "Epoch 577/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6047 - accuracy: 0.6877 - val_loss: 0.7702 - val_accuracy: 0.6667\n",
            "Epoch 578/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6047 - accuracy: 0.6869 - val_loss: 0.7702 - val_accuracy: 0.6667\n",
            "Epoch 579/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6046 - accuracy: 0.6869 - val_loss: 0.7702 - val_accuracy: 0.6667\n",
            "Epoch 580/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6048 - accuracy: 0.6886 - val_loss: 0.7704 - val_accuracy: 0.6667\n",
            "Epoch 581/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6046 - accuracy: 0.6877 - val_loss: 0.7704 - val_accuracy: 0.6667\n",
            "Epoch 582/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6046 - accuracy: 0.6877 - val_loss: 0.7703 - val_accuracy: 0.6667\n",
            "Epoch 583/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6045 - accuracy: 0.6877 - val_loss: 0.7703 - val_accuracy: 0.6667\n",
            "Epoch 584/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6046 - accuracy: 0.6894 - val_loss: 0.7705 - val_accuracy: 0.6667\n",
            "Epoch 585/1000\n",
            "297/594 [==============>...............] - ETA: 0s - loss: 0.5645 - accuracy: 0.7340\n",
            "Epoch 00585: ReduceLROnPlateau reducing learning rate to 0.03125.\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6045 - accuracy: 0.6877 - val_loss: 0.7705 - val_accuracy: 0.6667\n",
            "Epoch 586/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6045 - accuracy: 0.6886 - val_loss: 0.7705 - val_accuracy: 0.6667\n",
            "Epoch 587/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6044 - accuracy: 0.6877 - val_loss: 0.7705 - val_accuracy: 0.6667\n",
            "Epoch 588/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6044 - accuracy: 0.6877 - val_loss: 0.7704 - val_accuracy: 0.6667\n",
            "Epoch 589/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6044 - accuracy: 0.6877 - val_loss: 0.7704 - val_accuracy: 0.6667\n",
            "Epoch 590/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6045 - accuracy: 0.6886 - val_loss: 0.7704 - val_accuracy: 0.6667\n",
            "Epoch 591/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6044 - accuracy: 0.6877 - val_loss: 0.7704 - val_accuracy: 0.6667\n",
            "Epoch 592/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6044 - accuracy: 0.6877 - val_loss: 0.7704 - val_accuracy: 0.6667\n",
            "Epoch 593/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6044 - accuracy: 0.6877 - val_loss: 0.7704 - val_accuracy: 0.6667\n",
            "Epoch 594/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6044 - accuracy: 0.6877 - val_loss: 0.7704 - val_accuracy: 0.6667\n",
            "Epoch 595/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6044 - accuracy: 0.6894 - val_loss: 0.7704 - val_accuracy: 0.6667\n",
            "Epoch 596/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6043 - accuracy: 0.6886 - val_loss: 0.7704 - val_accuracy: 0.6667\n",
            "Epoch 597/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6043 - accuracy: 0.6886 - val_loss: 0.7704 - val_accuracy: 0.6667\n",
            "Epoch 598/1000\n",
            "594/594 [==============================] - 0s 43us/sample - loss: 0.6043 - accuracy: 0.6894 - val_loss: 0.7705 - val_accuracy: 0.6667\n",
            "Epoch 599/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6043 - accuracy: 0.6877 - val_loss: 0.7704 - val_accuracy: 0.6667\n",
            "Epoch 600/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6043 - accuracy: 0.6894 - val_loss: 0.7705 - val_accuracy: 0.6667\n",
            "Epoch 601/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6043 - accuracy: 0.6894 - val_loss: 0.7705 - val_accuracy: 0.6667\n",
            "Epoch 602/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.6043 - accuracy: 0.6894 - val_loss: 0.7704 - val_accuracy: 0.6667\n",
            "Epoch 603/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.6044 - accuracy: 0.6886 - val_loss: 0.7704 - val_accuracy: 0.6667\n",
            "Epoch 604/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6042 - accuracy: 0.6894 - val_loss: 0.7704 - val_accuracy: 0.6667\n",
            "Epoch 605/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6042 - accuracy: 0.6894 - val_loss: 0.7704 - val_accuracy: 0.6667\n",
            "Epoch 606/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.6042 - accuracy: 0.6894 - val_loss: 0.7704 - val_accuracy: 0.6667\n",
            "Epoch 607/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6042 - accuracy: 0.6877 - val_loss: 0.7704 - val_accuracy: 0.6667\n",
            "Epoch 608/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6042 - accuracy: 0.6886 - val_loss: 0.7704 - val_accuracy: 0.6667\n",
            "Epoch 609/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6043 - accuracy: 0.6877 - val_loss: 0.7704 - val_accuracy: 0.6667\n",
            "Epoch 610/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6042 - accuracy: 0.6886 - val_loss: 0.7704 - val_accuracy: 0.6667\n",
            "Epoch 611/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6043 - accuracy: 0.6902 - val_loss: 0.7704 - val_accuracy: 0.6667\n",
            "Epoch 612/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6042 - accuracy: 0.6877 - val_loss: 0.7704 - val_accuracy: 0.6667\n",
            "Epoch 613/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6041 - accuracy: 0.6894 - val_loss: 0.7704 - val_accuracy: 0.6667\n",
            "Epoch 614/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6041 - accuracy: 0.6894 - val_loss: 0.7704 - val_accuracy: 0.6667\n",
            "Epoch 615/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6041 - accuracy: 0.6894 - val_loss: 0.7704 - val_accuracy: 0.6667\n",
            "Epoch 616/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6041 - accuracy: 0.6902 - val_loss: 0.7704 - val_accuracy: 0.6667\n",
            "Epoch 617/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6042 - accuracy: 0.6902 - val_loss: 0.7705 - val_accuracy: 0.6667\n",
            "Epoch 618/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6042 - accuracy: 0.6902 - val_loss: 0.7704 - val_accuracy: 0.6667\n",
            "Epoch 619/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6041 - accuracy: 0.6894 - val_loss: 0.7704 - val_accuracy: 0.6667\n",
            "Epoch 620/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6040 - accuracy: 0.6894 - val_loss: 0.7704 - val_accuracy: 0.6667\n",
            "Epoch 621/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6040 - accuracy: 0.6902 - val_loss: 0.7704 - val_accuracy: 0.6667\n",
            "Epoch 622/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6040 - accuracy: 0.6902 - val_loss: 0.7704 - val_accuracy: 0.6667\n",
            "Epoch 623/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6040 - accuracy: 0.6894 - val_loss: 0.7704 - val_accuracy: 0.6667\n",
            "Epoch 624/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6040 - accuracy: 0.6902 - val_loss: 0.7704 - val_accuracy: 0.6667\n",
            "Epoch 625/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6040 - accuracy: 0.6902 - val_loss: 0.7704 - val_accuracy: 0.6667\n",
            "Epoch 626/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6040 - accuracy: 0.6902 - val_loss: 0.7704 - val_accuracy: 0.6667\n",
            "Epoch 627/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6040 - accuracy: 0.6894 - val_loss: 0.7703 - val_accuracy: 0.6667\n",
            "Epoch 628/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6039 - accuracy: 0.6902 - val_loss: 0.7703 - val_accuracy: 0.6667\n",
            "Epoch 629/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6039 - accuracy: 0.6902 - val_loss: 0.7704 - val_accuracy: 0.6667\n",
            "Epoch 630/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6039 - accuracy: 0.6902 - val_loss: 0.7704 - val_accuracy: 0.6667\n",
            "Epoch 631/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6039 - accuracy: 0.6902 - val_loss: 0.7704 - val_accuracy: 0.6667\n",
            "Epoch 632/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6039 - accuracy: 0.6894 - val_loss: 0.7704 - val_accuracy: 0.6667\n",
            "Epoch 633/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6040 - accuracy: 0.6886 - val_loss: 0.7703 - val_accuracy: 0.6667\n",
            "Epoch 634/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6040 - accuracy: 0.6902 - val_loss: 0.7703 - val_accuracy: 0.6667\n",
            "Epoch 635/1000\n",
            "297/594 [==============>...............] - ETA: 0s - loss: 0.6091 - accuracy: 0.7037\n",
            "Epoch 00635: ReduceLROnPlateau reducing learning rate to 0.015625.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6038 - accuracy: 0.6902 - val_loss: 0.7703 - val_accuracy: 0.6667\n",
            "Epoch 00635: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAGFCAYAAADAc+UQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wERyd6URmLsGgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHN_boMOmvJO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7156bb50-fe98-4168-bfdc-b44201826a58"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "mlp = Sequential()\n",
        "mlp.add(Dense(16, input_dim=2, activation='sigmoid'))\n",
        "mlp.add(Dense(16, activation='sigmoid'))\n",
        "mlp.add(Dense(16, activation='sigmoid'))\n",
        "mlp.add(Dense(2, activation='sigmoid'))\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(factor=0.5, monitor='accuracy',\n",
        "                              patience=50, min_lr=0.00000001,\n",
        "                              verbose = 1)\n",
        "\n",
        "stop_save = EarlyStopping(patience=200, monitor='accuracy',\n",
        "                          verbose=1, \n",
        "                          restore_best_weights=True)\n",
        "\n",
        "# All parameter gradients will be clipped to\n",
        "# a maximum norm of 1.\n",
        "sgd = optimizers.SGD(lr=1., clipnorm=1.)\n",
        "\n",
        "mlp.compile(loss='binary_crossentropy',\n",
        "            optimizer=sgd,\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "# trains the model\n",
        "mlp.fit(X, yv, epochs=1000, batch_size=297,\n",
        "        verbose=1, callbacks=[reduce_lr, stop_save], \n",
        "        validation_split = 0.01)\n",
        "\n",
        "y_pred = mlp.predict(X)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
        "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n",
        "                     np.arange(y_min, y_max, 0.02))\n",
        "Z = None\n",
        "Z = mlp.predict(np.c_[xx.ravel(), yy.ravel()])[:,1]\n",
        "Z = Z.reshape(xx.shape)\n",
        "cm = plt.cm.bwr\n",
        "\n",
        "fig = plt.figure(figsize=(6,6))\n",
        "\n",
        "plt.contourf(xx, yy, Z, cmap=cm, alpha=.25)\n",
        "\n",
        "plt.plot(X[1,0],X[1,1],'+', color='#648fff', label='Positive Class')\n",
        "plt.plot(X[2,1],X[2,1],'_', color='#fe6100', label='Negative Class')\n",
        "\n",
        "for i in range(len(y)):\n",
        "  x1 = X[i,0]\n",
        "  x2 = X[i,1]\n",
        "  if y[i]==1: \n",
        "    if (y_pred[i] == 0):\n",
        "      plt.plot(x1,x2,'+', color='#648fff')\n",
        "    else:\n",
        "      plt.plot(x1,x2,'k.', alpha=0.25)\n",
        "  else:\n",
        "    if (y_pred[i] == 1):\n",
        "      plt.plot(x1,x2,'_', color='#fe6100')\n",
        "    else:\n",
        "      plt.plot(x1,x2,'k.', alpha=0.25)\n",
        "\n",
        "accuracy = np.sum(np.equal(y_pred,y_actual))/len(y_actual)\n",
        "\n",
        "plt.axis('tight')\n",
        "plt.xlim(min(X[:,0])-0.1, max(X[:,0])+0.1)\n",
        "plt.ylim(min(X[:,1])-0.1, max(X[:,1])+0.1)\n",
        "plt.xlabel('$x_1$')\n",
        "plt.ylabel('$x_2$')\n",
        "plt.legend()\n",
        "plt.title('Keras-based 4-layer MLP on spiral dataset. Accuracy: {:04.3}'.format(accuracy))\n",
        "plt.savefig('ch.6.MLP.keras.deep.e.spirals.png', dpi=350, bbox_inches='tight')\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 594 samples, validate on 6 samples\n",
            "Epoch 1/1000\n",
            "594/594 [==============================] - 0s 460us/sample - loss: 0.7138 - accuracy: 0.5000 - val_loss: 0.7345 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6943 - accuracy: 0.5051 - val_loss: 0.6903 - val_accuracy: 0.8333\n",
            "Epoch 3/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6963 - accuracy: 0.4554 - val_loss: 0.6656 - val_accuracy: 1.0000\n",
            "Epoch 4/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6945 - accuracy: 0.4949 - val_loss: 0.7244 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6941 - accuracy: 0.4512 - val_loss: 0.7166 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6939 - accuracy: 0.4537 - val_loss: 0.7161 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6937 - accuracy: 0.5051 - val_loss: 0.6971 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6958 - accuracy: 0.4453 - val_loss: 0.7422 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6943 - accuracy: 0.5051 - val_loss: 0.7178 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6937 - accuracy: 0.4798 - val_loss: 0.7124 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6940 - accuracy: 0.4865 - val_loss: 0.7198 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6956 - accuracy: 0.5051 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
            "Epoch 13/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6968 - accuracy: 0.4663 - val_loss: 0.6647 - val_accuracy: 1.0000\n",
            "Epoch 14/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6950 - accuracy: 0.4949 - val_loss: 0.7357 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/1000\n",
            "594/594 [==============================] - 0s 37us/sample - loss: 0.6936 - accuracy: 0.5051 - val_loss: 0.6985 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6942 - accuracy: 0.4798 - val_loss: 0.7264 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6953 - accuracy: 0.4731 - val_loss: 0.7361 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6949 - accuracy: 0.5051 - val_loss: 0.6729 - val_accuracy: 1.0000\n",
            "Epoch 19/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6936 - accuracy: 0.4966 - val_loss: 0.6982 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6933 - accuracy: 0.5051 - val_loss: 0.7037 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6935 - accuracy: 0.5051 - val_loss: 0.6929 - val_accuracy: 0.7500\n",
            "Epoch 22/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6937 - accuracy: 0.4806 - val_loss: 0.7224 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6934 - accuracy: 0.5051 - val_loss: 0.6943 - val_accuracy: 0.1667\n",
            "Epoch 24/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6934 - accuracy: 0.4874 - val_loss: 0.7149 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6932 - accuracy: 0.5051 - val_loss: 0.7050 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6954 - accuracy: 0.4663 - val_loss: 0.7424 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6944 - accuracy: 0.5051 - val_loss: 0.6772 - val_accuracy: 1.0000\n",
            "Epoch 28/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6938 - accuracy: 0.4949 - val_loss: 0.7252 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6933 - accuracy: 0.5051 - val_loss: 0.7133 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6944 - accuracy: 0.5051 - val_loss: 0.6755 - val_accuracy: 1.0000\n",
            "Epoch 31/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6933 - accuracy: 0.4966 - val_loss: 0.6987 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6931 - accuracy: 0.5109 - val_loss: 0.7115 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6936 - accuracy: 0.4832 - val_loss: 0.7238 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6930 - accuracy: 0.5051 - val_loss: 0.7019 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6941 - accuracy: 0.5051 - val_loss: 0.6784 - val_accuracy: 1.0000\n",
            "Epoch 36/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.7027 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6933 - accuracy: 0.5051 - val_loss: 0.6896 - val_accuracy: 1.0000\n",
            "Epoch 38/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6939 - accuracy: 0.4798 - val_loss: 0.6814 - val_accuracy: 1.0000\n",
            "Epoch 39/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6957 - accuracy: 0.4949 - val_loss: 0.7486 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6934 - accuracy: 0.5051 - val_loss: 0.7112 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6928 - accuracy: 0.5051 - val_loss: 0.6976 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6928 - accuracy: 0.5194 - val_loss: 0.7079 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6928 - accuracy: 0.5210 - val_loss: 0.7124 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6930 - accuracy: 0.5177 - val_loss: 0.7163 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6934 - accuracy: 0.4832 - val_loss: 0.7243 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6931 - accuracy: 0.5051 - val_loss: 0.6876 - val_accuracy: 1.0000\n",
            "Epoch 47/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6944 - accuracy: 0.4731 - val_loss: 0.6743 - val_accuracy: 1.0000\n",
            "Epoch 48/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6931 - accuracy: 0.4949 - val_loss: 0.7215 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6928 - accuracy: 0.5051 - val_loss: 0.7135 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6929 - accuracy: 0.5051 - val_loss: 0.6906 - val_accuracy: 1.0000\n",
            "Epoch 51/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6927 - accuracy: 0.5194 - val_loss: 0.6964 - val_accuracy: 0.0000e+00\n",
            "Epoch 52/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6925 - accuracy: 0.5261 - val_loss: 0.7006 - val_accuracy: 0.0000e+00\n",
            "Epoch 53/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6930 - accuracy: 0.4832 - val_loss: 0.7236 - val_accuracy: 0.0000e+00\n",
            "Epoch 54/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6927 - accuracy: 0.5168 - val_loss: 0.7139 - val_accuracy: 0.0000e+00\n",
            "Epoch 55/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6938 - accuracy: 0.5051 - val_loss: 0.6762 - val_accuracy: 1.0000\n",
            "Epoch 56/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6929 - accuracy: 0.4949 - val_loss: 0.7218 - val_accuracy: 0.0000e+00\n",
            "Epoch 57/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6925 - accuracy: 0.5051 - val_loss: 0.6952 - val_accuracy: 0.2500\n",
            "Epoch 58/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6930 - accuracy: 0.5455 - val_loss: 0.6858 - val_accuracy: 1.0000\n",
            "Epoch 59/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6928 - accuracy: 0.4949 - val_loss: 0.7227 - val_accuracy: 0.0000e+00\n",
            "Epoch 60/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.6933 - accuracy: 0.4798 - val_loss: 0.7290 - val_accuracy: 0.0000e+00\n",
            "Epoch 61/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6924 - accuracy: 0.5051 - val_loss: 0.7105 - val_accuracy: 0.0000e+00\n",
            "Epoch 62/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6968 - accuracy: 0.4529 - val_loss: 0.7592 - val_accuracy: 0.0000e+00\n",
            "Epoch 63/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6930 - accuracy: 0.5051 - val_loss: 0.7126 - val_accuracy: 0.0000e+00\n",
            "Epoch 64/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6922 - accuracy: 0.5051 - val_loss: 0.7096 - val_accuracy: 0.0000e+00\n",
            "Epoch 65/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6923 - accuracy: 0.5219 - val_loss: 0.7169 - val_accuracy: 0.0000e+00\n",
            "Epoch 66/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6928 - accuracy: 0.4832 - val_loss: 0.7252 - val_accuracy: 0.0000e+00\n",
            "Epoch 67/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6922 - accuracy: 0.5051 - val_loss: 0.7106 - val_accuracy: 0.0000e+00\n",
            "Epoch 68/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6926 - accuracy: 0.4832 - val_loss: 0.7247 - val_accuracy: 0.0000e+00\n",
            "Epoch 69/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6931 - accuracy: 0.4798 - val_loss: 0.7296 - val_accuracy: 0.0000e+00\n",
            "Epoch 70/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6920 - accuracy: 0.5051 - val_loss: 0.6998 - val_accuracy: 0.0000e+00\n",
            "Epoch 71/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6943 - accuracy: 0.5362 - val_loss: 0.6685 - val_accuracy: 1.0000\n",
            "Epoch 72/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6938 - accuracy: 0.4949 - val_loss: 0.7414 - val_accuracy: 0.0000e+00\n",
            "Epoch 73/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6921 - accuracy: 0.5051 - val_loss: 0.7007 - val_accuracy: 0.0000e+00\n",
            "Epoch 74/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6918 - accuracy: 0.5328 - val_loss: 0.7016 - val_accuracy: 0.0000e+00\n",
            "Epoch 75/1000\n",
            "594/594 [==============================] - 0s 34us/sample - loss: 0.6920 - accuracy: 0.5219 - val_loss: 0.7206 - val_accuracy: 0.0000e+00\n",
            "Epoch 76/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6917 - accuracy: 0.5051 - val_loss: 0.7070 - val_accuracy: 0.0000e+00\n",
            "Epoch 77/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6949 - accuracy: 0.4596 - val_loss: 0.7521 - val_accuracy: 0.0000e+00\n",
            "Epoch 78/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6934 - accuracy: 0.5328 - val_loss: 0.7318 - val_accuracy: 0.0000e+00\n",
            "Epoch 79/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6917 - accuracy: 0.5051 - val_loss: 0.7075 - val_accuracy: 0.0000e+00\n",
            "Epoch 80/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6929 - accuracy: 0.5051 - val_loss: 0.6765 - val_accuracy: 1.0000\n",
            "Epoch 81/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6919 - accuracy: 0.4933 - val_loss: 0.6967 - val_accuracy: 0.1667\n",
            "Epoch 82/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6921 - accuracy: 0.5488 - val_loss: 0.6870 - val_accuracy: 1.0000\n",
            "Epoch 83/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6946 - accuracy: 0.4949 - val_loss: 0.6648 - val_accuracy: 1.0000\n",
            "Epoch 84/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6917 - accuracy: 0.5328 - val_loss: 0.7073 - val_accuracy: 0.0000e+00\n",
            "Epoch 85/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6927 - accuracy: 0.5051 - val_loss: 0.6769 - val_accuracy: 1.0000\n",
            "Epoch 86/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6938 - accuracy: 0.4697 - val_loss: 0.6712 - val_accuracy: 1.0000\n",
            "Epoch 87/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6916 - accuracy: 0.5295 - val_loss: 0.6999 - val_accuracy: 0.1667\n",
            "Epoch 88/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6911 - accuracy: 0.6178 - val_loss: 0.7098 - val_accuracy: 0.0000e+00\n",
            "Epoch 89/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6914 - accuracy: 0.5202 - val_loss: 0.7218 - val_accuracy: 0.0000e+00\n",
            "Epoch 90/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6936 - accuracy: 0.4663 - val_loss: 0.7464 - val_accuracy: 0.0000e+00\n",
            "Epoch 91/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6913 - accuracy: 0.5051 - val_loss: 0.6982 - val_accuracy: 0.1667\n",
            "Epoch 92/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6915 - accuracy: 0.5690 - val_loss: 0.6873 - val_accuracy: 0.8333\n",
            "Epoch 93/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6909 - accuracy: 0.5808 - val_loss: 0.7130 - val_accuracy: 0.0000e+00\n",
            "Epoch 94/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6908 - accuracy: 0.5673 - val_loss: 0.7150 - val_accuracy: 0.0000e+00\n",
            "Epoch 95/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6909 - accuracy: 0.5614 - val_loss: 0.7191 - val_accuracy: 0.0000e+00\n",
            "Epoch 96/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6913 - accuracy: 0.5278 - val_loss: 0.7270 - val_accuracy: 0.0000e+00\n",
            "Epoch 97/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6914 - accuracy: 0.5236 - val_loss: 0.7278 - val_accuracy: 0.0000e+00\n",
            "Epoch 98/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6928 - accuracy: 0.4697 - val_loss: 0.7435 - val_accuracy: 0.0000e+00\n",
            "Epoch 99/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6910 - accuracy: 0.5051 - val_loss: 0.6905 - val_accuracy: 0.6667\n",
            "Epoch 100/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6904 - accuracy: 0.6153 - val_loss: 0.7101 - val_accuracy: 0.0000e+00\n",
            "Epoch 101/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6904 - accuracy: 0.5429 - val_loss: 0.6965 - val_accuracy: 0.2500\n",
            "Epoch 102/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6904 - accuracy: 0.5438 - val_loss: 0.6954 - val_accuracy: 0.3333\n",
            "Epoch 103/1000\n",
            "594/594 [==============================] - 0s 33us/sample - loss: 0.6906 - accuracy: 0.5657 - val_loss: 0.6917 - val_accuracy: 0.6667\n",
            "Epoch 104/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6906 - accuracy: 0.5564 - val_loss: 0.6912 - val_accuracy: 0.6667\n",
            "Epoch 105/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6902 - accuracy: 0.5707 - val_loss: 0.7226 - val_accuracy: 0.0000e+00\n",
            "Epoch 106/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6899 - accuracy: 0.5051 - val_loss: 0.7017 - val_accuracy: 0.1667\n",
            "Epoch 107/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6900 - accuracy: 0.5640 - val_loss: 0.6959 - val_accuracy: 0.2500\n",
            "Epoch 108/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6902 - accuracy: 0.5707 - val_loss: 0.7271 - val_accuracy: 0.0000e+00\n",
            "Epoch 109/1000\n",
            "594/594 [==============================] - 0s 35us/sample - loss: 0.6897 - accuracy: 0.5286 - val_loss: 0.7129 - val_accuracy: 0.0000e+00\n",
            "Epoch 110/1000\n",
            "594/594 [==============================] - 0s 34us/sample - loss: 0.6901 - accuracy: 0.5488 - val_loss: 0.7283 - val_accuracy: 0.0000e+00\n",
            "Epoch 111/1000\n",
            "594/594 [==============================] - 0s 43us/sample - loss: 0.6900 - accuracy: 0.5640 - val_loss: 0.7253 - val_accuracy: 0.0000e+00\n",
            "Epoch 112/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6894 - accuracy: 0.5051 - val_loss: 0.6977 - val_accuracy: 0.1667\n",
            "Epoch 113/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6917 - accuracy: 0.5261 - val_loss: 0.6701 - val_accuracy: 1.0000\n",
            "Epoch 114/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6903 - accuracy: 0.4949 - val_loss: 0.7372 - val_accuracy: 0.0000e+00\n",
            "Epoch 115/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6897 - accuracy: 0.5051 - val_loss: 0.6865 - val_accuracy: 0.6667\n",
            "Epoch 116/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6893 - accuracy: 0.5749 - val_loss: 0.7278 - val_accuracy: 0.0000e+00\n",
            "Epoch 117/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6888 - accuracy: 0.5311 - val_loss: 0.7096 - val_accuracy: 0.1667\n",
            "Epoch 118/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6896 - accuracy: 0.5791 - val_loss: 0.7362 - val_accuracy: 0.0000e+00\n",
            "Epoch 119/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6898 - accuracy: 0.5219 - val_loss: 0.7351 - val_accuracy: 0.0000e+00\n",
            "Epoch 120/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6890 - accuracy: 0.5564 - val_loss: 0.7270 - val_accuracy: 0.0000e+00\n",
            "Epoch 121/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6900 - accuracy: 0.5135 - val_loss: 0.7425 - val_accuracy: 0.0000e+00\n",
            "Epoch 122/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6883 - accuracy: 0.5210 - val_loss: 0.7034 - val_accuracy: 0.1667\n",
            "Epoch 123/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6879 - accuracy: 0.6052 - val_loss: 0.7057 - val_accuracy: 0.1667\n",
            "Epoch 124/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6885 - accuracy: 0.5800 - val_loss: 0.7340 - val_accuracy: 0.0000e+00\n",
            "Epoch 125/1000\n",
            "594/594 [==============================] - 0s 33us/sample - loss: 0.6879 - accuracy: 0.5783 - val_loss: 0.7199 - val_accuracy: 0.0000e+00\n",
            "Epoch 126/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6876 - accuracy: 0.6162 - val_loss: 0.7187 - val_accuracy: 0.0000e+00\n",
            "Epoch 127/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6873 - accuracy: 0.5657 - val_loss: 0.7064 - val_accuracy: 0.1667\n",
            "Epoch 128/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6886 - accuracy: 0.5766 - val_loss: 0.7433 - val_accuracy: 0.0000e+00\n",
            "Epoch 129/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6872 - accuracy: 0.5219 - val_loss: 0.7002 - val_accuracy: 0.1667\n",
            "Epoch 130/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6878 - accuracy: 0.5311 - val_loss: 0.6864 - val_accuracy: 0.6667\n",
            "Epoch 131/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6882 - accuracy: 0.5606 - val_loss: 0.6819 - val_accuracy: 0.6667\n",
            "Epoch 132/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6867 - accuracy: 0.5918 - val_loss: 0.7050 - val_accuracy: 0.1667\n",
            "Epoch 133/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6883 - accuracy: 0.5598 - val_loss: 0.6746 - val_accuracy: 0.8333\n",
            "Epoch 134/1000\n",
            "594/594 [==============================] - 0s 39us/sample - loss: 0.6866 - accuracy: 0.5943 - val_loss: 0.7023 - val_accuracy: 0.1667\n",
            "Epoch 135/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6858 - accuracy: 0.6094 - val_loss: 0.7152 - val_accuracy: 0.1667\n",
            "Epoch 136/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6871 - accuracy: 0.5589 - val_loss: 0.6792 - val_accuracy: 0.7500\n",
            "Epoch 137/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6856 - accuracy: 0.6069 - val_loss: 0.7230 - val_accuracy: 0.1667\n",
            "Epoch 138/1000\n",
            "297/594 [==============>...............] - ETA: 0s - loss: 0.6856 - accuracy: 0.5657\n",
            "Epoch 00138: ReduceLROnPlateau reducing learning rate to 0.5.\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6896 - accuracy: 0.5084 - val_loss: 0.7696 - val_accuracy: 0.0000e+00\n",
            "Epoch 139/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6859 - accuracy: 0.5177 - val_loss: 0.7333 - val_accuracy: 0.0000e+00\n",
            "Epoch 140/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6850 - accuracy: 0.5842 - val_loss: 0.7227 - val_accuracy: 0.1667\n",
            "Epoch 141/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6847 - accuracy: 0.6035 - val_loss: 0.7156 - val_accuracy: 0.1667\n",
            "Epoch 142/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6847 - accuracy: 0.5993 - val_loss: 0.7090 - val_accuracy: 0.1667\n",
            "Epoch 143/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6844 - accuracy: 0.6246 - val_loss: 0.7137 - val_accuracy: 0.1667\n",
            "Epoch 144/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6843 - accuracy: 0.6372 - val_loss: 0.7112 - val_accuracy: 0.1667\n",
            "Epoch 145/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6845 - accuracy: 0.6035 - val_loss: 0.7193 - val_accuracy: 0.1667\n",
            "Epoch 146/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6841 - accuracy: 0.6086 - val_loss: 0.7114 - val_accuracy: 0.1667\n",
            "Epoch 147/1000\n",
            "594/594 [==============================] - 0s 35us/sample - loss: 0.6838 - accuracy: 0.6406 - val_loss: 0.7131 - val_accuracy: 0.1667\n",
            "Epoch 148/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6840 - accuracy: 0.6170 - val_loss: 0.7192 - val_accuracy: 0.1667\n",
            "Epoch 149/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6836 - accuracy: 0.6389 - val_loss: 0.7170 - val_accuracy: 0.1667\n",
            "Epoch 150/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6835 - accuracy: 0.6237 - val_loss: 0.7187 - val_accuracy: 0.1667\n",
            "Epoch 151/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6853 - accuracy: 0.5867 - val_loss: 0.7011 - val_accuracy: 0.1667\n",
            "Epoch 152/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6832 - accuracy: 0.6237 - val_loss: 0.7118 - val_accuracy: 0.1667\n",
            "Epoch 153/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6830 - accuracy: 0.6372 - val_loss: 0.7125 - val_accuracy: 0.1667\n",
            "Epoch 154/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6855 - accuracy: 0.5699 - val_loss: 0.7317 - val_accuracy: 0.1667\n",
            "Epoch 155/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6829 - accuracy: 0.5875 - val_loss: 0.7165 - val_accuracy: 0.1667\n",
            "Epoch 156/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6825 - accuracy: 0.6338 - val_loss: 0.7169 - val_accuracy: 0.1667\n",
            "Epoch 157/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6826 - accuracy: 0.6406 - val_loss: 0.7220 - val_accuracy: 0.1667\n",
            "Epoch 158/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6824 - accuracy: 0.6330 - val_loss: 0.7233 - val_accuracy: 0.1667\n",
            "Epoch 159/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6820 - accuracy: 0.6355 - val_loss: 0.7164 - val_accuracy: 0.1667\n",
            "Epoch 160/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6818 - accuracy: 0.6271 - val_loss: 0.7173 - val_accuracy: 0.1667\n",
            "Epoch 161/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6816 - accuracy: 0.6389 - val_loss: 0.7166 - val_accuracy: 0.1667\n",
            "Epoch 162/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6814 - accuracy: 0.6406 - val_loss: 0.7145 - val_accuracy: 0.1667\n",
            "Epoch 163/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6812 - accuracy: 0.6237 - val_loss: 0.7165 - val_accuracy: 0.1667\n",
            "Epoch 164/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6810 - accuracy: 0.6372 - val_loss: 0.7157 - val_accuracy: 0.1667\n",
            "Epoch 165/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6809 - accuracy: 0.6263 - val_loss: 0.7192 - val_accuracy: 0.1667\n",
            "Epoch 166/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6812 - accuracy: 0.6263 - val_loss: 0.7258 - val_accuracy: 0.1667\n",
            "Epoch 167/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6806 - accuracy: 0.6246 - val_loss: 0.7244 - val_accuracy: 0.1667\n",
            "Epoch 168/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6828 - accuracy: 0.5842 - val_loss: 0.7025 - val_accuracy: 0.2500\n",
            "Epoch 169/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6805 - accuracy: 0.6279 - val_loss: 0.7193 - val_accuracy: 0.1667\n",
            "Epoch 170/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6798 - accuracy: 0.6296 - val_loss: 0.7196 - val_accuracy: 0.1667\n",
            "Epoch 171/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6796 - accuracy: 0.6347 - val_loss: 0.7186 - val_accuracy: 0.1667\n",
            "Epoch 172/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6794 - accuracy: 0.6347 - val_loss: 0.7164 - val_accuracy: 0.1667\n",
            "Epoch 173/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6795 - accuracy: 0.6237 - val_loss: 0.7237 - val_accuracy: 0.1667\n",
            "Epoch 174/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6830 - accuracy: 0.5926 - val_loss: 0.7429 - val_accuracy: 0.1667\n",
            "Epoch 175/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6790 - accuracy: 0.6221 - val_loss: 0.7306 - val_accuracy: 0.1667\n",
            "Epoch 176/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6785 - accuracy: 0.6380 - val_loss: 0.7223 - val_accuracy: 0.1667\n",
            "Epoch 177/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6783 - accuracy: 0.6271 - val_loss: 0.7234 - val_accuracy: 0.1667\n",
            "Epoch 178/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6781 - accuracy: 0.6372 - val_loss: 0.7191 - val_accuracy: 0.1667\n",
            "Epoch 179/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6778 - accuracy: 0.6313 - val_loss: 0.7169 - val_accuracy: 0.1667\n",
            "Epoch 180/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6780 - accuracy: 0.6178 - val_loss: 0.7117 - val_accuracy: 0.1667\n",
            "Epoch 181/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6773 - accuracy: 0.6229 - val_loss: 0.7164 - val_accuracy: 0.1667\n",
            "Epoch 182/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6777 - accuracy: 0.6153 - val_loss: 0.7287 - val_accuracy: 0.1667\n",
            "Epoch 183/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6771 - accuracy: 0.6279 - val_loss: 0.7296 - val_accuracy: 0.1667\n",
            "Epoch 184/1000\n",
            "594/594 [==============================] - 0s 20us/sample - loss: 0.6765 - accuracy: 0.6330 - val_loss: 0.7250 - val_accuracy: 0.1667\n",
            "Epoch 185/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6764 - accuracy: 0.6305 - val_loss: 0.7276 - val_accuracy: 0.1667\n",
            "Epoch 186/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6771 - accuracy: 0.6153 - val_loss: 0.7113 - val_accuracy: 0.1667\n",
            "Epoch 187/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6758 - accuracy: 0.6111 - val_loss: 0.7223 - val_accuracy: 0.1667\n",
            "Epoch 188/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6756 - accuracy: 0.6355 - val_loss: 0.7176 - val_accuracy: 0.1667\n",
            "Epoch 189/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6751 - accuracy: 0.6212 - val_loss: 0.7219 - val_accuracy: 0.1667\n",
            "Epoch 190/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6761 - accuracy: 0.6162 - val_loss: 0.7363 - val_accuracy: 0.1667\n",
            "Epoch 191/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6746 - accuracy: 0.6347 - val_loss: 0.7280 - val_accuracy: 0.1667\n",
            "Epoch 192/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6752 - accuracy: 0.6120 - val_loss: 0.7370 - val_accuracy: 0.1667\n",
            "Epoch 193/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.6741 - accuracy: 0.6279 - val_loss: 0.7320 - val_accuracy: 0.1667\n",
            "Epoch 194/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6737 - accuracy: 0.6204 - val_loss: 0.7309 - val_accuracy: 0.1667\n",
            "Epoch 195/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6734 - accuracy: 0.6347 - val_loss: 0.7229 - val_accuracy: 0.1667\n",
            "Epoch 196/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6730 - accuracy: 0.6212 - val_loss: 0.7228 - val_accuracy: 0.1667\n",
            "Epoch 197/1000\n",
            "297/594 [==============>...............] - ETA: 0s - loss: 0.6708 - accuracy: 0.6481\n",
            "Epoch 00197: ReduceLROnPlateau reducing learning rate to 0.25.\n",
            "594/594 [==============================] - 0s 37us/sample - loss: 0.6726 - accuracy: 0.6204 - val_loss: 0.7234 - val_accuracy: 0.1667\n",
            "Epoch 198/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6728 - accuracy: 0.6153 - val_loss: 0.7277 - val_accuracy: 0.1667\n",
            "Epoch 199/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6722 - accuracy: 0.6229 - val_loss: 0.7272 - val_accuracy: 0.1667\n",
            "Epoch 200/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6722 - accuracy: 0.6153 - val_loss: 0.7290 - val_accuracy: 0.1667\n",
            "Epoch 201/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6718 - accuracy: 0.6221 - val_loss: 0.7281 - val_accuracy: 0.1667\n",
            "Epoch 202/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6717 - accuracy: 0.6221 - val_loss: 0.7273 - val_accuracy: 0.1667\n",
            "Epoch 203/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6717 - accuracy: 0.6195 - val_loss: 0.7291 - val_accuracy: 0.1667\n",
            "Epoch 204/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6714 - accuracy: 0.6237 - val_loss: 0.7295 - val_accuracy: 0.1667\n",
            "Epoch 205/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6712 - accuracy: 0.6204 - val_loss: 0.7299 - val_accuracy: 0.1667\n",
            "Epoch 206/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6710 - accuracy: 0.6204 - val_loss: 0.7287 - val_accuracy: 0.1667\n",
            "Epoch 207/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6710 - accuracy: 0.6204 - val_loss: 0.7262 - val_accuracy: 0.1667\n",
            "Epoch 208/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6712 - accuracy: 0.6094 - val_loss: 0.7305 - val_accuracy: 0.1667\n",
            "Epoch 209/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6715 - accuracy: 0.6153 - val_loss: 0.7345 - val_accuracy: 0.1667\n",
            "Epoch 210/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6705 - accuracy: 0.6170 - val_loss: 0.7345 - val_accuracy: 0.1667\n",
            "Epoch 211/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6706 - accuracy: 0.6103 - val_loss: 0.7355 - val_accuracy: 0.1667\n",
            "Epoch 212/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6701 - accuracy: 0.6288 - val_loss: 0.7310 - val_accuracy: 0.1667\n",
            "Epoch 213/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6699 - accuracy: 0.6170 - val_loss: 0.7327 - val_accuracy: 0.1667\n",
            "Epoch 214/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6698 - accuracy: 0.6246 - val_loss: 0.7291 - val_accuracy: 0.1667\n",
            "Epoch 215/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6698 - accuracy: 0.6212 - val_loss: 0.7264 - val_accuracy: 0.1667\n",
            "Epoch 216/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6693 - accuracy: 0.6221 - val_loss: 0.7260 - val_accuracy: 0.1667\n",
            "Epoch 217/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6690 - accuracy: 0.6237 - val_loss: 0.7273 - val_accuracy: 0.1667\n",
            "Epoch 218/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6689 - accuracy: 0.6254 - val_loss: 0.7270 - val_accuracy: 0.1667\n",
            "Epoch 219/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6688 - accuracy: 0.6170 - val_loss: 0.7309 - val_accuracy: 0.1667\n",
            "Epoch 220/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6684 - accuracy: 0.6204 - val_loss: 0.7315 - val_accuracy: 0.1667\n",
            "Epoch 221/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6686 - accuracy: 0.6195 - val_loss: 0.7345 - val_accuracy: 0.1667\n",
            "Epoch 222/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6693 - accuracy: 0.6204 - val_loss: 0.7388 - val_accuracy: 0.1667\n",
            "Epoch 223/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6679 - accuracy: 0.6254 - val_loss: 0.7370 - val_accuracy: 0.1667\n",
            "Epoch 224/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6676 - accuracy: 0.6237 - val_loss: 0.7349 - val_accuracy: 0.1667\n",
            "Epoch 225/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6674 - accuracy: 0.6204 - val_loss: 0.7342 - val_accuracy: 0.1667\n",
            "Epoch 226/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6673 - accuracy: 0.6170 - val_loss: 0.7347 - val_accuracy: 0.1667\n",
            "Epoch 227/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6670 - accuracy: 0.6221 - val_loss: 0.7345 - val_accuracy: 0.1667\n",
            "Epoch 228/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6680 - accuracy: 0.6178 - val_loss: 0.7288 - val_accuracy: 0.1667\n",
            "Epoch 229/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6667 - accuracy: 0.6187 - val_loss: 0.7297 - val_accuracy: 0.1667\n",
            "Epoch 230/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6665 - accuracy: 0.6145 - val_loss: 0.7326 - val_accuracy: 0.1667\n",
            "Epoch 231/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6662 - accuracy: 0.6204 - val_loss: 0.7333 - val_accuracy: 0.1667\n",
            "Epoch 232/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6660 - accuracy: 0.6195 - val_loss: 0.7345 - val_accuracy: 0.1667\n",
            "Epoch 233/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6662 - accuracy: 0.6229 - val_loss: 0.7316 - val_accuracy: 0.1667\n",
            "Epoch 234/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6656 - accuracy: 0.6204 - val_loss: 0.7330 - val_accuracy: 0.1667\n",
            "Epoch 235/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6654 - accuracy: 0.6204 - val_loss: 0.7334 - val_accuracy: 0.1667\n",
            "Epoch 236/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6652 - accuracy: 0.6187 - val_loss: 0.7336 - val_accuracy: 0.1667\n",
            "Epoch 237/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6651 - accuracy: 0.6229 - val_loss: 0.7331 - val_accuracy: 0.1667\n",
            "Epoch 238/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6648 - accuracy: 0.6187 - val_loss: 0.7335 - val_accuracy: 0.1667\n",
            "Epoch 239/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6646 - accuracy: 0.6204 - val_loss: 0.7334 - val_accuracy: 0.1667\n",
            "Epoch 240/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6644 - accuracy: 0.6170 - val_loss: 0.7354 - val_accuracy: 0.1667\n",
            "Epoch 241/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6645 - accuracy: 0.6229 - val_loss: 0.7330 - val_accuracy: 0.1667\n",
            "Epoch 242/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6640 - accuracy: 0.6178 - val_loss: 0.7331 - val_accuracy: 0.1667\n",
            "Epoch 243/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6638 - accuracy: 0.6187 - val_loss: 0.7359 - val_accuracy: 0.1667\n",
            "Epoch 244/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6636 - accuracy: 0.6187 - val_loss: 0.7350 - val_accuracy: 0.1667\n",
            "Epoch 245/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6636 - accuracy: 0.6229 - val_loss: 0.7392 - val_accuracy: 0.1667\n",
            "Epoch 246/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6633 - accuracy: 0.6246 - val_loss: 0.7367 - val_accuracy: 0.1667\n",
            "Epoch 247/1000\n",
            "297/594 [==============>...............] - ETA: 0s - loss: 0.6624 - accuracy: 0.6061\n",
            "Epoch 00247: ReduceLROnPlateau reducing learning rate to 0.125.\n",
            "594/594 [==============================] - 0s 34us/sample - loss: 0.6629 - accuracy: 0.6162 - val_loss: 0.7365 - val_accuracy: 0.1667\n",
            "Epoch 248/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6627 - accuracy: 0.6170 - val_loss: 0.7373 - val_accuracy: 0.1667\n",
            "Epoch 249/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6626 - accuracy: 0.6162 - val_loss: 0.7375 - val_accuracy: 0.1667\n",
            "Epoch 250/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6625 - accuracy: 0.6178 - val_loss: 0.7374 - val_accuracy: 0.1667\n",
            "Epoch 251/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6625 - accuracy: 0.6195 - val_loss: 0.7371 - val_accuracy: 0.1667\n",
            "Epoch 252/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6623 - accuracy: 0.6170 - val_loss: 0.7372 - val_accuracy: 0.1667\n",
            "Epoch 253/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6633 - accuracy: 0.6195 - val_loss: 0.7358 - val_accuracy: 0.1667\n",
            "Epoch 254/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6620 - accuracy: 0.6162 - val_loss: 0.7366 - val_accuracy: 0.1667\n",
            "Epoch 255/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6619 - accuracy: 0.6170 - val_loss: 0.7373 - val_accuracy: 0.1667\n",
            "Epoch 256/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6618 - accuracy: 0.6162 - val_loss: 0.7380 - val_accuracy: 0.1667\n",
            "Epoch 257/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6619 - accuracy: 0.6162 - val_loss: 0.7395 - val_accuracy: 0.1667\n",
            "Epoch 258/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6616 - accuracy: 0.6170 - val_loss: 0.7395 - val_accuracy: 0.1667\n",
            "Epoch 259/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6615 - accuracy: 0.6153 - val_loss: 0.7402 - val_accuracy: 0.1667\n",
            "Epoch 260/1000\n",
            "594/594 [==============================] - 0s 40us/sample - loss: 0.6614 - accuracy: 0.6162 - val_loss: 0.7408 - val_accuracy: 0.1667\n",
            "Epoch 261/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6616 - accuracy: 0.6237 - val_loss: 0.7398 - val_accuracy: 0.1667\n",
            "Epoch 262/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6612 - accuracy: 0.6162 - val_loss: 0.7406 - val_accuracy: 0.1667\n",
            "Epoch 263/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6610 - accuracy: 0.6170 - val_loss: 0.7408 - val_accuracy: 0.1667\n",
            "Epoch 264/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6610 - accuracy: 0.6153 - val_loss: 0.7415 - val_accuracy: 0.1667\n",
            "Epoch 265/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6608 - accuracy: 0.6162 - val_loss: 0.7418 - val_accuracy: 0.1667\n",
            "Epoch 266/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6608 - accuracy: 0.6153 - val_loss: 0.7424 - val_accuracy: 0.1667\n",
            "Epoch 267/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6606 - accuracy: 0.6170 - val_loss: 0.7422 - val_accuracy: 0.1667\n",
            "Epoch 268/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6605 - accuracy: 0.6162 - val_loss: 0.7423 - val_accuracy: 0.1667\n",
            "Epoch 269/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6604 - accuracy: 0.6162 - val_loss: 0.7425 - val_accuracy: 0.1667\n",
            "Epoch 270/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6604 - accuracy: 0.6162 - val_loss: 0.7432 - val_accuracy: 0.1667\n",
            "Epoch 271/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6602 - accuracy: 0.6128 - val_loss: 0.7437 - val_accuracy: 0.1667\n",
            "Epoch 272/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6608 - accuracy: 0.6128 - val_loss: 0.7453 - val_accuracy: 0.1667\n",
            "Epoch 273/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6599 - accuracy: 0.6178 - val_loss: 0.7448 - val_accuracy: 0.1667\n",
            "Epoch 274/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6599 - accuracy: 0.6187 - val_loss: 0.7441 - val_accuracy: 0.1667\n",
            "Epoch 275/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6601 - accuracy: 0.6195 - val_loss: 0.7453 - val_accuracy: 0.1667\n",
            "Epoch 276/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6596 - accuracy: 0.6153 - val_loss: 0.7454 - val_accuracy: 0.1667\n",
            "Epoch 277/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6597 - accuracy: 0.6195 - val_loss: 0.7443 - val_accuracy: 0.1667\n",
            "Epoch 278/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6594 - accuracy: 0.6170 - val_loss: 0.7447 - val_accuracy: 0.1667\n",
            "Epoch 279/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6593 - accuracy: 0.6212 - val_loss: 0.7441 - val_accuracy: 0.1667\n",
            "Epoch 280/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6591 - accuracy: 0.6153 - val_loss: 0.7443 - val_accuracy: 0.1667\n",
            "Epoch 281/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6590 - accuracy: 0.6145 - val_loss: 0.7443 - val_accuracy: 0.1667\n",
            "Epoch 282/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6589 - accuracy: 0.6162 - val_loss: 0.7445 - val_accuracy: 0.1667\n",
            "Epoch 283/1000\n",
            "594/594 [==============================] - 0s 38us/sample - loss: 0.6589 - accuracy: 0.6145 - val_loss: 0.7442 - val_accuracy: 0.1667\n",
            "Epoch 284/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6587 - accuracy: 0.6153 - val_loss: 0.7444 - val_accuracy: 0.1667\n",
            "Epoch 285/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6586 - accuracy: 0.6162 - val_loss: 0.7445 - val_accuracy: 0.1667\n",
            "Epoch 286/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6586 - accuracy: 0.6145 - val_loss: 0.7454 - val_accuracy: 0.1667\n",
            "Epoch 287/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6585 - accuracy: 0.6195 - val_loss: 0.7449 - val_accuracy: 0.1667\n",
            "Epoch 288/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6583 - accuracy: 0.6162 - val_loss: 0.7453 - val_accuracy: 0.1667\n",
            "Epoch 289/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6581 - accuracy: 0.6153 - val_loss: 0.7454 - val_accuracy: 0.1667\n",
            "Epoch 290/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6580 - accuracy: 0.6162 - val_loss: 0.7455 - val_accuracy: 0.1667\n",
            "Epoch 291/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6583 - accuracy: 0.6195 - val_loss: 0.7447 - val_accuracy: 0.1667\n",
            "Epoch 292/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6583 - accuracy: 0.6178 - val_loss: 0.7466 - val_accuracy: 0.1667\n",
            "Epoch 293/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6580 - accuracy: 0.6170 - val_loss: 0.7478 - val_accuracy: 0.1667\n",
            "Epoch 294/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6580 - accuracy: 0.6178 - val_loss: 0.7489 - val_accuracy: 0.1667\n",
            "Epoch 295/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6575 - accuracy: 0.6162 - val_loss: 0.7489 - val_accuracy: 0.1667\n",
            "Epoch 296/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6575 - accuracy: 0.6170 - val_loss: 0.7480 - val_accuracy: 0.1667\n",
            "Epoch 297/1000\n",
            "297/594 [==============>...............] - ETA: 0s - loss: 0.6568 - accuracy: 0.6145\n",
            "Epoch 00297: ReduceLROnPlateau reducing learning rate to 0.0625.\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6574 - accuracy: 0.6136 - val_loss: 0.7489 - val_accuracy: 0.1667\n",
            "Epoch 298/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6572 - accuracy: 0.6153 - val_loss: 0.7489 - val_accuracy: 0.1667\n",
            "Epoch 299/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6571 - accuracy: 0.6145 - val_loss: 0.7489 - val_accuracy: 0.1667\n",
            "Epoch 300/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6571 - accuracy: 0.6136 - val_loss: 0.7491 - val_accuracy: 0.1667\n",
            "Epoch 301/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6570 - accuracy: 0.6136 - val_loss: 0.7488 - val_accuracy: 0.1667\n",
            "Epoch 302/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6573 - accuracy: 0.6178 - val_loss: 0.7484 - val_accuracy: 0.1667\n",
            "Epoch 303/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6569 - accuracy: 0.6153 - val_loss: 0.7484 - val_accuracy: 0.1667\n",
            "Epoch 304/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6569 - accuracy: 0.6153 - val_loss: 0.7486 - val_accuracy: 0.1667\n",
            "Epoch 305/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6568 - accuracy: 0.6153 - val_loss: 0.7486 - val_accuracy: 0.1667\n",
            "Epoch 306/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6568 - accuracy: 0.6162 - val_loss: 0.7488 - val_accuracy: 0.1667\n",
            "Epoch 307/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6567 - accuracy: 0.6162 - val_loss: 0.7489 - val_accuracy: 0.1667\n",
            "Epoch 308/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6567 - accuracy: 0.6162 - val_loss: 0.7487 - val_accuracy: 0.1667\n",
            "Epoch 309/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6566 - accuracy: 0.6145 - val_loss: 0.7489 - val_accuracy: 0.1667\n",
            "Epoch 310/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6566 - accuracy: 0.6170 - val_loss: 0.7491 - val_accuracy: 0.1667\n",
            "Epoch 311/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6565 - accuracy: 0.6162 - val_loss: 0.7491 - val_accuracy: 0.1667\n",
            "Epoch 312/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6564 - accuracy: 0.6153 - val_loss: 0.7492 - val_accuracy: 0.1667\n",
            "Epoch 313/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6565 - accuracy: 0.6162 - val_loss: 0.7489 - val_accuracy: 0.1667\n",
            "Epoch 314/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6564 - accuracy: 0.6145 - val_loss: 0.7487 - val_accuracy: 0.1667\n",
            "Epoch 315/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6563 - accuracy: 0.6153 - val_loss: 0.7487 - val_accuracy: 0.1667\n",
            "Epoch 316/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6562 - accuracy: 0.6153 - val_loss: 0.7488 - val_accuracy: 0.1667\n",
            "Epoch 317/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6563 - accuracy: 0.6153 - val_loss: 0.7486 - val_accuracy: 0.1667\n",
            "Epoch 318/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6562 - accuracy: 0.6128 - val_loss: 0.7486 - val_accuracy: 0.1667\n",
            "Epoch 319/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6560 - accuracy: 0.6145 - val_loss: 0.7487 - val_accuracy: 0.1667\n",
            "Epoch 320/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6560 - accuracy: 0.6128 - val_loss: 0.7491 - val_accuracy: 0.1667\n",
            "Epoch 321/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6559 - accuracy: 0.6162 - val_loss: 0.7492 - val_accuracy: 0.1667\n",
            "Epoch 322/1000\n",
            "594/594 [==============================] - 0s 44us/sample - loss: 0.6559 - accuracy: 0.6145 - val_loss: 0.7495 - val_accuracy: 0.1667\n",
            "Epoch 323/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6558 - accuracy: 0.6153 - val_loss: 0.7498 - val_accuracy: 0.1667\n",
            "Epoch 324/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6558 - accuracy: 0.6145 - val_loss: 0.7501 - val_accuracy: 0.1667\n",
            "Epoch 325/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6557 - accuracy: 0.6153 - val_loss: 0.7501 - val_accuracy: 0.1667\n",
            "Epoch 326/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6556 - accuracy: 0.6153 - val_loss: 0.7502 - val_accuracy: 0.1667\n",
            "Epoch 327/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6556 - accuracy: 0.6153 - val_loss: 0.7503 - val_accuracy: 0.1667\n",
            "Epoch 328/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6555 - accuracy: 0.6162 - val_loss: 0.7503 - val_accuracy: 0.1667\n",
            "Epoch 329/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6554 - accuracy: 0.6153 - val_loss: 0.7504 - val_accuracy: 0.1667\n",
            "Epoch 330/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6554 - accuracy: 0.6145 - val_loss: 0.7506 - val_accuracy: 0.1667\n",
            "Epoch 331/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6553 - accuracy: 0.6145 - val_loss: 0.7508 - val_accuracy: 0.1667\n",
            "Epoch 332/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6553 - accuracy: 0.6153 - val_loss: 0.7507 - val_accuracy: 0.1667\n",
            "Epoch 333/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6553 - accuracy: 0.6162 - val_loss: 0.7507 - val_accuracy: 0.1667\n",
            "Epoch 334/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6552 - accuracy: 0.6162 - val_loss: 0.7508 - val_accuracy: 0.1667\n",
            "Epoch 335/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6551 - accuracy: 0.6145 - val_loss: 0.7509 - val_accuracy: 0.1667\n",
            "Epoch 336/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6552 - accuracy: 0.6145 - val_loss: 0.7512 - val_accuracy: 0.1667\n",
            "Epoch 337/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6551 - accuracy: 0.6153 - val_loss: 0.7515 - val_accuracy: 0.1667\n",
            "Epoch 338/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6550 - accuracy: 0.6153 - val_loss: 0.7514 - val_accuracy: 0.1667\n",
            "Epoch 339/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6549 - accuracy: 0.6153 - val_loss: 0.7517 - val_accuracy: 0.1667\n",
            "Epoch 340/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6549 - accuracy: 0.6153 - val_loss: 0.7517 - val_accuracy: 0.1667\n",
            "Epoch 341/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6548 - accuracy: 0.6145 - val_loss: 0.7519 - val_accuracy: 0.1667\n",
            "Epoch 342/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6548 - accuracy: 0.6128 - val_loss: 0.7517 - val_accuracy: 0.1667\n",
            "Epoch 343/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6549 - accuracy: 0.6136 - val_loss: 0.7516 - val_accuracy: 0.1667\n",
            "Epoch 344/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6547 - accuracy: 0.6153 - val_loss: 0.7516 - val_accuracy: 0.1667\n",
            "Epoch 345/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6546 - accuracy: 0.6145 - val_loss: 0.7519 - val_accuracy: 0.1667\n",
            "Epoch 346/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6545 - accuracy: 0.6145 - val_loss: 0.7520 - val_accuracy: 0.1667\n",
            "Epoch 347/1000\n",
            "297/594 [==============>...............] - ETA: 0s - loss: 0.6535 - accuracy: 0.6397\n",
            "Epoch 00347: ReduceLROnPlateau reducing learning rate to 0.03125.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6545 - accuracy: 0.6145 - val_loss: 0.7521 - val_accuracy: 0.1667\n",
            "Epoch 00347: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAGFCAYAAADAc+UQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcUz3ceSnsVt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "45b61e6a-e066-4297-e599-e14988ce52d4"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "mlp = Sequential()\n",
        "mlp.add(Dense(16, input_dim=2, activation='relu'))\n",
        "mlp.add(Dense(16, activation='sigmoid'))\n",
        "mlp.add(Dense(16, activation='relu'))\n",
        "mlp.add(Dense(2, activation='sigmoid'))\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(factor=0.5, monitor='accuracy',\n",
        "                              patience=50, min_lr=0.00000001,\n",
        "                              verbose = 1)\n",
        "\n",
        "stop_save = EarlyStopping(patience=200, monitor='accuracy',\n",
        "                          verbose=1, \n",
        "                          restore_best_weights=True)\n",
        "\n",
        "# All parameter gradients will be clipped to\n",
        "# a maximum norm of 1.\n",
        "sgd = optimizers.SGD(lr=1., clipnorm=1.)\n",
        "\n",
        "mlp.compile(loss='binary_crossentropy',\n",
        "            optimizer=sgd,\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "# trains the model\n",
        "mlp.fit(X, yv, epochs=1000, batch_size=297,\n",
        "        verbose=1, callbacks=[reduce_lr, stop_save], \n",
        "        validation_split = 0.01)\n",
        "\n",
        "y_pred = mlp.predict(X)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
        "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n",
        "                     np.arange(y_min, y_max, 0.02))\n",
        "Z = None\n",
        "Z = mlp.predict(np.c_[xx.ravel(), yy.ravel()])[:,1]\n",
        "Z = Z.reshape(xx.shape)\n",
        "cm = plt.cm.bwr\n",
        "\n",
        "fig = plt.figure(figsize=(6,6))\n",
        "\n",
        "plt.contourf(xx, yy, Z, cmap=cm, alpha=.25)\n",
        "\n",
        "plt.plot(X[1,0],X[1,1],'+', color='#648fff', label='Positive Class')\n",
        "plt.plot(X[2,1],X[2,1],'_', color='#fe6100', label='Negative Class')\n",
        "\n",
        "for i in range(len(y)):\n",
        "  x1 = X[i,0]\n",
        "  x2 = X[i,1]\n",
        "  if y[i]==1: \n",
        "    if (y_pred[i] == 0):\n",
        "      plt.plot(x1,x2,'+', color='#648fff')\n",
        "    else:\n",
        "      plt.plot(x1,x2,'k.', alpha=0.25)\n",
        "  else:\n",
        "    if (y_pred[i] == 1):\n",
        "      plt.plot(x1,x2,'_', color='#fe6100')\n",
        "    else:\n",
        "      plt.plot(x1,x2,'k.', alpha=0.25)\n",
        "\n",
        "accuracy = np.sum(np.equal(y_pred,y_actual))/len(y_actual)\n",
        "\n",
        "plt.axis('tight')\n",
        "plt.xlim(min(X[:,0])-0.1, max(X[:,0])+0.1)\n",
        "plt.ylim(min(X[:,1])-0.1, max(X[:,1])+0.1)\n",
        "plt.xlabel('$x_1$')\n",
        "plt.ylabel('$x_2$')\n",
        "plt.legend()\n",
        "plt.title('Keras-based 4-layer MLP on spiral dataset. Accuracy: {:04.3}'.format(accuracy))\n",
        "plt.savefig('ch.6.MLP.keras.deep.f.spirals.png', dpi=350, bbox_inches='tight')\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 594 samples, validate on 6 samples\n",
            "Epoch 1/1000\n",
            "594/594 [==============================] - 0s 469us/sample - loss: 0.6987 - accuracy: 0.4949 - val_loss: 0.7272 - val_accuracy: 0.1667\n",
            "Epoch 2/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6971 - accuracy: 0.4924 - val_loss: 0.6153 - val_accuracy: 1.0000\n",
            "Epoch 3/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6943 - accuracy: 0.4949 - val_loss: 0.7993 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6922 - accuracy: 0.5303 - val_loss: 0.7170 - val_accuracy: 0.0833\n",
            "Epoch 5/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6909 - accuracy: 0.5286 - val_loss: 0.6366 - val_accuracy: 1.0000\n",
            "Epoch 6/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6930 - accuracy: 0.4949 - val_loss: 0.8502 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6949 - accuracy: 0.4949 - val_loss: 0.7517 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6856 - accuracy: 0.5875 - val_loss: 0.7203 - val_accuracy: 0.1667\n",
            "Epoch 9/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6846 - accuracy: 0.5934 - val_loss: 0.7570 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6820 - accuracy: 0.5640 - val_loss: 0.7090 - val_accuracy: 0.1667\n",
            "Epoch 11/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6833 - accuracy: 0.5884 - val_loss: 0.6273 - val_accuracy: 1.0000\n",
            "Epoch 12/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6789 - accuracy: 0.5699 - val_loss: 0.7903 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6818 - accuracy: 0.5328 - val_loss: 0.7955 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6743 - accuracy: 0.5909 - val_loss: 0.7139 - val_accuracy: 0.1667\n",
            "Epoch 15/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6746 - accuracy: 0.5816 - val_loss: 0.8514 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/1000\n",
            "594/594 [==============================] - 0s 38us/sample - loss: 0.6711 - accuracy: 0.5968 - val_loss: 0.7270 - val_accuracy: 0.1667\n",
            "Epoch 17/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6683 - accuracy: 0.6019 - val_loss: 0.8637 - val_accuracy: 0.1667\n",
            "Epoch 18/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6639 - accuracy: 0.5968 - val_loss: 0.7210 - val_accuracy: 0.1667\n",
            "Epoch 19/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6614 - accuracy: 0.6086 - val_loss: 0.6233 - val_accuracy: 0.7500\n",
            "Epoch 20/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6577 - accuracy: 0.6035 - val_loss: 0.7755 - val_accuracy: 0.1667\n",
            "Epoch 21/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6536 - accuracy: 0.6077 - val_loss: 0.6394 - val_accuracy: 0.6667\n",
            "Epoch 22/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6539 - accuracy: 0.6187 - val_loss: 0.7037 - val_accuracy: 0.5000\n",
            "Epoch 23/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6534 - accuracy: 0.6305 - val_loss: 0.6247 - val_accuracy: 0.6667\n",
            "Epoch 24/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6499 - accuracy: 0.6019 - val_loss: 0.7653 - val_accuracy: 0.1667\n",
            "Epoch 25/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6483 - accuracy: 0.6229 - val_loss: 1.0202 - val_accuracy: 0.1667\n",
            "Epoch 26/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6673 - accuracy: 0.6010 - val_loss: 1.0537 - val_accuracy: 0.1667\n",
            "Epoch 27/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6495 - accuracy: 0.6178 - val_loss: 0.7870 - val_accuracy: 0.1667\n",
            "Epoch 28/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6416 - accuracy: 0.6162 - val_loss: 0.7158 - val_accuracy: 0.5000\n",
            "Epoch 29/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6427 - accuracy: 0.6103 - val_loss: 0.7380 - val_accuracy: 0.3333\n",
            "Epoch 30/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6491 - accuracy: 0.6120 - val_loss: 0.6103 - val_accuracy: 0.6667\n",
            "Epoch 31/1000\n",
            "594/594 [==============================] - 0s 36us/sample - loss: 0.6447 - accuracy: 0.6498 - val_loss: 0.8154 - val_accuracy: 0.1667\n",
            "Epoch 32/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6429 - accuracy: 0.6094 - val_loss: 1.0328 - val_accuracy: 0.1667\n",
            "Epoch 33/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6484 - accuracy: 0.6616 - val_loss: 0.9196 - val_accuracy: 0.1667\n",
            "Epoch 34/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6389 - accuracy: 0.6195 - val_loss: 0.8276 - val_accuracy: 0.1667\n",
            "Epoch 35/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6422 - accuracy: 0.6204 - val_loss: 1.0479 - val_accuracy: 0.1667\n",
            "Epoch 36/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6465 - accuracy: 0.6229 - val_loss: 0.9170 - val_accuracy: 0.1667\n",
            "Epoch 37/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6371 - accuracy: 0.6145 - val_loss: 0.7442 - val_accuracy: 0.3333\n",
            "Epoch 38/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6390 - accuracy: 0.6246 - val_loss: 0.8083 - val_accuracy: 0.1667\n",
            "Epoch 39/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6395 - accuracy: 0.6221 - val_loss: 1.0538 - val_accuracy: 0.1667\n",
            "Epoch 40/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6618 - accuracy: 0.6397 - val_loss: 1.1378 - val_accuracy: 0.1667\n",
            "Epoch 41/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6547 - accuracy: 0.6178 - val_loss: 0.9544 - val_accuracy: 0.1667\n",
            "Epoch 42/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6388 - accuracy: 0.6271 - val_loss: 0.8864 - val_accuracy: 0.1667\n",
            "Epoch 43/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6356 - accuracy: 0.6094 - val_loss: 0.8178 - val_accuracy: 0.1667\n",
            "Epoch 44/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6370 - accuracy: 0.6237 - val_loss: 0.7284 - val_accuracy: 0.5000\n",
            "Epoch 45/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.6362 - accuracy: 0.6237 - val_loss: 0.8399 - val_accuracy: 0.1667\n",
            "Epoch 46/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6359 - accuracy: 0.6111 - val_loss: 0.7419 - val_accuracy: 0.5000\n",
            "Epoch 47/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6461 - accuracy: 0.6372 - val_loss: 0.6555 - val_accuracy: 0.6667\n",
            "Epoch 48/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6535 - accuracy: 0.6355 - val_loss: 0.6452 - val_accuracy: 0.6667\n",
            "Epoch 49/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6576 - accuracy: 0.6338 - val_loss: 0.6258 - val_accuracy: 0.6667\n",
            "Epoch 50/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6498 - accuracy: 0.6296 - val_loss: 0.7089 - val_accuracy: 0.5000\n",
            "Epoch 51/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6364 - accuracy: 0.6397 - val_loss: 0.8185 - val_accuracy: 0.1667\n",
            "Epoch 52/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6509 - accuracy: 0.6246 - val_loss: 0.5401 - val_accuracy: 0.6667\n",
            "Epoch 53/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6593 - accuracy: 0.6246 - val_loss: 0.7552 - val_accuracy: 0.3333\n",
            "Epoch 54/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6338 - accuracy: 0.6170 - val_loss: 0.9004 - val_accuracy: 0.1667\n",
            "Epoch 55/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6336 - accuracy: 0.6237 - val_loss: 0.7247 - val_accuracy: 0.5000\n",
            "Epoch 56/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6383 - accuracy: 0.6221 - val_loss: 0.7510 - val_accuracy: 0.5000\n",
            "Epoch 57/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6327 - accuracy: 0.6271 - val_loss: 0.9203 - val_accuracy: 0.1667\n",
            "Epoch 58/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6354 - accuracy: 0.6254 - val_loss: 0.9129 - val_accuracy: 0.1667\n",
            "Epoch 59/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6336 - accuracy: 0.6263 - val_loss: 0.8833 - val_accuracy: 0.1667\n",
            "Epoch 60/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6426 - accuracy: 0.6170 - val_loss: 1.0943 - val_accuracy: 0.1667\n",
            "Epoch 61/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6607 - accuracy: 0.6128 - val_loss: 1.0671 - val_accuracy: 0.1667\n",
            "Epoch 62/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6830 - accuracy: 0.5909 - val_loss: 1.1966 - val_accuracy: 0.0000e+00\n",
            "Epoch 63/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6665 - accuracy: 0.5976 - val_loss: 0.9597 - val_accuracy: 0.1667\n",
            "Epoch 64/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6407 - accuracy: 0.6473 - val_loss: 0.9235 - val_accuracy: 0.1667\n",
            "Epoch 65/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6341 - accuracy: 0.6254 - val_loss: 0.8630 - val_accuracy: 0.1667\n",
            "Epoch 66/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6313 - accuracy: 0.6271 - val_loss: 0.8312 - val_accuracy: 0.1667\n",
            "Epoch 67/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6328 - accuracy: 0.6128 - val_loss: 0.9384 - val_accuracy: 0.1667\n",
            "Epoch 68/1000\n",
            "594/594 [==============================] - 0s 35us/sample - loss: 0.6312 - accuracy: 0.6456 - val_loss: 0.7109 - val_accuracy: 0.6667\n",
            "Epoch 69/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6336 - accuracy: 0.6380 - val_loss: 0.8185 - val_accuracy: 0.1667\n",
            "Epoch 70/1000\n",
            "594/594 [==============================] - 0s 48us/sample - loss: 0.6438 - accuracy: 0.6305 - val_loss: 0.5943 - val_accuracy: 0.6667\n",
            "Epoch 71/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6449 - accuracy: 0.6582 - val_loss: 0.7849 - val_accuracy: 0.2500\n",
            "Epoch 72/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6402 - accuracy: 0.6246 - val_loss: 0.6448 - val_accuracy: 0.6667\n",
            "Epoch 73/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6316 - accuracy: 0.6322 - val_loss: 0.9516 - val_accuracy: 0.1667\n",
            "Epoch 74/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6313 - accuracy: 0.6414 - val_loss: 0.8266 - val_accuracy: 0.1667\n",
            "Epoch 75/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6303 - accuracy: 0.6380 - val_loss: 0.7562 - val_accuracy: 0.5000\n",
            "Epoch 76/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.6316 - accuracy: 0.6212 - val_loss: 0.7689 - val_accuracy: 0.5000\n",
            "Epoch 77/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6292 - accuracy: 0.6178 - val_loss: 0.9371 - val_accuracy: 0.1667\n",
            "Epoch 78/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6302 - accuracy: 0.6532 - val_loss: 0.6746 - val_accuracy: 0.6667\n",
            "Epoch 79/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6400 - accuracy: 0.6389 - val_loss: 0.7209 - val_accuracy: 0.6667\n",
            "Epoch 80/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6472 - accuracy: 0.6237 - val_loss: 0.6158 - val_accuracy: 0.6667\n",
            "Epoch 81/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6455 - accuracy: 0.6271 - val_loss: 0.7306 - val_accuracy: 0.6667\n",
            "Epoch 82/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6332 - accuracy: 0.6364 - val_loss: 0.7542 - val_accuracy: 0.5000\n",
            "Epoch 83/1000\n",
            "297/594 [==============>...............] - ETA: 0s - loss: 0.6484 - accuracy: 0.6010\n",
            "Epoch 00083: ReduceLROnPlateau reducing learning rate to 0.5.\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6349 - accuracy: 0.6322 - val_loss: 0.7032 - val_accuracy: 0.6667\n",
            "Epoch 84/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6305 - accuracy: 0.6296 - val_loss: 0.8514 - val_accuracy: 0.1667\n",
            "Epoch 85/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6288 - accuracy: 0.6178 - val_loss: 0.8658 - val_accuracy: 0.1667\n",
            "Epoch 86/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6273 - accuracy: 0.6347 - val_loss: 0.8302 - val_accuracy: 0.1667\n",
            "Epoch 87/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6273 - accuracy: 0.6397 - val_loss: 0.8172 - val_accuracy: 0.2500\n",
            "Epoch 88/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6272 - accuracy: 0.6229 - val_loss: 0.8340 - val_accuracy: 0.1667\n",
            "Epoch 89/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6276 - accuracy: 0.6322 - val_loss: 0.8104 - val_accuracy: 0.3333\n",
            "Epoch 90/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6297 - accuracy: 0.6254 - val_loss: 0.7868 - val_accuracy: 0.3333\n",
            "Epoch 91/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6272 - accuracy: 0.6263 - val_loss: 0.8245 - val_accuracy: 0.2500\n",
            "Epoch 92/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6277 - accuracy: 0.6204 - val_loss: 0.8722 - val_accuracy: 0.1667\n",
            "Epoch 93/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6282 - accuracy: 0.6524 - val_loss: 0.7906 - val_accuracy: 0.3333\n",
            "Epoch 94/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6271 - accuracy: 0.6145 - val_loss: 0.8597 - val_accuracy: 0.1667\n",
            "Epoch 95/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6286 - accuracy: 0.6448 - val_loss: 0.8805 - val_accuracy: 0.1667\n",
            "Epoch 96/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6301 - accuracy: 0.6347 - val_loss: 0.8864 - val_accuracy: 0.1667\n",
            "Epoch 97/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6273 - accuracy: 0.6313 - val_loss: 0.8581 - val_accuracy: 0.1667\n",
            "Epoch 98/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6263 - accuracy: 0.6288 - val_loss: 0.8514 - val_accuracy: 0.1667\n",
            "Epoch 99/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6273 - accuracy: 0.6347 - val_loss: 0.8738 - val_accuracy: 0.1667\n",
            "Epoch 100/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6265 - accuracy: 0.6507 - val_loss: 0.8003 - val_accuracy: 0.3333\n",
            "Epoch 101/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6256 - accuracy: 0.6178 - val_loss: 0.8436 - val_accuracy: 0.1667\n",
            "Epoch 102/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6257 - accuracy: 0.6263 - val_loss: 0.8576 - val_accuracy: 0.1667\n",
            "Epoch 103/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6255 - accuracy: 0.6423 - val_loss: 0.8394 - val_accuracy: 0.1667\n",
            "Epoch 104/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6251 - accuracy: 0.6254 - val_loss: 0.8428 - val_accuracy: 0.1667\n",
            "Epoch 105/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6259 - accuracy: 0.6490 - val_loss: 0.8090 - val_accuracy: 0.3333\n",
            "Epoch 106/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6324 - accuracy: 0.6305 - val_loss: 0.7535 - val_accuracy: 0.5000\n",
            "Epoch 107/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6265 - accuracy: 0.6145 - val_loss: 0.8335 - val_accuracy: 0.2500\n",
            "Epoch 108/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6265 - accuracy: 0.6439 - val_loss: 0.7927 - val_accuracy: 0.3333\n",
            "Epoch 109/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6268 - accuracy: 0.6322 - val_loss: 0.8011 - val_accuracy: 0.3333\n",
            "Epoch 110/1000\n",
            "594/594 [==============================] - 0s 35us/sample - loss: 0.6249 - accuracy: 0.6170 - val_loss: 0.8672 - val_accuracy: 0.1667\n",
            "Epoch 111/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6244 - accuracy: 0.6465 - val_loss: 0.8417 - val_accuracy: 0.2500\n",
            "Epoch 112/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6244 - accuracy: 0.6271 - val_loss: 0.8570 - val_accuracy: 0.1667\n",
            "Epoch 113/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6253 - accuracy: 0.6296 - val_loss: 0.8730 - val_accuracy: 0.1667\n",
            "Epoch 114/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6263 - accuracy: 0.6582 - val_loss: 0.7808 - val_accuracy: 0.3333\n",
            "Epoch 115/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6253 - accuracy: 0.6355 - val_loss: 0.8167 - val_accuracy: 0.3333\n",
            "Epoch 116/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6258 - accuracy: 0.6263 - val_loss: 0.8930 - val_accuracy: 0.1667\n",
            "Epoch 117/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6239 - accuracy: 0.6574 - val_loss: 0.8299 - val_accuracy: 0.3333\n",
            "Epoch 118/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6235 - accuracy: 0.6380 - val_loss: 0.8224 - val_accuracy: 0.3333\n",
            "Epoch 119/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6232 - accuracy: 0.6212 - val_loss: 0.8428 - val_accuracy: 0.3333\n",
            "Epoch 120/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6233 - accuracy: 0.6347 - val_loss: 0.8509 - val_accuracy: 0.2500\n",
            "Epoch 121/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6272 - accuracy: 0.6305 - val_loss: 0.9093 - val_accuracy: 0.1667\n",
            "Epoch 122/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6261 - accuracy: 0.6254 - val_loss: 0.8778 - val_accuracy: 0.1667\n",
            "Epoch 123/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6231 - accuracy: 0.6372 - val_loss: 0.8488 - val_accuracy: 0.2500\n",
            "Epoch 124/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6227 - accuracy: 0.6355 - val_loss: 0.8454 - val_accuracy: 0.3333\n",
            "Epoch 125/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6225 - accuracy: 0.6498 - val_loss: 0.8250 - val_accuracy: 0.3333\n",
            "Epoch 126/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6227 - accuracy: 0.6229 - val_loss: 0.8601 - val_accuracy: 0.1667\n",
            "Epoch 127/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6231 - accuracy: 0.6515 - val_loss: 0.8697 - val_accuracy: 0.1667\n",
            "Epoch 128/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6221 - accuracy: 0.6540 - val_loss: 0.8285 - val_accuracy: 0.3333\n",
            "Epoch 129/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6219 - accuracy: 0.6372 - val_loss: 0.8344 - val_accuracy: 0.3333\n",
            "Epoch 130/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6219 - accuracy: 0.6414 - val_loss: 0.8288 - val_accuracy: 0.3333\n",
            "Epoch 131/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6256 - accuracy: 0.6364 - val_loss: 0.7681 - val_accuracy: 0.5000\n",
            "Epoch 132/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6224 - accuracy: 0.6162 - val_loss: 0.8504 - val_accuracy: 0.3333\n",
            "Epoch 133/1000\n",
            "297/594 [==============>...............] - ETA: 0s - loss: 0.6463 - accuracy: 0.6195\n",
            "Epoch 00133: ReduceLROnPlateau reducing learning rate to 0.25.\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6221 - accuracy: 0.6599 - val_loss: 0.8111 - val_accuracy: 0.3333\n",
            "Epoch 134/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6214 - accuracy: 0.6296 - val_loss: 0.8264 - val_accuracy: 0.3333\n",
            "Epoch 135/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6211 - accuracy: 0.6364 - val_loss: 0.8328 - val_accuracy: 0.3333\n",
            "Epoch 136/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6212 - accuracy: 0.6397 - val_loss: 0.8338 - val_accuracy: 0.3333\n",
            "Epoch 137/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6229 - accuracy: 0.6397 - val_loss: 0.8175 - val_accuracy: 0.3333\n",
            "Epoch 138/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6216 - accuracy: 0.6221 - val_loss: 0.8466 - val_accuracy: 0.3333\n",
            "Epoch 139/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6236 - accuracy: 0.6566 - val_loss: 0.8164 - val_accuracy: 0.3333\n",
            "Epoch 140/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6209 - accuracy: 0.6254 - val_loss: 0.8322 - val_accuracy: 0.3333\n",
            "Epoch 141/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6208 - accuracy: 0.6338 - val_loss: 0.8450 - val_accuracy: 0.3333\n",
            "Epoch 142/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6216 - accuracy: 0.6431 - val_loss: 0.8562 - val_accuracy: 0.2500\n",
            "Epoch 143/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6210 - accuracy: 0.6557 - val_loss: 0.8331 - val_accuracy: 0.3333\n",
            "Epoch 144/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6204 - accuracy: 0.6397 - val_loss: 0.8380 - val_accuracy: 0.3333\n",
            "Epoch 145/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6207 - accuracy: 0.6313 - val_loss: 0.8504 - val_accuracy: 0.3333\n",
            "Epoch 146/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6206 - accuracy: 0.6532 - val_loss: 0.8324 - val_accuracy: 0.3333\n",
            "Epoch 147/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6209 - accuracy: 0.6439 - val_loss: 0.8253 - val_accuracy: 0.3333\n",
            "Epoch 148/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6205 - accuracy: 0.6380 - val_loss: 0.8264 - val_accuracy: 0.3333\n",
            "Epoch 149/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6203 - accuracy: 0.6364 - val_loss: 0.8281 - val_accuracy: 0.3333\n",
            "Epoch 150/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6201 - accuracy: 0.6456 - val_loss: 0.8334 - val_accuracy: 0.3333\n",
            "Epoch 151/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6198 - accuracy: 0.6423 - val_loss: 0.8389 - val_accuracy: 0.3333\n",
            "Epoch 152/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6197 - accuracy: 0.6473 - val_loss: 0.8372 - val_accuracy: 0.3333\n",
            "Epoch 153/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6198 - accuracy: 0.6347 - val_loss: 0.8475 - val_accuracy: 0.3333\n",
            "Epoch 154/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6203 - accuracy: 0.6380 - val_loss: 0.8563 - val_accuracy: 0.3333\n",
            "Epoch 155/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6201 - accuracy: 0.6439 - val_loss: 0.8564 - val_accuracy: 0.3333\n",
            "Epoch 156/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6202 - accuracy: 0.6456 - val_loss: 0.8587 - val_accuracy: 0.2500\n",
            "Epoch 157/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6220 - accuracy: 0.6406 - val_loss: 0.8703 - val_accuracy: 0.1667\n",
            "Epoch 158/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6197 - accuracy: 0.6574 - val_loss: 0.8391 - val_accuracy: 0.3333\n",
            "Epoch 159/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6210 - accuracy: 0.6532 - val_loss: 0.8192 - val_accuracy: 0.3333\n",
            "Epoch 160/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6208 - accuracy: 0.6473 - val_loss: 0.8162 - val_accuracy: 0.3333\n",
            "Epoch 161/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6203 - accuracy: 0.6170 - val_loss: 0.8542 - val_accuracy: 0.3333\n",
            "Epoch 162/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.6189 - accuracy: 0.6515 - val_loss: 0.8495 - val_accuracy: 0.3333\n",
            "Epoch 163/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6209 - accuracy: 0.6338 - val_loss: 0.8673 - val_accuracy: 0.1667\n",
            "Epoch 164/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6190 - accuracy: 0.6582 - val_loss: 0.8386 - val_accuracy: 0.3333\n",
            "Epoch 165/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6190 - accuracy: 0.6423 - val_loss: 0.8497 - val_accuracy: 0.3333\n",
            "Epoch 166/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6187 - accuracy: 0.6473 - val_loss: 0.8492 - val_accuracy: 0.3333\n",
            "Epoch 167/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6198 - accuracy: 0.6540 - val_loss: 0.8258 - val_accuracy: 0.3333\n",
            "Epoch 168/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6183 - accuracy: 0.6380 - val_loss: 0.8416 - val_accuracy: 0.3333\n",
            "Epoch 169/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6184 - accuracy: 0.6355 - val_loss: 0.8518 - val_accuracy: 0.3333\n",
            "Epoch 170/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6200 - accuracy: 0.6591 - val_loss: 0.8220 - val_accuracy: 0.3333\n",
            "Epoch 171/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6187 - accuracy: 0.6364 - val_loss: 0.8278 - val_accuracy: 0.3333\n",
            "Epoch 172/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6184 - accuracy: 0.6557 - val_loss: 0.8284 - val_accuracy: 0.3333\n",
            "Epoch 173/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6189 - accuracy: 0.6465 - val_loss: 0.8238 - val_accuracy: 0.3333\n",
            "Epoch 174/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6177 - accuracy: 0.6380 - val_loss: 0.8393 - val_accuracy: 0.3333\n",
            "Epoch 175/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6177 - accuracy: 0.6557 - val_loss: 0.8348 - val_accuracy: 0.3333\n",
            "Epoch 176/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6182 - accuracy: 0.6574 - val_loss: 0.8282 - val_accuracy: 0.3333\n",
            "Epoch 177/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6182 - accuracy: 0.6507 - val_loss: 0.8262 - val_accuracy: 0.3333\n",
            "Epoch 178/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6173 - accuracy: 0.6397 - val_loss: 0.8440 - val_accuracy: 0.3333\n",
            "Epoch 179/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6170 - accuracy: 0.6515 - val_loss: 0.8458 - val_accuracy: 0.3333\n",
            "Epoch 180/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6175 - accuracy: 0.6566 - val_loss: 0.8321 - val_accuracy: 0.3333\n",
            "Epoch 181/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6170 - accuracy: 0.6481 - val_loss: 0.8371 - val_accuracy: 0.3333\n",
            "Epoch 182/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6180 - accuracy: 0.6465 - val_loss: 0.8253 - val_accuracy: 0.3333\n",
            "Epoch 183/1000\n",
            "297/594 [==============>...............] - ETA: 0s - loss: 0.6034 - accuracy: 0.6599\n",
            "Epoch 00183: ReduceLROnPlateau reducing learning rate to 0.125.\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6178 - accuracy: 0.6254 - val_loss: 0.8609 - val_accuracy: 0.3333\n",
            "Epoch 184/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6169 - accuracy: 0.6650 - val_loss: 0.8501 - val_accuracy: 0.3333\n",
            "Epoch 185/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6170 - accuracy: 0.6498 - val_loss: 0.8533 - val_accuracy: 0.3333\n",
            "Epoch 186/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6164 - accuracy: 0.6625 - val_loss: 0.8494 - val_accuracy: 0.3333\n",
            "Epoch 187/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6164 - accuracy: 0.6633 - val_loss: 0.8451 - val_accuracy: 0.3333\n",
            "Epoch 188/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6162 - accuracy: 0.6532 - val_loss: 0.8459 - val_accuracy: 0.3333\n",
            "Epoch 189/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6171 - accuracy: 0.6582 - val_loss: 0.8398 - val_accuracy: 0.3333\n",
            "Epoch 190/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6161 - accuracy: 0.6490 - val_loss: 0.8432 - val_accuracy: 0.3333\n",
            "Epoch 191/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6167 - accuracy: 0.6406 - val_loss: 0.8502 - val_accuracy: 0.3333\n",
            "Epoch 192/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6160 - accuracy: 0.6557 - val_loss: 0.8499 - val_accuracy: 0.3333\n",
            "Epoch 193/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6163 - accuracy: 0.6481 - val_loss: 0.8526 - val_accuracy: 0.3333\n",
            "Epoch 194/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6161 - accuracy: 0.6633 - val_loss: 0.8465 - val_accuracy: 0.3333\n",
            "Epoch 195/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6159 - accuracy: 0.6515 - val_loss: 0.8489 - val_accuracy: 0.3333\n",
            "Epoch 196/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6158 - accuracy: 0.6616 - val_loss: 0.8465 - val_accuracy: 0.3333\n",
            "Epoch 197/1000\n",
            "594/594 [==============================] - 0s 37us/sample - loss: 0.6157 - accuracy: 0.6608 - val_loss: 0.8443 - val_accuracy: 0.3333\n",
            "Epoch 198/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6157 - accuracy: 0.6582 - val_loss: 0.8435 - val_accuracy: 0.3333\n",
            "Epoch 199/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6155 - accuracy: 0.6549 - val_loss: 0.8444 - val_accuracy: 0.3333\n",
            "Epoch 200/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6154 - accuracy: 0.6557 - val_loss: 0.8453 - val_accuracy: 0.3333\n",
            "Epoch 201/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6155 - accuracy: 0.6515 - val_loss: 0.8484 - val_accuracy: 0.3333\n",
            "Epoch 202/1000\n",
            "594/594 [==============================] - 0s 44us/sample - loss: 0.6157 - accuracy: 0.6507 - val_loss: 0.8526 - val_accuracy: 0.3333\n",
            "Epoch 203/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6161 - accuracy: 0.6650 - val_loss: 0.8442 - val_accuracy: 0.3333\n",
            "Epoch 204/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6151 - accuracy: 0.6574 - val_loss: 0.8458 - val_accuracy: 0.3333\n",
            "Epoch 205/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6164 - accuracy: 0.6507 - val_loss: 0.8546 - val_accuracy: 0.3333\n",
            "Epoch 206/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6150 - accuracy: 0.6641 - val_loss: 0.8513 - val_accuracy: 0.3333\n",
            "Epoch 207/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6149 - accuracy: 0.6608 - val_loss: 0.8517 - val_accuracy: 0.3333\n",
            "Epoch 208/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6157 - accuracy: 0.6557 - val_loss: 0.8569 - val_accuracy: 0.3333\n",
            "Epoch 209/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6148 - accuracy: 0.6650 - val_loss: 0.8555 - val_accuracy: 0.3333\n",
            "Epoch 210/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6148 - accuracy: 0.6625 - val_loss: 0.8543 - val_accuracy: 0.3333\n",
            "Epoch 211/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6146 - accuracy: 0.6650 - val_loss: 0.8530 - val_accuracy: 0.3333\n",
            "Epoch 212/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6149 - accuracy: 0.6633 - val_loss: 0.8554 - val_accuracy: 0.3333\n",
            "Epoch 213/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6157 - accuracy: 0.6473 - val_loss: 0.8607 - val_accuracy: 0.2500\n",
            "Epoch 214/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6146 - accuracy: 0.6591 - val_loss: 0.8585 - val_accuracy: 0.2500\n",
            "Epoch 215/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6144 - accuracy: 0.6633 - val_loss: 0.8559 - val_accuracy: 0.3333\n",
            "Epoch 216/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6145 - accuracy: 0.6658 - val_loss: 0.8495 - val_accuracy: 0.3333\n",
            "Epoch 217/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6151 - accuracy: 0.6625 - val_loss: 0.8432 - val_accuracy: 0.3333\n",
            "Epoch 218/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6148 - accuracy: 0.6456 - val_loss: 0.8527 - val_accuracy: 0.3333\n",
            "Epoch 219/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6141 - accuracy: 0.6658 - val_loss: 0.8492 - val_accuracy: 0.3333\n",
            "Epoch 220/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6141 - accuracy: 0.6599 - val_loss: 0.8524 - val_accuracy: 0.3333\n",
            "Epoch 221/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6140 - accuracy: 0.6641 - val_loss: 0.8547 - val_accuracy: 0.3333\n",
            "Epoch 222/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6144 - accuracy: 0.6658 - val_loss: 0.8469 - val_accuracy: 0.3333\n",
            "Epoch 223/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6139 - accuracy: 0.6667 - val_loss: 0.8453 - val_accuracy: 0.3333\n",
            "Epoch 224/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6138 - accuracy: 0.6574 - val_loss: 0.8524 - val_accuracy: 0.3333\n",
            "Epoch 225/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6139 - accuracy: 0.6709 - val_loss: 0.8475 - val_accuracy: 0.3333\n",
            "Epoch 226/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6134 - accuracy: 0.6658 - val_loss: 0.8500 - val_accuracy: 0.3333\n",
            "Epoch 227/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6134 - accuracy: 0.6675 - val_loss: 0.8516 - val_accuracy: 0.3333\n",
            "Epoch 228/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6133 - accuracy: 0.6709 - val_loss: 0.8501 - val_accuracy: 0.3333\n",
            "Epoch 229/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6133 - accuracy: 0.6692 - val_loss: 0.8538 - val_accuracy: 0.3333\n",
            "Epoch 230/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6144 - accuracy: 0.6566 - val_loss: 0.8616 - val_accuracy: 0.2500\n",
            "Epoch 231/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6133 - accuracy: 0.6667 - val_loss: 0.8607 - val_accuracy: 0.2500\n",
            "Epoch 232/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6136 - accuracy: 0.6684 - val_loss: 0.8511 - val_accuracy: 0.3333\n",
            "Epoch 233/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6147 - accuracy: 0.6641 - val_loss: 0.8421 - val_accuracy: 0.3333\n",
            "Epoch 234/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6128 - accuracy: 0.6658 - val_loss: 0.8462 - val_accuracy: 0.3333\n",
            "Epoch 235/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6132 - accuracy: 0.6692 - val_loss: 0.8451 - val_accuracy: 0.3333\n",
            "Epoch 236/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6126 - accuracy: 0.6684 - val_loss: 0.8491 - val_accuracy: 0.3333\n",
            "Epoch 237/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6134 - accuracy: 0.6566 - val_loss: 0.8586 - val_accuracy: 0.3333\n",
            "Epoch 238/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6124 - accuracy: 0.6709 - val_loss: 0.8549 - val_accuracy: 0.3333\n",
            "Epoch 239/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6124 - accuracy: 0.6700 - val_loss: 0.8572 - val_accuracy: 0.3333\n",
            "Epoch 240/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6123 - accuracy: 0.6734 - val_loss: 0.8562 - val_accuracy: 0.3333\n",
            "Epoch 241/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6126 - accuracy: 0.6658 - val_loss: 0.8604 - val_accuracy: 0.3333\n",
            "Epoch 242/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6120 - accuracy: 0.6717 - val_loss: 0.8573 - val_accuracy: 0.3333\n",
            "Epoch 243/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6126 - accuracy: 0.6599 - val_loss: 0.8621 - val_accuracy: 0.3333\n",
            "Epoch 244/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6136 - accuracy: 0.6524 - val_loss: 0.8686 - val_accuracy: 0.2500\n",
            "Epoch 245/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6122 - accuracy: 0.6734 - val_loss: 0.8663 - val_accuracy: 0.3333\n",
            "Epoch 246/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6121 - accuracy: 0.6717 - val_loss: 0.8646 - val_accuracy: 0.3333\n",
            "Epoch 247/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6122 - accuracy: 0.6759 - val_loss: 0.8546 - val_accuracy: 0.3333\n",
            "Epoch 248/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6116 - accuracy: 0.6709 - val_loss: 0.8566 - val_accuracy: 0.3333\n",
            "Epoch 249/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6114 - accuracy: 0.6709 - val_loss: 0.8568 - val_accuracy: 0.3333\n",
            "Epoch 250/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6120 - accuracy: 0.6625 - val_loss: 0.8625 - val_accuracy: 0.3333\n",
            "Epoch 251/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6114 - accuracy: 0.6717 - val_loss: 0.8605 - val_accuracy: 0.3333\n",
            "Epoch 252/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6121 - accuracy: 0.6667 - val_loss: 0.8647 - val_accuracy: 0.3333\n",
            "Epoch 253/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6112 - accuracy: 0.6734 - val_loss: 0.8623 - val_accuracy: 0.3333\n",
            "Epoch 254/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6117 - accuracy: 0.6734 - val_loss: 0.8651 - val_accuracy: 0.3333\n",
            "Epoch 255/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6111 - accuracy: 0.6734 - val_loss: 0.8578 - val_accuracy: 0.3333\n",
            "Epoch 256/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6109 - accuracy: 0.6709 - val_loss: 0.8567 - val_accuracy: 0.3333\n",
            "Epoch 257/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6108 - accuracy: 0.6726 - val_loss: 0.8554 - val_accuracy: 0.3333\n",
            "Epoch 258/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6108 - accuracy: 0.6717 - val_loss: 0.8531 - val_accuracy: 0.3333\n",
            "Epoch 259/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.6107 - accuracy: 0.6726 - val_loss: 0.8539 - val_accuracy: 0.3333\n",
            "Epoch 260/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6106 - accuracy: 0.6751 - val_loss: 0.8565 - val_accuracy: 0.3333\n",
            "Epoch 261/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6105 - accuracy: 0.6734 - val_loss: 0.8574 - val_accuracy: 0.3333\n",
            "Epoch 262/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6104 - accuracy: 0.6726 - val_loss: 0.8567 - val_accuracy: 0.3333\n",
            "Epoch 263/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6108 - accuracy: 0.6692 - val_loss: 0.8619 - val_accuracy: 0.3333\n",
            "Epoch 264/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6115 - accuracy: 0.6734 - val_loss: 0.8499 - val_accuracy: 0.3333\n",
            "Epoch 265/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6103 - accuracy: 0.6776 - val_loss: 0.8554 - val_accuracy: 0.3333\n",
            "Epoch 266/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6103 - accuracy: 0.6768 - val_loss: 0.8596 - val_accuracy: 0.3333\n",
            "Epoch 267/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6100 - accuracy: 0.6734 - val_loss: 0.8554 - val_accuracy: 0.3333\n",
            "Epoch 268/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6107 - accuracy: 0.6650 - val_loss: 0.8630 - val_accuracy: 0.3333\n",
            "Epoch 269/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6110 - accuracy: 0.6675 - val_loss: 0.8679 - val_accuracy: 0.3333\n",
            "Epoch 270/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6099 - accuracy: 0.6700 - val_loss: 0.8589 - val_accuracy: 0.3333\n",
            "Epoch 271/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6098 - accuracy: 0.6734 - val_loss: 0.8539 - val_accuracy: 0.3333\n",
            "Epoch 272/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6096 - accuracy: 0.6734 - val_loss: 0.8569 - val_accuracy: 0.3333\n",
            "Epoch 273/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6095 - accuracy: 0.6742 - val_loss: 0.8545 - val_accuracy: 0.3333\n",
            "Epoch 274/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6095 - accuracy: 0.6785 - val_loss: 0.8571 - val_accuracy: 0.3333\n",
            "Epoch 275/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6094 - accuracy: 0.6793 - val_loss: 0.8592 - val_accuracy: 0.3333\n",
            "Epoch 276/1000\n",
            "594/594 [==============================] - 0s 40us/sample - loss: 0.6097 - accuracy: 0.6692 - val_loss: 0.8631 - val_accuracy: 0.3333\n",
            "Epoch 277/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6098 - accuracy: 0.6726 - val_loss: 0.8522 - val_accuracy: 0.3333\n",
            "Epoch 278/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6091 - accuracy: 0.6768 - val_loss: 0.8561 - val_accuracy: 0.3333\n",
            "Epoch 279/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6103 - accuracy: 0.6768 - val_loss: 0.8465 - val_accuracy: 0.3333\n",
            "Epoch 280/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6089 - accuracy: 0.6793 - val_loss: 0.8505 - val_accuracy: 0.3333\n",
            "Epoch 281/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6091 - accuracy: 0.6734 - val_loss: 0.8480 - val_accuracy: 0.3333\n",
            "Epoch 282/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6087 - accuracy: 0.6768 - val_loss: 0.8511 - val_accuracy: 0.3333\n",
            "Epoch 283/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6089 - accuracy: 0.6759 - val_loss: 0.8491 - val_accuracy: 0.3333\n",
            "Epoch 284/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6086 - accuracy: 0.6776 - val_loss: 0.8510 - val_accuracy: 0.3333\n",
            "Epoch 285/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6096 - accuracy: 0.6641 - val_loss: 0.8622 - val_accuracy: 0.3333\n",
            "Epoch 286/1000\n",
            "594/594 [==============================] - 0s 20us/sample - loss: 0.6092 - accuracy: 0.6684 - val_loss: 0.8656 - val_accuracy: 0.3333\n",
            "Epoch 287/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6083 - accuracy: 0.6717 - val_loss: 0.8585 - val_accuracy: 0.3333\n",
            "Epoch 288/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6083 - accuracy: 0.6734 - val_loss: 0.8531 - val_accuracy: 0.3333\n",
            "Epoch 289/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6082 - accuracy: 0.6759 - val_loss: 0.8512 - val_accuracy: 0.3333\n",
            "Epoch 290/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6082 - accuracy: 0.6717 - val_loss: 0.8573 - val_accuracy: 0.3333\n",
            "Epoch 291/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6080 - accuracy: 0.6751 - val_loss: 0.8531 - val_accuracy: 0.3333\n",
            "Epoch 292/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6083 - accuracy: 0.6717 - val_loss: 0.8598 - val_accuracy: 0.3333\n",
            "Epoch 293/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6079 - accuracy: 0.6734 - val_loss: 0.8536 - val_accuracy: 0.3333\n",
            "Epoch 294/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6086 - accuracy: 0.6751 - val_loss: 0.8464 - val_accuracy: 0.3333\n",
            "Epoch 295/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6076 - accuracy: 0.6776 - val_loss: 0.8498 - val_accuracy: 0.3333\n",
            "Epoch 296/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6075 - accuracy: 0.6793 - val_loss: 0.8532 - val_accuracy: 0.3333\n",
            "Epoch 297/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6074 - accuracy: 0.6768 - val_loss: 0.8541 - val_accuracy: 0.3333\n",
            "Epoch 298/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6075 - accuracy: 0.6793 - val_loss: 0.8588 - val_accuracy: 0.3333\n",
            "Epoch 299/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6073 - accuracy: 0.6742 - val_loss: 0.8529 - val_accuracy: 0.3333\n",
            "Epoch 300/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6070 - accuracy: 0.6776 - val_loss: 0.8545 - val_accuracy: 0.3333\n",
            "Epoch 301/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6072 - accuracy: 0.6742 - val_loss: 0.8505 - val_accuracy: 0.3333\n",
            "Epoch 302/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6070 - accuracy: 0.6768 - val_loss: 0.8549 - val_accuracy: 0.3333\n",
            "Epoch 303/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6068 - accuracy: 0.6751 - val_loss: 0.8522 - val_accuracy: 0.3333\n",
            "Epoch 304/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6070 - accuracy: 0.6726 - val_loss: 0.8588 - val_accuracy: 0.3333\n",
            "Epoch 305/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6066 - accuracy: 0.6776 - val_loss: 0.8557 - val_accuracy: 0.3333\n",
            "Epoch 306/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6068 - accuracy: 0.6785 - val_loss: 0.8585 - val_accuracy: 0.3333\n",
            "Epoch 307/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6074 - accuracy: 0.6759 - val_loss: 0.8651 - val_accuracy: 0.3333\n",
            "Epoch 308/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6066 - accuracy: 0.6700 - val_loss: 0.8540 - val_accuracy: 0.3333\n",
            "Epoch 309/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6067 - accuracy: 0.6717 - val_loss: 0.8605 - val_accuracy: 0.3333\n",
            "Epoch 310/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6061 - accuracy: 0.6751 - val_loss: 0.8555 - val_accuracy: 0.3333\n",
            "Epoch 311/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6060 - accuracy: 0.6776 - val_loss: 0.8551 - val_accuracy: 0.3333\n",
            "Epoch 312/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6061 - accuracy: 0.6801 - val_loss: 0.8585 - val_accuracy: 0.3333\n",
            "Epoch 313/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6060 - accuracy: 0.6751 - val_loss: 0.8512 - val_accuracy: 0.3333\n",
            "Epoch 314/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6061 - accuracy: 0.6734 - val_loss: 0.8468 - val_accuracy: 0.3333\n",
            "Epoch 315/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6057 - accuracy: 0.6785 - val_loss: 0.8477 - val_accuracy: 0.3333\n",
            "Epoch 316/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6068 - accuracy: 0.6726 - val_loss: 0.8408 - val_accuracy: 0.3333\n",
            "Epoch 317/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6061 - accuracy: 0.6717 - val_loss: 0.8555 - val_accuracy: 0.3333\n",
            "Epoch 318/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6057 - accuracy: 0.6785 - val_loss: 0.8586 - val_accuracy: 0.3333\n",
            "Epoch 319/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6057 - accuracy: 0.6726 - val_loss: 0.8493 - val_accuracy: 0.3333\n",
            "Epoch 320/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6058 - accuracy: 0.6684 - val_loss: 0.8588 - val_accuracy: 0.3333\n",
            "Epoch 321/1000\n",
            "594/594 [==============================] - 0s 34us/sample - loss: 0.6051 - accuracy: 0.6759 - val_loss: 0.8525 - val_accuracy: 0.3333\n",
            "Epoch 322/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6054 - accuracy: 0.6717 - val_loss: 0.8461 - val_accuracy: 0.3333\n",
            "Epoch 323/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6055 - accuracy: 0.6751 - val_loss: 0.8430 - val_accuracy: 0.3333\n",
            "Epoch 324/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6051 - accuracy: 0.6785 - val_loss: 0.8535 - val_accuracy: 0.3333\n",
            "Epoch 325/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6048 - accuracy: 0.6810 - val_loss: 0.8575 - val_accuracy: 0.3333\n",
            "Epoch 326/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6047 - accuracy: 0.6793 - val_loss: 0.8581 - val_accuracy: 0.3333\n",
            "Epoch 327/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6048 - accuracy: 0.6768 - val_loss: 0.8605 - val_accuracy: 0.3333\n",
            "Epoch 328/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6060 - accuracy: 0.6776 - val_loss: 0.8436 - val_accuracy: 0.3333\n",
            "Epoch 329/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6046 - accuracy: 0.6751 - val_loss: 0.8542 - val_accuracy: 0.3333\n",
            "Epoch 330/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6041 - accuracy: 0.6785 - val_loss: 0.8534 - val_accuracy: 0.3333\n",
            "Epoch 331/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6040 - accuracy: 0.6785 - val_loss: 0.8533 - val_accuracy: 0.3333\n",
            "Epoch 332/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6068 - accuracy: 0.6801 - val_loss: 0.8361 - val_accuracy: 0.3333\n",
            "Epoch 333/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6040 - accuracy: 0.6793 - val_loss: 0.8425 - val_accuracy: 0.3333\n",
            "Epoch 334/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6039 - accuracy: 0.6810 - val_loss: 0.8492 - val_accuracy: 0.3333\n",
            "Epoch 335/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6040 - accuracy: 0.6759 - val_loss: 0.8444 - val_accuracy: 0.3333\n",
            "Epoch 336/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6043 - accuracy: 0.6667 - val_loss: 0.8569 - val_accuracy: 0.3333\n",
            "Epoch 337/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6034 - accuracy: 0.6768 - val_loss: 0.8514 - val_accuracy: 0.3333\n",
            "Epoch 338/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6050 - accuracy: 0.6726 - val_loss: 0.8387 - val_accuracy: 0.3333\n",
            "Epoch 339/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6032 - accuracy: 0.6810 - val_loss: 0.8438 - val_accuracy: 0.3333\n",
            "Epoch 340/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6030 - accuracy: 0.6776 - val_loss: 0.8478 - val_accuracy: 0.3333\n",
            "Epoch 341/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6030 - accuracy: 0.6793 - val_loss: 0.8518 - val_accuracy: 0.3333\n",
            "Epoch 342/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6032 - accuracy: 0.6759 - val_loss: 0.8459 - val_accuracy: 0.3333\n",
            "Epoch 343/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6028 - accuracy: 0.6768 - val_loss: 0.8480 - val_accuracy: 0.3333\n",
            "Epoch 344/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6027 - accuracy: 0.6776 - val_loss: 0.8480 - val_accuracy: 0.3333\n",
            "Epoch 345/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6029 - accuracy: 0.6785 - val_loss: 0.8552 - val_accuracy: 0.3333\n",
            "Epoch 346/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6025 - accuracy: 0.6785 - val_loss: 0.8515 - val_accuracy: 0.3333\n",
            "Epoch 347/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6026 - accuracy: 0.6785 - val_loss: 0.8450 - val_accuracy: 0.3333\n",
            "Epoch 348/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6023 - accuracy: 0.6776 - val_loss: 0.8475 - val_accuracy: 0.3333\n",
            "Epoch 349/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6022 - accuracy: 0.6801 - val_loss: 0.8527 - val_accuracy: 0.3333\n",
            "Epoch 350/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.6036 - accuracy: 0.6776 - val_loss: 0.8377 - val_accuracy: 0.3333\n",
            "Epoch 351/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6021 - accuracy: 0.6768 - val_loss: 0.8400 - val_accuracy: 0.3333\n",
            "Epoch 352/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6021 - accuracy: 0.6751 - val_loss: 0.8512 - val_accuracy: 0.3333\n",
            "Epoch 353/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6017 - accuracy: 0.6785 - val_loss: 0.8482 - val_accuracy: 0.3333\n",
            "Epoch 354/1000\n",
            "594/594 [==============================] - 0s 41us/sample - loss: 0.6019 - accuracy: 0.6768 - val_loss: 0.8550 - val_accuracy: 0.3333\n",
            "Epoch 355/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6014 - accuracy: 0.6785 - val_loss: 0.8533 - val_accuracy: 0.3333\n",
            "Epoch 356/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6013 - accuracy: 0.6776 - val_loss: 0.8517 - val_accuracy: 0.3333\n",
            "Epoch 357/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6011 - accuracy: 0.6785 - val_loss: 0.8492 - val_accuracy: 0.3333\n",
            "Epoch 358/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6018 - accuracy: 0.6751 - val_loss: 0.8398 - val_accuracy: 0.3333\n",
            "Epoch 359/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6010 - accuracy: 0.6793 - val_loss: 0.8474 - val_accuracy: 0.3333\n",
            "Epoch 360/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6013 - accuracy: 0.6717 - val_loss: 0.8543 - val_accuracy: 0.3333\n",
            "Epoch 361/1000\n",
            "594/594 [==============================] - 0s 34us/sample - loss: 0.6008 - accuracy: 0.6751 - val_loss: 0.8532 - val_accuracy: 0.3333\n",
            "Epoch 362/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6005 - accuracy: 0.6768 - val_loss: 0.8493 - val_accuracy: 0.3333\n",
            "Epoch 363/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6006 - accuracy: 0.6742 - val_loss: 0.8431 - val_accuracy: 0.3333\n",
            "Epoch 364/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6004 - accuracy: 0.6785 - val_loss: 0.8411 - val_accuracy: 0.3333\n",
            "Epoch 365/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6002 - accuracy: 0.6785 - val_loss: 0.8439 - val_accuracy: 0.3333\n",
            "Epoch 366/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6000 - accuracy: 0.6759 - val_loss: 0.8447 - val_accuracy: 0.3333\n",
            "Epoch 367/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6006 - accuracy: 0.6759 - val_loss: 0.8376 - val_accuracy: 0.3333\n",
            "Epoch 368/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.5999 - accuracy: 0.6801 - val_loss: 0.8440 - val_accuracy: 0.3333\n",
            "Epoch 369/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6005 - accuracy: 0.6726 - val_loss: 0.8550 - val_accuracy: 0.3333\n",
            "Epoch 370/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5998 - accuracy: 0.6776 - val_loss: 0.8541 - val_accuracy: 0.3333\n",
            "Epoch 371/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.5995 - accuracy: 0.6759 - val_loss: 0.8469 - val_accuracy: 0.3333\n",
            "Epoch 372/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5994 - accuracy: 0.6751 - val_loss: 0.8447 - val_accuracy: 0.3333\n",
            "Epoch 373/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5993 - accuracy: 0.6801 - val_loss: 0.8487 - val_accuracy: 0.3333\n",
            "Epoch 374/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5991 - accuracy: 0.6751 - val_loss: 0.8452 - val_accuracy: 0.3333\n",
            "Epoch 375/1000\n",
            "297/594 [==============>...............] - ETA: 0s - loss: 0.6017 - accuracy: 0.6667\n",
            "Epoch 00375: ReduceLROnPlateau reducing learning rate to 0.0625.\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5992 - accuracy: 0.6742 - val_loss: 0.8508 - val_accuracy: 0.3333\n",
            "Epoch 376/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5988 - accuracy: 0.6751 - val_loss: 0.8493 - val_accuracy: 0.3333\n",
            "Epoch 377/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5988 - accuracy: 0.6751 - val_loss: 0.8486 - val_accuracy: 0.3333\n",
            "Epoch 378/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5987 - accuracy: 0.6751 - val_loss: 0.8478 - val_accuracy: 0.3333\n",
            "Epoch 379/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5991 - accuracy: 0.6751 - val_loss: 0.8498 - val_accuracy: 0.3333\n",
            "Epoch 380/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5987 - accuracy: 0.6726 - val_loss: 0.8464 - val_accuracy: 0.3333\n",
            "Epoch 381/1000\n",
            "594/594 [==============================] - 0s 36us/sample - loss: 0.5987 - accuracy: 0.6751 - val_loss: 0.8444 - val_accuracy: 0.3333\n",
            "Epoch 382/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5984 - accuracy: 0.6768 - val_loss: 0.8449 - val_accuracy: 0.3333\n",
            "Epoch 383/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5989 - accuracy: 0.6751 - val_loss: 0.8418 - val_accuracy: 0.3333\n",
            "Epoch 384/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5989 - accuracy: 0.6759 - val_loss: 0.8402 - val_accuracy: 0.3333\n",
            "Epoch 385/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.5983 - accuracy: 0.6785 - val_loss: 0.8407 - val_accuracy: 0.3333\n",
            "Epoch 386/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5984 - accuracy: 0.6768 - val_loss: 0.8406 - val_accuracy: 0.3333\n",
            "Epoch 387/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.5981 - accuracy: 0.6785 - val_loss: 0.8428 - val_accuracy: 0.3333\n",
            "Epoch 388/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.5980 - accuracy: 0.6793 - val_loss: 0.8437 - val_accuracy: 0.3333\n",
            "Epoch 389/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.5986 - accuracy: 0.6742 - val_loss: 0.8409 - val_accuracy: 0.3333\n",
            "Epoch 390/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5980 - accuracy: 0.6768 - val_loss: 0.8413 - val_accuracy: 0.3333\n",
            "Epoch 391/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5979 - accuracy: 0.6768 - val_loss: 0.8434 - val_accuracy: 0.3333\n",
            "Epoch 392/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5980 - accuracy: 0.6742 - val_loss: 0.8461 - val_accuracy: 0.3333\n",
            "Epoch 393/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5982 - accuracy: 0.6793 - val_loss: 0.8429 - val_accuracy: 0.3333\n",
            "Epoch 394/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5977 - accuracy: 0.6793 - val_loss: 0.8442 - val_accuracy: 0.3333\n",
            "Epoch 395/1000\n",
            "594/594 [==============================] - 0s 34us/sample - loss: 0.5982 - accuracy: 0.6726 - val_loss: 0.8479 - val_accuracy: 0.3333\n",
            "Epoch 396/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.5976 - accuracy: 0.6751 - val_loss: 0.8480 - val_accuracy: 0.3333\n",
            "Epoch 397/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.5975 - accuracy: 0.6759 - val_loss: 0.8479 - val_accuracy: 0.3333\n",
            "Epoch 398/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5977 - accuracy: 0.6742 - val_loss: 0.8447 - val_accuracy: 0.3333\n",
            "Epoch 399/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.5974 - accuracy: 0.6759 - val_loss: 0.8436 - val_accuracy: 0.3333\n",
            "Epoch 400/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5972 - accuracy: 0.6768 - val_loss: 0.8433 - val_accuracy: 0.3333\n",
            "Epoch 401/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5973 - accuracy: 0.6793 - val_loss: 0.8420 - val_accuracy: 0.3333\n",
            "Epoch 402/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5972 - accuracy: 0.6785 - val_loss: 0.8448 - val_accuracy: 0.3333\n",
            "Epoch 403/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5970 - accuracy: 0.6785 - val_loss: 0.8449 - val_accuracy: 0.3333\n",
            "Epoch 404/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5972 - accuracy: 0.6742 - val_loss: 0.8428 - val_accuracy: 0.3333\n",
            "Epoch 405/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5969 - accuracy: 0.6776 - val_loss: 0.8435 - val_accuracy: 0.3333\n",
            "Epoch 406/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5969 - accuracy: 0.6801 - val_loss: 0.8436 - val_accuracy: 0.3333\n",
            "Epoch 407/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5968 - accuracy: 0.6785 - val_loss: 0.8452 - val_accuracy: 0.3333\n",
            "Epoch 408/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5967 - accuracy: 0.6768 - val_loss: 0.8460 - val_accuracy: 0.3333\n",
            "Epoch 409/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5966 - accuracy: 0.6759 - val_loss: 0.8456 - val_accuracy: 0.3333\n",
            "Epoch 410/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5966 - accuracy: 0.6751 - val_loss: 0.8446 - val_accuracy: 0.3333\n",
            "Epoch 411/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5967 - accuracy: 0.6776 - val_loss: 0.8467 - val_accuracy: 0.3333\n",
            "Epoch 412/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5964 - accuracy: 0.6751 - val_loss: 0.8455 - val_accuracy: 0.3333\n",
            "Epoch 413/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.5964 - accuracy: 0.6751 - val_loss: 0.8449 - val_accuracy: 0.3333\n",
            "Epoch 414/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.5978 - accuracy: 0.6742 - val_loss: 0.8503 - val_accuracy: 0.3333\n",
            "Epoch 415/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5962 - accuracy: 0.6751 - val_loss: 0.8483 - val_accuracy: 0.3333\n",
            "Epoch 416/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5962 - accuracy: 0.6742 - val_loss: 0.8464 - val_accuracy: 0.3333\n",
            "Epoch 417/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5972 - accuracy: 0.6734 - val_loss: 0.8503 - val_accuracy: 0.3333\n",
            "Epoch 418/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5960 - accuracy: 0.6768 - val_loss: 0.8495 - val_accuracy: 0.3333\n",
            "Epoch 419/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5967 - accuracy: 0.6759 - val_loss: 0.8517 - val_accuracy: 0.3333\n",
            "Epoch 420/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5962 - accuracy: 0.6759 - val_loss: 0.8468 - val_accuracy: 0.3333\n",
            "Epoch 421/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5959 - accuracy: 0.6751 - val_loss: 0.8454 - val_accuracy: 0.3333\n",
            "Epoch 422/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5958 - accuracy: 0.6776 - val_loss: 0.8448 - val_accuracy: 0.3333\n",
            "Epoch 423/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5957 - accuracy: 0.6768 - val_loss: 0.8451 - val_accuracy: 0.3333\n",
            "Epoch 424/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5956 - accuracy: 0.6759 - val_loss: 0.8448 - val_accuracy: 0.3333\n",
            "Epoch 425/1000\n",
            "297/594 [==============>...............] - ETA: 0s - loss: 0.6016 - accuracy: 0.6852\n",
            "Epoch 00425: ReduceLROnPlateau reducing learning rate to 0.03125.\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.5955 - accuracy: 0.6759 - val_loss: 0.8449 - val_accuracy: 0.3333\n",
            "Epoch 426/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.5954 - accuracy: 0.6776 - val_loss: 0.8447 - val_accuracy: 0.3333\n",
            "Epoch 427/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.5954 - accuracy: 0.6768 - val_loss: 0.8448 - val_accuracy: 0.3333\n",
            "Epoch 428/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.5954 - accuracy: 0.6751 - val_loss: 0.8444 - val_accuracy: 0.3333\n",
            "Epoch 429/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.5953 - accuracy: 0.6759 - val_loss: 0.8446 - val_accuracy: 0.3333\n",
            "Epoch 430/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5953 - accuracy: 0.6768 - val_loss: 0.8444 - val_accuracy: 0.3333\n",
            "Epoch 431/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.5955 - accuracy: 0.6776 - val_loss: 0.8453 - val_accuracy: 0.3333\n",
            "Epoch 432/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5952 - accuracy: 0.6768 - val_loss: 0.8454 - val_accuracy: 0.3333\n",
            "Epoch 433/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5952 - accuracy: 0.6768 - val_loss: 0.8455 - val_accuracy: 0.3333\n",
            "Epoch 434/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.5952 - accuracy: 0.6776 - val_loss: 0.8450 - val_accuracy: 0.3333\n",
            "Epoch 435/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5951 - accuracy: 0.6759 - val_loss: 0.8451 - val_accuracy: 0.3333\n",
            "Epoch 436/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5950 - accuracy: 0.6759 - val_loss: 0.8452 - val_accuracy: 0.3333\n",
            "Epoch 437/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5953 - accuracy: 0.6734 - val_loss: 0.8443 - val_accuracy: 0.3333\n",
            "Epoch 438/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.5952 - accuracy: 0.6759 - val_loss: 0.8452 - val_accuracy: 0.3333\n",
            "Epoch 439/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5951 - accuracy: 0.6751 - val_loss: 0.8458 - val_accuracy: 0.3333\n",
            "Epoch 440/1000\n",
            "594/594 [==============================] - 0s 35us/sample - loss: 0.5949 - accuracy: 0.6751 - val_loss: 0.8461 - val_accuracy: 0.3333\n",
            "Epoch 441/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.5948 - accuracy: 0.6759 - val_loss: 0.8458 - val_accuracy: 0.3333\n",
            "Epoch 442/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5948 - accuracy: 0.6751 - val_loss: 0.8457 - val_accuracy: 0.3333\n",
            "Epoch 443/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5949 - accuracy: 0.6726 - val_loss: 0.8449 - val_accuracy: 0.3333\n",
            "Epoch 444/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5947 - accuracy: 0.6768 - val_loss: 0.8449 - val_accuracy: 0.3333\n",
            "Epoch 445/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5947 - accuracy: 0.6759 - val_loss: 0.8448 - val_accuracy: 0.3333\n",
            "Epoch 446/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5946 - accuracy: 0.6768 - val_loss: 0.8449 - val_accuracy: 0.3333\n",
            "Epoch 447/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5946 - accuracy: 0.6768 - val_loss: 0.8450 - val_accuracy: 0.3333\n",
            "Epoch 448/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5946 - accuracy: 0.6768 - val_loss: 0.8452 - val_accuracy: 0.3333\n",
            "Epoch 449/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.5946 - accuracy: 0.6751 - val_loss: 0.8450 - val_accuracy: 0.3333\n",
            "Epoch 450/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5945 - accuracy: 0.6768 - val_loss: 0.8455 - val_accuracy: 0.3333\n",
            "Epoch 451/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5947 - accuracy: 0.6759 - val_loss: 0.8447 - val_accuracy: 0.3333\n",
            "Epoch 452/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5944 - accuracy: 0.6768 - val_loss: 0.8451 - val_accuracy: 0.3333\n",
            "Epoch 453/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5944 - accuracy: 0.6751 - val_loss: 0.8448 - val_accuracy: 0.3333\n",
            "Epoch 454/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5943 - accuracy: 0.6768 - val_loss: 0.8451 - val_accuracy: 0.3333\n",
            "Epoch 455/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5943 - accuracy: 0.6768 - val_loss: 0.8455 - val_accuracy: 0.3333\n",
            "Epoch 456/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5943 - accuracy: 0.6742 - val_loss: 0.8452 - val_accuracy: 0.3333\n",
            "Epoch 457/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5942 - accuracy: 0.6768 - val_loss: 0.8454 - val_accuracy: 0.3333\n",
            "Epoch 458/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5942 - accuracy: 0.6734 - val_loss: 0.8451 - val_accuracy: 0.3333\n",
            "Epoch 459/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5942 - accuracy: 0.6768 - val_loss: 0.8456 - val_accuracy: 0.3333\n",
            "Epoch 460/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5943 - accuracy: 0.6742 - val_loss: 0.8450 - val_accuracy: 0.3333\n",
            "Epoch 461/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.5941 - accuracy: 0.6734 - val_loss: 0.8449 - val_accuracy: 0.3333\n",
            "Epoch 462/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5940 - accuracy: 0.6759 - val_loss: 0.8448 - val_accuracy: 0.3333\n",
            "Epoch 463/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5940 - accuracy: 0.6759 - val_loss: 0.8447 - val_accuracy: 0.3333\n",
            "Epoch 464/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.5939 - accuracy: 0.6759 - val_loss: 0.8451 - val_accuracy: 0.3333\n",
            "Epoch 465/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5942 - accuracy: 0.6726 - val_loss: 0.8444 - val_accuracy: 0.3333\n",
            "Epoch 466/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5939 - accuracy: 0.6759 - val_loss: 0.8446 - val_accuracy: 0.3333\n",
            "Epoch 467/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5939 - accuracy: 0.6734 - val_loss: 0.8447 - val_accuracy: 0.3333\n",
            "Epoch 468/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5938 - accuracy: 0.6768 - val_loss: 0.8452 - val_accuracy: 0.3333\n",
            "Epoch 469/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5939 - accuracy: 0.6759 - val_loss: 0.8456 - val_accuracy: 0.3333\n",
            "Epoch 470/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5937 - accuracy: 0.6742 - val_loss: 0.8460 - val_accuracy: 0.3333\n",
            "Epoch 471/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5937 - accuracy: 0.6742 - val_loss: 0.8461 - val_accuracy: 0.3333\n",
            "Epoch 472/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5936 - accuracy: 0.6734 - val_loss: 0.8459 - val_accuracy: 0.3333\n",
            "Epoch 473/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5936 - accuracy: 0.6726 - val_loss: 0.8465 - val_accuracy: 0.3333\n",
            "Epoch 474/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5936 - accuracy: 0.6709 - val_loss: 0.8460 - val_accuracy: 0.3333\n",
            "Epoch 475/1000\n",
            "297/594 [==============>...............] - ETA: 0s - loss: 0.5772 - accuracy: 0.6835\n",
            "Epoch 00475: ReduceLROnPlateau reducing learning rate to 0.015625.\n",
            "594/594 [==============================] - 0s 36us/sample - loss: 0.5936 - accuracy: 0.6709 - val_loss: 0.8457 - val_accuracy: 0.3333\n",
            "Epoch 476/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5935 - accuracy: 0.6734 - val_loss: 0.8459 - val_accuracy: 0.3333\n",
            "Epoch 477/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.5935 - accuracy: 0.6751 - val_loss: 0.8458 - val_accuracy: 0.3333\n",
            "Epoch 478/1000\n",
            "594/594 [==============================] - 0s 36us/sample - loss: 0.5934 - accuracy: 0.6734 - val_loss: 0.8460 - val_accuracy: 0.3333\n",
            "Epoch 479/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.5934 - accuracy: 0.6742 - val_loss: 0.8461 - val_accuracy: 0.3333\n",
            "Epoch 480/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5935 - accuracy: 0.6751 - val_loss: 0.8463 - val_accuracy: 0.3333\n",
            "Epoch 481/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5934 - accuracy: 0.6742 - val_loss: 0.8463 - val_accuracy: 0.3333\n",
            "Epoch 482/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5933 - accuracy: 0.6734 - val_loss: 0.8464 - val_accuracy: 0.3333\n",
            "Epoch 483/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5933 - accuracy: 0.6726 - val_loss: 0.8464 - val_accuracy: 0.3333\n",
            "Epoch 484/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5933 - accuracy: 0.6751 - val_loss: 0.8466 - val_accuracy: 0.3333\n",
            "Epoch 485/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5934 - accuracy: 0.6700 - val_loss: 0.8464 - val_accuracy: 0.3333\n",
            "Epoch 486/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5932 - accuracy: 0.6717 - val_loss: 0.8464 - val_accuracy: 0.3333\n",
            "Epoch 487/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5932 - accuracy: 0.6717 - val_loss: 0.8464 - val_accuracy: 0.3333\n",
            "Epoch 488/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5933 - accuracy: 0.6742 - val_loss: 0.8465 - val_accuracy: 0.3333\n",
            "Epoch 489/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.5932 - accuracy: 0.6726 - val_loss: 0.8467 - val_accuracy: 0.3333\n",
            "Epoch 490/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5932 - accuracy: 0.6717 - val_loss: 0.8467 - val_accuracy: 0.3333\n",
            "Epoch 491/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5932 - accuracy: 0.6709 - val_loss: 0.8465 - val_accuracy: 0.3333\n",
            "Epoch 492/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5932 - accuracy: 0.6717 - val_loss: 0.8467 - val_accuracy: 0.3333\n",
            "Epoch 493/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5931 - accuracy: 0.6709 - val_loss: 0.8466 - val_accuracy: 0.3333\n",
            "Epoch 494/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5931 - accuracy: 0.6726 - val_loss: 0.8467 - val_accuracy: 0.3333\n",
            "Epoch 495/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.5931 - accuracy: 0.6717 - val_loss: 0.8466 - val_accuracy: 0.3333\n",
            "Epoch 496/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5930 - accuracy: 0.6726 - val_loss: 0.8466 - val_accuracy: 0.3333\n",
            "Epoch 497/1000\n",
            "594/594 [==============================] - 0s 33us/sample - loss: 0.5931 - accuracy: 0.6742 - val_loss: 0.8468 - val_accuracy: 0.3333\n",
            "Epoch 498/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5930 - accuracy: 0.6717 - val_loss: 0.8468 - val_accuracy: 0.3333\n",
            "Epoch 499/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.5930 - accuracy: 0.6717 - val_loss: 0.8468 - val_accuracy: 0.3333\n",
            "Epoch 500/1000\n",
            "594/594 [==============================] - 0s 36us/sample - loss: 0.5930 - accuracy: 0.6742 - val_loss: 0.8469 - val_accuracy: 0.3333\n",
            "Epoch 501/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5931 - accuracy: 0.6742 - val_loss: 0.8471 - val_accuracy: 0.3333\n",
            "Epoch 502/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5929 - accuracy: 0.6717 - val_loss: 0.8470 - val_accuracy: 0.3333\n",
            "Epoch 503/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5929 - accuracy: 0.6717 - val_loss: 0.8470 - val_accuracy: 0.3333\n",
            "Epoch 504/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5930 - accuracy: 0.6717 - val_loss: 0.8468 - val_accuracy: 0.3333\n",
            "Epoch 505/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5929 - accuracy: 0.6726 - val_loss: 0.8469 - val_accuracy: 0.3333\n",
            "Epoch 506/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.5930 - accuracy: 0.6692 - val_loss: 0.8467 - val_accuracy: 0.3333\n",
            "Epoch 507/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5928 - accuracy: 0.6709 - val_loss: 0.8467 - val_accuracy: 0.3333\n",
            "Epoch 508/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5928 - accuracy: 0.6717 - val_loss: 0.8467 - val_accuracy: 0.3333\n",
            "Epoch 509/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5928 - accuracy: 0.6709 - val_loss: 0.8467 - val_accuracy: 0.3333\n",
            "Epoch 510/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5928 - accuracy: 0.6700 - val_loss: 0.8468 - val_accuracy: 0.3333\n",
            "Epoch 511/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5927 - accuracy: 0.6700 - val_loss: 0.8467 - val_accuracy: 0.3333\n",
            "Epoch 512/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5927 - accuracy: 0.6700 - val_loss: 0.8468 - val_accuracy: 0.3333\n",
            "Epoch 513/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5928 - accuracy: 0.6726 - val_loss: 0.8470 - val_accuracy: 0.3333\n",
            "Epoch 514/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5927 - accuracy: 0.6684 - val_loss: 0.8469 - val_accuracy: 0.3333\n",
            "Epoch 515/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.5928 - accuracy: 0.6700 - val_loss: 0.8471 - val_accuracy: 0.3333\n",
            "Epoch 516/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5927 - accuracy: 0.6717 - val_loss: 0.8473 - val_accuracy: 0.3333\n",
            "Epoch 517/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5926 - accuracy: 0.6700 - val_loss: 0.8473 - val_accuracy: 0.3333\n",
            "Epoch 518/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5930 - accuracy: 0.6734 - val_loss: 0.8477 - val_accuracy: 0.3333\n",
            "Epoch 519/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5926 - accuracy: 0.6692 - val_loss: 0.8475 - val_accuracy: 0.3333\n",
            "Epoch 520/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5926 - accuracy: 0.6700 - val_loss: 0.8474 - val_accuracy: 0.3333\n",
            "Epoch 521/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.5925 - accuracy: 0.6684 - val_loss: 0.8473 - val_accuracy: 0.3333\n",
            "Epoch 522/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5925 - accuracy: 0.6692 - val_loss: 0.8473 - val_accuracy: 0.3333\n",
            "Epoch 523/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5925 - accuracy: 0.6709 - val_loss: 0.8474 - val_accuracy: 0.3333\n",
            "Epoch 524/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.5925 - accuracy: 0.6726 - val_loss: 0.8475 - val_accuracy: 0.3333\n",
            "Epoch 525/1000\n",
            "297/594 [==============>...............] - ETA: 0s - loss: 0.6004 - accuracy: 0.6717\n",
            "Epoch 00525: ReduceLROnPlateau reducing learning rate to 0.0078125.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.5924 - accuracy: 0.6692 - val_loss: 0.8474 - val_accuracy: 0.3333\n",
            "Epoch 00525: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAGFCAYAAADAc+UQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-1gJ7X5n3k5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3bdd8b52-e20c-4e10-f94b-1e2beb8dcbbc"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "mlp = Sequential()\n",
        "mlp.add(Dense(16, input_dim=2, activation='relu'))\n",
        "mlp.add(Dense(16, activation='relu'))\n",
        "mlp.add(Dense(16, activation='relu'))\n",
        "mlp.add(Dense(2, activation='sigmoid'))\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(factor=0.5, monitor='accuracy',\n",
        "                              patience=50, min_lr=0.00000001,\n",
        "                              verbose = 1)\n",
        "\n",
        "stop_save = EarlyStopping(patience=200, monitor='accuracy',\n",
        "                          verbose=1, \n",
        "                          restore_best_weights=True)\n",
        "\n",
        "# All parameter gradients will be clipped to\n",
        "# a maximum norm of 1.\n",
        "sgd = optimizers.SGD(lr=1., clipnorm=1.)\n",
        "\n",
        "mlp.compile(loss='binary_crossentropy',\n",
        "            optimizer=sgd,\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "# trains the model\n",
        "mlp.fit(X, yv, epochs=1000, batch_size=297,\n",
        "        verbose=1, callbacks=[reduce_lr, stop_save], \n",
        "        validation_split = 0.01)\n",
        "\n",
        "y_pred = mlp.predict(X)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
        "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n",
        "                     np.arange(y_min, y_max, 0.02))\n",
        "Z = None\n",
        "Z = mlp.predict(np.c_[xx.ravel(), yy.ravel()])[:,1]\n",
        "Z = Z.reshape(xx.shape)\n",
        "cm = plt.cm.bwr\n",
        "\n",
        "fig = plt.figure(figsize=(6,6))\n",
        "\n",
        "plt.contourf(xx, yy, Z, cmap=cm, alpha=.25)\n",
        "\n",
        "plt.plot(X[1,0],X[1,1],'+', color='#648fff', label='Positive Class')\n",
        "plt.plot(X[2,1],X[2,1],'_', color='#fe6100', label='Negative Class')\n",
        "\n",
        "for i in range(len(y)):\n",
        "  x1 = X[i,0]\n",
        "  x2 = X[i,1]\n",
        "  if y[i]==1: \n",
        "    if (y_pred[i] == 0):\n",
        "      plt.plot(x1,x2,'+', color='#648fff')\n",
        "    else:\n",
        "      plt.plot(x1,x2,'k.', alpha=0.25)\n",
        "  else:\n",
        "    if (y_pred[i] == 1):\n",
        "      plt.plot(x1,x2,'_', color='#fe6100')\n",
        "    else:\n",
        "      plt.plot(x1,x2,'k.', alpha=0.25)\n",
        "\n",
        "accuracy = np.sum(np.equal(y_pred,y_actual))/len(y_actual)\n",
        "\n",
        "plt.axis('tight')\n",
        "plt.xlim(min(X[:,0])-0.1, max(X[:,0])+0.1)\n",
        "plt.ylim(min(X[:,1])-0.1, max(X[:,1])+0.1)\n",
        "plt.xlabel('$x_1$')\n",
        "plt.ylabel('$x_2$')\n",
        "plt.legend()\n",
        "plt.title('Keras-based 4-layer MLP on spiral dataset. Accuracy: {:04.3}'.format(accuracy))\n",
        "plt.savefig('ch.6.MLP.keras.deep.h.spirals.png', dpi=350, bbox_inches='tight')\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 594 samples, validate on 6 samples\n",
            "Epoch 1/1000\n",
            "594/594 [==============================] - 0s 452us/sample - loss: 0.6923 - accuracy: 0.5219 - val_loss: 0.6769 - val_accuracy: 0.7500\n",
            "Epoch 2/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6857 - accuracy: 0.5244 - val_loss: 0.6730 - val_accuracy: 0.5833\n",
            "Epoch 3/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6805 - accuracy: 0.5421 - val_loss: 0.6818 - val_accuracy: 0.4167\n",
            "Epoch 4/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6756 - accuracy: 0.5513 - val_loss: 0.6872 - val_accuracy: 0.3333\n",
            "Epoch 5/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6721 - accuracy: 0.5926 - val_loss: 0.6753 - val_accuracy: 0.3333\n",
            "Epoch 6/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6655 - accuracy: 0.6077 - val_loss: 0.6994 - val_accuracy: 0.3333\n",
            "Epoch 7/1000\n",
            "594/594 [==============================] - 0s 33us/sample - loss: 0.6603 - accuracy: 0.6120 - val_loss: 0.7333 - val_accuracy: 0.2500\n",
            "Epoch 8/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6546 - accuracy: 0.6195 - val_loss: 0.7492 - val_accuracy: 0.1667\n",
            "Epoch 9/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6493 - accuracy: 0.6221 - val_loss: 0.7419 - val_accuracy: 0.3333\n",
            "Epoch 10/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6452 - accuracy: 0.6128 - val_loss: 0.7978 - val_accuracy: 0.1667\n",
            "Epoch 11/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6419 - accuracy: 0.6263 - val_loss: 0.7604 - val_accuracy: 0.3333\n",
            "Epoch 12/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6392 - accuracy: 0.6237 - val_loss: 0.8090 - val_accuracy: 0.1667\n",
            "Epoch 13/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6404 - accuracy: 0.6187 - val_loss: 0.9077 - val_accuracy: 0.1667\n",
            "Epoch 14/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6373 - accuracy: 0.6406 - val_loss: 0.8333 - val_accuracy: 0.1667\n",
            "Epoch 15/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6329 - accuracy: 0.6389 - val_loss: 0.8236 - val_accuracy: 0.1667\n",
            "Epoch 16/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6314 - accuracy: 0.6288 - val_loss: 0.8908 - val_accuracy: 0.1667\n",
            "Epoch 17/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6327 - accuracy: 0.6397 - val_loss: 0.8993 - val_accuracy: 0.1667\n",
            "Epoch 18/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6298 - accuracy: 0.6347 - val_loss: 0.9174 - val_accuracy: 0.1667\n",
            "Epoch 19/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6281 - accuracy: 0.6330 - val_loss: 0.8907 - val_accuracy: 0.1667\n",
            "Epoch 20/1000\n",
            "594/594 [==============================] - 0s 34us/sample - loss: 0.6265 - accuracy: 0.6389 - val_loss: 0.8240 - val_accuracy: 0.3333\n",
            "Epoch 21/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6253 - accuracy: 0.6364 - val_loss: 0.8141 - val_accuracy: 0.3333\n",
            "Epoch 22/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6230 - accuracy: 0.6448 - val_loss: 0.8738 - val_accuracy: 0.1667\n",
            "Epoch 23/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6226 - accuracy: 0.6423 - val_loss: 0.9207 - val_accuracy: 0.1667\n",
            "Epoch 24/1000\n",
            "594/594 [==============================] - 0s 36us/sample - loss: 0.6212 - accuracy: 0.6498 - val_loss: 0.7646 - val_accuracy: 0.3333\n",
            "Epoch 25/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6224 - accuracy: 0.6355 - val_loss: 0.8485 - val_accuracy: 0.2500\n",
            "Epoch 26/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6200 - accuracy: 0.6473 - val_loss: 0.9672 - val_accuracy: 0.1667\n",
            "Epoch 27/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6240 - accuracy: 0.6364 - val_loss: 0.9369 - val_accuracy: 0.1667\n",
            "Epoch 28/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6194 - accuracy: 0.6389 - val_loss: 0.9082 - val_accuracy: 0.1667\n",
            "Epoch 29/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6201 - accuracy: 0.6423 - val_loss: 0.9673 - val_accuracy: 0.1667\n",
            "Epoch 30/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6408 - accuracy: 0.6305 - val_loss: 1.1310 - val_accuracy: 0.0833\n",
            "Epoch 31/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6329 - accuracy: 0.6372 - val_loss: 0.8873 - val_accuracy: 0.1667\n",
            "Epoch 32/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6158 - accuracy: 0.6582 - val_loss: 0.8257 - val_accuracy: 0.3333\n",
            "Epoch 33/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6185 - accuracy: 0.6549 - val_loss: 0.7613 - val_accuracy: 0.6667\n",
            "Epoch 34/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6221 - accuracy: 0.6372 - val_loss: 0.7529 - val_accuracy: 0.6667\n",
            "Epoch 35/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6206 - accuracy: 0.6456 - val_loss: 0.8619 - val_accuracy: 0.2500\n",
            "Epoch 36/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6116 - accuracy: 0.6633 - val_loss: 0.8332 - val_accuracy: 0.5833\n",
            "Epoch 37/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6168 - accuracy: 0.6608 - val_loss: 0.7321 - val_accuracy: 0.6667\n",
            "Epoch 38/1000\n",
            "594/594 [==============================] - 0s 37us/sample - loss: 0.6324 - accuracy: 0.6254 - val_loss: 0.7388 - val_accuracy: 0.6667\n",
            "Epoch 39/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6105 - accuracy: 0.6532 - val_loss: 0.9073 - val_accuracy: 0.5000\n",
            "Epoch 40/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6073 - accuracy: 0.6675 - val_loss: 0.8092 - val_accuracy: 0.6667\n",
            "Epoch 41/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6063 - accuracy: 0.6793 - val_loss: 0.9094 - val_accuracy: 0.5000\n",
            "Epoch 42/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6097 - accuracy: 0.6591 - val_loss: 0.9581 - val_accuracy: 0.2500\n",
            "Epoch 43/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6082 - accuracy: 0.6515 - val_loss: 0.9298 - val_accuracy: 0.5000\n",
            "Epoch 44/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6056 - accuracy: 0.6742 - val_loss: 0.9060 - val_accuracy: 0.5000\n",
            "Epoch 45/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6100 - accuracy: 0.6751 - val_loss: 0.9699 - val_accuracy: 0.5000\n",
            "Epoch 46/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6048 - accuracy: 0.6818 - val_loss: 0.8785 - val_accuracy: 0.5000\n",
            "Epoch 47/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6032 - accuracy: 0.6717 - val_loss: 0.9250 - val_accuracy: 0.5000\n",
            "Epoch 48/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6067 - accuracy: 0.6726 - val_loss: 0.9920 - val_accuracy: 0.4167\n",
            "Epoch 49/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6093 - accuracy: 0.6726 - val_loss: 0.9197 - val_accuracy: 0.5000\n",
            "Epoch 50/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5978 - accuracy: 0.6835 - val_loss: 0.7824 - val_accuracy: 0.6667\n",
            "Epoch 51/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6005 - accuracy: 0.6734 - val_loss: 0.7578 - val_accuracy: 0.6667\n",
            "Epoch 52/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6043 - accuracy: 0.6456 - val_loss: 0.7406 - val_accuracy: 0.6667\n",
            "Epoch 53/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6023 - accuracy: 0.6751 - val_loss: 0.7439 - val_accuracy: 0.6667\n",
            "Epoch 54/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.5951 - accuracy: 0.6818 - val_loss: 0.8862 - val_accuracy: 0.3333\n",
            "Epoch 55/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5919 - accuracy: 0.6768 - val_loss: 0.8118 - val_accuracy: 0.6667\n",
            "Epoch 56/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5944 - accuracy: 0.6717 - val_loss: 0.7820 - val_accuracy: 0.6667\n",
            "Epoch 57/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6066 - accuracy: 0.6641 - val_loss: 0.6187 - val_accuracy: 0.6667\n",
            "Epoch 58/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6286 - accuracy: 0.6481 - val_loss: 0.6963 - val_accuracy: 0.6667\n",
            "Epoch 59/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6159 - accuracy: 0.6406 - val_loss: 0.6843 - val_accuracy: 0.6667\n",
            "Epoch 60/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5926 - accuracy: 0.6700 - val_loss: 0.8505 - val_accuracy: 0.5000\n",
            "Epoch 61/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.5935 - accuracy: 0.6827 - val_loss: 0.8666 - val_accuracy: 0.3333\n",
            "Epoch 62/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5887 - accuracy: 0.6751 - val_loss: 0.8352 - val_accuracy: 0.5000\n",
            "Epoch 63/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5884 - accuracy: 0.6751 - val_loss: 0.9193 - val_accuracy: 0.3333\n",
            "Epoch 64/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5893 - accuracy: 0.6751 - val_loss: 0.8801 - val_accuracy: 0.3333\n",
            "Epoch 65/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.5854 - accuracy: 0.6768 - val_loss: 0.8960 - val_accuracy: 0.3333\n",
            "Epoch 66/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5922 - accuracy: 0.6591 - val_loss: 1.0374 - val_accuracy: 0.3333\n",
            "Epoch 67/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6230 - accuracy: 0.6389 - val_loss: 1.0036 - val_accuracy: 0.0000e+00\n",
            "Epoch 68/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5913 - accuracy: 0.6279 - val_loss: 0.7949 - val_accuracy: 0.5000\n",
            "Epoch 69/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5832 - accuracy: 0.6633 - val_loss: 0.7402 - val_accuracy: 0.6667\n",
            "Epoch 70/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.5786 - accuracy: 0.6818 - val_loss: 0.7385 - val_accuracy: 0.6667\n",
            "Epoch 71/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.5819 - accuracy: 0.6759 - val_loss: 0.6767 - val_accuracy: 0.6667\n",
            "Epoch 72/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5997 - accuracy: 0.6667 - val_loss: 0.6189 - val_accuracy: 0.6667\n",
            "Epoch 73/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5835 - accuracy: 0.6785 - val_loss: 0.7807 - val_accuracy: 0.5000\n",
            "Epoch 74/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5739 - accuracy: 0.6700 - val_loss: 0.8996 - val_accuracy: 0.3333\n",
            "Epoch 75/1000\n",
            "594/594 [==============================] - 0s 33us/sample - loss: 0.5815 - accuracy: 0.6616 - val_loss: 0.9902 - val_accuracy: 0.3333\n",
            "Epoch 76/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6410 - accuracy: 0.6397 - val_loss: 1.0551 - val_accuracy: 0.0000e+00\n",
            "Epoch 77/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6026 - accuracy: 0.6389 - val_loss: 0.8434 - val_accuracy: 0.3333\n",
            "Epoch 78/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5779 - accuracy: 0.6726 - val_loss: 0.8659 - val_accuracy: 0.3333\n",
            "Epoch 79/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5729 - accuracy: 0.6759 - val_loss: 0.7340 - val_accuracy: 0.5000\n",
            "Epoch 80/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.5650 - accuracy: 0.6734 - val_loss: 0.7162 - val_accuracy: 0.6667\n",
            "Epoch 81/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5684 - accuracy: 0.6877 - val_loss: 0.7230 - val_accuracy: 0.5833\n",
            "Epoch 82/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.5683 - accuracy: 0.6776 - val_loss: 0.8240 - val_accuracy: 0.5000\n",
            "Epoch 83/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5681 - accuracy: 0.6692 - val_loss: 1.0476 - val_accuracy: 0.3333\n",
            "Epoch 84/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6515 - accuracy: 0.5951 - val_loss: 0.9849 - val_accuracy: 0.0000e+00\n",
            "Epoch 85/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5917 - accuracy: 0.6481 - val_loss: 0.8225 - val_accuracy: 0.3333\n",
            "Epoch 86/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5572 - accuracy: 0.6650 - val_loss: 0.7773 - val_accuracy: 0.5000\n",
            "Epoch 87/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5527 - accuracy: 0.6717 - val_loss: 0.7260 - val_accuracy: 0.5000\n",
            "Epoch 88/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5577 - accuracy: 0.6709 - val_loss: 0.7025 - val_accuracy: 0.5000\n",
            "Epoch 89/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5757 - accuracy: 0.6684 - val_loss: 0.6268 - val_accuracy: 0.6667\n",
            "Epoch 90/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5895 - accuracy: 0.6625 - val_loss: 0.6597 - val_accuracy: 0.5000\n",
            "Epoch 91/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5564 - accuracy: 0.6793 - val_loss: 0.6586 - val_accuracy: 0.5000\n",
            "Epoch 92/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5680 - accuracy: 0.6700 - val_loss: 0.5889 - val_accuracy: 0.5000\n",
            "Epoch 93/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5979 - accuracy: 0.6423 - val_loss: 0.6191 - val_accuracy: 0.5000\n",
            "Epoch 94/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.5611 - accuracy: 0.6742 - val_loss: 0.6492 - val_accuracy: 0.5000\n",
            "Epoch 95/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5418 - accuracy: 0.6397 - val_loss: 0.6467 - val_accuracy: 0.5000\n",
            "Epoch 96/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.5518 - accuracy: 0.6684 - val_loss: 0.5805 - val_accuracy: 0.5000\n",
            "Epoch 97/1000\n",
            "594/594 [==============================] - 0s 35us/sample - loss: 0.5707 - accuracy: 0.6465 - val_loss: 0.5961 - val_accuracy: 0.5833\n",
            "Epoch 98/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.5563 - accuracy: 0.6608 - val_loss: 0.6303 - val_accuracy: 0.5833\n",
            "Epoch 99/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5532 - accuracy: 0.6667 - val_loss: 0.5842 - val_accuracy: 0.6667\n",
            "Epoch 100/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5421 - accuracy: 0.6658 - val_loss: 0.6460 - val_accuracy: 0.1667\n",
            "Epoch 101/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5401 - accuracy: 0.6372 - val_loss: 0.6045 - val_accuracy: 0.3333\n",
            "Epoch 102/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5942 - accuracy: 0.6111 - val_loss: 0.5710 - val_accuracy: 0.8333\n",
            "Epoch 103/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5963 - accuracy: 0.6052 - val_loss: 0.6329 - val_accuracy: 0.3333\n",
            "Epoch 104/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5440 - accuracy: 0.6406 - val_loss: 0.6716 - val_accuracy: 0.5833\n",
            "Epoch 105/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5070 - accuracy: 0.6608 - val_loss: 0.6515 - val_accuracy: 0.6667\n",
            "Epoch 106/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4763 - accuracy: 0.7029 - val_loss: 0.7688 - val_accuracy: 0.5833\n",
            "Epoch 107/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4793 - accuracy: 0.7214 - val_loss: 0.7188 - val_accuracy: 0.5833\n",
            "Epoch 108/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5087 - accuracy: 0.7003 - val_loss: 0.7742 - val_accuracy: 0.1667\n",
            "Epoch 109/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4602 - accuracy: 0.6987 - val_loss: 0.6951 - val_accuracy: 0.3333\n",
            "Epoch 110/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4575 - accuracy: 0.7357 - val_loss: 0.7442 - val_accuracy: 0.5000\n",
            "Epoch 111/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5777 - accuracy: 0.6296 - val_loss: 0.6521 - val_accuracy: 0.5000\n",
            "Epoch 112/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5997 - accuracy: 0.5505 - val_loss: 0.8481 - val_accuracy: 0.8333\n",
            "Epoch 113/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5381 - accuracy: 0.6751 - val_loss: 0.6826 - val_accuracy: 0.6667\n",
            "Epoch 114/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.4726 - accuracy: 0.7138 - val_loss: 0.5951 - val_accuracy: 0.8333\n",
            "Epoch 115/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4845 - accuracy: 0.7239 - val_loss: 0.7356 - val_accuracy: 0.7500\n",
            "Epoch 116/1000\n",
            "594/594 [==============================] - 0s 33us/sample - loss: 0.4621 - accuracy: 0.7433 - val_loss: 0.7130 - val_accuracy: 0.7500\n",
            "Epoch 117/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5688 - accuracy: 0.6953 - val_loss: 0.8695 - val_accuracy: 0.8333\n",
            "Epoch 118/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6262 - accuracy: 0.5648 - val_loss: 0.7322 - val_accuracy: 0.5000\n",
            "Epoch 119/1000\n",
            "594/594 [==============================] - 0s 37us/sample - loss: 0.5243 - accuracy: 0.6751 - val_loss: 0.6805 - val_accuracy: 0.5000\n",
            "Epoch 120/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4838 - accuracy: 0.7416 - val_loss: 0.6963 - val_accuracy: 0.5000\n",
            "Epoch 121/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5635 - accuracy: 0.6684 - val_loss: 0.6711 - val_accuracy: 0.3333\n",
            "Epoch 122/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4930 - accuracy: 0.6751 - val_loss: 0.5372 - val_accuracy: 1.0000\n",
            "Epoch 123/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5737 - accuracy: 0.6557 - val_loss: 0.5724 - val_accuracy: 1.0000\n",
            "Epoch 124/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4302 - accuracy: 0.7652 - val_loss: 0.5510 - val_accuracy: 1.0000\n",
            "Epoch 125/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4730 - accuracy: 0.7273 - val_loss: 0.6250 - val_accuracy: 1.0000\n",
            "Epoch 126/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5505 - accuracy: 0.6768 - val_loss: 0.7539 - val_accuracy: 0.1667\n",
            "Epoch 127/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4935 - accuracy: 0.6953 - val_loss: 0.7168 - val_accuracy: 0.1667\n",
            "Epoch 128/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4513 - accuracy: 0.7433 - val_loss: 0.6257 - val_accuracy: 0.5000\n",
            "Epoch 129/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.4120 - accuracy: 0.7938 - val_loss: 0.6079 - val_accuracy: 0.5833\n",
            "Epoch 130/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.4074 - accuracy: 0.7997 - val_loss: 0.7783 - val_accuracy: 0.3333\n",
            "Epoch 131/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.4077 - accuracy: 0.8089 - val_loss: 0.7375 - val_accuracy: 0.5833\n",
            "Epoch 132/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4083 - accuracy: 0.7786 - val_loss: 0.7525 - val_accuracy: 0.7500\n",
            "Epoch 133/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.4186 - accuracy: 0.7971 - val_loss: 0.7911 - val_accuracy: 0.4167\n",
            "Epoch 134/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4708 - accuracy: 0.7424 - val_loss: 0.8533 - val_accuracy: 0.5000\n",
            "Epoch 135/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.4283 - accuracy: 0.7542 - val_loss: 0.6878 - val_accuracy: 0.5000\n",
            "Epoch 136/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.4909 - accuracy: 0.6970 - val_loss: 0.5856 - val_accuracy: 0.5000\n",
            "Epoch 137/1000\n",
            "594/594 [==============================] - 0s 33us/sample - loss: 0.3839 - accuracy: 0.8072 - val_loss: 0.5906 - val_accuracy: 0.6667\n",
            "Epoch 138/1000\n",
            "594/594 [==============================] - 0s 35us/sample - loss: 0.3805 - accuracy: 0.8039 - val_loss: 0.6860 - val_accuracy: 0.5000\n",
            "Epoch 139/1000\n",
            "594/594 [==============================] - 0s 34us/sample - loss: 0.4492 - accuracy: 0.7609 - val_loss: 1.1917 - val_accuracy: 0.5000\n",
            "Epoch 140/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.7866 - accuracy: 0.4184 - val_loss: 0.6316 - val_accuracy: 0.9167\n",
            "Epoch 141/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.7103 - accuracy: 0.4377 - val_loss: 0.7646 - val_accuracy: 0.5833\n",
            "Epoch 142/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6479 - accuracy: 0.5623 - val_loss: 0.5867 - val_accuracy: 1.0000\n",
            "Epoch 143/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6206 - accuracy: 0.6010 - val_loss: 0.5999 - val_accuracy: 1.0000\n",
            "Epoch 144/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6010 - accuracy: 0.6145 - val_loss: 0.5250 - val_accuracy: 1.0000\n",
            "Epoch 145/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5765 - accuracy: 0.6380 - val_loss: 0.5135 - val_accuracy: 1.0000\n",
            "Epoch 146/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5636 - accuracy: 0.6582 - val_loss: 0.4876 - val_accuracy: 1.0000\n",
            "Epoch 147/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5379 - accuracy: 0.6860 - val_loss: 0.4966 - val_accuracy: 1.0000\n",
            "Epoch 148/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.5290 - accuracy: 0.6835 - val_loss: 0.4636 - val_accuracy: 1.0000\n",
            "Epoch 149/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5272 - accuracy: 0.6886 - val_loss: 0.4597 - val_accuracy: 1.0000\n",
            "Epoch 150/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5107 - accuracy: 0.6928 - val_loss: 0.5167 - val_accuracy: 1.0000\n",
            "Epoch 151/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5043 - accuracy: 0.6944 - val_loss: 0.4640 - val_accuracy: 1.0000\n",
            "Epoch 152/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.4954 - accuracy: 0.6902 - val_loss: 0.5885 - val_accuracy: 0.8333\n",
            "Epoch 153/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4877 - accuracy: 0.6936 - val_loss: 0.5952 - val_accuracy: 0.6667\n",
            "Epoch 154/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.4785 - accuracy: 0.7088 - val_loss: 0.5848 - val_accuracy: 0.9167\n",
            "Epoch 155/1000\n",
            "594/594 [==============================] - 0s 36us/sample - loss: 0.4693 - accuracy: 0.6835 - val_loss: 0.6219 - val_accuracy: 0.5000\n",
            "Epoch 156/1000\n",
            "594/594 [==============================] - 0s 33us/sample - loss: 0.4561 - accuracy: 0.7214 - val_loss: 0.6866 - val_accuracy: 0.4167\n",
            "Epoch 157/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4566 - accuracy: 0.6911 - val_loss: 0.7267 - val_accuracy: 0.3333\n",
            "Epoch 158/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5128 - accuracy: 0.6953 - val_loss: 1.3806 - val_accuracy: 0.0000e+00\n",
            "Epoch 159/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.8611 - accuracy: 0.5370 - val_loss: 1.2685 - val_accuracy: 0.0000e+00\n",
            "Epoch 160/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6876 - accuracy: 0.5589 - val_loss: 0.9670 - val_accuracy: 0.0000e+00\n",
            "Epoch 161/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6223 - accuracy: 0.6465 - val_loss: 0.8775 - val_accuracy: 0.1667\n",
            "Epoch 162/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6021 - accuracy: 0.6532 - val_loss: 0.8947 - val_accuracy: 0.1667\n",
            "Epoch 163/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6104 - accuracy: 0.6288 - val_loss: 1.1501 - val_accuracy: 0.0000e+00\n",
            "Epoch 164/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6078 - accuracy: 0.6498 - val_loss: 0.8803 - val_accuracy: 0.1667\n",
            "Epoch 165/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5824 - accuracy: 0.6111 - val_loss: 0.9316 - val_accuracy: 0.1667\n",
            "Epoch 166/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5750 - accuracy: 0.6221 - val_loss: 1.0136 - val_accuracy: 0.0000e+00\n",
            "Epoch 167/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5891 - accuracy: 0.6473 - val_loss: 1.2343 - val_accuracy: 0.0000e+00\n",
            "Epoch 168/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6543 - accuracy: 0.6061 - val_loss: 1.2953 - val_accuracy: 0.0000e+00\n",
            "Epoch 169/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6137 - accuracy: 0.6431 - val_loss: 0.9785 - val_accuracy: 0.0000e+00\n",
            "Epoch 170/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5749 - accuracy: 0.6625 - val_loss: 0.9027 - val_accuracy: 0.1667\n",
            "Epoch 171/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5692 - accuracy: 0.6574 - val_loss: 0.9582 - val_accuracy: 0.0000e+00\n",
            "Epoch 172/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5772 - accuracy: 0.6549 - val_loss: 0.9377 - val_accuracy: 0.0000e+00\n",
            "Epoch 173/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5661 - accuracy: 0.6692 - val_loss: 0.9379 - val_accuracy: 0.0000e+00\n",
            "Epoch 174/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5714 - accuracy: 0.6481 - val_loss: 0.9723 - val_accuracy: 0.0000e+00\n",
            "Epoch 175/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5789 - accuracy: 0.6389 - val_loss: 0.9656 - val_accuracy: 0.0000e+00\n",
            "Epoch 176/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.5832 - accuracy: 0.6338 - val_loss: 0.9269 - val_accuracy: 0.0000e+00\n",
            "Epoch 177/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5553 - accuracy: 0.6490 - val_loss: 0.8837 - val_accuracy: 0.0000e+00\n",
            "Epoch 178/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.5480 - accuracy: 0.6717 - val_loss: 0.8786 - val_accuracy: 0.0000e+00\n",
            "Epoch 179/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5568 - accuracy: 0.6465 - val_loss: 0.9813 - val_accuracy: 0.0000e+00\n",
            "Epoch 180/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5627 - accuracy: 0.6465 - val_loss: 0.8675 - val_accuracy: 0.0000e+00\n",
            "Epoch 181/1000\n",
            "297/594 [==============>...............] - ETA: 0s - loss: 0.5628 - accuracy: 0.6734\n",
            "Epoch 00181: ReduceLROnPlateau reducing learning rate to 0.5.\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5446 - accuracy: 0.6591 - val_loss: 0.8895 - val_accuracy: 0.0000e+00\n",
            "Epoch 182/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5277 - accuracy: 0.7003 - val_loss: 0.7794 - val_accuracy: 0.1667\n",
            "Epoch 183/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5209 - accuracy: 0.6776 - val_loss: 0.7822 - val_accuracy: 0.1667\n",
            "Epoch 184/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5178 - accuracy: 0.6970 - val_loss: 0.7661 - val_accuracy: 0.1667\n",
            "Epoch 185/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5170 - accuracy: 0.6886 - val_loss: 0.7493 - val_accuracy: 0.1667\n",
            "Epoch 186/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5124 - accuracy: 0.6835 - val_loss: 0.7685 - val_accuracy: 0.1667\n",
            "Epoch 187/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5111 - accuracy: 0.6894 - val_loss: 0.7955 - val_accuracy: 0.1667\n",
            "Epoch 188/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5079 - accuracy: 0.7029 - val_loss: 0.7636 - val_accuracy: 0.1667\n",
            "Epoch 189/1000\n",
            "594/594 [==============================] - 0s 37us/sample - loss: 0.5059 - accuracy: 0.7045 - val_loss: 0.7538 - val_accuracy: 0.1667\n",
            "Epoch 190/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5067 - accuracy: 0.6936 - val_loss: 0.7547 - val_accuracy: 0.1667\n",
            "Epoch 191/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5080 - accuracy: 0.6886 - val_loss: 0.7300 - val_accuracy: 0.1667\n",
            "Epoch 192/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5030 - accuracy: 0.7003 - val_loss: 0.7308 - val_accuracy: 0.1667\n",
            "Epoch 193/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.4999 - accuracy: 0.7045 - val_loss: 0.7175 - val_accuracy: 0.1667\n",
            "Epoch 194/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4974 - accuracy: 0.6902 - val_loss: 0.7434 - val_accuracy: 0.1667\n",
            "Epoch 195/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4953 - accuracy: 0.6995 - val_loss: 0.7885 - val_accuracy: 0.1667\n",
            "Epoch 196/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.4922 - accuracy: 0.7054 - val_loss: 0.7009 - val_accuracy: 0.1667\n",
            "Epoch 197/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4989 - accuracy: 0.6700 - val_loss: 0.6986 - val_accuracy: 0.1667\n",
            "Epoch 198/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.4898 - accuracy: 0.6978 - val_loss: 0.7149 - val_accuracy: 0.1667\n",
            "Epoch 199/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4844 - accuracy: 0.7155 - val_loss: 0.7300 - val_accuracy: 0.1667\n",
            "Epoch 200/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4822 - accuracy: 0.6970 - val_loss: 0.7251 - val_accuracy: 0.1667\n",
            "Epoch 201/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4816 - accuracy: 0.7012 - val_loss: 0.7352 - val_accuracy: 0.1667\n",
            "Epoch 202/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.4771 - accuracy: 0.7163 - val_loss: 0.6900 - val_accuracy: 0.1667\n",
            "Epoch 203/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.4748 - accuracy: 0.7071 - val_loss: 0.6902 - val_accuracy: 0.1667\n",
            "Epoch 204/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4716 - accuracy: 0.7172 - val_loss: 0.6699 - val_accuracy: 0.2500\n",
            "Epoch 205/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4740 - accuracy: 0.6953 - val_loss: 0.6636 - val_accuracy: 0.3333\n",
            "Epoch 206/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.4661 - accuracy: 0.7205 - val_loss: 0.6676 - val_accuracy: 0.3333\n",
            "Epoch 207/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4626 - accuracy: 0.7146 - val_loss: 0.7160 - val_accuracy: 0.1667\n",
            "Epoch 208/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4616 - accuracy: 0.7155 - val_loss: 0.7338 - val_accuracy: 0.1667\n",
            "Epoch 209/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4570 - accuracy: 0.7205 - val_loss: 0.6668 - val_accuracy: 0.3333\n",
            "Epoch 210/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4519 - accuracy: 0.7247 - val_loss: 0.7099 - val_accuracy: 0.1667\n",
            "Epoch 211/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4505 - accuracy: 0.7172 - val_loss: 0.7071 - val_accuracy: 0.1667\n",
            "Epoch 212/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4446 - accuracy: 0.7180 - val_loss: 0.6269 - val_accuracy: 0.5833\n",
            "Epoch 213/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.4399 - accuracy: 0.7273 - val_loss: 0.6250 - val_accuracy: 0.6667\n",
            "Epoch 214/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4418 - accuracy: 0.7449 - val_loss: 0.5889 - val_accuracy: 0.6667\n",
            "Epoch 215/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4438 - accuracy: 0.7071 - val_loss: 0.5561 - val_accuracy: 0.8333\n",
            "Epoch 216/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4406 - accuracy: 0.7382 - val_loss: 0.5515 - val_accuracy: 0.8333\n",
            "Epoch 217/1000\n",
            "594/594 [==============================] - 0s 35us/sample - loss: 0.4559 - accuracy: 0.6970 - val_loss: 0.5169 - val_accuracy: 1.0000\n",
            "Epoch 218/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4441 - accuracy: 0.7323 - val_loss: 0.5468 - val_accuracy: 0.8333\n",
            "Epoch 219/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.4183 - accuracy: 0.7441 - val_loss: 0.5757 - val_accuracy: 0.6667\n",
            "Epoch 220/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4123 - accuracy: 0.7374 - val_loss: 0.5525 - val_accuracy: 0.8333\n",
            "Epoch 221/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.4276 - accuracy: 0.7290 - val_loss: 0.5064 - val_accuracy: 1.0000\n",
            "Epoch 222/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4458 - accuracy: 0.7146 - val_loss: 0.4899 - val_accuracy: 1.0000\n",
            "Epoch 223/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4798 - accuracy: 0.7146 - val_loss: 0.4822 - val_accuracy: 1.0000\n",
            "Epoch 224/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.5183 - accuracy: 0.6742 - val_loss: 0.4839 - val_accuracy: 1.0000\n",
            "Epoch 225/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4618 - accuracy: 0.6995 - val_loss: 0.4957 - val_accuracy: 1.0000\n",
            "Epoch 226/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4166 - accuracy: 0.7618 - val_loss: 0.5094 - val_accuracy: 1.0000\n",
            "Epoch 227/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4092 - accuracy: 0.7584 - val_loss: 0.4902 - val_accuracy: 1.0000\n",
            "Epoch 228/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4175 - accuracy: 0.7433 - val_loss: 0.4912 - val_accuracy: 1.0000\n",
            "Epoch 229/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4100 - accuracy: 0.7643 - val_loss: 0.4914 - val_accuracy: 1.0000\n",
            "Epoch 230/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3955 - accuracy: 0.7660 - val_loss: 0.4923 - val_accuracy: 1.0000\n",
            "Epoch 231/1000\n",
            "297/594 [==============>...............] - ETA: 0s - loss: 0.4054 - accuracy: 0.7929\n",
            "Epoch 00231: ReduceLROnPlateau reducing learning rate to 0.25.\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.3849 - accuracy: 0.7795 - val_loss: 0.4957 - val_accuracy: 1.0000\n",
            "Epoch 232/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.3736 - accuracy: 0.8207 - val_loss: 0.5115 - val_accuracy: 1.0000\n",
            "Epoch 233/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.3614 - accuracy: 0.8258 - val_loss: 0.5165 - val_accuracy: 0.8333\n",
            "Epoch 234/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.3584 - accuracy: 0.8140 - val_loss: 0.5063 - val_accuracy: 1.0000\n",
            "Epoch 235/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3563 - accuracy: 0.8224 - val_loss: 0.5079 - val_accuracy: 1.0000\n",
            "Epoch 236/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.3544 - accuracy: 0.8350 - val_loss: 0.5106 - val_accuracy: 0.9167\n",
            "Epoch 237/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3524 - accuracy: 0.8291 - val_loss: 0.5076 - val_accuracy: 1.0000\n",
            "Epoch 238/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.3505 - accuracy: 0.8367 - val_loss: 0.5143 - val_accuracy: 0.8333\n",
            "Epoch 239/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3489 - accuracy: 0.8224 - val_loss: 0.4961 - val_accuracy: 1.0000\n",
            "Epoch 240/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3481 - accuracy: 0.8199 - val_loss: 0.4976 - val_accuracy: 1.0000\n",
            "Epoch 241/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.3459 - accuracy: 0.8359 - val_loss: 0.4970 - val_accuracy: 1.0000\n",
            "Epoch 242/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.3450 - accuracy: 0.8392 - val_loss: 0.4981 - val_accuracy: 1.0000\n",
            "Epoch 243/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.3419 - accuracy: 0.8418 - val_loss: 0.5053 - val_accuracy: 1.0000\n",
            "Epoch 244/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.3405 - accuracy: 0.8401 - val_loss: 0.4887 - val_accuracy: 1.0000\n",
            "Epoch 245/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.3398 - accuracy: 0.8409 - val_loss: 0.4914 - val_accuracy: 1.0000\n",
            "Epoch 246/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.3385 - accuracy: 0.8443 - val_loss: 0.4883 - val_accuracy: 1.0000\n",
            "Epoch 247/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.3365 - accuracy: 0.8392 - val_loss: 0.5006 - val_accuracy: 1.0000\n",
            "Epoch 248/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.3351 - accuracy: 0.8443 - val_loss: 0.4871 - val_accuracy: 1.0000\n",
            "Epoch 249/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.3337 - accuracy: 0.8434 - val_loss: 0.4860 - val_accuracy: 1.0000\n",
            "Epoch 250/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.3323 - accuracy: 0.8426 - val_loss: 0.4855 - val_accuracy: 1.0000\n",
            "Epoch 251/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3313 - accuracy: 0.8426 - val_loss: 0.4798 - val_accuracy: 1.0000\n",
            "Epoch 252/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.3297 - accuracy: 0.8451 - val_loss: 0.4903 - val_accuracy: 1.0000\n",
            "Epoch 253/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3283 - accuracy: 0.8418 - val_loss: 0.4799 - val_accuracy: 1.0000\n",
            "Epoch 254/1000\n",
            "594/594 [==============================] - 0s 20us/sample - loss: 0.3276 - accuracy: 0.8426 - val_loss: 0.4818 - val_accuracy: 1.0000\n",
            "Epoch 255/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.3266 - accuracy: 0.8451 - val_loss: 0.4767 - val_accuracy: 1.0000\n",
            "Epoch 256/1000\n",
            "594/594 [==============================] - 0s 37us/sample - loss: 0.3254 - accuracy: 0.8392 - val_loss: 0.4733 - val_accuracy: 1.0000\n",
            "Epoch 257/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.3242 - accuracy: 0.8443 - val_loss: 0.4778 - val_accuracy: 1.0000\n",
            "Epoch 258/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.3229 - accuracy: 0.8443 - val_loss: 0.4728 - val_accuracy: 1.0000\n",
            "Epoch 259/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.3220 - accuracy: 0.8451 - val_loss: 0.4724 - val_accuracy: 1.0000\n",
            "Epoch 260/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.3212 - accuracy: 0.8401 - val_loss: 0.4711 - val_accuracy: 1.0000\n",
            "Epoch 261/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.3198 - accuracy: 0.8451 - val_loss: 0.4677 - val_accuracy: 1.0000\n",
            "Epoch 262/1000\n",
            "594/594 [==============================] - 0s 33us/sample - loss: 0.3190 - accuracy: 0.8443 - val_loss: 0.4766 - val_accuracy: 1.0000\n",
            "Epoch 263/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.3193 - accuracy: 0.8409 - val_loss: 0.4715 - val_accuracy: 1.0000\n",
            "Epoch 264/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.3176 - accuracy: 0.8434 - val_loss: 0.4706 - val_accuracy: 1.0000\n",
            "Epoch 265/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.3167 - accuracy: 0.8434 - val_loss: 0.4613 - val_accuracy: 1.0000\n",
            "Epoch 266/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.3173 - accuracy: 0.8443 - val_loss: 0.4610 - val_accuracy: 1.0000\n",
            "Epoch 267/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.3153 - accuracy: 0.8468 - val_loss: 0.4592 - val_accuracy: 1.0000\n",
            "Epoch 268/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3141 - accuracy: 0.8451 - val_loss: 0.4595 - val_accuracy: 1.0000\n",
            "Epoch 269/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.3133 - accuracy: 0.8460 - val_loss: 0.4693 - val_accuracy: 1.0000\n",
            "Epoch 270/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.3158 - accuracy: 0.8434 - val_loss: 0.4657 - val_accuracy: 1.0000\n",
            "Epoch 271/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.3131 - accuracy: 0.8460 - val_loss: 0.4617 - val_accuracy: 1.0000\n",
            "Epoch 272/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.3119 - accuracy: 0.8468 - val_loss: 0.4602 - val_accuracy: 1.0000\n",
            "Epoch 273/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3105 - accuracy: 0.8468 - val_loss: 0.4581 - val_accuracy: 1.0000\n",
            "Epoch 274/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3092 - accuracy: 0.8460 - val_loss: 0.4548 - val_accuracy: 1.0000\n",
            "Epoch 275/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3083 - accuracy: 0.8460 - val_loss: 0.4542 - val_accuracy: 1.0000\n",
            "Epoch 276/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.3088 - accuracy: 0.8468 - val_loss: 0.4578 - val_accuracy: 1.0000\n",
            "Epoch 277/1000\n",
            "594/594 [==============================] - 0s 37us/sample - loss: 0.3088 - accuracy: 0.8443 - val_loss: 0.4555 - val_accuracy: 1.0000\n",
            "Epoch 278/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.3069 - accuracy: 0.8451 - val_loss: 0.4500 - val_accuracy: 1.0000\n",
            "Epoch 279/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3061 - accuracy: 0.8451 - val_loss: 0.4471 - val_accuracy: 1.0000\n",
            "Epoch 280/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3051 - accuracy: 0.8468 - val_loss: 0.4478 - val_accuracy: 1.0000\n",
            "Epoch 281/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3045 - accuracy: 0.8468 - val_loss: 0.4475 - val_accuracy: 1.0000\n",
            "Epoch 282/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3039 - accuracy: 0.8451 - val_loss: 0.4448 - val_accuracy: 1.0000\n",
            "Epoch 283/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.3045 - accuracy: 0.8451 - val_loss: 0.4426 - val_accuracy: 1.0000\n",
            "Epoch 284/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.3042 - accuracy: 0.8460 - val_loss: 0.4421 - val_accuracy: 1.0000\n",
            "Epoch 285/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.3020 - accuracy: 0.8460 - val_loss: 0.4427 - val_accuracy: 1.0000\n",
            "Epoch 286/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.3015 - accuracy: 0.8468 - val_loss: 0.4408 - val_accuracy: 1.0000\n",
            "Epoch 287/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.3014 - accuracy: 0.8468 - val_loss: 0.4411 - val_accuracy: 1.0000\n",
            "Epoch 288/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.3012 - accuracy: 0.8460 - val_loss: 0.4396 - val_accuracy: 1.0000\n",
            "Epoch 289/1000\n",
            "594/594 [==============================] - 0s 20us/sample - loss: 0.3002 - accuracy: 0.8468 - val_loss: 0.4384 - val_accuracy: 1.0000\n",
            "Epoch 290/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.2997 - accuracy: 0.8468 - val_loss: 0.4371 - val_accuracy: 1.0000\n",
            "Epoch 291/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.2995 - accuracy: 0.8460 - val_loss: 0.4362 - val_accuracy: 1.0000\n",
            "Epoch 292/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.2986 - accuracy: 0.8468 - val_loss: 0.4362 - val_accuracy: 1.0000\n",
            "Epoch 293/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.2985 - accuracy: 0.8468 - val_loss: 0.4384 - val_accuracy: 1.0000\n",
            "Epoch 294/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.2989 - accuracy: 0.8451 - val_loss: 0.4354 - val_accuracy: 1.0000\n",
            "Epoch 295/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.2976 - accuracy: 0.8468 - val_loss: 0.4347 - val_accuracy: 1.0000\n",
            "Epoch 296/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.2971 - accuracy: 0.8468 - val_loss: 0.4327 - val_accuracy: 1.0000\n",
            "Epoch 297/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.2966 - accuracy: 0.8468 - val_loss: 0.4322 - val_accuracy: 1.0000\n",
            "Epoch 298/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.2957 - accuracy: 0.8468 - val_loss: 0.4311 - val_accuracy: 1.0000\n",
            "Epoch 299/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.2953 - accuracy: 0.8468 - val_loss: 0.4316 - val_accuracy: 1.0000\n",
            "Epoch 300/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.2954 - accuracy: 0.8468 - val_loss: 0.4295 - val_accuracy: 1.0000\n",
            "Epoch 301/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.2948 - accuracy: 0.8468 - val_loss: 0.4317 - val_accuracy: 1.0000\n",
            "Epoch 302/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.2942 - accuracy: 0.8460 - val_loss: 0.4282 - val_accuracy: 1.0000\n",
            "Epoch 303/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.2937 - accuracy: 0.8468 - val_loss: 0.4274 - val_accuracy: 1.0000\n",
            "Epoch 304/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.2934 - accuracy: 0.8468 - val_loss: 0.4264 - val_accuracy: 1.0000\n",
            "Epoch 305/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.2931 - accuracy: 0.8468 - val_loss: 0.4258 - val_accuracy: 1.0000\n",
            "Epoch 306/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.2934 - accuracy: 0.8468 - val_loss: 0.4248 - val_accuracy: 1.0000\n",
            "Epoch 307/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.2940 - accuracy: 0.8468 - val_loss: 0.4252 - val_accuracy: 1.0000\n",
            "Epoch 308/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.2923 - accuracy: 0.8468 - val_loss: 0.4237 - val_accuracy: 1.0000\n",
            "Epoch 309/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.2915 - accuracy: 0.8485 - val_loss: 0.4233 - val_accuracy: 1.0000\n",
            "Epoch 310/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.2920 - accuracy: 0.8468 - val_loss: 0.4232 - val_accuracy: 1.0000\n",
            "Epoch 311/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.2910 - accuracy: 0.8485 - val_loss: 0.4216 - val_accuracy: 1.0000\n",
            "Epoch 312/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.2909 - accuracy: 0.8468 - val_loss: 0.4213 - val_accuracy: 1.0000\n",
            "Epoch 313/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.2917 - accuracy: 0.8468 - val_loss: 0.4230 - val_accuracy: 1.0000\n",
            "Epoch 314/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.2905 - accuracy: 0.8485 - val_loss: 0.4200 - val_accuracy: 1.0000\n",
            "Epoch 315/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.2896 - accuracy: 0.8468 - val_loss: 0.4196 - val_accuracy: 1.0000\n",
            "Epoch 316/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.2895 - accuracy: 0.8468 - val_loss: 0.4183 - val_accuracy: 1.0000\n",
            "Epoch 317/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.2905 - accuracy: 0.8468 - val_loss: 0.4182 - val_accuracy: 1.0000\n",
            "Epoch 318/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.2896 - accuracy: 0.8468 - val_loss: 0.4194 - val_accuracy: 1.0000\n",
            "Epoch 319/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.2906 - accuracy: 0.8468 - val_loss: 0.4178 - val_accuracy: 1.0000\n",
            "Epoch 320/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.2883 - accuracy: 0.8485 - val_loss: 0.4168 - val_accuracy: 1.0000\n",
            "Epoch 321/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.2879 - accuracy: 0.8468 - val_loss: 0.4163 - val_accuracy: 1.0000\n",
            "Epoch 322/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.2879 - accuracy: 0.8476 - val_loss: 0.4160 - val_accuracy: 1.0000\n",
            "Epoch 323/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.2883 - accuracy: 0.8468 - val_loss: 0.4154 - val_accuracy: 1.0000\n",
            "Epoch 324/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.2876 - accuracy: 0.8468 - val_loss: 0.4156 - val_accuracy: 1.0000\n",
            "Epoch 325/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.2871 - accuracy: 0.8485 - val_loss: 0.4148 - val_accuracy: 1.0000\n",
            "Epoch 326/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.2864 - accuracy: 0.8468 - val_loss: 0.4156 - val_accuracy: 1.0000\n",
            "Epoch 327/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.2862 - accuracy: 0.8468 - val_loss: 0.4137 - val_accuracy: 1.0000\n",
            "Epoch 328/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.2860 - accuracy: 0.8468 - val_loss: 0.4136 - val_accuracy: 1.0000\n",
            "Epoch 329/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.2856 - accuracy: 0.8468 - val_loss: 0.4131 - val_accuracy: 1.0000\n",
            "Epoch 330/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.2857 - accuracy: 0.8468 - val_loss: 0.4127 - val_accuracy: 1.0000\n",
            "Epoch 331/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.2855 - accuracy: 0.8468 - val_loss: 0.4124 - val_accuracy: 1.0000\n",
            "Epoch 332/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.2849 - accuracy: 0.8485 - val_loss: 0.4119 - val_accuracy: 1.0000\n",
            "Epoch 333/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.2853 - accuracy: 0.8468 - val_loss: 0.4116 - val_accuracy: 1.0000\n",
            "Epoch 334/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.2849 - accuracy: 0.8468 - val_loss: 0.4134 - val_accuracy: 1.0000\n",
            "Epoch 335/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.2857 - accuracy: 0.8485 - val_loss: 0.4109 - val_accuracy: 1.0000\n",
            "Epoch 336/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.2846 - accuracy: 0.8476 - val_loss: 0.4104 - val_accuracy: 1.0000\n",
            "Epoch 337/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.2852 - accuracy: 0.8468 - val_loss: 0.4096 - val_accuracy: 1.0000\n",
            "Epoch 338/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.2846 - accuracy: 0.8468 - val_loss: 0.4098 - val_accuracy: 1.0000\n",
            "Epoch 339/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.2842 - accuracy: 0.8468 - val_loss: 0.4095 - val_accuracy: 1.0000\n",
            "Epoch 340/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.2837 - accuracy: 0.8485 - val_loss: 0.4090 - val_accuracy: 1.0000\n",
            "Epoch 341/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.2836 - accuracy: 0.8468 - val_loss: 0.4085 - val_accuracy: 1.0000\n",
            "Epoch 342/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.2833 - accuracy: 0.8468 - val_loss: 0.4086 - val_accuracy: 1.0000\n",
            "Epoch 343/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.2830 - accuracy: 0.8485 - val_loss: 0.4078 - val_accuracy: 1.0000\n",
            "Epoch 344/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.2839 - accuracy: 0.8476 - val_loss: 0.4072 - val_accuracy: 1.0000\n",
            "Epoch 345/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.2837 - accuracy: 0.8468 - val_loss: 0.4074 - val_accuracy: 1.0000\n",
            "Epoch 346/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.2830 - accuracy: 0.8468 - val_loss: 0.4073 - val_accuracy: 1.0000\n",
            "Epoch 347/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.2825 - accuracy: 0.8485 - val_loss: 0.4071 - val_accuracy: 1.0000\n",
            "Epoch 348/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.2826 - accuracy: 0.8485 - val_loss: 0.4066 - val_accuracy: 1.0000\n",
            "Epoch 349/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.2821 - accuracy: 0.8485 - val_loss: 0.4061 - val_accuracy: 1.0000\n",
            "Epoch 350/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.2820 - accuracy: 0.8485 - val_loss: 0.4062 - val_accuracy: 1.0000\n",
            "Epoch 351/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.2819 - accuracy: 0.8485 - val_loss: 0.4055 - val_accuracy: 1.0000\n",
            "Epoch 352/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.2822 - accuracy: 0.8468 - val_loss: 0.4056 - val_accuracy: 1.0000\n",
            "Epoch 353/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.2818 - accuracy: 0.8485 - val_loss: 0.4050 - val_accuracy: 1.0000\n",
            "Epoch 354/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.2817 - accuracy: 0.8485 - val_loss: 0.4048 - val_accuracy: 1.0000\n",
            "Epoch 355/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.2812 - accuracy: 0.8485 - val_loss: 0.4046 - val_accuracy: 1.0000\n",
            "Epoch 356/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.2813 - accuracy: 0.8485 - val_loss: 0.4043 - val_accuracy: 1.0000\n",
            "Epoch 357/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.2813 - accuracy: 0.8468 - val_loss: 0.4044 - val_accuracy: 1.0000\n",
            "Epoch 358/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.2811 - accuracy: 0.8485 - val_loss: 0.4038 - val_accuracy: 1.0000\n",
            "Epoch 359/1000\n",
            "297/594 [==============>...............] - ETA: 0s - loss: 0.2791 - accuracy: 0.8519\n",
            "Epoch 00359: ReduceLROnPlateau reducing learning rate to 0.125.\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.2810 - accuracy: 0.8485 - val_loss: 0.4034 - val_accuracy: 1.0000\n",
            "Epoch 360/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.2809 - accuracy: 0.8485 - val_loss: 0.4034 - val_accuracy: 1.0000\n",
            "Epoch 361/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.2805 - accuracy: 0.8485 - val_loss: 0.4033 - val_accuracy: 1.0000\n",
            "Epoch 362/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.2804 - accuracy: 0.8485 - val_loss: 0.4032 - val_accuracy: 1.0000\n",
            "Epoch 363/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.2804 - accuracy: 0.8485 - val_loss: 0.4030 - val_accuracy: 1.0000\n",
            "Epoch 364/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.2804 - accuracy: 0.8485 - val_loss: 0.4030 - val_accuracy: 1.0000\n",
            "Epoch 365/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.2803 - accuracy: 0.8485 - val_loss: 0.4028 - val_accuracy: 1.0000\n",
            "Epoch 366/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.2802 - accuracy: 0.8485 - val_loss: 0.4027 - val_accuracy: 1.0000\n",
            "Epoch 367/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.2801 - accuracy: 0.8485 - val_loss: 0.4027 - val_accuracy: 1.0000\n",
            "Epoch 368/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.2801 - accuracy: 0.8485 - val_loss: 0.4024 - val_accuracy: 1.0000\n",
            "Epoch 369/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.2802 - accuracy: 0.8485 - val_loss: 0.4024 - val_accuracy: 1.0000\n",
            "Epoch 370/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.2800 - accuracy: 0.8485 - val_loss: 0.4023 - val_accuracy: 1.0000\n",
            "Epoch 371/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.2799 - accuracy: 0.8485 - val_loss: 0.4022 - val_accuracy: 1.0000\n",
            "Epoch 372/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.2799 - accuracy: 0.8485 - val_loss: 0.4021 - val_accuracy: 1.0000\n",
            "Epoch 373/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.2797 - accuracy: 0.8485 - val_loss: 0.4020 - val_accuracy: 1.0000\n",
            "Epoch 374/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.2798 - accuracy: 0.8485 - val_loss: 0.4019 - val_accuracy: 1.0000\n",
            "Epoch 375/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.2796 - accuracy: 0.8485 - val_loss: 0.4017 - val_accuracy: 1.0000\n",
            "Epoch 376/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.2794 - accuracy: 0.8485 - val_loss: 0.4017 - val_accuracy: 1.0000\n",
            "Epoch 377/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.2795 - accuracy: 0.8468 - val_loss: 0.4016 - val_accuracy: 1.0000\n",
            "Epoch 378/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.2796 - accuracy: 0.8468 - val_loss: 0.4015 - val_accuracy: 1.0000\n",
            "Epoch 379/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.2793 - accuracy: 0.8485 - val_loss: 0.4014 - val_accuracy: 1.0000\n",
            "Epoch 380/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.2792 - accuracy: 0.8485 - val_loss: 0.4013 - val_accuracy: 1.0000\n",
            "Epoch 381/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.2791 - accuracy: 0.8485 - val_loss: 0.4012 - val_accuracy: 1.0000\n",
            "Epoch 382/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.2792 - accuracy: 0.8468 - val_loss: 0.4012 - val_accuracy: 1.0000\n",
            "Epoch 383/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.2788 - accuracy: 0.8485 - val_loss: 0.4011 - val_accuracy: 1.0000\n",
            "Epoch 384/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.2788 - accuracy: 0.8468 - val_loss: 0.4010 - val_accuracy: 1.0000\n",
            "Epoch 385/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.2788 - accuracy: 0.8485 - val_loss: 0.4010 - val_accuracy: 1.0000\n",
            "Epoch 386/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.2785 - accuracy: 0.8468 - val_loss: 0.4008 - val_accuracy: 1.0000\n",
            "Epoch 387/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.2786 - accuracy: 0.8468 - val_loss: 0.4007 - val_accuracy: 1.0000\n",
            "Epoch 388/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.2785 - accuracy: 0.8468 - val_loss: 0.4008 - val_accuracy: 1.0000\n",
            "Epoch 389/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.2781 - accuracy: 0.8485 - val_loss: 0.4007 - val_accuracy: 1.0000\n",
            "Epoch 390/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.2781 - accuracy: 0.8468 - val_loss: 0.4008 - val_accuracy: 1.0000\n",
            "Epoch 391/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.2782 - accuracy: 0.8485 - val_loss: 0.4006 - val_accuracy: 1.0000\n",
            "Epoch 392/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.2779 - accuracy: 0.8468 - val_loss: 0.4006 - val_accuracy: 1.0000\n",
            "Epoch 393/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.2777 - accuracy: 0.8468 - val_loss: 0.4005 - val_accuracy: 1.0000\n",
            "Epoch 394/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.2777 - accuracy: 0.8485 - val_loss: 0.4005 - val_accuracy: 1.0000\n",
            "Epoch 395/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.2780 - accuracy: 0.8468 - val_loss: 0.4005 - val_accuracy: 1.0000\n",
            "Epoch 396/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.2776 - accuracy: 0.8468 - val_loss: 0.4005 - val_accuracy: 1.0000\n",
            "Epoch 397/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.2773 - accuracy: 0.8468 - val_loss: 0.4004 - val_accuracy: 1.0000\n",
            "Epoch 398/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.2771 - accuracy: 0.8468 - val_loss: 0.4004 - val_accuracy: 1.0000\n",
            "Epoch 399/1000\n",
            "594/594 [==============================] - 0s 35us/sample - loss: 0.2770 - accuracy: 0.8485 - val_loss: 0.4004 - val_accuracy: 1.0000\n",
            "Epoch 400/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.2770 - accuracy: 0.8476 - val_loss: 0.4004 - val_accuracy: 1.0000\n",
            "Epoch 401/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.2771 - accuracy: 0.8485 - val_loss: 0.4003 - val_accuracy: 1.0000\n",
            "Epoch 402/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.2769 - accuracy: 0.8468 - val_loss: 0.4003 - val_accuracy: 1.0000\n",
            "Epoch 403/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.2771 - accuracy: 0.8485 - val_loss: 0.4002 - val_accuracy: 1.0000\n",
            "Epoch 404/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.2768 - accuracy: 0.8468 - val_loss: 0.4002 - val_accuracy: 1.0000\n",
            "Epoch 405/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.2767 - accuracy: 0.8468 - val_loss: 0.4002 - val_accuracy: 1.0000\n",
            "Epoch 406/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.2765 - accuracy: 0.8485 - val_loss: 0.4001 - val_accuracy: 1.0000\n",
            "Epoch 407/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.2763 - accuracy: 0.8468 - val_loss: 0.4002 - val_accuracy: 1.0000\n",
            "Epoch 408/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.2766 - accuracy: 0.8468 - val_loss: 0.4002 - val_accuracy: 1.0000\n",
            "Epoch 409/1000\n",
            "297/594 [==============>...............] - ETA: 0s - loss: 0.2976 - accuracy: 0.8451\n",
            "Epoch 00409: ReduceLROnPlateau reducing learning rate to 0.0625.\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.2760 - accuracy: 0.8485 - val_loss: 0.4002 - val_accuracy: 1.0000\n",
            "Epoch 410/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.2760 - accuracy: 0.8476 - val_loss: 0.4002 - val_accuracy: 1.0000\n",
            "Epoch 411/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.2758 - accuracy: 0.8468 - val_loss: 0.4002 - val_accuracy: 1.0000\n",
            "Epoch 412/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.2758 - accuracy: 0.8468 - val_loss: 0.4002 - val_accuracy: 1.0000\n",
            "Epoch 413/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.2758 - accuracy: 0.8468 - val_loss: 0.4001 - val_accuracy: 1.0000\n",
            "Epoch 414/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.2757 - accuracy: 0.8468 - val_loss: 0.4002 - val_accuracy: 1.0000\n",
            "Epoch 415/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.2756 - accuracy: 0.8476 - val_loss: 0.4002 - val_accuracy: 1.0000\n",
            "Epoch 416/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.2756 - accuracy: 0.8468 - val_loss: 0.4002 - val_accuracy: 1.0000\n",
            "Epoch 417/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.2756 - accuracy: 0.8468 - val_loss: 0.4002 - val_accuracy: 1.0000\n",
            "Epoch 418/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.2755 - accuracy: 0.8468 - val_loss: 0.4002 - val_accuracy: 1.0000\n",
            "Epoch 419/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.2754 - accuracy: 0.8468 - val_loss: 0.4002 - val_accuracy: 1.0000\n",
            "Epoch 420/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.2754 - accuracy: 0.8468 - val_loss: 0.4002 - val_accuracy: 1.0000\n",
            "Epoch 421/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.2752 - accuracy: 0.8468 - val_loss: 0.4002 - val_accuracy: 1.0000\n",
            "Epoch 422/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.2752 - accuracy: 0.8468 - val_loss: 0.4002 - val_accuracy: 1.0000\n",
            "Epoch 423/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.2751 - accuracy: 0.8468 - val_loss: 0.4002 - val_accuracy: 1.0000\n",
            "Epoch 424/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.2752 - accuracy: 0.8468 - val_loss: 0.4002 - val_accuracy: 1.0000\n",
            "Epoch 425/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.2750 - accuracy: 0.8485 - val_loss: 0.4002 - val_accuracy: 1.0000\n",
            "Epoch 426/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.2750 - accuracy: 0.8485 - val_loss: 0.4002 - val_accuracy: 1.0000\n",
            "Epoch 427/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.2749 - accuracy: 0.8476 - val_loss: 0.4002 - val_accuracy: 1.0000\n",
            "Epoch 428/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.2749 - accuracy: 0.8476 - val_loss: 0.4003 - val_accuracy: 1.0000\n",
            "Epoch 429/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.2749 - accuracy: 0.8468 - val_loss: 0.4002 - val_accuracy: 1.0000\n",
            "Epoch 430/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.2748 - accuracy: 0.8476 - val_loss: 0.4003 - val_accuracy: 1.0000\n",
            "Epoch 431/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.2747 - accuracy: 0.8476 - val_loss: 0.4003 - val_accuracy: 1.0000\n",
            "Epoch 432/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.2748 - accuracy: 0.8485 - val_loss: 0.4003 - val_accuracy: 1.0000\n",
            "Epoch 433/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.2749 - accuracy: 0.8476 - val_loss: 0.4003 - val_accuracy: 1.0000\n",
            "Epoch 434/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.2747 - accuracy: 0.8485 - val_loss: 0.4003 - val_accuracy: 1.0000\n",
            "Epoch 435/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.2746 - accuracy: 0.8468 - val_loss: 0.4003 - val_accuracy: 1.0000\n",
            "Epoch 436/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.2747 - accuracy: 0.8485 - val_loss: 0.4003 - val_accuracy: 1.0000\n",
            "Epoch 437/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.2746 - accuracy: 0.8468 - val_loss: 0.4003 - val_accuracy: 1.0000\n",
            "Epoch 438/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.2744 - accuracy: 0.8485 - val_loss: 0.4003 - val_accuracy: 1.0000\n",
            "Epoch 439/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.2744 - accuracy: 0.8468 - val_loss: 0.4004 - val_accuracy: 1.0000\n",
            "Epoch 440/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.2743 - accuracy: 0.8468 - val_loss: 0.4004 - val_accuracy: 1.0000\n",
            "Epoch 441/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.2742 - accuracy: 0.8485 - val_loss: 0.4004 - val_accuracy: 1.0000\n",
            "Epoch 442/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.2741 - accuracy: 0.8468 - val_loss: 0.4004 - val_accuracy: 1.0000\n",
            "Epoch 443/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.2740 - accuracy: 0.8468 - val_loss: 0.4004 - val_accuracy: 1.0000\n",
            "Epoch 444/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.2741 - accuracy: 0.8476 - val_loss: 0.4004 - val_accuracy: 1.0000\n",
            "Epoch 445/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.2739 - accuracy: 0.8468 - val_loss: 0.4005 - val_accuracy: 1.0000\n",
            "Epoch 446/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.2738 - accuracy: 0.8468 - val_loss: 0.4005 - val_accuracy: 1.0000\n",
            "Epoch 447/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.2737 - accuracy: 0.8468 - val_loss: 0.4005 - val_accuracy: 1.0000\n",
            "Epoch 448/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.2738 - accuracy: 0.8468 - val_loss: 0.4005 - val_accuracy: 1.0000\n",
            "Epoch 449/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.2736 - accuracy: 0.8476 - val_loss: 0.4005 - val_accuracy: 1.0000\n",
            "Epoch 450/1000\n",
            "594/594 [==============================] - 0s 34us/sample - loss: 0.2736 - accuracy: 0.8468 - val_loss: 0.4006 - val_accuracy: 1.0000\n",
            "Epoch 451/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.2734 - accuracy: 0.8476 - val_loss: 0.4006 - val_accuracy: 1.0000\n",
            "Epoch 452/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.2733 - accuracy: 0.8468 - val_loss: 0.4007 - val_accuracy: 1.0000\n",
            "Epoch 453/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.2732 - accuracy: 0.8468 - val_loss: 0.4007 - val_accuracy: 1.0000\n",
            "Epoch 454/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.2729 - accuracy: 0.8468 - val_loss: 0.4007 - val_accuracy: 1.0000\n",
            "Epoch 455/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.2730 - accuracy: 0.8468 - val_loss: 0.4008 - val_accuracy: 1.0000\n",
            "Epoch 456/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.2728 - accuracy: 0.8468 - val_loss: 0.4008 - val_accuracy: 1.0000\n",
            "Epoch 457/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.2726 - accuracy: 0.8468 - val_loss: 0.4009 - val_accuracy: 1.0000\n",
            "Epoch 458/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.2725 - accuracy: 0.8468 - val_loss: 0.4009 - val_accuracy: 1.0000\n",
            "Epoch 459/1000\n",
            "297/594 [==============>...............] - ETA: 0s - loss: 0.2654 - accuracy: 0.8586\n",
            "Epoch 00459: ReduceLROnPlateau reducing learning rate to 0.03125.\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.2724 - accuracy: 0.8468 - val_loss: 0.4010 - val_accuracy: 1.0000\n",
            "Epoch 460/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.2722 - accuracy: 0.8468 - val_loss: 0.4010 - val_accuracy: 1.0000\n",
            "Epoch 461/1000\n",
            "594/594 [==============================] - 0s 37us/sample - loss: 0.2720 - accuracy: 0.8468 - val_loss: 0.4010 - val_accuracy: 1.0000\n",
            "Epoch 462/1000\n",
            "594/594 [==============================] - 0s 34us/sample - loss: 0.2720 - accuracy: 0.8468 - val_loss: 0.4011 - val_accuracy: 1.0000\n",
            "Epoch 463/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.2719 - accuracy: 0.8468 - val_loss: 0.4011 - val_accuracy: 1.0000\n",
            "Epoch 464/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.2718 - accuracy: 0.8468 - val_loss: 0.4011 - val_accuracy: 1.0000\n",
            "Epoch 465/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.2717 - accuracy: 0.8468 - val_loss: 0.4012 - val_accuracy: 1.0000\n",
            "Epoch 466/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.2716 - accuracy: 0.8468 - val_loss: 0.4012 - val_accuracy: 1.0000\n",
            "Epoch 467/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.2715 - accuracy: 0.8468 - val_loss: 0.4012 - val_accuracy: 1.0000\n",
            "Epoch 468/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.2713 - accuracy: 0.8468 - val_loss: 0.4013 - val_accuracy: 1.0000\n",
            "Epoch 469/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.2712 - accuracy: 0.8468 - val_loss: 0.4013 - val_accuracy: 1.0000\n",
            "Epoch 470/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.2709 - accuracy: 0.8468 - val_loss: 0.4013 - val_accuracy: 1.0000\n",
            "Epoch 471/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.2708 - accuracy: 0.8468 - val_loss: 0.4014 - val_accuracy: 1.0000\n",
            "Epoch 472/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.2706 - accuracy: 0.8468 - val_loss: 0.4014 - val_accuracy: 1.0000\n",
            "Epoch 473/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.2704 - accuracy: 0.8468 - val_loss: 0.4015 - val_accuracy: 1.0000\n",
            "Epoch 474/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.2702 - accuracy: 0.8468 - val_loss: 0.4015 - val_accuracy: 1.0000\n",
            "Epoch 475/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.2701 - accuracy: 0.8468 - val_loss: 0.4016 - val_accuracy: 1.0000\n",
            "Epoch 476/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.2700 - accuracy: 0.8468 - val_loss: 0.4016 - val_accuracy: 1.0000\n",
            "Epoch 477/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.2698 - accuracy: 0.8468 - val_loss: 0.4017 - val_accuracy: 1.0000\n",
            "Epoch 478/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.2697 - accuracy: 0.8468 - val_loss: 0.4017 - val_accuracy: 1.0000\n",
            "Epoch 479/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.2696 - accuracy: 0.8468 - val_loss: 0.4018 - val_accuracy: 1.0000\n",
            "Epoch 480/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.2695 - accuracy: 0.8468 - val_loss: 0.4018 - val_accuracy: 1.0000\n",
            "Epoch 481/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.2693 - accuracy: 0.8468 - val_loss: 0.4019 - val_accuracy: 1.0000\n",
            "Epoch 482/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.2693 - accuracy: 0.8468 - val_loss: 0.4019 - val_accuracy: 1.0000\n",
            "Epoch 483/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.2691 - accuracy: 0.8468 - val_loss: 0.4020 - val_accuracy: 1.0000\n",
            "Epoch 484/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.2691 - accuracy: 0.8468 - val_loss: 0.4021 - val_accuracy: 1.0000\n",
            "Epoch 485/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.2689 - accuracy: 0.8468 - val_loss: 0.4021 - val_accuracy: 1.0000\n",
            "Epoch 486/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.2689 - accuracy: 0.8468 - val_loss: 0.4022 - val_accuracy: 1.0000\n",
            "Epoch 487/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.2688 - accuracy: 0.8468 - val_loss: 0.4022 - val_accuracy: 1.0000\n",
            "Epoch 488/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.2686 - accuracy: 0.8468 - val_loss: 0.4023 - val_accuracy: 1.0000\n",
            "Epoch 489/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.2686 - accuracy: 0.8468 - val_loss: 0.4023 - val_accuracy: 1.0000\n",
            "Epoch 490/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.2684 - accuracy: 0.8468 - val_loss: 0.4024 - val_accuracy: 1.0000\n",
            "Epoch 491/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.2684 - accuracy: 0.8468 - val_loss: 0.4025 - val_accuracy: 1.0000\n",
            "Epoch 492/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.2683 - accuracy: 0.8468 - val_loss: 0.4025 - val_accuracy: 1.0000\n",
            "Epoch 493/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.2682 - accuracy: 0.8476 - val_loss: 0.4026 - val_accuracy: 1.0000\n",
            "Epoch 494/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.2681 - accuracy: 0.8476 - val_loss: 0.4026 - val_accuracy: 1.0000\n",
            "Epoch 495/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.2681 - accuracy: 0.8468 - val_loss: 0.4027 - val_accuracy: 1.0000\n",
            "Epoch 496/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.2679 - accuracy: 0.8476 - val_loss: 0.4027 - val_accuracy: 1.0000\n",
            "Epoch 497/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.2679 - accuracy: 0.8468 - val_loss: 0.4028 - val_accuracy: 1.0000\n",
            "Epoch 498/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.2678 - accuracy: 0.8485 - val_loss: 0.4029 - val_accuracy: 1.0000\n",
            "Epoch 499/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.2677 - accuracy: 0.8485 - val_loss: 0.4029 - val_accuracy: 1.0000\n",
            "Epoch 500/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.2676 - accuracy: 0.8485 - val_loss: 0.4030 - val_accuracy: 1.0000\n",
            "Epoch 501/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.2676 - accuracy: 0.8476 - val_loss: 0.4030 - val_accuracy: 1.0000\n",
            "Epoch 502/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.2675 - accuracy: 0.8476 - val_loss: 0.4031 - val_accuracy: 1.0000\n",
            "Epoch 503/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.2675 - accuracy: 0.8485 - val_loss: 0.4031 - val_accuracy: 1.0000\n",
            "Epoch 504/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.2674 - accuracy: 0.8476 - val_loss: 0.4032 - val_accuracy: 1.0000\n",
            "Epoch 505/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.2673 - accuracy: 0.8476 - val_loss: 0.4033 - val_accuracy: 1.0000\n",
            "Epoch 506/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.2672 - accuracy: 0.8485 - val_loss: 0.4033 - val_accuracy: 1.0000\n",
            "Epoch 507/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.2672 - accuracy: 0.8476 - val_loss: 0.4034 - val_accuracy: 1.0000\n",
            "Epoch 508/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.2671 - accuracy: 0.8485 - val_loss: 0.4034 - val_accuracy: 1.0000\n",
            "Epoch 509/1000\n",
            "297/594 [==============>...............] - ETA: 0s - loss: 0.2594 - accuracy: 0.8653\n",
            "Epoch 00509: ReduceLROnPlateau reducing learning rate to 0.015625.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "594/594 [==============================] - 0s 34us/sample - loss: 0.2670 - accuracy: 0.8485 - val_loss: 0.4035 - val_accuracy: 1.0000\n",
            "Epoch 00509: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAGFCAYAAADAc+UQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TegkvaZIoGHm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3f363467-4671-4c67-f529-d51e241e2d4d"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "mlp = Sequential()\n",
        "mlp.add(Dense(16, input_dim=2, activation='relu'))\n",
        "mlp.add(Dense(16, activation='sigmoid'))\n",
        "mlp.add(Dense(16, activation='sigmoid'))\n",
        "mlp.add(Dense(2, activation='sigmoid'))\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(factor=0.5, monitor='accuracy',\n",
        "                              patience=50, min_lr=0.00000001,\n",
        "                              verbose = 1)\n",
        "\n",
        "stop_save = EarlyStopping(patience=200, monitor='accuracy',\n",
        "                          verbose=1, \n",
        "                          restore_best_weights=True)\n",
        "\n",
        "# All parameter gradients will be clipped to\n",
        "# a maximum norm of 1.\n",
        "sgd = optimizers.SGD(lr=1., clipnorm=1.)\n",
        "\n",
        "mlp.compile(loss='binary_crossentropy',\n",
        "            optimizer=sgd,\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "# trains the model\n",
        "mlp.fit(X, yv, epochs=1000, batch_size=297,\n",
        "        verbose=1, callbacks=[reduce_lr, stop_save], \n",
        "        validation_split = 0.01)\n",
        "\n",
        "y_pred = mlp.predict(X)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
        "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n",
        "                     np.arange(y_min, y_max, 0.02))\n",
        "Z = None\n",
        "Z = mlp.predict(np.c_[xx.ravel(), yy.ravel()])[:,1]\n",
        "Z = Z.reshape(xx.shape)\n",
        "cm = plt.cm.bwr\n",
        "\n",
        "fig = plt.figure(figsize=(6,6))\n",
        "\n",
        "plt.contourf(xx, yy, Z, cmap=cm, alpha=.25)\n",
        "\n",
        "plt.plot(X[1,0],X[1,1],'+', color='#648fff', label='Positive Class')\n",
        "plt.plot(X[2,1],X[2,1],'_', color='#fe6100', label='Negative Class')\n",
        "\n",
        "for i in range(len(y)):\n",
        "  x1 = X[i,0]\n",
        "  x2 = X[i,1]\n",
        "  if y[i]==1: \n",
        "    if (y_pred[i] == 0):\n",
        "      plt.plot(x1,x2,'+', color='#648fff')\n",
        "    else:\n",
        "      plt.plot(x1,x2,'k.', alpha=0.25)\n",
        "  else:\n",
        "    if (y_pred[i] == 1):\n",
        "      plt.plot(x1,x2,'_', color='#fe6100')\n",
        "    else:\n",
        "      plt.plot(x1,x2,'k.', alpha=0.25)\n",
        "\n",
        "accuracy = np.sum(np.equal(y_pred,y_actual))/len(y_actual)\n",
        "\n",
        "plt.axis('tight')\n",
        "plt.xlim(min(X[:,0])-0.1, max(X[:,0])+0.1)\n",
        "plt.ylim(min(X[:,1])-0.1, max(X[:,1])+0.1)\n",
        "plt.xlabel('$x_1$')\n",
        "plt.ylabel('$x_2$')\n",
        "plt.legend()\n",
        "plt.title('Keras-based 4-layer MLP on spiral dataset. Accuracy: {:04.3}'.format(accuracy))\n",
        "plt.savefig('ch.6.MLP.keras.deep.i.spirals.png', dpi=350, bbox_inches='tight')\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 594 samples, validate on 6 samples\n",
            "Epoch 1/1000\n",
            "594/594 [==============================] - 0s 489us/sample - loss: 0.8531 - accuracy: 0.4949 - val_loss: 0.5854 - val_accuracy: 1.0000\n",
            "Epoch 2/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6978 - accuracy: 0.4949 - val_loss: 0.7120 - val_accuracy: 0.0833\n",
            "Epoch 3/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6942 - accuracy: 0.4781 - val_loss: 0.7142 - val_accuracy: 0.0833\n",
            "Epoch 4/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6941 - accuracy: 0.5261 - val_loss: 0.6909 - val_accuracy: 0.5833\n",
            "Epoch 5/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6943 - accuracy: 0.4958 - val_loss: 0.6855 - val_accuracy: 0.7500\n",
            "Epoch 6/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6945 - accuracy: 0.4941 - val_loss: 0.6821 - val_accuracy: 0.8333\n",
            "Epoch 7/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6935 - accuracy: 0.4529 - val_loss: 0.7014 - val_accuracy: 0.0833\n",
            "Epoch 8/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6934 - accuracy: 0.4992 - val_loss: 0.6966 - val_accuracy: 0.2500\n",
            "Epoch 9/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6933 - accuracy: 0.4823 - val_loss: 0.7128 - val_accuracy: 0.0833\n",
            "Epoch 10/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6939 - accuracy: 0.4781 - val_loss: 0.7246 - val_accuracy: 0.0833\n",
            "Epoch 11/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6935 - accuracy: 0.5185 - val_loss: 0.7190 - val_accuracy: 0.0833\n",
            "Epoch 12/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6930 - accuracy: 0.5539 - val_loss: 0.6951 - val_accuracy: 0.2500\n",
            "Epoch 13/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6934 - accuracy: 0.4621 - val_loss: 0.7232 - val_accuracy: 0.0833\n",
            "Epoch 14/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6929 - accuracy: 0.5455 - val_loss: 0.6920 - val_accuracy: 0.6667\n",
            "Epoch 15/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6958 - accuracy: 0.4823 - val_loss: 0.7470 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6928 - accuracy: 0.5202 - val_loss: 0.6976 - val_accuracy: 0.1667\n",
            "Epoch 17/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6930 - accuracy: 0.5227 - val_loss: 0.6833 - val_accuracy: 0.8333\n",
            "Epoch 18/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6922 - accuracy: 0.5025 - val_loss: 0.6987 - val_accuracy: 0.1667\n",
            "Epoch 19/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6944 - accuracy: 0.4865 - val_loss: 0.7412 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6933 - accuracy: 0.4949 - val_loss: 0.7281 - val_accuracy: 0.0833\n",
            "Epoch 21/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6936 - accuracy: 0.5261 - val_loss: 0.6731 - val_accuracy: 0.9167\n",
            "Epoch 22/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6920 - accuracy: 0.4992 - val_loss: 0.6949 - val_accuracy: 0.4167\n",
            "Epoch 23/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6914 - accuracy: 0.5202 - val_loss: 0.7036 - val_accuracy: 0.1667\n",
            "Epoch 24/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6913 - accuracy: 0.5396 - val_loss: 0.7078 - val_accuracy: 0.0833\n",
            "Epoch 25/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6922 - accuracy: 0.4949 - val_loss: 0.7285 - val_accuracy: 0.0833\n",
            "Epoch 26/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6911 - accuracy: 0.5455 - val_loss: 0.7063 - val_accuracy: 0.0833\n",
            "Epoch 27/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6913 - accuracy: 0.5530 - val_loss: 0.6883 - val_accuracy: 0.7500\n",
            "Epoch 28/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6908 - accuracy: 0.5126 - val_loss: 0.6968 - val_accuracy: 0.2500\n",
            "Epoch 29/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6915 - accuracy: 0.4891 - val_loss: 0.7284 - val_accuracy: 0.0833\n",
            "Epoch 30/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6905 - accuracy: 0.5581 - val_loss: 0.6975 - val_accuracy: 0.2500\n",
            "Epoch 31/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6901 - accuracy: 0.5606 - val_loss: 0.7046 - val_accuracy: 0.2500\n",
            "Epoch 32/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6900 - accuracy: 0.5589 - val_loss: 0.7020 - val_accuracy: 0.2500\n",
            "Epoch 33/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6899 - accuracy: 0.5505 - val_loss: 0.6980 - val_accuracy: 0.2500\n",
            "Epoch 34/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6905 - accuracy: 0.5244 - val_loss: 0.7290 - val_accuracy: 0.0833\n",
            "Epoch 35/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6897 - accuracy: 0.5623 - val_loss: 0.6947 - val_accuracy: 0.3333\n",
            "Epoch 36/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6898 - accuracy: 0.5665 - val_loss: 0.6881 - val_accuracy: 0.7500\n",
            "Epoch 37/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.7142 - val_accuracy: 0.0833\n",
            "Epoch 38/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6904 - accuracy: 0.5387 - val_loss: 0.6765 - val_accuracy: 0.7500\n",
            "Epoch 39/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6887 - accuracy: 0.5328 - val_loss: 0.7145 - val_accuracy: 0.0833\n",
            "Epoch 40/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6915 - accuracy: 0.5000 - val_loss: 0.7496 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6884 - accuracy: 0.5598 - val_loss: 0.7003 - val_accuracy: 0.2500\n",
            "Epoch 42/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6891 - accuracy: 0.5581 - val_loss: 0.6800 - val_accuracy: 0.7500\n",
            "Epoch 43/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6877 - accuracy: 0.5547 - val_loss: 0.7015 - val_accuracy: 0.2500\n",
            "Epoch 44/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6880 - accuracy: 0.5614 - val_loss: 0.6858 - val_accuracy: 0.7500\n",
            "Epoch 45/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6870 - accuracy: 0.5564 - val_loss: 0.7015 - val_accuracy: 0.2500\n",
            "Epoch 46/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6865 - accuracy: 0.5943 - val_loss: 0.7069 - val_accuracy: 0.2500\n",
            "Epoch 47/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6861 - accuracy: 0.5758 - val_loss: 0.7079 - val_accuracy: 0.2500\n",
            "Epoch 48/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6858 - accuracy: 0.5783 - val_loss: 0.7093 - val_accuracy: 0.2500\n",
            "Epoch 49/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6857 - accuracy: 0.5901 - val_loss: 0.6960 - val_accuracy: 0.3333\n",
            "Epoch 50/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6857 - accuracy: 0.5732 - val_loss: 0.7294 - val_accuracy: 0.0833\n",
            "Epoch 51/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6902 - accuracy: 0.5168 - val_loss: 0.7654 - val_accuracy: 0.0000e+00\n",
            "Epoch 52/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6860 - accuracy: 0.5699 - val_loss: 0.7318 - val_accuracy: 0.1667\n",
            "Epoch 53/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6839 - accuracy: 0.6002 - val_loss: 0.7060 - val_accuracy: 0.3333\n",
            "Epoch 54/1000\n",
            "594/594 [==============================] - 0s 36us/sample - loss: 0.6833 - accuracy: 0.6103 - val_loss: 0.7102 - val_accuracy: 0.3333\n",
            "Epoch 55/1000\n",
            "594/594 [==============================] - 0s 34us/sample - loss: 0.6829 - accuracy: 0.6077 - val_loss: 0.7193 - val_accuracy: 0.2500\n",
            "Epoch 56/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6829 - accuracy: 0.5842 - val_loss: 0.7304 - val_accuracy: 0.2500\n",
            "Epoch 57/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6827 - accuracy: 0.5985 - val_loss: 0.7337 - val_accuracy: 0.2500\n",
            "Epoch 58/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6827 - accuracy: 0.5842 - val_loss: 0.6834 - val_accuracy: 0.5000\n",
            "Epoch 59/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6830 - accuracy: 0.5530 - val_loss: 0.7529 - val_accuracy: 0.0833\n",
            "Epoch 60/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6810 - accuracy: 0.5951 - val_loss: 0.6918 - val_accuracy: 0.3333\n",
            "Epoch 61/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6799 - accuracy: 0.6061 - val_loss: 0.7012 - val_accuracy: 0.3333\n",
            "Epoch 62/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6787 - accuracy: 0.6162 - val_loss: 0.7168 - val_accuracy: 0.3333\n",
            "Epoch 63/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6794 - accuracy: 0.5816 - val_loss: 0.7475 - val_accuracy: 0.2500\n",
            "Epoch 64/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6776 - accuracy: 0.6204 - val_loss: 0.7051 - val_accuracy: 0.3333\n",
            "Epoch 65/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6796 - accuracy: 0.5909 - val_loss: 0.6772 - val_accuracy: 0.5000\n",
            "Epoch 66/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6761 - accuracy: 0.5960 - val_loss: 0.7173 - val_accuracy: 0.3333\n",
            "Epoch 67/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6758 - accuracy: 0.6019 - val_loss: 0.7474 - val_accuracy: 0.2500\n",
            "Epoch 68/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6750 - accuracy: 0.6061 - val_loss: 0.7464 - val_accuracy: 0.3333\n",
            "Epoch 69/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6759 - accuracy: 0.5976 - val_loss: 0.7648 - val_accuracy: 0.2500\n",
            "Epoch 70/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6733 - accuracy: 0.6212 - val_loss: 0.6981 - val_accuracy: 0.3333\n",
            "Epoch 71/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6733 - accuracy: 0.5985 - val_loss: 0.7668 - val_accuracy: 0.3333\n",
            "Epoch 72/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6723 - accuracy: 0.6153 - val_loss: 0.6906 - val_accuracy: 0.3333\n",
            "Epoch 73/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6696 - accuracy: 0.6094 - val_loss: 0.7191 - val_accuracy: 0.3333\n",
            "Epoch 74/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6682 - accuracy: 0.5976 - val_loss: 0.7452 - val_accuracy: 0.3333\n",
            "Epoch 75/1000\n",
            "594/594 [==============================] - 0s 33us/sample - loss: 0.6677 - accuracy: 0.6355 - val_loss: 0.7102 - val_accuracy: 0.3333\n",
            "Epoch 76/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6664 - accuracy: 0.6212 - val_loss: 0.7198 - val_accuracy: 0.3333\n",
            "Epoch 77/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6648 - accuracy: 0.6077 - val_loss: 0.7426 - val_accuracy: 0.3333\n",
            "Epoch 78/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6638 - accuracy: 0.6271 - val_loss: 0.7281 - val_accuracy: 0.3333\n",
            "Epoch 79/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6640 - accuracy: 0.5951 - val_loss: 0.7763 - val_accuracy: 0.3333\n",
            "Epoch 80/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6627 - accuracy: 0.6153 - val_loss: 0.7704 - val_accuracy: 0.3333\n",
            "Epoch 81/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6617 - accuracy: 0.6077 - val_loss: 0.7763 - val_accuracy: 0.3333\n",
            "Epoch 82/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6597 - accuracy: 0.6229 - val_loss: 0.7648 - val_accuracy: 0.3333\n",
            "Epoch 83/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6590 - accuracy: 0.6128 - val_loss: 0.7777 - val_accuracy: 0.3333\n",
            "Epoch 84/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6570 - accuracy: 0.6322 - val_loss: 0.7482 - val_accuracy: 0.3333\n",
            "Epoch 85/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6580 - accuracy: 0.6052 - val_loss: 0.8014 - val_accuracy: 0.3333\n",
            "Epoch 86/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6554 - accuracy: 0.6448 - val_loss: 0.7424 - val_accuracy: 0.3333\n",
            "Epoch 87/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.6547 - accuracy: 0.6237 - val_loss: 0.7396 - val_accuracy: 0.3333\n",
            "Epoch 88/1000\n",
            "594/594 [==============================] - 0s 40us/sample - loss: 0.6532 - accuracy: 0.6077 - val_loss: 0.7894 - val_accuracy: 0.3333\n",
            "Epoch 89/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6531 - accuracy: 0.6389 - val_loss: 0.7365 - val_accuracy: 0.3333\n",
            "Epoch 90/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6525 - accuracy: 0.6271 - val_loss: 0.7452 - val_accuracy: 0.3333\n",
            "Epoch 91/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6516 - accuracy: 0.6094 - val_loss: 0.8165 - val_accuracy: 0.3333\n",
            "Epoch 92/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6510 - accuracy: 0.6389 - val_loss: 0.7410 - val_accuracy: 0.3333\n",
            "Epoch 93/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6498 - accuracy: 0.6086 - val_loss: 0.8210 - val_accuracy: 0.3333\n",
            "Epoch 94/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6533 - accuracy: 0.6296 - val_loss: 0.7180 - val_accuracy: 0.3333\n",
            "Epoch 95/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6489 - accuracy: 0.6111 - val_loss: 0.7708 - val_accuracy: 0.3333\n",
            "Epoch 96/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6463 - accuracy: 0.6178 - val_loss: 0.7965 - val_accuracy: 0.3333\n",
            "Epoch 97/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6460 - accuracy: 0.6136 - val_loss: 0.8103 - val_accuracy: 0.3333\n",
            "Epoch 98/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6463 - accuracy: 0.6187 - val_loss: 0.8290 - val_accuracy: 0.3333\n",
            "Epoch 99/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6448 - accuracy: 0.6279 - val_loss: 0.8026 - val_accuracy: 0.3333\n",
            "Epoch 100/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6447 - accuracy: 0.6195 - val_loss: 0.8279 - val_accuracy: 0.3333\n",
            "Epoch 101/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6438 - accuracy: 0.6322 - val_loss: 0.8027 - val_accuracy: 0.3333\n",
            "Epoch 102/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6432 - accuracy: 0.6178 - val_loss: 0.8080 - val_accuracy: 0.3333\n",
            "Epoch 103/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6435 - accuracy: 0.6178 - val_loss: 0.8365 - val_accuracy: 0.3333\n",
            "Epoch 104/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6428 - accuracy: 0.6178 - val_loss: 0.8234 - val_accuracy: 0.3333\n",
            "Epoch 105/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6427 - accuracy: 0.6288 - val_loss: 0.7932 - val_accuracy: 0.3333\n",
            "Epoch 106/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6450 - accuracy: 0.6305 - val_loss: 0.7699 - val_accuracy: 0.3333\n",
            "Epoch 107/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6442 - accuracy: 0.6061 - val_loss: 0.7825 - val_accuracy: 0.3333\n",
            "Epoch 108/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6416 - accuracy: 0.6145 - val_loss: 0.8288 - val_accuracy: 0.3333\n",
            "Epoch 109/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6410 - accuracy: 0.6246 - val_loss: 0.8258 - val_accuracy: 0.3333\n",
            "Epoch 110/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6410 - accuracy: 0.6145 - val_loss: 0.8402 - val_accuracy: 0.3333\n",
            "Epoch 111/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6407 - accuracy: 0.6279 - val_loss: 0.8385 - val_accuracy: 0.3333\n",
            "Epoch 112/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6421 - accuracy: 0.6111 - val_loss: 0.8689 - val_accuracy: 0.3333\n",
            "Epoch 113/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6407 - accuracy: 0.6364 - val_loss: 0.8070 - val_accuracy: 0.3333\n",
            "Epoch 114/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6400 - accuracy: 0.6128 - val_loss: 0.8372 - val_accuracy: 0.3333\n",
            "Epoch 115/1000\n",
            "594/594 [==============================] - 0s 39us/sample - loss: 0.6398 - accuracy: 0.6195 - val_loss: 0.8361 - val_accuracy: 0.3333\n",
            "Epoch 116/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6396 - accuracy: 0.6237 - val_loss: 0.8285 - val_accuracy: 0.3333\n",
            "Epoch 117/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6395 - accuracy: 0.6221 - val_loss: 0.8475 - val_accuracy: 0.3333\n",
            "Epoch 118/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6396 - accuracy: 0.6229 - val_loss: 0.8538 - val_accuracy: 0.3333\n",
            "Epoch 119/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6443 - accuracy: 0.6313 - val_loss: 0.7656 - val_accuracy: 0.3333\n",
            "Epoch 120/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6398 - accuracy: 0.6120 - val_loss: 0.8387 - val_accuracy: 0.3333\n",
            "Epoch 121/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6397 - accuracy: 0.6246 - val_loss: 0.8074 - val_accuracy: 0.3333\n",
            "Epoch 122/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6387 - accuracy: 0.6162 - val_loss: 0.8458 - val_accuracy: 0.3333\n",
            "Epoch 123/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6387 - accuracy: 0.6246 - val_loss: 0.8554 - val_accuracy: 0.3333\n",
            "Epoch 124/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6389 - accuracy: 0.6204 - val_loss: 0.8656 - val_accuracy: 0.3333\n",
            "Epoch 125/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6381 - accuracy: 0.6229 - val_loss: 0.8431 - val_accuracy: 0.3333\n",
            "Epoch 126/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6381 - accuracy: 0.6195 - val_loss: 0.8497 - val_accuracy: 0.3333\n",
            "Epoch 127/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6385 - accuracy: 0.6195 - val_loss: 0.8697 - val_accuracy: 0.3333\n",
            "Epoch 128/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6394 - accuracy: 0.6237 - val_loss: 0.8783 - val_accuracy: 0.3333\n",
            "Epoch 129/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6375 - accuracy: 0.6313 - val_loss: 0.8362 - val_accuracy: 0.3333\n",
            "Epoch 130/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6390 - accuracy: 0.6296 - val_loss: 0.8008 - val_accuracy: 0.3333\n",
            "Epoch 131/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6374 - accuracy: 0.6120 - val_loss: 0.8584 - val_accuracy: 0.3333\n",
            "Epoch 132/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6380 - accuracy: 0.6120 - val_loss: 0.8769 - val_accuracy: 0.3333\n",
            "Epoch 133/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6451 - accuracy: 0.6229 - val_loss: 0.9322 - val_accuracy: 0.1667\n",
            "Epoch 134/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6381 - accuracy: 0.6507 - val_loss: 0.8082 - val_accuracy: 0.3333\n",
            "Epoch 135/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6395 - accuracy: 0.6305 - val_loss: 0.7931 - val_accuracy: 0.3333\n",
            "Epoch 136/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6364 - accuracy: 0.6221 - val_loss: 0.8450 - val_accuracy: 0.3333\n",
            "Epoch 137/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6359 - accuracy: 0.6254 - val_loss: 0.8350 - val_accuracy: 0.3333\n",
            "Epoch 138/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6357 - accuracy: 0.6187 - val_loss: 0.8492 - val_accuracy: 0.3333\n",
            "Epoch 139/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6373 - accuracy: 0.6355 - val_loss: 0.7974 - val_accuracy: 0.3333\n",
            "Epoch 140/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6358 - accuracy: 0.6212 - val_loss: 0.8457 - val_accuracy: 0.3333\n",
            "Epoch 141/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6360 - accuracy: 0.6347 - val_loss: 0.8107 - val_accuracy: 0.3333\n",
            "Epoch 142/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6390 - accuracy: 0.6263 - val_loss: 0.7839 - val_accuracy: 0.3333\n",
            "Epoch 143/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6357 - accuracy: 0.6120 - val_loss: 0.8638 - val_accuracy: 0.3333\n",
            "Epoch 144/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6354 - accuracy: 0.6246 - val_loss: 0.8613 - val_accuracy: 0.3333\n",
            "Epoch 145/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6353 - accuracy: 0.6414 - val_loss: 0.8113 - val_accuracy: 0.3333\n",
            "Epoch 146/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6352 - accuracy: 0.6237 - val_loss: 0.8186 - val_accuracy: 0.3333\n",
            "Epoch 147/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6373 - accuracy: 0.6305 - val_loss: 0.7886 - val_accuracy: 0.3333\n",
            "Epoch 148/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6355 - accuracy: 0.6246 - val_loss: 0.8163 - val_accuracy: 0.3333\n",
            "Epoch 149/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6341 - accuracy: 0.6128 - val_loss: 0.8540 - val_accuracy: 0.3333\n",
            "Epoch 150/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6342 - accuracy: 0.6338 - val_loss: 0.8521 - val_accuracy: 0.3333\n",
            "Epoch 151/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6342 - accuracy: 0.6254 - val_loss: 0.8595 - val_accuracy: 0.3333\n",
            "Epoch 152/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6362 - accuracy: 0.6212 - val_loss: 0.8862 - val_accuracy: 0.3333\n",
            "Epoch 153/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6349 - accuracy: 0.6288 - val_loss: 0.8634 - val_accuracy: 0.3333\n",
            "Epoch 154/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6336 - accuracy: 0.6338 - val_loss: 0.8472 - val_accuracy: 0.3333\n",
            "Epoch 155/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6347 - accuracy: 0.6237 - val_loss: 0.8749 - val_accuracy: 0.3333\n",
            "Epoch 156/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6330 - accuracy: 0.6490 - val_loss: 0.8237 - val_accuracy: 0.3333\n",
            "Epoch 157/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6328 - accuracy: 0.6237 - val_loss: 0.8464 - val_accuracy: 0.3333\n",
            "Epoch 158/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6337 - accuracy: 0.6423 - val_loss: 0.7949 - val_accuracy: 0.3333\n",
            "Epoch 159/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6324 - accuracy: 0.6145 - val_loss: 0.8394 - val_accuracy: 0.3333\n",
            "Epoch 160/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6320 - accuracy: 0.6355 - val_loss: 0.8300 - val_accuracy: 0.3333\n",
            "Epoch 161/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6326 - accuracy: 0.6279 - val_loss: 0.8585 - val_accuracy: 0.3333\n",
            "Epoch 162/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6334 - accuracy: 0.6389 - val_loss: 0.8638 - val_accuracy: 0.3333\n",
            "Epoch 163/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6340 - accuracy: 0.6288 - val_loss: 0.8739 - val_accuracy: 0.3333\n",
            "Epoch 164/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6316 - accuracy: 0.6507 - val_loss: 0.8208 - val_accuracy: 0.3333\n",
            "Epoch 165/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6321 - accuracy: 0.6515 - val_loss: 0.7962 - val_accuracy: 0.3333\n",
            "Epoch 166/1000\n",
            "594/594 [==============================] - 0s 20us/sample - loss: 0.6312 - accuracy: 0.6338 - val_loss: 0.8205 - val_accuracy: 0.3333\n",
            "Epoch 167/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6326 - accuracy: 0.6397 - val_loss: 0.7809 - val_accuracy: 0.3333\n",
            "Epoch 168/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6316 - accuracy: 0.6111 - val_loss: 0.8635 - val_accuracy: 0.3333\n",
            "Epoch 169/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6346 - accuracy: 0.6288 - val_loss: 0.8849 - val_accuracy: 0.3333\n",
            "Epoch 170/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6309 - accuracy: 0.6574 - val_loss: 0.7958 - val_accuracy: 0.3333\n",
            "Epoch 171/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6301 - accuracy: 0.6246 - val_loss: 0.8281 - val_accuracy: 0.3333\n",
            "Epoch 172/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6299 - accuracy: 0.6439 - val_loss: 0.8101 - val_accuracy: 0.3333\n",
            "Epoch 173/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6307 - accuracy: 0.6246 - val_loss: 0.8561 - val_accuracy: 0.3333\n",
            "Epoch 174/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6303 - accuracy: 0.6582 - val_loss: 0.7890 - val_accuracy: 0.3333\n",
            "Epoch 175/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6335 - accuracy: 0.6322 - val_loss: 0.7606 - val_accuracy: 0.4167\n",
            "Epoch 176/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6379 - accuracy: 0.6229 - val_loss: 0.7373 - val_accuracy: 0.5000\n",
            "Epoch 177/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6317 - accuracy: 0.6237 - val_loss: 0.7944 - val_accuracy: 0.3333\n",
            "Epoch 178/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6331 - accuracy: 0.6338 - val_loss: 0.7572 - val_accuracy: 0.4167\n",
            "Epoch 179/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6295 - accuracy: 0.6195 - val_loss: 0.8469 - val_accuracy: 0.3333\n",
            "Epoch 180/1000\n",
            "594/594 [==============================] - 0s 36us/sample - loss: 0.6287 - accuracy: 0.6616 - val_loss: 0.8147 - val_accuracy: 0.3333\n",
            "Epoch 181/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6312 - accuracy: 0.6296 - val_loss: 0.8787 - val_accuracy: 0.3333\n",
            "Epoch 182/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6289 - accuracy: 0.6490 - val_loss: 0.8159 - val_accuracy: 0.3333\n",
            "Epoch 183/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6300 - accuracy: 0.6162 - val_loss: 0.8654 - val_accuracy: 0.3333\n",
            "Epoch 184/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6292 - accuracy: 0.6490 - val_loss: 0.8397 - val_accuracy: 0.3333\n",
            "Epoch 185/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6315 - accuracy: 0.6515 - val_loss: 0.7475 - val_accuracy: 0.5000\n",
            "Epoch 186/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6283 - accuracy: 0.6271 - val_loss: 0.8234 - val_accuracy: 0.3333\n",
            "Epoch 187/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6294 - accuracy: 0.6296 - val_loss: 0.8530 - val_accuracy: 0.3333\n",
            "Epoch 188/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6290 - accuracy: 0.6599 - val_loss: 0.7635 - val_accuracy: 0.3333\n",
            "Epoch 189/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6279 - accuracy: 0.6212 - val_loss: 0.8045 - val_accuracy: 0.3333\n",
            "Epoch 190/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6277 - accuracy: 0.6524 - val_loss: 0.7879 - val_accuracy: 0.3333\n",
            "Epoch 191/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6276 - accuracy: 0.6296 - val_loss: 0.8496 - val_accuracy: 0.3333\n",
            "Epoch 192/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6268 - accuracy: 0.6608 - val_loss: 0.8005 - val_accuracy: 0.3333\n",
            "Epoch 193/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6269 - accuracy: 0.6532 - val_loss: 0.7932 - val_accuracy: 0.3333\n",
            "Epoch 194/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6263 - accuracy: 0.6431 - val_loss: 0.8213 - val_accuracy: 0.3333\n",
            "Epoch 195/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6283 - accuracy: 0.6557 - val_loss: 0.7575 - val_accuracy: 0.3333\n",
            "Epoch 196/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6274 - accuracy: 0.6271 - val_loss: 0.7878 - val_accuracy: 0.3333\n",
            "Epoch 197/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6348 - accuracy: 0.6296 - val_loss: 0.9247 - val_accuracy: 0.1667\n",
            "Epoch 198/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6288 - accuracy: 0.6591 - val_loss: 0.8175 - val_accuracy: 0.3333\n",
            "Epoch 199/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6257 - accuracy: 0.6498 - val_loss: 0.8106 - val_accuracy: 0.3333\n",
            "Epoch 200/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6282 - accuracy: 0.6524 - val_loss: 0.7469 - val_accuracy: 0.4167\n",
            "Epoch 201/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6266 - accuracy: 0.6338 - val_loss: 0.7881 - val_accuracy: 0.3333\n",
            "Epoch 202/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6272 - accuracy: 0.6296 - val_loss: 0.8630 - val_accuracy: 0.3333\n",
            "Epoch 203/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6269 - accuracy: 0.6574 - val_loss: 0.7459 - val_accuracy: 0.4167\n",
            "Epoch 204/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6280 - accuracy: 0.6372 - val_loss: 0.7571 - val_accuracy: 0.3333\n",
            "Epoch 205/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6268 - accuracy: 0.6162 - val_loss: 0.8673 - val_accuracy: 0.3333\n",
            "Epoch 206/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6249 - accuracy: 0.6616 - val_loss: 0.7794 - val_accuracy: 0.3333\n",
            "Epoch 207/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6252 - accuracy: 0.6254 - val_loss: 0.8415 - val_accuracy: 0.3333\n",
            "Epoch 208/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6263 - accuracy: 0.6372 - val_loss: 0.8430 - val_accuracy: 0.3333\n",
            "Epoch 209/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6243 - accuracy: 0.6557 - val_loss: 0.8089 - val_accuracy: 0.3333\n",
            "Epoch 210/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6296 - accuracy: 0.6246 - val_loss: 0.8878 - val_accuracy: 0.2500\n",
            "Epoch 211/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6276 - accuracy: 0.6355 - val_loss: 0.8391 - val_accuracy: 0.3333\n",
            "Epoch 212/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6233 - accuracy: 0.6591 - val_loss: 0.7849 - val_accuracy: 0.3333\n",
            "Epoch 213/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6233 - accuracy: 0.6389 - val_loss: 0.8282 - val_accuracy: 0.3333\n",
            "Epoch 214/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6230 - accuracy: 0.6625 - val_loss: 0.7563 - val_accuracy: 0.3333\n",
            "Epoch 215/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6222 - accuracy: 0.6355 - val_loss: 0.8010 - val_accuracy: 0.3333\n",
            "Epoch 216/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6218 - accuracy: 0.6591 - val_loss: 0.7808 - val_accuracy: 0.3333\n",
            "Epoch 217/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6237 - accuracy: 0.6524 - val_loss: 0.7389 - val_accuracy: 0.4167\n",
            "Epoch 218/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6249 - accuracy: 0.6279 - val_loss: 0.7390 - val_accuracy: 0.4167\n",
            "Epoch 219/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6226 - accuracy: 0.6380 - val_loss: 0.7607 - val_accuracy: 0.3333\n",
            "Epoch 220/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6216 - accuracy: 0.6296 - val_loss: 0.8283 - val_accuracy: 0.3333\n",
            "Epoch 221/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6210 - accuracy: 0.6608 - val_loss: 0.7683 - val_accuracy: 0.3333\n",
            "Epoch 222/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6212 - accuracy: 0.6591 - val_loss: 0.7559 - val_accuracy: 0.3333\n",
            "Epoch 223/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6255 - accuracy: 0.6111 - val_loss: 0.8855 - val_accuracy: 0.1667\n",
            "Epoch 224/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6233 - accuracy: 0.6557 - val_loss: 0.8109 - val_accuracy: 0.3333\n",
            "Epoch 225/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6255 - accuracy: 0.6338 - val_loss: 0.8715 - val_accuracy: 0.1667\n",
            "Epoch 226/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6242 - accuracy: 0.6473 - val_loss: 0.8368 - val_accuracy: 0.3333\n",
            "Epoch 227/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6200 - accuracy: 0.6675 - val_loss: 0.7939 - val_accuracy: 0.3333\n",
            "Epoch 228/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6194 - accuracy: 0.6574 - val_loss: 0.8059 - val_accuracy: 0.3333\n",
            "Epoch 229/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6194 - accuracy: 0.6599 - val_loss: 0.7527 - val_accuracy: 0.3333\n",
            "Epoch 230/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6193 - accuracy: 0.6507 - val_loss: 0.7844 - val_accuracy: 0.3333\n",
            "Epoch 231/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6191 - accuracy: 0.6549 - val_loss: 0.7506 - val_accuracy: 0.3333\n",
            "Epoch 232/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6182 - accuracy: 0.6406 - val_loss: 0.7969 - val_accuracy: 0.3333\n",
            "Epoch 233/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6184 - accuracy: 0.6616 - val_loss: 0.7590 - val_accuracy: 0.3333\n",
            "Epoch 234/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6178 - accuracy: 0.6490 - val_loss: 0.7694 - val_accuracy: 0.3333\n",
            "Epoch 235/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6206 - accuracy: 0.6549 - val_loss: 0.7211 - val_accuracy: 0.5833\n",
            "Epoch 236/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6176 - accuracy: 0.6431 - val_loss: 0.7984 - val_accuracy: 0.3333\n",
            "Epoch 237/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6179 - accuracy: 0.6372 - val_loss: 0.8297 - val_accuracy: 0.3333\n",
            "Epoch 238/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.6182 - accuracy: 0.6355 - val_loss: 0.8229 - val_accuracy: 0.3333\n",
            "Epoch 239/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6229 - accuracy: 0.6414 - val_loss: 0.8816 - val_accuracy: 0.1667\n",
            "Epoch 240/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6215 - accuracy: 0.6221 - val_loss: 0.8490 - val_accuracy: 0.3333\n",
            "Epoch 241/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6165 - accuracy: 0.6566 - val_loss: 0.8025 - val_accuracy: 0.3333\n",
            "Epoch 242/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6151 - accuracy: 0.6633 - val_loss: 0.7706 - val_accuracy: 0.3333\n",
            "Epoch 243/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6149 - accuracy: 0.6515 - val_loss: 0.8086 - val_accuracy: 0.3333\n",
            "Epoch 244/1000\n",
            "594/594 [==============================] - 0s 41us/sample - loss: 0.6164 - accuracy: 0.6414 - val_loss: 0.8369 - val_accuracy: 0.3333\n",
            "Epoch 245/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6162 - accuracy: 0.6330 - val_loss: 0.8289 - val_accuracy: 0.3333\n",
            "Epoch 246/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6142 - accuracy: 0.6540 - val_loss: 0.7587 - val_accuracy: 0.3333\n",
            "Epoch 247/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6139 - accuracy: 0.6507 - val_loss: 0.7827 - val_accuracy: 0.3333\n",
            "Epoch 248/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6137 - accuracy: 0.6608 - val_loss: 0.7639 - val_accuracy: 0.3333\n",
            "Epoch 249/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6132 - accuracy: 0.6439 - val_loss: 0.8100 - val_accuracy: 0.3333\n",
            "Epoch 250/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6130 - accuracy: 0.6540 - val_loss: 0.8070 - val_accuracy: 0.3333\n",
            "Epoch 251/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6141 - accuracy: 0.6431 - val_loss: 0.8414 - val_accuracy: 0.3333\n",
            "Epoch 252/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6126 - accuracy: 0.6549 - val_loss: 0.7624 - val_accuracy: 0.3333\n",
            "Epoch 253/1000\n",
            "594/594 [==============================] - 0s 39us/sample - loss: 0.6118 - accuracy: 0.6431 - val_loss: 0.7991 - val_accuracy: 0.3333\n",
            "Epoch 254/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6116 - accuracy: 0.6641 - val_loss: 0.7729 - val_accuracy: 0.3333\n",
            "Epoch 255/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6116 - accuracy: 0.6448 - val_loss: 0.8266 - val_accuracy: 0.3333\n",
            "Epoch 256/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6156 - accuracy: 0.6557 - val_loss: 0.6874 - val_accuracy: 0.6667\n",
            "Epoch 257/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6157 - accuracy: 0.6633 - val_loss: 0.7472 - val_accuracy: 0.5000\n",
            "Epoch 258/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6108 - accuracy: 0.6473 - val_loss: 0.8046 - val_accuracy: 0.3333\n",
            "Epoch 259/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6098 - accuracy: 0.6566 - val_loss: 0.8029 - val_accuracy: 0.3333\n",
            "Epoch 260/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6109 - accuracy: 0.6414 - val_loss: 0.8371 - val_accuracy: 0.3333\n",
            "Epoch 261/1000\n",
            "594/594 [==============================] - 0s 36us/sample - loss: 0.6105 - accuracy: 0.6582 - val_loss: 0.7219 - val_accuracy: 0.6667\n",
            "Epoch 262/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.6108 - accuracy: 0.6431 - val_loss: 0.7763 - val_accuracy: 0.3333\n",
            "Epoch 263/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.6100 - accuracy: 0.6658 - val_loss: 0.7322 - val_accuracy: 0.5833\n",
            "Epoch 264/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6081 - accuracy: 0.6465 - val_loss: 0.8022 - val_accuracy: 0.3333\n",
            "Epoch 265/1000\n",
            "594/594 [==============================] - 0s 34us/sample - loss: 0.6099 - accuracy: 0.6473 - val_loss: 0.8578 - val_accuracy: 0.3333\n",
            "Epoch 266/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6073 - accuracy: 0.6549 - val_loss: 0.7664 - val_accuracy: 0.3333\n",
            "Epoch 267/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6061 - accuracy: 0.6616 - val_loss: 0.8036 - val_accuracy: 0.3333\n",
            "Epoch 268/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6065 - accuracy: 0.6574 - val_loss: 0.8217 - val_accuracy: 0.3333\n",
            "Epoch 269/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6072 - accuracy: 0.6540 - val_loss: 0.7108 - val_accuracy: 0.6667\n",
            "Epoch 270/1000\n",
            "594/594 [==============================] - 0s 37us/sample - loss: 0.6075 - accuracy: 0.6389 - val_loss: 0.7531 - val_accuracy: 0.4167\n",
            "Epoch 271/1000\n",
            "594/594 [==============================] - 0s 35us/sample - loss: 0.6045 - accuracy: 0.6557 - val_loss: 0.8105 - val_accuracy: 0.3333\n",
            "Epoch 272/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6046 - accuracy: 0.6582 - val_loss: 0.8194 - val_accuracy: 0.3333\n",
            "Epoch 273/1000\n",
            "594/594 [==============================] - 0s 33us/sample - loss: 0.6034 - accuracy: 0.6566 - val_loss: 0.7811 - val_accuracy: 0.3333\n",
            "Epoch 274/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6029 - accuracy: 0.6616 - val_loss: 0.7779 - val_accuracy: 0.3333\n",
            "Epoch 275/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6024 - accuracy: 0.6599 - val_loss: 0.8167 - val_accuracy: 0.3333\n",
            "Epoch 276/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.6039 - accuracy: 0.6448 - val_loss: 0.8412 - val_accuracy: 0.3333\n",
            "Epoch 277/1000\n",
            "297/594 [==============>...............] - ETA: 0s - loss: 0.5978 - accuracy: 0.6566\n",
            "Epoch 00277: ReduceLROnPlateau reducing learning rate to 0.5.\n",
            "594/594 [==============================] - 0s 35us/sample - loss: 0.6036 - accuracy: 0.6591 - val_loss: 0.6870 - val_accuracy: 0.6667\n",
            "Epoch 278/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6026 - accuracy: 0.6540 - val_loss: 0.7765 - val_accuracy: 0.3333\n",
            "Epoch 279/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.5999 - accuracy: 0.6608 - val_loss: 0.7802 - val_accuracy: 0.3333\n",
            "Epoch 280/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6004 - accuracy: 0.6684 - val_loss: 0.7974 - val_accuracy: 0.3333\n",
            "Epoch 281/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6008 - accuracy: 0.6608 - val_loss: 0.7645 - val_accuracy: 0.3333\n",
            "Epoch 282/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5991 - accuracy: 0.6608 - val_loss: 0.7781 - val_accuracy: 0.3333\n",
            "Epoch 283/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5983 - accuracy: 0.6633 - val_loss: 0.7816 - val_accuracy: 0.3333\n",
            "Epoch 284/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5981 - accuracy: 0.6599 - val_loss: 0.8008 - val_accuracy: 0.3333\n",
            "Epoch 285/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6005 - accuracy: 0.6557 - val_loss: 0.8296 - val_accuracy: 0.3333\n",
            "Epoch 286/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5975 - accuracy: 0.6524 - val_loss: 0.8067 - val_accuracy: 0.3333\n",
            "Epoch 287/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5966 - accuracy: 0.6616 - val_loss: 0.7944 - val_accuracy: 0.3333\n",
            "Epoch 288/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5967 - accuracy: 0.6608 - val_loss: 0.8116 - val_accuracy: 0.3333\n",
            "Epoch 289/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5960 - accuracy: 0.6633 - val_loss: 0.7903 - val_accuracy: 0.3333\n",
            "Epoch 290/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5953 - accuracy: 0.6625 - val_loss: 0.7985 - val_accuracy: 0.3333\n",
            "Epoch 291/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5955 - accuracy: 0.6599 - val_loss: 0.7836 - val_accuracy: 0.3333\n",
            "Epoch 292/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.5945 - accuracy: 0.6641 - val_loss: 0.8011 - val_accuracy: 0.3333\n",
            "Epoch 293/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5940 - accuracy: 0.6633 - val_loss: 0.8098 - val_accuracy: 0.3333\n",
            "Epoch 294/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5942 - accuracy: 0.6574 - val_loss: 0.8216 - val_accuracy: 0.3333\n",
            "Epoch 295/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.5934 - accuracy: 0.6625 - val_loss: 0.8062 - val_accuracy: 0.3333\n",
            "Epoch 296/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5933 - accuracy: 0.6641 - val_loss: 0.7933 - val_accuracy: 0.3333\n",
            "Epoch 297/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5929 - accuracy: 0.6591 - val_loss: 0.8240 - val_accuracy: 0.3333\n",
            "Epoch 298/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5919 - accuracy: 0.6658 - val_loss: 0.8181 - val_accuracy: 0.3333\n",
            "Epoch 299/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5963 - accuracy: 0.6574 - val_loss: 0.7671 - val_accuracy: 0.3333\n",
            "Epoch 300/1000\n",
            "594/594 [==============================] - 0s 35us/sample - loss: 0.5913 - accuracy: 0.6633 - val_loss: 0.8060 - val_accuracy: 0.3333\n",
            "Epoch 301/1000\n",
            "594/594 [==============================] - 0s 33us/sample - loss: 0.5909 - accuracy: 0.6658 - val_loss: 0.8334 - val_accuracy: 0.3333\n",
            "Epoch 302/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5898 - accuracy: 0.6667 - val_loss: 0.8245 - val_accuracy: 0.3333\n",
            "Epoch 303/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5894 - accuracy: 0.6633 - val_loss: 0.8297 - val_accuracy: 0.3333\n",
            "Epoch 304/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5923 - accuracy: 0.6684 - val_loss: 0.8621 - val_accuracy: 0.3333\n",
            "Epoch 305/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.5889 - accuracy: 0.6684 - val_loss: 0.8326 - val_accuracy: 0.3333\n",
            "Epoch 306/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5881 - accuracy: 0.6658 - val_loss: 0.8334 - val_accuracy: 0.3333\n",
            "Epoch 307/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.5900 - accuracy: 0.6700 - val_loss: 0.8583 - val_accuracy: 0.3333\n",
            "Epoch 308/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5876 - accuracy: 0.6650 - val_loss: 0.8352 - val_accuracy: 0.3333\n",
            "Epoch 309/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5873 - accuracy: 0.6658 - val_loss: 0.8035 - val_accuracy: 0.3333\n",
            "Epoch 310/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5864 - accuracy: 0.6650 - val_loss: 0.8061 - val_accuracy: 0.3333\n",
            "Epoch 311/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5866 - accuracy: 0.6625 - val_loss: 0.8075 - val_accuracy: 0.3333\n",
            "Epoch 312/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5859 - accuracy: 0.6599 - val_loss: 0.8041 - val_accuracy: 0.3333\n",
            "Epoch 313/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.5852 - accuracy: 0.6650 - val_loss: 0.8372 - val_accuracy: 0.3333\n",
            "Epoch 314/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5843 - accuracy: 0.6658 - val_loss: 0.8252 - val_accuracy: 0.3333\n",
            "Epoch 315/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5841 - accuracy: 0.6684 - val_loss: 0.8205 - val_accuracy: 0.3333\n",
            "Epoch 316/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.5853 - accuracy: 0.6667 - val_loss: 0.8524 - val_accuracy: 0.3333\n",
            "Epoch 317/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5841 - accuracy: 0.6684 - val_loss: 0.8393 - val_accuracy: 0.3333\n",
            "Epoch 318/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5828 - accuracy: 0.6667 - val_loss: 0.8309 - val_accuracy: 0.3333\n",
            "Epoch 319/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5837 - accuracy: 0.6616 - val_loss: 0.8511 - val_accuracy: 0.3333\n",
            "Epoch 320/1000\n",
            "594/594 [==============================] - 0s 33us/sample - loss: 0.5821 - accuracy: 0.6667 - val_loss: 0.8278 - val_accuracy: 0.3333\n",
            "Epoch 321/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5835 - accuracy: 0.6675 - val_loss: 0.8596 - val_accuracy: 0.3333\n",
            "Epoch 322/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5813 - accuracy: 0.6709 - val_loss: 0.8343 - val_accuracy: 0.3333\n",
            "Epoch 323/1000\n",
            "594/594 [==============================] - 0s 36us/sample - loss: 0.5804 - accuracy: 0.6667 - val_loss: 0.8227 - val_accuracy: 0.3333\n",
            "Epoch 324/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.5804 - accuracy: 0.6675 - val_loss: 0.8410 - val_accuracy: 0.3333\n",
            "Epoch 325/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.5799 - accuracy: 0.6633 - val_loss: 0.8306 - val_accuracy: 0.3333\n",
            "Epoch 326/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5808 - accuracy: 0.6591 - val_loss: 0.7901 - val_accuracy: 0.3333\n",
            "Epoch 327/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.5819 - accuracy: 0.6675 - val_loss: 0.7833 - val_accuracy: 0.3333\n",
            "Epoch 328/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5791 - accuracy: 0.6633 - val_loss: 0.8085 - val_accuracy: 0.3333\n",
            "Epoch 329/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5780 - accuracy: 0.6616 - val_loss: 0.8197 - val_accuracy: 0.3333\n",
            "Epoch 330/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5805 - accuracy: 0.6667 - val_loss: 0.7817 - val_accuracy: 0.3333\n",
            "Epoch 331/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5785 - accuracy: 0.6599 - val_loss: 0.7988 - val_accuracy: 0.3333\n",
            "Epoch 332/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5774 - accuracy: 0.6675 - val_loss: 0.8468 - val_accuracy: 0.3333\n",
            "Epoch 333/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5780 - accuracy: 0.6599 - val_loss: 0.7886 - val_accuracy: 0.3333\n",
            "Epoch 334/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5760 - accuracy: 0.6658 - val_loss: 0.8352 - val_accuracy: 0.3333\n",
            "Epoch 335/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5776 - accuracy: 0.6608 - val_loss: 0.7835 - val_accuracy: 0.3333\n",
            "Epoch 336/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5755 - accuracy: 0.6675 - val_loss: 0.8054 - val_accuracy: 0.3333\n",
            "Epoch 337/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5749 - accuracy: 0.6684 - val_loss: 0.8057 - val_accuracy: 0.3333\n",
            "Epoch 338/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5763 - accuracy: 0.6625 - val_loss: 0.7818 - val_accuracy: 0.3333\n",
            "Epoch 339/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5756 - accuracy: 0.6658 - val_loss: 0.7933 - val_accuracy: 0.3333\n",
            "Epoch 340/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5750 - accuracy: 0.6641 - val_loss: 0.8606 - val_accuracy: 0.3333\n",
            "Epoch 341/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5728 - accuracy: 0.6684 - val_loss: 0.8329 - val_accuracy: 0.3333\n",
            "Epoch 342/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.5719 - accuracy: 0.6641 - val_loss: 0.8085 - val_accuracy: 0.3333\n",
            "Epoch 343/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5719 - accuracy: 0.6667 - val_loss: 0.8094 - val_accuracy: 0.3333\n",
            "Epoch 344/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5713 - accuracy: 0.6692 - val_loss: 0.8421 - val_accuracy: 0.3333\n",
            "Epoch 345/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5705 - accuracy: 0.6684 - val_loss: 0.8347 - val_accuracy: 0.3333\n",
            "Epoch 346/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5699 - accuracy: 0.6582 - val_loss: 0.8246 - val_accuracy: 0.3333\n",
            "Epoch 347/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5702 - accuracy: 0.6675 - val_loss: 0.8154 - val_accuracy: 0.3333\n",
            "Epoch 348/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5686 - accuracy: 0.6658 - val_loss: 0.8230 - val_accuracy: 0.3333\n",
            "Epoch 349/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.5693 - accuracy: 0.6633 - val_loss: 0.8450 - val_accuracy: 0.3333\n",
            "Epoch 350/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.5685 - accuracy: 0.6658 - val_loss: 0.8383 - val_accuracy: 0.3333\n",
            "Epoch 351/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5676 - accuracy: 0.6574 - val_loss: 0.8100 - val_accuracy: 0.3333\n",
            "Epoch 352/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5667 - accuracy: 0.6675 - val_loss: 0.8250 - val_accuracy: 0.3333\n",
            "Epoch 353/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5663 - accuracy: 0.6625 - val_loss: 0.8191 - val_accuracy: 0.3333\n",
            "Epoch 354/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5700 - accuracy: 0.6616 - val_loss: 0.7710 - val_accuracy: 0.5000\n",
            "Epoch 355/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5662 - accuracy: 0.6650 - val_loss: 0.8128 - val_accuracy: 0.3333\n",
            "Epoch 356/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5706 - accuracy: 0.6524 - val_loss: 0.7617 - val_accuracy: 0.6667\n",
            "Epoch 357/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.5693 - accuracy: 0.6734 - val_loss: 0.7806 - val_accuracy: 0.3333\n",
            "Epoch 358/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5640 - accuracy: 0.6650 - val_loss: 0.8368 - val_accuracy: 0.3333\n",
            "Epoch 359/1000\n",
            "594/594 [==============================] - 0s 34us/sample - loss: 0.5651 - accuracy: 0.6625 - val_loss: 0.7812 - val_accuracy: 0.3333\n",
            "Epoch 360/1000\n",
            "594/594 [==============================] - 0s 35us/sample - loss: 0.5630 - accuracy: 0.6709 - val_loss: 0.8252 - val_accuracy: 0.3333\n",
            "Epoch 361/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5642 - accuracy: 0.6717 - val_loss: 0.8699 - val_accuracy: 0.3333\n",
            "Epoch 362/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5630 - accuracy: 0.6599 - val_loss: 0.8502 - val_accuracy: 0.3333\n",
            "Epoch 363/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5611 - accuracy: 0.6616 - val_loss: 0.8170 - val_accuracy: 0.3333\n",
            "Epoch 364/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5608 - accuracy: 0.6684 - val_loss: 0.8482 - val_accuracy: 0.3333\n",
            "Epoch 365/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5641 - accuracy: 0.6717 - val_loss: 0.8845 - val_accuracy: 0.3333\n",
            "Epoch 366/1000\n",
            "594/594 [==============================] - 0s 34us/sample - loss: 0.5605 - accuracy: 0.6616 - val_loss: 0.8353 - val_accuracy: 0.3333\n",
            "Epoch 367/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5598 - accuracy: 0.6658 - val_loss: 0.8554 - val_accuracy: 0.3333\n",
            "Epoch 368/1000\n",
            "594/594 [==============================] - 0s 48us/sample - loss: 0.5596 - accuracy: 0.6599 - val_loss: 0.7884 - val_accuracy: 0.3333\n",
            "Epoch 369/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5586 - accuracy: 0.6658 - val_loss: 0.8152 - val_accuracy: 0.3333\n",
            "Epoch 370/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5573 - accuracy: 0.6675 - val_loss: 0.8285 - val_accuracy: 0.3333\n",
            "Epoch 371/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5572 - accuracy: 0.6700 - val_loss: 0.8478 - val_accuracy: 0.3333\n",
            "Epoch 372/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5570 - accuracy: 0.6599 - val_loss: 0.8297 - val_accuracy: 0.3333\n",
            "Epoch 373/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.5570 - accuracy: 0.6625 - val_loss: 0.8533 - val_accuracy: 0.3333\n",
            "Epoch 374/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.5566 - accuracy: 0.6549 - val_loss: 0.7827 - val_accuracy: 0.6667\n",
            "Epoch 375/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5583 - accuracy: 0.6667 - val_loss: 0.7745 - val_accuracy: 0.6667\n",
            "Epoch 376/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5544 - accuracy: 0.6684 - val_loss: 0.8291 - val_accuracy: 0.3333\n",
            "Epoch 377/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.5544 - accuracy: 0.6759 - val_loss: 0.8503 - val_accuracy: 0.3333\n",
            "Epoch 378/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5536 - accuracy: 0.6650 - val_loss: 0.8449 - val_accuracy: 0.3333\n",
            "Epoch 379/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5537 - accuracy: 0.6692 - val_loss: 0.8534 - val_accuracy: 0.3333\n",
            "Epoch 380/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.5545 - accuracy: 0.6582 - val_loss: 0.7737 - val_accuracy: 0.6667\n",
            "Epoch 381/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5525 - accuracy: 0.6776 - val_loss: 0.8138 - val_accuracy: 0.3333\n",
            "Epoch 382/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5526 - accuracy: 0.6549 - val_loss: 0.8003 - val_accuracy: 0.6667\n",
            "Epoch 383/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5510 - accuracy: 0.6768 - val_loss: 0.8585 - val_accuracy: 0.3333\n",
            "Epoch 384/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.5502 - accuracy: 0.6566 - val_loss: 0.7988 - val_accuracy: 0.6667\n",
            "Epoch 385/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.5493 - accuracy: 0.6734 - val_loss: 0.8380 - val_accuracy: 0.3333\n",
            "Epoch 386/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5489 - accuracy: 0.6582 - val_loss: 0.8010 - val_accuracy: 0.5833\n",
            "Epoch 387/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5485 - accuracy: 0.6709 - val_loss: 0.8269 - val_accuracy: 0.3333\n",
            "Epoch 388/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5486 - accuracy: 0.6591 - val_loss: 0.8271 - val_accuracy: 0.3333\n",
            "Epoch 389/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5479 - accuracy: 0.6616 - val_loss: 0.8242 - val_accuracy: 0.3333\n",
            "Epoch 390/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5468 - accuracy: 0.6608 - val_loss: 0.8063 - val_accuracy: 0.5833\n",
            "Epoch 391/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5479 - accuracy: 0.6633 - val_loss: 0.7942 - val_accuracy: 0.6667\n",
            "Epoch 392/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5457 - accuracy: 0.6633 - val_loss: 0.8154 - val_accuracy: 0.5000\n",
            "Epoch 393/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5450 - accuracy: 0.6675 - val_loss: 0.8065 - val_accuracy: 0.5833\n",
            "Epoch 394/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5478 - accuracy: 0.6751 - val_loss: 0.7685 - val_accuracy: 0.6667\n",
            "Epoch 395/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.5469 - accuracy: 0.7037 - val_loss: 0.8932 - val_accuracy: 0.1667\n",
            "Epoch 396/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5472 - accuracy: 0.6625 - val_loss: 0.8621 - val_accuracy: 0.1667\n",
            "Epoch 397/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5436 - accuracy: 0.6650 - val_loss: 0.8122 - val_accuracy: 0.6667\n",
            "Epoch 398/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5423 - accuracy: 0.6734 - val_loss: 0.8310 - val_accuracy: 0.3333\n",
            "Epoch 399/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.5419 - accuracy: 0.6574 - val_loss: 0.7963 - val_accuracy: 0.6667\n",
            "Epoch 400/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.5436 - accuracy: 0.6768 - val_loss: 0.7712 - val_accuracy: 0.6667\n",
            "Epoch 401/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5411 - accuracy: 0.6869 - val_loss: 0.8134 - val_accuracy: 0.6667\n",
            "Epoch 402/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5417 - accuracy: 0.6970 - val_loss: 0.8478 - val_accuracy: 0.1667\n",
            "Epoch 403/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5408 - accuracy: 0.6709 - val_loss: 0.8372 - val_accuracy: 0.1667\n",
            "Epoch 404/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5400 - accuracy: 0.6515 - val_loss: 0.7899 - val_accuracy: 0.6667\n",
            "Epoch 405/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5411 - accuracy: 0.6818 - val_loss: 0.7761 - val_accuracy: 0.6667\n",
            "Epoch 406/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5383 - accuracy: 0.6810 - val_loss: 0.7964 - val_accuracy: 0.6667\n",
            "Epoch 407/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5372 - accuracy: 0.6877 - val_loss: 0.8112 - val_accuracy: 0.6667\n",
            "Epoch 408/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.5369 - accuracy: 0.6818 - val_loss: 0.7908 - val_accuracy: 0.6667\n",
            "Epoch 409/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5406 - accuracy: 0.6709 - val_loss: 0.7457 - val_accuracy: 0.6667\n",
            "Epoch 410/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.5388 - accuracy: 0.6818 - val_loss: 0.7768 - val_accuracy: 0.6667\n",
            "Epoch 411/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.5402 - accuracy: 0.6717 - val_loss: 0.7387 - val_accuracy: 0.6667\n",
            "Epoch 412/1000\n",
            "594/594 [==============================] - 0s 34us/sample - loss: 0.5356 - accuracy: 0.7079 - val_loss: 0.8430 - val_accuracy: 0.3333\n",
            "Epoch 413/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5343 - accuracy: 0.6911 - val_loss: 0.7874 - val_accuracy: 0.6667\n",
            "Epoch 414/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5335 - accuracy: 0.7003 - val_loss: 0.8199 - val_accuracy: 0.5000\n",
            "Epoch 415/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5332 - accuracy: 0.6911 - val_loss: 0.7841 - val_accuracy: 0.6667\n",
            "Epoch 416/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5348 - accuracy: 0.6936 - val_loss: 0.7527 - val_accuracy: 0.6667\n",
            "Epoch 417/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5344 - accuracy: 0.6928 - val_loss: 0.7683 - val_accuracy: 0.6667\n",
            "Epoch 418/1000\n",
            "594/594 [==============================] - 0s 34us/sample - loss: 0.5357 - accuracy: 0.6734 - val_loss: 0.7359 - val_accuracy: 0.6667\n",
            "Epoch 419/1000\n",
            "594/594 [==============================] - 0s 34us/sample - loss: 0.5399 - accuracy: 0.6726 - val_loss: 0.7203 - val_accuracy: 0.6667\n",
            "Epoch 420/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5318 - accuracy: 0.7012 - val_loss: 0.8610 - val_accuracy: 0.3333\n",
            "Epoch 421/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.5301 - accuracy: 0.7088 - val_loss: 0.8024 - val_accuracy: 0.5000\n",
            "Epoch 422/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.5303 - accuracy: 0.6936 - val_loss: 0.7582 - val_accuracy: 0.6667\n",
            "Epoch 423/1000\n",
            "594/594 [==============================] - 0s 20us/sample - loss: 0.5291 - accuracy: 0.6987 - val_loss: 0.8436 - val_accuracy: 0.4167\n",
            "Epoch 424/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5389 - accuracy: 0.6768 - val_loss: 0.9233 - val_accuracy: 0.1667\n",
            "Epoch 425/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5326 - accuracy: 0.6843 - val_loss: 0.8344 - val_accuracy: 0.5000\n",
            "Epoch 426/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5270 - accuracy: 0.7012 - val_loss: 0.8073 - val_accuracy: 0.5000\n",
            "Epoch 427/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5259 - accuracy: 0.7113 - val_loss: 0.7800 - val_accuracy: 0.5000\n",
            "Epoch 428/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5257 - accuracy: 0.7037 - val_loss: 0.7890 - val_accuracy: 0.5000\n",
            "Epoch 429/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5306 - accuracy: 0.6869 - val_loss: 0.7033 - val_accuracy: 0.6667\n",
            "Epoch 430/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.5275 - accuracy: 0.7113 - val_loss: 0.8857 - val_accuracy: 0.2500\n",
            "Epoch 431/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5292 - accuracy: 0.6953 - val_loss: 0.8462 - val_accuracy: 0.4167\n",
            "Epoch 432/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5238 - accuracy: 0.7071 - val_loss: 0.7897 - val_accuracy: 0.5000\n",
            "Epoch 433/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.5235 - accuracy: 0.7079 - val_loss: 0.7814 - val_accuracy: 0.5000\n",
            "Epoch 434/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.5257 - accuracy: 0.6928 - val_loss: 0.7337 - val_accuracy: 0.6667\n",
            "Epoch 435/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5231 - accuracy: 0.7130 - val_loss: 0.8383 - val_accuracy: 0.5000\n",
            "Epoch 436/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5220 - accuracy: 0.7020 - val_loss: 0.7457 - val_accuracy: 0.6667\n",
            "Epoch 437/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.5213 - accuracy: 0.7155 - val_loss: 0.8275 - val_accuracy: 0.5000\n",
            "Epoch 438/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5198 - accuracy: 0.7189 - val_loss: 0.7640 - val_accuracy: 0.5000\n",
            "Epoch 439/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5194 - accuracy: 0.7172 - val_loss: 0.7814 - val_accuracy: 0.5000\n",
            "Epoch 440/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.5190 - accuracy: 0.7256 - val_loss: 0.7996 - val_accuracy: 0.5000\n",
            "Epoch 441/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5189 - accuracy: 0.7146 - val_loss: 0.8069 - val_accuracy: 0.5000\n",
            "Epoch 442/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.5176 - accuracy: 0.7231 - val_loss: 0.7887 - val_accuracy: 0.5000\n",
            "Epoch 443/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.5188 - accuracy: 0.7315 - val_loss: 0.8458 - val_accuracy: 0.5000\n",
            "Epoch 444/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5214 - accuracy: 0.7088 - val_loss: 0.8678 - val_accuracy: 0.3333\n",
            "Epoch 445/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5171 - accuracy: 0.6902 - val_loss: 0.7980 - val_accuracy: 0.5000\n",
            "Epoch 446/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5168 - accuracy: 0.7239 - val_loss: 0.7448 - val_accuracy: 0.5000\n",
            "Epoch 447/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5192 - accuracy: 0.7079 - val_loss: 0.7231 - val_accuracy: 0.6667\n",
            "Epoch 448/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5145 - accuracy: 0.7290 - val_loss: 0.8212 - val_accuracy: 0.5000\n",
            "Epoch 449/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5143 - accuracy: 0.7290 - val_loss: 0.7642 - val_accuracy: 0.5000\n",
            "Epoch 450/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5146 - accuracy: 0.7273 - val_loss: 0.8252 - val_accuracy: 0.5000\n",
            "Epoch 451/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5138 - accuracy: 0.7071 - val_loss: 0.7960 - val_accuracy: 0.5000\n",
            "Epoch 452/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5122 - accuracy: 0.7348 - val_loss: 0.8108 - val_accuracy: 0.5000\n",
            "Epoch 453/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5121 - accuracy: 0.7264 - val_loss: 0.8230 - val_accuracy: 0.5000\n",
            "Epoch 454/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5114 - accuracy: 0.7239 - val_loss: 0.7500 - val_accuracy: 0.5000\n",
            "Epoch 455/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5130 - accuracy: 0.7231 - val_loss: 0.7257 - val_accuracy: 0.5000\n",
            "Epoch 456/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5183 - accuracy: 0.7146 - val_loss: 0.6811 - val_accuracy: 0.6667\n",
            "Epoch 457/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5122 - accuracy: 0.7306 - val_loss: 0.7616 - val_accuracy: 0.5000\n",
            "Epoch 458/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5092 - accuracy: 0.7273 - val_loss: 0.8170 - val_accuracy: 0.5000\n",
            "Epoch 459/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5086 - accuracy: 0.7407 - val_loss: 0.7942 - val_accuracy: 0.5000\n",
            "Epoch 460/1000\n",
            "594/594 [==============================] - 0s 33us/sample - loss: 0.5111 - accuracy: 0.7416 - val_loss: 0.8838 - val_accuracy: 0.3333\n",
            "Epoch 461/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5084 - accuracy: 0.7088 - val_loss: 0.7678 - val_accuracy: 0.5000\n",
            "Epoch 462/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5088 - accuracy: 0.7155 - val_loss: 0.7221 - val_accuracy: 0.5000\n",
            "Epoch 463/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5068 - accuracy: 0.7256 - val_loss: 0.8745 - val_accuracy: 0.4167\n",
            "Epoch 464/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5095 - accuracy: 0.7172 - val_loss: 0.8417 - val_accuracy: 0.5000\n",
            "Epoch 465/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5056 - accuracy: 0.7264 - val_loss: 0.7664 - val_accuracy: 0.5000\n",
            "Epoch 466/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5037 - accuracy: 0.7416 - val_loss: 0.7904 - val_accuracy: 0.5000\n",
            "Epoch 467/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5039 - accuracy: 0.7306 - val_loss: 0.8381 - val_accuracy: 0.5000\n",
            "Epoch 468/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5035 - accuracy: 0.7315 - val_loss: 0.8021 - val_accuracy: 0.5000\n",
            "Epoch 469/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5028 - accuracy: 0.7348 - val_loss: 0.8052 - val_accuracy: 0.5000\n",
            "Epoch 470/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5040 - accuracy: 0.7214 - val_loss: 0.7142 - val_accuracy: 0.5000\n",
            "Epoch 471/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5019 - accuracy: 0.7407 - val_loss: 0.8451 - val_accuracy: 0.5000\n",
            "Epoch 472/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5013 - accuracy: 0.7281 - val_loss: 0.7751 - val_accuracy: 0.5000\n",
            "Epoch 473/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5006 - accuracy: 0.7382 - val_loss: 0.8432 - val_accuracy: 0.5000\n",
            "Epoch 474/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5003 - accuracy: 0.7231 - val_loss: 0.7593 - val_accuracy: 0.5000\n",
            "Epoch 475/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5007 - accuracy: 0.7365 - val_loss: 0.8339 - val_accuracy: 0.5000\n",
            "Epoch 476/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5012 - accuracy: 0.7424 - val_loss: 0.8400 - val_accuracy: 0.5000\n",
            "Epoch 477/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.5033 - accuracy: 0.7138 - val_loss: 0.8686 - val_accuracy: 0.3333\n",
            "Epoch 478/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5045 - accuracy: 0.7163 - val_loss: 0.8604 - val_accuracy: 0.5000\n",
            "Epoch 479/1000\n",
            "594/594 [==============================] - 0s 41us/sample - loss: 0.4985 - accuracy: 0.7205 - val_loss: 0.7821 - val_accuracy: 0.5000\n",
            "Epoch 480/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4979 - accuracy: 0.7306 - val_loss: 0.7378 - val_accuracy: 0.5000\n",
            "Epoch 481/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5033 - accuracy: 0.7121 - val_loss: 0.6611 - val_accuracy: 0.6667\n",
            "Epoch 482/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5025 - accuracy: 0.7407 - val_loss: 0.7606 - val_accuracy: 0.5000\n",
            "Epoch 483/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4997 - accuracy: 0.7306 - val_loss: 0.9079 - val_accuracy: 0.3333\n",
            "Epoch 484/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.4977 - accuracy: 0.7273 - val_loss: 0.7281 - val_accuracy: 0.5000\n",
            "Epoch 485/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.4986 - accuracy: 0.7256 - val_loss: 0.6877 - val_accuracy: 0.5000\n",
            "Epoch 486/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.5122 - accuracy: 0.6970 - val_loss: 0.6061 - val_accuracy: 0.6667\n",
            "Epoch 487/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5075 - accuracy: 0.7113 - val_loss: 0.7180 - val_accuracy: 0.5000\n",
            "Epoch 488/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.4932 - accuracy: 0.7357 - val_loss: 0.7789 - val_accuracy: 0.5000\n",
            "Epoch 489/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.4945 - accuracy: 0.7340 - val_loss: 0.7298 - val_accuracy: 0.5000\n",
            "Epoch 490/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4936 - accuracy: 0.7365 - val_loss: 0.7523 - val_accuracy: 0.5000\n",
            "Epoch 491/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.4914 - accuracy: 0.7458 - val_loss: 0.7753 - val_accuracy: 0.5000\n",
            "Epoch 492/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4942 - accuracy: 0.7264 - val_loss: 0.8670 - val_accuracy: 0.3333\n",
            "Epoch 493/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4926 - accuracy: 0.7247 - val_loss: 0.7188 - val_accuracy: 0.5000\n",
            "Epoch 494/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.4937 - accuracy: 0.7264 - val_loss: 0.7364 - val_accuracy: 0.5000\n",
            "Epoch 495/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4901 - accuracy: 0.7391 - val_loss: 0.7886 - val_accuracy: 0.5000\n",
            "Epoch 496/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.4984 - accuracy: 0.7231 - val_loss: 0.9194 - val_accuracy: 0.3333\n",
            "Epoch 497/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5294 - accuracy: 0.6801 - val_loss: 1.0536 - val_accuracy: 0.1667\n",
            "Epoch 498/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5088 - accuracy: 0.7239 - val_loss: 0.8029 - val_accuracy: 0.5000\n",
            "Epoch 499/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.4896 - accuracy: 0.7315 - val_loss: 0.7898 - val_accuracy: 0.5000\n",
            "Epoch 500/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.4919 - accuracy: 0.7306 - val_loss: 0.6676 - val_accuracy: 0.5000\n",
            "Epoch 501/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4954 - accuracy: 0.7155 - val_loss: 0.6977 - val_accuracy: 0.5000\n",
            "Epoch 502/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4897 - accuracy: 0.7264 - val_loss: 0.7248 - val_accuracy: 0.5000\n",
            "Epoch 503/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4878 - accuracy: 0.7298 - val_loss: 0.7478 - val_accuracy: 0.5000\n",
            "Epoch 504/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4861 - accuracy: 0.7407 - val_loss: 0.8161 - val_accuracy: 0.5000\n",
            "Epoch 505/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4860 - accuracy: 0.7399 - val_loss: 0.7144 - val_accuracy: 0.5000\n",
            "Epoch 506/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.4906 - accuracy: 0.7121 - val_loss: 0.6762 - val_accuracy: 0.5000\n",
            "Epoch 507/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.4865 - accuracy: 0.7205 - val_loss: 0.7762 - val_accuracy: 0.5000\n",
            "Epoch 508/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4851 - accuracy: 0.7239 - val_loss: 0.7378 - val_accuracy: 0.5000\n",
            "Epoch 509/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4874 - accuracy: 0.7290 - val_loss: 0.6689 - val_accuracy: 0.5000\n",
            "Epoch 510/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5064 - accuracy: 0.7130 - val_loss: 0.5717 - val_accuracy: 0.6667\n",
            "Epoch 511/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4982 - accuracy: 0.7130 - val_loss: 0.7135 - val_accuracy: 0.5000\n",
            "Epoch 512/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4820 - accuracy: 0.7264 - val_loss: 0.7847 - val_accuracy: 0.5000\n",
            "Epoch 513/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.4818 - accuracy: 0.7239 - val_loss: 0.8274 - val_accuracy: 0.5000\n",
            "Epoch 514/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.4805 - accuracy: 0.7332 - val_loss: 0.6786 - val_accuracy: 0.5000\n",
            "Epoch 515/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4788 - accuracy: 0.7247 - val_loss: 0.8196 - val_accuracy: 0.5000\n",
            "Epoch 516/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4780 - accuracy: 0.7315 - val_loss: 0.7947 - val_accuracy: 0.5000\n",
            "Epoch 517/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.4791 - accuracy: 0.7348 - val_loss: 0.8063 - val_accuracy: 0.5000\n",
            "Epoch 518/1000\n",
            "594/594 [==============================] - 0s 35us/sample - loss: 0.4771 - accuracy: 0.7306 - val_loss: 0.6601 - val_accuracy: 0.5000\n",
            "Epoch 519/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.4781 - accuracy: 0.7146 - val_loss: 0.8480 - val_accuracy: 0.5000\n",
            "Epoch 520/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.4800 - accuracy: 0.7315 - val_loss: 0.8535 - val_accuracy: 0.5000\n",
            "Epoch 521/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4790 - accuracy: 0.7433 - val_loss: 0.8301 - val_accuracy: 0.5000\n",
            "Epoch 522/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4744 - accuracy: 0.7315 - val_loss: 0.7189 - val_accuracy: 0.5000\n",
            "Epoch 523/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4750 - accuracy: 0.7340 - val_loss: 0.6954 - val_accuracy: 0.5000\n",
            "Epoch 524/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.4805 - accuracy: 0.7273 - val_loss: 0.6410 - val_accuracy: 0.5000\n",
            "Epoch 525/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.4749 - accuracy: 0.7130 - val_loss: 0.8151 - val_accuracy: 0.5000\n",
            "Epoch 526/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4755 - accuracy: 0.7306 - val_loss: 0.8509 - val_accuracy: 0.5000\n",
            "Epoch 527/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4870 - accuracy: 0.7315 - val_loss: 0.9819 - val_accuracy: 0.3333\n",
            "Epoch 528/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4959 - accuracy: 0.7205 - val_loss: 0.9295 - val_accuracy: 0.3333\n",
            "Epoch 529/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.4719 - accuracy: 0.7441 - val_loss: 0.7089 - val_accuracy: 0.5000\n",
            "Epoch 530/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4703 - accuracy: 0.7407 - val_loss: 0.7582 - val_accuracy: 0.5000\n",
            "Epoch 531/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.4693 - accuracy: 0.7306 - val_loss: 0.7231 - val_accuracy: 0.5000\n",
            "Epoch 532/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4698 - accuracy: 0.7374 - val_loss: 0.7029 - val_accuracy: 0.5000\n",
            "Epoch 533/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4683 - accuracy: 0.7264 - val_loss: 0.7441 - val_accuracy: 0.5000\n",
            "Epoch 534/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4784 - accuracy: 0.6987 - val_loss: 1.0283 - val_accuracy: 0.1667\n",
            "Epoch 535/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5169 - accuracy: 0.7138 - val_loss: 0.9841 - val_accuracy: 0.3333\n",
            "Epoch 536/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5088 - accuracy: 0.7155 - val_loss: 1.0332 - val_accuracy: 0.2500\n",
            "Epoch 537/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5215 - accuracy: 0.6911 - val_loss: 1.0057 - val_accuracy: 0.3333\n",
            "Epoch 538/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.5037 - accuracy: 0.7382 - val_loss: 0.9660 - val_accuracy: 0.3333\n",
            "Epoch 539/1000\n",
            "594/594 [==============================] - 0s 33us/sample - loss: 0.4775 - accuracy: 0.7273 - val_loss: 0.8510 - val_accuracy: 0.5000\n",
            "Epoch 540/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4771 - accuracy: 0.7256 - val_loss: 0.9001 - val_accuracy: 0.3333\n",
            "Epoch 541/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.4697 - accuracy: 0.7517 - val_loss: 0.8345 - val_accuracy: 0.5000\n",
            "Epoch 542/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4658 - accuracy: 0.7399 - val_loss: 0.6543 - val_accuracy: 0.5000\n",
            "Epoch 543/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4764 - accuracy: 0.7155 - val_loss: 0.6322 - val_accuracy: 0.5000\n",
            "Epoch 544/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4654 - accuracy: 0.7189 - val_loss: 0.8404 - val_accuracy: 0.5000\n",
            "Epoch 545/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4687 - accuracy: 0.7323 - val_loss: 0.8732 - val_accuracy: 0.4167\n",
            "Epoch 546/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4893 - accuracy: 0.7256 - val_loss: 1.0091 - val_accuracy: 0.3333\n",
            "Epoch 547/1000\n",
            "594/594 [==============================] - 0s 33us/sample - loss: 0.4962 - accuracy: 0.7315 - val_loss: 1.0126 - val_accuracy: 0.3333\n",
            "Epoch 548/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.4874 - accuracy: 0.7197 - val_loss: 0.9432 - val_accuracy: 0.3333\n",
            "Epoch 549/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.4756 - accuracy: 0.7374 - val_loss: 0.8838 - val_accuracy: 0.3333\n",
            "Epoch 550/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4611 - accuracy: 0.7424 - val_loss: 0.6280 - val_accuracy: 0.5000\n",
            "Epoch 551/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.4628 - accuracy: 0.7205 - val_loss: 0.8414 - val_accuracy: 0.5000\n",
            "Epoch 552/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4662 - accuracy: 0.7273 - val_loss: 0.8540 - val_accuracy: 0.5000\n",
            "Epoch 553/1000\n",
            "594/594 [==============================] - 0s 36us/sample - loss: 0.4622 - accuracy: 0.7534 - val_loss: 0.7979 - val_accuracy: 0.5000\n",
            "Epoch 554/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.4609 - accuracy: 0.7374 - val_loss: 0.8118 - val_accuracy: 0.5000\n",
            "Epoch 555/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4585 - accuracy: 0.7399 - val_loss: 0.6732 - val_accuracy: 0.5000\n",
            "Epoch 556/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4687 - accuracy: 0.7298 - val_loss: 0.6142 - val_accuracy: 0.5000\n",
            "Epoch 557/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4825 - accuracy: 0.7088 - val_loss: 0.5657 - val_accuracy: 0.6667\n",
            "Epoch 558/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5224 - accuracy: 0.7003 - val_loss: 0.4289 - val_accuracy: 0.6667\n",
            "Epoch 559/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5164 - accuracy: 0.7121 - val_loss: 0.6632 - val_accuracy: 0.5000\n",
            "Epoch 560/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4643 - accuracy: 0.7365 - val_loss: 0.6677 - val_accuracy: 0.5000\n",
            "Epoch 561/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.4635 - accuracy: 0.7332 - val_loss: 0.7262 - val_accuracy: 0.5000\n",
            "Epoch 562/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4564 - accuracy: 0.7214 - val_loss: 0.7614 - val_accuracy: 0.5000\n",
            "Epoch 563/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4736 - accuracy: 0.7466 - val_loss: 0.4986 - val_accuracy: 0.6667\n",
            "Epoch 564/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4969 - accuracy: 0.7340 - val_loss: 0.5884 - val_accuracy: 0.6667\n",
            "Epoch 565/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4729 - accuracy: 0.7306 - val_loss: 0.6784 - val_accuracy: 0.5000\n",
            "Epoch 566/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.4593 - accuracy: 0.7508 - val_loss: 0.7270 - val_accuracy: 0.5000\n",
            "Epoch 567/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.4551 - accuracy: 0.7273 - val_loss: 0.7646 - val_accuracy: 0.5000\n",
            "Epoch 568/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.4536 - accuracy: 0.7290 - val_loss: 0.7534 - val_accuracy: 0.5000\n",
            "Epoch 569/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4623 - accuracy: 0.7273 - val_loss: 1.0074 - val_accuracy: 0.3333\n",
            "Epoch 570/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4727 - accuracy: 0.7424 - val_loss: 0.8718 - val_accuracy: 0.5000\n",
            "Epoch 571/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4537 - accuracy: 0.7382 - val_loss: 0.6829 - val_accuracy: 0.5000\n",
            "Epoch 572/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4536 - accuracy: 0.7348 - val_loss: 0.7690 - val_accuracy: 0.5000\n",
            "Epoch 573/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4550 - accuracy: 0.7214 - val_loss: 0.9113 - val_accuracy: 0.3333\n",
            "Epoch 574/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4536 - accuracy: 0.7416 - val_loss: 0.7276 - val_accuracy: 0.5000\n",
            "Epoch 575/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.4513 - accuracy: 0.7239 - val_loss: 0.8424 - val_accuracy: 0.5000\n",
            "Epoch 576/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4539 - accuracy: 0.7407 - val_loss: 0.7918 - val_accuracy: 0.5000\n",
            "Epoch 577/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4627 - accuracy: 0.7332 - val_loss: 1.0050 - val_accuracy: 0.3333\n",
            "Epoch 578/1000\n",
            "594/594 [==============================] - 0s 35us/sample - loss: 0.4547 - accuracy: 0.7576 - val_loss: 0.7209 - val_accuracy: 0.5000\n",
            "Epoch 579/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4508 - accuracy: 0.7424 - val_loss: 0.6968 - val_accuracy: 0.5000\n",
            "Epoch 580/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4559 - accuracy: 0.7374 - val_loss: 0.6215 - val_accuracy: 0.5000\n",
            "Epoch 581/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4579 - accuracy: 0.7466 - val_loss: 0.6462 - val_accuracy: 0.5000\n",
            "Epoch 582/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4737 - accuracy: 0.7340 - val_loss: 0.5084 - val_accuracy: 0.6667\n",
            "Epoch 583/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4607 - accuracy: 0.7382 - val_loss: 0.8198 - val_accuracy: 0.5000\n",
            "Epoch 584/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4467 - accuracy: 0.7391 - val_loss: 0.8108 - val_accuracy: 0.5000\n",
            "Epoch 585/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4462 - accuracy: 0.7374 - val_loss: 0.7676 - val_accuracy: 0.5000\n",
            "Epoch 586/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4516 - accuracy: 0.7273 - val_loss: 0.9539 - val_accuracy: 0.3333\n",
            "Epoch 587/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.4649 - accuracy: 0.7365 - val_loss: 0.9691 - val_accuracy: 0.3333\n",
            "Epoch 588/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4654 - accuracy: 0.7483 - val_loss: 0.9178 - val_accuracy: 0.3333\n",
            "Epoch 589/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4657 - accuracy: 0.7424 - val_loss: 0.9578 - val_accuracy: 0.3333\n",
            "Epoch 590/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4985 - accuracy: 0.7340 - val_loss: 1.0947 - val_accuracy: 0.1667\n",
            "Epoch 591/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4884 - accuracy: 0.7239 - val_loss: 1.0436 - val_accuracy: 0.3333\n",
            "Epoch 592/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4841 - accuracy: 0.7593 - val_loss: 0.9493 - val_accuracy: 0.3333\n",
            "Epoch 593/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4496 - accuracy: 0.7492 - val_loss: 0.7731 - val_accuracy: 0.5000\n",
            "Epoch 594/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.4445 - accuracy: 0.7315 - val_loss: 0.9369 - val_accuracy: 0.3333\n",
            "Epoch 595/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4510 - accuracy: 0.7416 - val_loss: 0.9072 - val_accuracy: 0.3333\n",
            "Epoch 596/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4604 - accuracy: 0.7458 - val_loss: 1.0204 - val_accuracy: 0.3333\n",
            "Epoch 597/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4697 - accuracy: 0.7492 - val_loss: 1.0065 - val_accuracy: 0.3333\n",
            "Epoch 598/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4808 - accuracy: 0.7391 - val_loss: 1.0583 - val_accuracy: 0.3333\n",
            "Epoch 599/1000\n",
            "594/594 [==============================] - 0s 34us/sample - loss: 0.4733 - accuracy: 0.7652 - val_loss: 0.9812 - val_accuracy: 0.3333\n",
            "Epoch 600/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4931 - accuracy: 0.7121 - val_loss: 1.1999 - val_accuracy: 0.1667\n",
            "Epoch 601/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5628 - accuracy: 0.6818 - val_loss: 1.2120 - val_accuracy: 0.1667\n",
            "Epoch 602/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5127 - accuracy: 0.7037 - val_loss: 1.0882 - val_accuracy: 0.1667\n",
            "Epoch 603/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5017 - accuracy: 0.6928 - val_loss: 1.1251 - val_accuracy: 0.1667\n",
            "Epoch 604/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4936 - accuracy: 0.7155 - val_loss: 0.9777 - val_accuracy: 0.3333\n",
            "Epoch 605/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4532 - accuracy: 0.7576 - val_loss: 0.8942 - val_accuracy: 0.5000\n",
            "Epoch 606/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4423 - accuracy: 0.7247 - val_loss: 0.8842 - val_accuracy: 0.5000\n",
            "Epoch 607/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4369 - accuracy: 0.7593 - val_loss: 0.6501 - val_accuracy: 0.5000\n",
            "Epoch 608/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4404 - accuracy: 0.7492 - val_loss: 0.7398 - val_accuracy: 0.5000\n",
            "Epoch 609/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4442 - accuracy: 0.7559 - val_loss: 0.5958 - val_accuracy: 0.5000\n",
            "Epoch 610/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4384 - accuracy: 0.7525 - val_loss: 0.8309 - val_accuracy: 0.5000\n",
            "Epoch 611/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.4363 - accuracy: 0.7407 - val_loss: 0.7717 - val_accuracy: 0.5000\n",
            "Epoch 612/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.4348 - accuracy: 0.7525 - val_loss: 0.7251 - val_accuracy: 0.5000\n",
            "Epoch 613/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4332 - accuracy: 0.7441 - val_loss: 0.8269 - val_accuracy: 0.5000\n",
            "Epoch 614/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.4351 - accuracy: 0.7492 - val_loss: 0.8316 - val_accuracy: 0.5000\n",
            "Epoch 615/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.4356 - accuracy: 0.7424 - val_loss: 0.8466 - val_accuracy: 0.5000\n",
            "Epoch 616/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.4393 - accuracy: 0.7441 - val_loss: 0.9163 - val_accuracy: 0.3333\n",
            "Epoch 617/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.4488 - accuracy: 0.7584 - val_loss: 0.9705 - val_accuracy: 0.3333\n",
            "Epoch 618/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4669 - accuracy: 0.7449 - val_loss: 1.0326 - val_accuracy: 0.1667\n",
            "Epoch 619/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.4772 - accuracy: 0.7323 - val_loss: 1.0468 - val_accuracy: 0.3333\n",
            "Epoch 620/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4850 - accuracy: 0.7281 - val_loss: 1.1716 - val_accuracy: 0.1667\n",
            "Epoch 621/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4764 - accuracy: 0.7138 - val_loss: 1.0214 - val_accuracy: 0.3333\n",
            "Epoch 622/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.4465 - accuracy: 0.7719 - val_loss: 0.8649 - val_accuracy: 0.5000\n",
            "Epoch 623/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4315 - accuracy: 0.7551 - val_loss: 0.7144 - val_accuracy: 0.5000\n",
            "Epoch 624/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4461 - accuracy: 0.7466 - val_loss: 0.5571 - val_accuracy: 0.5000\n",
            "Epoch 625/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4718 - accuracy: 0.7382 - val_loss: 0.4880 - val_accuracy: 0.6667\n",
            "Epoch 626/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4622 - accuracy: 0.7492 - val_loss: 0.6689 - val_accuracy: 0.5000\n",
            "Epoch 627/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.4355 - accuracy: 0.7466 - val_loss: 0.6786 - val_accuracy: 0.5000\n",
            "Epoch 628/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4391 - accuracy: 0.7492 - val_loss: 0.6063 - val_accuracy: 0.5000\n",
            "Epoch 629/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.4317 - accuracy: 0.7458 - val_loss: 0.8180 - val_accuracy: 0.5000\n",
            "Epoch 630/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.4302 - accuracy: 0.7593 - val_loss: 0.6713 - val_accuracy: 0.5000\n",
            "Epoch 631/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.4310 - accuracy: 0.7281 - val_loss: 0.7766 - val_accuracy: 0.5000\n",
            "Epoch 632/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4286 - accuracy: 0.7576 - val_loss: 0.6837 - val_accuracy: 0.5000\n",
            "Epoch 633/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4424 - accuracy: 0.7492 - val_loss: 0.5412 - val_accuracy: 0.5000\n",
            "Epoch 634/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5155 - accuracy: 0.6835 - val_loss: 0.3781 - val_accuracy: 0.8333\n",
            "Epoch 635/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5507 - accuracy: 0.7222 - val_loss: 0.4847 - val_accuracy: 0.6667\n",
            "Epoch 636/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5016 - accuracy: 0.7323 - val_loss: 0.5141 - val_accuracy: 0.6667\n",
            "Epoch 637/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4531 - accuracy: 0.7458 - val_loss: 0.6759 - val_accuracy: 0.5000\n",
            "Epoch 638/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4429 - accuracy: 0.7525 - val_loss: 0.5778 - val_accuracy: 0.5000\n",
            "Epoch 639/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.4389 - accuracy: 0.7483 - val_loss: 0.6965 - val_accuracy: 0.5000\n",
            "Epoch 640/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4252 - accuracy: 0.7374 - val_loss: 0.9089 - val_accuracy: 0.3333\n",
            "Epoch 641/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.4285 - accuracy: 0.7576 - val_loss: 0.7868 - val_accuracy: 0.5000\n",
            "Epoch 642/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4268 - accuracy: 0.7407 - val_loss: 0.8585 - val_accuracy: 0.5000\n",
            "Epoch 643/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4244 - accuracy: 0.7593 - val_loss: 0.6801 - val_accuracy: 0.5000\n",
            "Epoch 644/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.4258 - accuracy: 0.7475 - val_loss: 0.8353 - val_accuracy: 0.4167\n",
            "Epoch 645/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4345 - accuracy: 0.7576 - val_loss: 1.0220 - val_accuracy: 0.3333\n",
            "Epoch 646/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4429 - accuracy: 0.7559 - val_loss: 0.9363 - val_accuracy: 0.3333\n",
            "Epoch 647/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4374 - accuracy: 0.7559 - val_loss: 0.9889 - val_accuracy: 0.3333\n",
            "Epoch 648/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.4381 - accuracy: 0.7593 - val_loss: 0.9429 - val_accuracy: 0.3333\n",
            "Epoch 649/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.4380 - accuracy: 0.7365 - val_loss: 0.9726 - val_accuracy: 0.3333\n",
            "Epoch 650/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.4352 - accuracy: 0.7643 - val_loss: 0.8310 - val_accuracy: 0.5000\n",
            "Epoch 651/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.4322 - accuracy: 0.7753 - val_loss: 0.4917 - val_accuracy: 0.6667\n",
            "Epoch 652/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4430 - accuracy: 0.7626 - val_loss: 0.7055 - val_accuracy: 0.5000\n",
            "Epoch 653/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4338 - accuracy: 0.7500 - val_loss: 0.6027 - val_accuracy: 0.5000\n",
            "Epoch 654/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4464 - accuracy: 0.7500 - val_loss: 0.5596 - val_accuracy: 0.5000\n",
            "Epoch 655/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4317 - accuracy: 0.7643 - val_loss: 0.7463 - val_accuracy: 0.5000\n",
            "Epoch 656/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.4325 - accuracy: 0.7660 - val_loss: 0.5818 - val_accuracy: 0.5000\n",
            "Epoch 657/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4646 - accuracy: 0.7391 - val_loss: 0.5107 - val_accuracy: 0.6667\n",
            "Epoch 658/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4342 - accuracy: 0.7593 - val_loss: 0.8442 - val_accuracy: 0.5000\n",
            "Epoch 659/1000\n",
            "594/594 [==============================] - 0s 35us/sample - loss: 0.4258 - accuracy: 0.7727 - val_loss: 0.5653 - val_accuracy: 0.5000\n",
            "Epoch 660/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.4528 - accuracy: 0.7239 - val_loss: 0.5337 - val_accuracy: 0.6667\n",
            "Epoch 661/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4708 - accuracy: 0.7180 - val_loss: 0.5164 - val_accuracy: 0.6667\n",
            "Epoch 662/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4760 - accuracy: 0.7273 - val_loss: 0.5219 - val_accuracy: 0.6667\n",
            "Epoch 663/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5292 - accuracy: 0.6734 - val_loss: 0.3677 - val_accuracy: 0.8333\n",
            "Epoch 664/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5851 - accuracy: 0.6970 - val_loss: 0.4029 - val_accuracy: 0.8333\n",
            "Epoch 665/1000\n",
            "594/594 [==============================] - 0s 20us/sample - loss: 0.5087 - accuracy: 0.7264 - val_loss: 0.5782 - val_accuracy: 0.5000\n",
            "Epoch 666/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4439 - accuracy: 0.7449 - val_loss: 0.7370 - val_accuracy: 0.5000\n",
            "Epoch 667/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.4219 - accuracy: 0.7542 - val_loss: 0.7409 - val_accuracy: 0.5000\n",
            "Epoch 668/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4261 - accuracy: 0.7694 - val_loss: 0.6243 - val_accuracy: 0.5000\n",
            "Epoch 669/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4391 - accuracy: 0.7466 - val_loss: 0.6064 - val_accuracy: 0.5000\n",
            "Epoch 670/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4533 - accuracy: 0.7492 - val_loss: 0.5199 - val_accuracy: 0.6667\n",
            "Epoch 671/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4821 - accuracy: 0.7155 - val_loss: 0.4916 - val_accuracy: 0.6667\n",
            "Epoch 672/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.4792 - accuracy: 0.7273 - val_loss: 0.5861 - val_accuracy: 0.5000\n",
            "Epoch 673/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4941 - accuracy: 0.7062 - val_loss: 0.4455 - val_accuracy: 0.6667\n",
            "Epoch 674/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4595 - accuracy: 0.7525 - val_loss: 0.7828 - val_accuracy: 0.5000\n",
            "Epoch 675/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4235 - accuracy: 0.7609 - val_loss: 0.6514 - val_accuracy: 0.5000\n",
            "Epoch 676/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4219 - accuracy: 0.7551 - val_loss: 0.7192 - val_accuracy: 0.5000\n",
            "Epoch 677/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4193 - accuracy: 0.7374 - val_loss: 0.9966 - val_accuracy: 0.3333\n",
            "Epoch 678/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4189 - accuracy: 0.7761 - val_loss: 0.7608 - val_accuracy: 0.5000\n",
            "Epoch 679/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4176 - accuracy: 0.7458 - val_loss: 0.9443 - val_accuracy: 0.3333\n",
            "Epoch 680/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4343 - accuracy: 0.7601 - val_loss: 1.0082 - val_accuracy: 0.3333\n",
            "Epoch 681/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.4632 - accuracy: 0.7315 - val_loss: 1.2133 - val_accuracy: 0.1667\n",
            "Epoch 682/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5208 - accuracy: 0.7071 - val_loss: 1.2831 - val_accuracy: 0.1667\n",
            "Epoch 683/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.4568 - accuracy: 0.7407 - val_loss: 0.9013 - val_accuracy: 0.3333\n",
            "Epoch 684/1000\n",
            "594/594 [==============================] - 0s 34us/sample - loss: 0.4209 - accuracy: 0.7567 - val_loss: 0.8478 - val_accuracy: 0.5000\n",
            "Epoch 685/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.4135 - accuracy: 0.7811 - val_loss: 0.7354 - val_accuracy: 0.5000\n",
            "Epoch 686/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.4197 - accuracy: 0.7458 - val_loss: 1.0470 - val_accuracy: 0.1667\n",
            "Epoch 687/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4215 - accuracy: 0.7685 - val_loss: 0.7645 - val_accuracy: 0.5000\n",
            "Epoch 688/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4135 - accuracy: 0.7652 - val_loss: 0.7458 - val_accuracy: 0.5000\n",
            "Epoch 689/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4122 - accuracy: 0.7576 - val_loss: 0.8560 - val_accuracy: 0.3333\n",
            "Epoch 690/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.4133 - accuracy: 0.7820 - val_loss: 0.6320 - val_accuracy: 0.5000\n",
            "Epoch 691/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4264 - accuracy: 0.7677 - val_loss: 0.6280 - val_accuracy: 0.5000\n",
            "Epoch 692/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4203 - accuracy: 0.7593 - val_loss: 0.6765 - val_accuracy: 0.5000\n",
            "Epoch 693/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.4119 - accuracy: 0.7609 - val_loss: 0.7920 - val_accuracy: 0.5000\n",
            "Epoch 694/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4110 - accuracy: 0.7753 - val_loss: 0.7410 - val_accuracy: 0.5000\n",
            "Epoch 695/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4194 - accuracy: 0.7643 - val_loss: 0.6089 - val_accuracy: 0.5000\n",
            "Epoch 696/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4452 - accuracy: 0.7483 - val_loss: 0.5113 - val_accuracy: 0.6667\n",
            "Epoch 697/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4511 - accuracy: 0.7559 - val_loss: 0.5881 - val_accuracy: 0.5000\n",
            "Epoch 698/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4245 - accuracy: 0.7483 - val_loss: 0.6928 - val_accuracy: 0.5000\n",
            "Epoch 699/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4248 - accuracy: 0.7458 - val_loss: 0.5568 - val_accuracy: 0.5000\n",
            "Epoch 700/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.4781 - accuracy: 0.6869 - val_loss: 0.4331 - val_accuracy: 0.6667\n",
            "Epoch 701/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5296 - accuracy: 0.7189 - val_loss: 0.4267 - val_accuracy: 0.8333\n",
            "Epoch 702/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4566 - accuracy: 0.7525 - val_loss: 0.7205 - val_accuracy: 0.5000\n",
            "Epoch 703/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4340 - accuracy: 0.7702 - val_loss: 0.5430 - val_accuracy: 0.6667\n",
            "Epoch 704/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4393 - accuracy: 0.7424 - val_loss: 0.6582 - val_accuracy: 0.5000\n",
            "Epoch 705/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4403 - accuracy: 0.7483 - val_loss: 0.5146 - val_accuracy: 0.6667\n",
            "Epoch 706/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4308 - accuracy: 0.7618 - val_loss: 0.7126 - val_accuracy: 0.5000\n",
            "Epoch 707/1000\n",
            "594/594 [==============================] - 0s 35us/sample - loss: 0.4072 - accuracy: 0.7626 - val_loss: 0.8431 - val_accuracy: 0.3333\n",
            "Epoch 708/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.4074 - accuracy: 0.7710 - val_loss: 0.8441 - val_accuracy: 0.3333\n",
            "Epoch 709/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4056 - accuracy: 0.7862 - val_loss: 0.7377 - val_accuracy: 0.5000\n",
            "Epoch 710/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4053 - accuracy: 0.7694 - val_loss: 0.8740 - val_accuracy: 0.3333\n",
            "Epoch 711/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4104 - accuracy: 0.7584 - val_loss: 0.9338 - val_accuracy: 0.3333\n",
            "Epoch 712/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4170 - accuracy: 0.7660 - val_loss: 0.9453 - val_accuracy: 0.3333\n",
            "Epoch 713/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4188 - accuracy: 0.7609 - val_loss: 0.9235 - val_accuracy: 0.3333\n",
            "Epoch 714/1000\n",
            "594/594 [==============================] - 0s 20us/sample - loss: 0.4235 - accuracy: 0.7702 - val_loss: 1.0694 - val_accuracy: 0.1667\n",
            "Epoch 715/1000\n",
            "594/594 [==============================] - 0s 20us/sample - loss: 0.4122 - accuracy: 0.7694 - val_loss: 0.8131 - val_accuracy: 0.3333\n",
            "Epoch 716/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4062 - accuracy: 0.7702 - val_loss: 0.9138 - val_accuracy: 0.3333\n",
            "Epoch 717/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4065 - accuracy: 0.7744 - val_loss: 0.8267 - val_accuracy: 0.3333\n",
            "Epoch 718/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4153 - accuracy: 0.7618 - val_loss: 1.0872 - val_accuracy: 0.1667\n",
            "Epoch 719/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.4540 - accuracy: 0.7424 - val_loss: 1.1187 - val_accuracy: 0.1667\n",
            "Epoch 720/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.4178 - accuracy: 0.7517 - val_loss: 0.7792 - val_accuracy: 0.5000\n",
            "Epoch 721/1000\n",
            "594/594 [==============================] - 0s 34us/sample - loss: 0.4159 - accuracy: 0.7694 - val_loss: 0.5126 - val_accuracy: 0.6667\n",
            "Epoch 722/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.4333 - accuracy: 0.7643 - val_loss: 0.6156 - val_accuracy: 0.5000\n",
            "Epoch 723/1000\n",
            "594/594 [==============================] - 0s 20us/sample - loss: 0.4256 - accuracy: 0.7534 - val_loss: 0.5900 - val_accuracy: 0.5000\n",
            "Epoch 724/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4016 - accuracy: 0.7433 - val_loss: 0.9457 - val_accuracy: 0.3333\n",
            "Epoch 725/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.4188 - accuracy: 0.7584 - val_loss: 1.0452 - val_accuracy: 0.1667\n",
            "Epoch 726/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4172 - accuracy: 0.7643 - val_loss: 0.9074 - val_accuracy: 0.3333\n",
            "Epoch 727/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4055 - accuracy: 0.7643 - val_loss: 0.8139 - val_accuracy: 0.3333\n",
            "Epoch 728/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.4040 - accuracy: 0.7862 - val_loss: 0.6136 - val_accuracy: 0.5000\n",
            "Epoch 729/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4265 - accuracy: 0.7593 - val_loss: 0.5566 - val_accuracy: 0.5000\n",
            "Epoch 730/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4506 - accuracy: 0.7197 - val_loss: 0.5217 - val_accuracy: 0.6667\n",
            "Epoch 731/1000\n",
            "594/594 [==============================] - 0s 20us/sample - loss: 0.4677 - accuracy: 0.7281 - val_loss: 0.4911 - val_accuracy: 0.6667\n",
            "Epoch 732/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4659 - accuracy: 0.7391 - val_loss: 0.6575 - val_accuracy: 0.5000\n",
            "Epoch 733/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4160 - accuracy: 0.7576 - val_loss: 0.6504 - val_accuracy: 0.5000\n",
            "Epoch 734/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4072 - accuracy: 0.7668 - val_loss: 0.7438 - val_accuracy: 0.5000\n",
            "Epoch 735/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4009 - accuracy: 0.7727 - val_loss: 0.9151 - val_accuracy: 0.3333\n",
            "Epoch 736/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4155 - accuracy: 0.7652 - val_loss: 1.0740 - val_accuracy: 0.1667\n",
            "Epoch 737/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4566 - accuracy: 0.7374 - val_loss: 1.2544 - val_accuracy: 0.1667\n",
            "Epoch 738/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4669 - accuracy: 0.7492 - val_loss: 1.1364 - val_accuracy: 0.1667\n",
            "Epoch 739/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4280 - accuracy: 0.7517 - val_loss: 0.9688 - val_accuracy: 0.3333\n",
            "Epoch 740/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4241 - accuracy: 0.7433 - val_loss: 1.0078 - val_accuracy: 0.1667\n",
            "Epoch 741/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4013 - accuracy: 0.7769 - val_loss: 0.7262 - val_accuracy: 0.5000\n",
            "Epoch 742/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4027 - accuracy: 0.7786 - val_loss: 0.7282 - val_accuracy: 0.5000\n",
            "Epoch 743/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4004 - accuracy: 0.7795 - val_loss: 0.7689 - val_accuracy: 0.5000\n",
            "Epoch 744/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.3977 - accuracy: 0.7567 - val_loss: 0.9765 - val_accuracy: 0.1667\n",
            "Epoch 745/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4181 - accuracy: 0.7407 - val_loss: 1.0552 - val_accuracy: 0.1667\n",
            "Epoch 746/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4430 - accuracy: 0.7433 - val_loss: 1.1635 - val_accuracy: 0.1667\n",
            "Epoch 747/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.4735 - accuracy: 0.7281 - val_loss: 1.3353 - val_accuracy: 0.1667\n",
            "Epoch 748/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4353 - accuracy: 0.7357 - val_loss: 0.9280 - val_accuracy: 0.3333\n",
            "Epoch 749/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4056 - accuracy: 0.7710 - val_loss: 0.9616 - val_accuracy: 0.3333\n",
            "Epoch 750/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3964 - accuracy: 0.7778 - val_loss: 0.7769 - val_accuracy: 0.5000\n",
            "Epoch 751/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3947 - accuracy: 0.7820 - val_loss: 0.7578 - val_accuracy: 0.5000\n",
            "Epoch 752/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.3949 - accuracy: 0.7845 - val_loss: 0.7514 - val_accuracy: 0.5000\n",
            "Epoch 753/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.4028 - accuracy: 0.7786 - val_loss: 0.6013 - val_accuracy: 0.5000\n",
            "Epoch 754/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.3983 - accuracy: 0.7668 - val_loss: 0.7824 - val_accuracy: 0.5000\n",
            "Epoch 755/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.3928 - accuracy: 0.7845 - val_loss: 0.8540 - val_accuracy: 0.3333\n",
            "Epoch 756/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3976 - accuracy: 0.7845 - val_loss: 0.8771 - val_accuracy: 0.3333\n",
            "Epoch 757/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4005 - accuracy: 0.7887 - val_loss: 0.8545 - val_accuracy: 0.3333\n",
            "Epoch 758/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.3982 - accuracy: 0.7828 - val_loss: 0.8141 - val_accuracy: 0.3333\n",
            "Epoch 759/1000\n",
            "594/594 [==============================] - 0s 34us/sample - loss: 0.3951 - accuracy: 0.7938 - val_loss: 0.7619 - val_accuracy: 0.5000\n",
            "Epoch 760/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.3998 - accuracy: 0.7609 - val_loss: 1.0785 - val_accuracy: 0.1667\n",
            "Epoch 761/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4153 - accuracy: 0.7525 - val_loss: 1.0402 - val_accuracy: 0.1667\n",
            "Epoch 762/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4315 - accuracy: 0.7500 - val_loss: 1.2119 - val_accuracy: 0.1667\n",
            "Epoch 763/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4973 - accuracy: 0.7214 - val_loss: 1.4484 - val_accuracy: 0.1667\n",
            "Epoch 764/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6008 - accuracy: 0.7020 - val_loss: 1.5631 - val_accuracy: 0.1667\n",
            "Epoch 765/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.4766 - accuracy: 0.7189 - val_loss: 1.1033 - val_accuracy: 0.1667\n",
            "Epoch 766/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4312 - accuracy: 0.7525 - val_loss: 1.1401 - val_accuracy: 0.1667\n",
            "Epoch 767/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4732 - accuracy: 0.7399 - val_loss: 1.2676 - val_accuracy: 0.1667\n",
            "Epoch 768/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4099 - accuracy: 0.7761 - val_loss: 0.6910 - val_accuracy: 0.5000\n",
            "Epoch 769/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.3941 - accuracy: 0.7677 - val_loss: 0.8004 - val_accuracy: 0.5000\n",
            "Epoch 770/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.3930 - accuracy: 0.7912 - val_loss: 0.6927 - val_accuracy: 0.5000\n",
            "Epoch 771/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4075 - accuracy: 0.7694 - val_loss: 0.5637 - val_accuracy: 0.5000\n",
            "Epoch 772/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4414 - accuracy: 0.7281 - val_loss: 0.5126 - val_accuracy: 0.6667\n",
            "Epoch 773/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.4079 - accuracy: 0.7845 - val_loss: 0.8187 - val_accuracy: 0.5000\n",
            "Epoch 774/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3915 - accuracy: 0.7904 - val_loss: 0.7351 - val_accuracy: 0.5000\n",
            "Epoch 775/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.4001 - accuracy: 0.7795 - val_loss: 0.5988 - val_accuracy: 0.5000\n",
            "Epoch 776/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4023 - accuracy: 0.7449 - val_loss: 0.7109 - val_accuracy: 0.5000\n",
            "Epoch 777/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.3937 - accuracy: 0.7609 - val_loss: 0.6966 - val_accuracy: 0.5000\n",
            "Epoch 778/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4000 - accuracy: 0.7652 - val_loss: 0.6305 - val_accuracy: 0.5000\n",
            "Epoch 779/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.4213 - accuracy: 0.7660 - val_loss: 0.5180 - val_accuracy: 0.5000\n",
            "Epoch 780/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4320 - accuracy: 0.7508 - val_loss: 0.5721 - val_accuracy: 0.5000\n",
            "Epoch 781/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.4326 - accuracy: 0.7601 - val_loss: 0.5480 - val_accuracy: 0.5000\n",
            "Epoch 782/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.4332 - accuracy: 0.7593 - val_loss: 0.5516 - val_accuracy: 0.5000\n",
            "Epoch 783/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4008 - accuracy: 0.7551 - val_loss: 0.7995 - val_accuracy: 0.3333\n",
            "Epoch 784/1000\n",
            "594/594 [==============================] - 0s 33us/sample - loss: 0.3938 - accuracy: 0.7567 - val_loss: 1.0088 - val_accuracy: 0.1667\n",
            "Epoch 785/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.3917 - accuracy: 0.7896 - val_loss: 0.6668 - val_accuracy: 0.5000\n",
            "Epoch 786/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.3929 - accuracy: 0.7736 - val_loss: 0.7109 - val_accuracy: 0.5000\n",
            "Epoch 787/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.3899 - accuracy: 0.7803 - val_loss: 0.7849 - val_accuracy: 0.4167\n",
            "Epoch 788/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3896 - accuracy: 0.7576 - val_loss: 0.9589 - val_accuracy: 0.1667\n",
            "Epoch 789/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4074 - accuracy: 0.7618 - val_loss: 1.0480 - val_accuracy: 0.1667\n",
            "Epoch 790/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4254 - accuracy: 0.7618 - val_loss: 1.1425 - val_accuracy: 0.1667\n",
            "Epoch 791/1000\n",
            "594/594 [==============================] - 0s 20us/sample - loss: 0.4239 - accuracy: 0.7702 - val_loss: 1.1129 - val_accuracy: 0.1667\n",
            "Epoch 792/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4266 - accuracy: 0.7449 - val_loss: 1.1007 - val_accuracy: 0.1667\n",
            "Epoch 793/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4178 - accuracy: 0.7508 - val_loss: 1.0379 - val_accuracy: 0.1667\n",
            "Epoch 794/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4212 - accuracy: 0.7584 - val_loss: 1.1110 - val_accuracy: 0.1667\n",
            "Epoch 795/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4141 - accuracy: 0.7517 - val_loss: 0.9772 - val_accuracy: 0.1667\n",
            "Epoch 796/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4219 - accuracy: 0.7668 - val_loss: 1.2102 - val_accuracy: 0.1667\n",
            "Epoch 797/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4124 - accuracy: 0.7584 - val_loss: 0.9405 - val_accuracy: 0.3333\n",
            "Epoch 798/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.3865 - accuracy: 0.7929 - val_loss: 0.7298 - val_accuracy: 0.5000\n",
            "Epoch 799/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.3859 - accuracy: 0.7736 - val_loss: 0.7806 - val_accuracy: 0.5000\n",
            "Epoch 800/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.3949 - accuracy: 0.7879 - val_loss: 0.6027 - val_accuracy: 0.5000\n",
            "Epoch 801/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4011 - accuracy: 0.7727 - val_loss: 0.7049 - val_accuracy: 0.5000\n",
            "Epoch 802/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3907 - accuracy: 0.7778 - val_loss: 0.6877 - val_accuracy: 0.5000\n",
            "Epoch 803/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3893 - accuracy: 0.7702 - val_loss: 0.7249 - val_accuracy: 0.5000\n",
            "Epoch 804/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3985 - accuracy: 0.7609 - val_loss: 0.5697 - val_accuracy: 0.5000\n",
            "Epoch 805/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4031 - accuracy: 0.7719 - val_loss: 0.6369 - val_accuracy: 0.5000\n",
            "Epoch 806/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4204 - accuracy: 0.7576 - val_loss: 0.5034 - val_accuracy: 0.6667\n",
            "Epoch 807/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4190 - accuracy: 0.7710 - val_loss: 0.6363 - val_accuracy: 0.5000\n",
            "Epoch 808/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4080 - accuracy: 0.7694 - val_loss: 0.5449 - val_accuracy: 0.5000\n",
            "Epoch 809/1000\n",
            "297/594 [==============>...............] - ETA: 0s - loss: 0.4295 - accuracy: 0.7391\n",
            "Epoch 00809: ReduceLROnPlateau reducing learning rate to 0.25.\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4087 - accuracy: 0.7702 - val_loss: 0.6673 - val_accuracy: 0.5000\n",
            "Epoch 810/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.3864 - accuracy: 0.7534 - val_loss: 0.8439 - val_accuracy: 0.3333\n",
            "Epoch 811/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.3827 - accuracy: 0.7912 - val_loss: 0.7707 - val_accuracy: 0.4167\n",
            "Epoch 812/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.3822 - accuracy: 0.7753 - val_loss: 0.8184 - val_accuracy: 0.3333\n",
            "Epoch 813/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.3845 - accuracy: 0.7912 - val_loss: 0.7369 - val_accuracy: 0.5000\n",
            "Epoch 814/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3827 - accuracy: 0.7593 - val_loss: 0.8404 - val_accuracy: 0.3333\n",
            "Epoch 815/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.3823 - accuracy: 0.8022 - val_loss: 0.7631 - val_accuracy: 0.4167\n",
            "Epoch 816/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.3838 - accuracy: 0.7820 - val_loss: 0.7407 - val_accuracy: 0.5000\n",
            "Epoch 817/1000\n",
            "594/594 [==============================] - 0s 20us/sample - loss: 0.3816 - accuracy: 0.7584 - val_loss: 0.8131 - val_accuracy: 0.3333\n",
            "Epoch 818/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.3807 - accuracy: 0.7921 - val_loss: 0.7930 - val_accuracy: 0.3333\n",
            "Epoch 819/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.3834 - accuracy: 0.7769 - val_loss: 0.8635 - val_accuracy: 0.3333\n",
            "Epoch 820/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.3821 - accuracy: 0.8039 - val_loss: 0.7466 - val_accuracy: 0.5000\n",
            "Epoch 821/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3812 - accuracy: 0.7803 - val_loss: 0.7958 - val_accuracy: 0.3333\n",
            "Epoch 822/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.3840 - accuracy: 0.7702 - val_loss: 0.8842 - val_accuracy: 0.3333\n",
            "Epoch 823/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.3848 - accuracy: 0.7702 - val_loss: 0.8591 - val_accuracy: 0.3333\n",
            "Epoch 824/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3825 - accuracy: 0.7896 - val_loss: 0.8015 - val_accuracy: 0.3333\n",
            "Epoch 825/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.3821 - accuracy: 0.7702 - val_loss: 0.8589 - val_accuracy: 0.3333\n",
            "Epoch 826/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.3827 - accuracy: 0.7761 - val_loss: 0.8611 - val_accuracy: 0.3333\n",
            "Epoch 827/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.3803 - accuracy: 0.7955 - val_loss: 0.8053 - val_accuracy: 0.3333\n",
            "Epoch 828/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.3794 - accuracy: 0.7929 - val_loss: 0.8145 - val_accuracy: 0.3333\n",
            "Epoch 829/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.3810 - accuracy: 0.7896 - val_loss: 0.8486 - val_accuracy: 0.3333\n",
            "Epoch 830/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3795 - accuracy: 0.7997 - val_loss: 0.7947 - val_accuracy: 0.3333\n",
            "Epoch 831/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.3815 - accuracy: 0.7938 - val_loss: 0.7525 - val_accuracy: 0.4167\n",
            "Epoch 832/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.3792 - accuracy: 0.7668 - val_loss: 0.8333 - val_accuracy: 0.3333\n",
            "Epoch 833/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3787 - accuracy: 0.8013 - val_loss: 0.7896 - val_accuracy: 0.3333\n",
            "Epoch 834/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3787 - accuracy: 0.7904 - val_loss: 0.7895 - val_accuracy: 0.3333\n",
            "Epoch 835/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.3787 - accuracy: 0.7912 - val_loss: 0.8143 - val_accuracy: 0.3333\n",
            "Epoch 836/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.3792 - accuracy: 0.7963 - val_loss: 0.7915 - val_accuracy: 0.3333\n",
            "Epoch 837/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3785 - accuracy: 0.7828 - val_loss: 0.8151 - val_accuracy: 0.3333\n",
            "Epoch 838/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3792 - accuracy: 0.7997 - val_loss: 0.7667 - val_accuracy: 0.3333\n",
            "Epoch 839/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.3814 - accuracy: 0.7845 - val_loss: 0.7658 - val_accuracy: 0.3333\n",
            "Epoch 840/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.3804 - accuracy: 0.7618 - val_loss: 0.8922 - val_accuracy: 0.2500\n",
            "Epoch 841/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.3802 - accuracy: 0.8030 - val_loss: 0.7299 - val_accuracy: 0.5000\n",
            "Epoch 842/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3783 - accuracy: 0.7593 - val_loss: 0.8389 - val_accuracy: 0.3333\n",
            "Epoch 843/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.3788 - accuracy: 0.7929 - val_loss: 0.8301 - val_accuracy: 0.3333\n",
            "Epoch 844/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.3782 - accuracy: 0.7997 - val_loss: 0.7994 - val_accuracy: 0.3333\n",
            "Epoch 845/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.3797 - accuracy: 0.7744 - val_loss: 0.8571 - val_accuracy: 0.3333\n",
            "Epoch 846/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.3786 - accuracy: 0.8039 - val_loss: 0.8161 - val_accuracy: 0.3333\n",
            "Epoch 847/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.3791 - accuracy: 0.7896 - val_loss: 0.7432 - val_accuracy: 0.3333\n",
            "Epoch 848/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.3776 - accuracy: 0.7643 - val_loss: 0.8279 - val_accuracy: 0.3333\n",
            "Epoch 849/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.3768 - accuracy: 0.7980 - val_loss: 0.7940 - val_accuracy: 0.3333\n",
            "Epoch 850/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.3770 - accuracy: 0.7778 - val_loss: 0.8396 - val_accuracy: 0.3333\n",
            "Epoch 851/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3768 - accuracy: 0.7988 - val_loss: 0.7632 - val_accuracy: 0.3333\n",
            "Epoch 852/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.3775 - accuracy: 0.7837 - val_loss: 0.7773 - val_accuracy: 0.3333\n",
            "Epoch 853/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.3773 - accuracy: 0.7820 - val_loss: 0.7988 - val_accuracy: 0.3333\n",
            "Epoch 854/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.3763 - accuracy: 0.7753 - val_loss: 0.8094 - val_accuracy: 0.3333\n",
            "Epoch 855/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3755 - accuracy: 0.7912 - val_loss: 0.8074 - val_accuracy: 0.3333\n",
            "Epoch 856/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.3760 - accuracy: 0.7971 - val_loss: 0.7837 - val_accuracy: 0.3333\n",
            "Epoch 857/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.3807 - accuracy: 0.7870 - val_loss: 0.7437 - val_accuracy: 0.3333\n",
            "Epoch 858/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.3759 - accuracy: 0.7694 - val_loss: 0.8396 - val_accuracy: 0.3333\n",
            "Epoch 859/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3766 - accuracy: 0.7963 - val_loss: 0.7434 - val_accuracy: 0.3333\n",
            "Epoch 860/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.3773 - accuracy: 0.7820 - val_loss: 0.8382 - val_accuracy: 0.3333\n",
            "Epoch 861/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.3761 - accuracy: 0.7963 - val_loss: 0.7670 - val_accuracy: 0.3333\n",
            "Epoch 862/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.3768 - accuracy: 0.7626 - val_loss: 0.8786 - val_accuracy: 0.1667\n",
            "Epoch 863/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.3750 - accuracy: 0.7946 - val_loss: 0.7821 - val_accuracy: 0.3333\n",
            "Epoch 864/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.3747 - accuracy: 0.7803 - val_loss: 0.7972 - val_accuracy: 0.3333\n",
            "Epoch 865/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.3744 - accuracy: 0.7778 - val_loss: 0.7885 - val_accuracy: 0.3333\n",
            "Epoch 866/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.3742 - accuracy: 0.7736 - val_loss: 0.7913 - val_accuracy: 0.3333\n",
            "Epoch 867/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3739 - accuracy: 0.7727 - val_loss: 0.8105 - val_accuracy: 0.3333\n",
            "Epoch 868/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.3746 - accuracy: 0.7912 - val_loss: 0.7767 - val_accuracy: 0.3333\n",
            "Epoch 869/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.3738 - accuracy: 0.7710 - val_loss: 0.8076 - val_accuracy: 0.3333\n",
            "Epoch 870/1000\n",
            "297/594 [==============>...............] - ETA: 0s - loss: 0.3328 - accuracy: 0.8249\n",
            "Epoch 00870: ReduceLROnPlateau reducing learning rate to 0.125.\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3767 - accuracy: 0.7912 - val_loss: 0.7324 - val_accuracy: 0.3333\n",
            "Epoch 871/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.3742 - accuracy: 0.7736 - val_loss: 0.7839 - val_accuracy: 0.3333\n",
            "Epoch 872/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.3732 - accuracy: 0.7727 - val_loss: 0.8028 - val_accuracy: 0.3333\n",
            "Epoch 873/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.3742 - accuracy: 0.7912 - val_loss: 0.7808 - val_accuracy: 0.3333\n",
            "Epoch 874/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.3732 - accuracy: 0.7694 - val_loss: 0.7983 - val_accuracy: 0.3333\n",
            "Epoch 875/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.3732 - accuracy: 0.7845 - val_loss: 0.7920 - val_accuracy: 0.3333\n",
            "Epoch 876/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.3725 - accuracy: 0.7719 - val_loss: 0.8041 - val_accuracy: 0.3333\n",
            "Epoch 877/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.3727 - accuracy: 0.7854 - val_loss: 0.7950 - val_accuracy: 0.3333\n",
            "Epoch 878/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.3730 - accuracy: 0.7828 - val_loss: 0.7927 - val_accuracy: 0.3333\n",
            "Epoch 879/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3732 - accuracy: 0.7795 - val_loss: 0.7883 - val_accuracy: 0.3333\n",
            "Epoch 880/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.3731 - accuracy: 0.7786 - val_loss: 0.7853 - val_accuracy: 0.3333\n",
            "Epoch 881/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.3723 - accuracy: 0.7727 - val_loss: 0.8011 - val_accuracy: 0.3333\n",
            "Epoch 882/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.3723 - accuracy: 0.7769 - val_loss: 0.7966 - val_accuracy: 0.3333\n",
            "Epoch 883/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.3723 - accuracy: 0.7769 - val_loss: 0.7954 - val_accuracy: 0.3333\n",
            "Epoch 884/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3723 - accuracy: 0.7786 - val_loss: 0.7886 - val_accuracy: 0.3333\n",
            "Epoch 885/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.3721 - accuracy: 0.7736 - val_loss: 0.8007 - val_accuracy: 0.3333\n",
            "Epoch 886/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.3725 - accuracy: 0.7736 - val_loss: 0.8082 - val_accuracy: 0.3333\n",
            "Epoch 887/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.3719 - accuracy: 0.7769 - val_loss: 0.8099 - val_accuracy: 0.3333\n",
            "Epoch 888/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.3719 - accuracy: 0.7795 - val_loss: 0.7985 - val_accuracy: 0.3333\n",
            "Epoch 889/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.3724 - accuracy: 0.7685 - val_loss: 0.8197 - val_accuracy: 0.3333\n",
            "Epoch 890/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.3741 - accuracy: 0.7837 - val_loss: 0.7767 - val_accuracy: 0.3333\n",
            "Epoch 891/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.3723 - accuracy: 0.7660 - val_loss: 0.7834 - val_accuracy: 0.3333\n",
            "Epoch 892/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.3716 - accuracy: 0.7736 - val_loss: 0.8072 - val_accuracy: 0.3333\n",
            "Epoch 893/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3741 - accuracy: 0.7811 - val_loss: 0.7739 - val_accuracy: 0.3333\n",
            "Epoch 894/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.3723 - accuracy: 0.7753 - val_loss: 0.7841 - val_accuracy: 0.3333\n",
            "Epoch 895/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3716 - accuracy: 0.7694 - val_loss: 0.7973 - val_accuracy: 0.3333\n",
            "Epoch 896/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.3715 - accuracy: 0.7795 - val_loss: 0.7907 - val_accuracy: 0.3333\n",
            "Epoch 897/1000\n",
            "594/594 [==============================] - 0s 20us/sample - loss: 0.3711 - accuracy: 0.7727 - val_loss: 0.7937 - val_accuracy: 0.3333\n",
            "Epoch 898/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.3712 - accuracy: 0.7710 - val_loss: 0.8085 - val_accuracy: 0.3333\n",
            "Epoch 899/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.3710 - accuracy: 0.7702 - val_loss: 0.8041 - val_accuracy: 0.3333\n",
            "Epoch 900/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.3708 - accuracy: 0.7702 - val_loss: 0.8029 - val_accuracy: 0.3333\n",
            "Epoch 901/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.3706 - accuracy: 0.7727 - val_loss: 0.8059 - val_accuracy: 0.3333\n",
            "Epoch 902/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.3713 - accuracy: 0.7736 - val_loss: 0.7883 - val_accuracy: 0.3333\n",
            "Epoch 903/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3710 - accuracy: 0.7727 - val_loss: 0.8159 - val_accuracy: 0.3333\n",
            "Epoch 904/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.3710 - accuracy: 0.7761 - val_loss: 0.7930 - val_accuracy: 0.3333\n",
            "Epoch 905/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.3713 - accuracy: 0.7761 - val_loss: 0.8175 - val_accuracy: 0.2500\n",
            "Epoch 906/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.3704 - accuracy: 0.7710 - val_loss: 0.8050 - val_accuracy: 0.3333\n",
            "Epoch 907/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.3707 - accuracy: 0.7727 - val_loss: 0.8031 - val_accuracy: 0.3333\n",
            "Epoch 908/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.3703 - accuracy: 0.7702 - val_loss: 0.7981 - val_accuracy: 0.3333\n",
            "Epoch 909/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.3709 - accuracy: 0.7786 - val_loss: 0.7843 - val_accuracy: 0.3333\n",
            "Epoch 910/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.3702 - accuracy: 0.7727 - val_loss: 0.8062 - val_accuracy: 0.3333\n",
            "Epoch 911/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.3701 - accuracy: 0.7710 - val_loss: 0.7992 - val_accuracy: 0.3333\n",
            "Epoch 912/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.3702 - accuracy: 0.7710 - val_loss: 0.7945 - val_accuracy: 0.3333\n",
            "Epoch 913/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.3710 - accuracy: 0.7694 - val_loss: 0.8034 - val_accuracy: 0.3333\n",
            "Epoch 914/1000\n",
            "594/594 [==============================] - 0s 35us/sample - loss: 0.3699 - accuracy: 0.7761 - val_loss: 0.8006 - val_accuracy: 0.3333\n",
            "Epoch 915/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.3706 - accuracy: 0.7710 - val_loss: 0.8188 - val_accuracy: 0.1667\n",
            "Epoch 916/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3696 - accuracy: 0.7694 - val_loss: 0.7981 - val_accuracy: 0.3333\n",
            "Epoch 917/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3695 - accuracy: 0.7710 - val_loss: 0.7983 - val_accuracy: 0.3333\n",
            "Epoch 918/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3712 - accuracy: 0.7702 - val_loss: 0.7752 - val_accuracy: 0.3333\n",
            "Epoch 919/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.3694 - accuracy: 0.7736 - val_loss: 0.7951 - val_accuracy: 0.3333\n",
            "Epoch 920/1000\n",
            "297/594 [==============>...............] - ETA: 0s - loss: 0.3507 - accuracy: 0.7879\n",
            "Epoch 00920: ReduceLROnPlateau reducing learning rate to 0.0625.\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3692 - accuracy: 0.7744 - val_loss: 0.7938 - val_accuracy: 0.3333\n",
            "Epoch 921/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3692 - accuracy: 0.7727 - val_loss: 0.7976 - val_accuracy: 0.3333\n",
            "Epoch 922/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.3692 - accuracy: 0.7727 - val_loss: 0.7962 - val_accuracy: 0.3333\n",
            "Epoch 923/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.3689 - accuracy: 0.7719 - val_loss: 0.7989 - val_accuracy: 0.3333\n",
            "Epoch 924/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.3688 - accuracy: 0.7710 - val_loss: 0.8002 - val_accuracy: 0.3333\n",
            "Epoch 925/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3692 - accuracy: 0.7694 - val_loss: 0.7970 - val_accuracy: 0.3333\n",
            "Epoch 926/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3687 - accuracy: 0.7727 - val_loss: 0.8000 - val_accuracy: 0.3333\n",
            "Epoch 927/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.3687 - accuracy: 0.7727 - val_loss: 0.8015 - val_accuracy: 0.3333\n",
            "Epoch 928/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.3695 - accuracy: 0.7702 - val_loss: 0.8073 - val_accuracy: 0.2500\n",
            "Epoch 929/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.3688 - accuracy: 0.7727 - val_loss: 0.8010 - val_accuracy: 0.3333\n",
            "Epoch 930/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.3686 - accuracy: 0.7710 - val_loss: 0.8019 - val_accuracy: 0.3333\n",
            "Epoch 931/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.3696 - accuracy: 0.7710 - val_loss: 0.8088 - val_accuracy: 0.2500\n",
            "Epoch 932/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3686 - accuracy: 0.7727 - val_loss: 0.8028 - val_accuracy: 0.3333\n",
            "Epoch 933/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.3686 - accuracy: 0.7702 - val_loss: 0.8004 - val_accuracy: 0.3333\n",
            "Epoch 934/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.3689 - accuracy: 0.7710 - val_loss: 0.8056 - val_accuracy: 0.2500\n",
            "Epoch 935/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.3684 - accuracy: 0.7727 - val_loss: 0.8039 - val_accuracy: 0.3333\n",
            "Epoch 936/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.3684 - accuracy: 0.7710 - val_loss: 0.8032 - val_accuracy: 0.3333\n",
            "Epoch 937/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.3687 - accuracy: 0.7736 - val_loss: 0.8079 - val_accuracy: 0.2500\n",
            "Epoch 938/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.3684 - accuracy: 0.7727 - val_loss: 0.8079 - val_accuracy: 0.2500\n",
            "Epoch 939/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.3683 - accuracy: 0.7727 - val_loss: 0.8079 - val_accuracy: 0.2500\n",
            "Epoch 940/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3683 - accuracy: 0.7710 - val_loss: 0.8070 - val_accuracy: 0.2500\n",
            "Epoch 941/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.3690 - accuracy: 0.7677 - val_loss: 0.7999 - val_accuracy: 0.3333\n",
            "Epoch 942/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3681 - accuracy: 0.7744 - val_loss: 0.8034 - val_accuracy: 0.2500\n",
            "Epoch 943/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.3682 - accuracy: 0.7744 - val_loss: 0.8058 - val_accuracy: 0.2500\n",
            "Epoch 944/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.3683 - accuracy: 0.7685 - val_loss: 0.8032 - val_accuracy: 0.2500\n",
            "Epoch 945/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.3680 - accuracy: 0.7710 - val_loss: 0.8020 - val_accuracy: 0.2500\n",
            "Epoch 946/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.3683 - accuracy: 0.7727 - val_loss: 0.8069 - val_accuracy: 0.2500\n",
            "Epoch 947/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.3695 - accuracy: 0.7736 - val_loss: 0.8141 - val_accuracy: 0.1667\n",
            "Epoch 948/1000\n",
            "594/594 [==============================] - 0s 20us/sample - loss: 0.3681 - accuracy: 0.7744 - val_loss: 0.8127 - val_accuracy: 0.1667\n",
            "Epoch 949/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.3677 - accuracy: 0.7710 - val_loss: 0.8079 - val_accuracy: 0.1667\n",
            "Epoch 950/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3678 - accuracy: 0.7710 - val_loss: 0.8065 - val_accuracy: 0.2500\n",
            "Epoch 951/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.3676 - accuracy: 0.7702 - val_loss: 0.8045 - val_accuracy: 0.2500\n",
            "Epoch 952/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3681 - accuracy: 0.7677 - val_loss: 0.7993 - val_accuracy: 0.2500\n",
            "Epoch 953/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.3678 - accuracy: 0.7710 - val_loss: 0.8056 - val_accuracy: 0.1667\n",
            "Epoch 954/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3676 - accuracy: 0.7710 - val_loss: 0.8024 - val_accuracy: 0.2500\n",
            "Epoch 955/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.3675 - accuracy: 0.7710 - val_loss: 0.8046 - val_accuracy: 0.2500\n",
            "Epoch 956/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.3679 - accuracy: 0.7727 - val_loss: 0.8081 - val_accuracy: 0.1667\n",
            "Epoch 957/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.3675 - accuracy: 0.7719 - val_loss: 0.8042 - val_accuracy: 0.2500\n",
            "Epoch 958/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.3676 - accuracy: 0.7694 - val_loss: 0.8018 - val_accuracy: 0.2500\n",
            "Epoch 959/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3673 - accuracy: 0.7744 - val_loss: 0.8048 - val_accuracy: 0.1667\n",
            "Epoch 960/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3674 - accuracy: 0.7719 - val_loss: 0.8009 - val_accuracy: 0.2500\n",
            "Epoch 961/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.3674 - accuracy: 0.7710 - val_loss: 0.8053 - val_accuracy: 0.1667\n",
            "Epoch 962/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.3675 - accuracy: 0.7710 - val_loss: 0.8087 - val_accuracy: 0.1667\n",
            "Epoch 963/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.3671 - accuracy: 0.7694 - val_loss: 0.8042 - val_accuracy: 0.1667\n",
            "Epoch 964/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.3675 - accuracy: 0.7710 - val_loss: 0.8093 - val_accuracy: 0.1667\n",
            "Epoch 965/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3669 - accuracy: 0.7702 - val_loss: 0.8050 - val_accuracy: 0.1667\n",
            "Epoch 966/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.3672 - accuracy: 0.7727 - val_loss: 0.8090 - val_accuracy: 0.1667\n",
            "Epoch 967/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.3668 - accuracy: 0.7710 - val_loss: 0.8088 - val_accuracy: 0.1667\n",
            "Epoch 968/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.3668 - accuracy: 0.7694 - val_loss: 0.8081 - val_accuracy: 0.1667\n",
            "Epoch 969/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.3669 - accuracy: 0.7710 - val_loss: 0.8099 - val_accuracy: 0.1667\n",
            "Epoch 970/1000\n",
            "297/594 [==============>...............] - ETA: 0s - loss: 0.3874 - accuracy: 0.7492\n",
            "Epoch 00970: ReduceLROnPlateau reducing learning rate to 0.03125.\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.3668 - accuracy: 0.7702 - val_loss: 0.8098 - val_accuracy: 0.1667\n",
            "Epoch 971/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.3665 - accuracy: 0.7702 - val_loss: 0.8083 - val_accuracy: 0.1667\n",
            "Epoch 972/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3665 - accuracy: 0.7710 - val_loss: 0.8080 - val_accuracy: 0.1667\n",
            "Epoch 973/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.3664 - accuracy: 0.7702 - val_loss: 0.8071 - val_accuracy: 0.1667\n",
            "Epoch 974/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.3664 - accuracy: 0.7685 - val_loss: 0.8056 - val_accuracy: 0.1667\n",
            "Epoch 975/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.3667 - accuracy: 0.7710 - val_loss: 0.8063 - val_accuracy: 0.1667\n",
            "Epoch 976/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.3664 - accuracy: 0.7694 - val_loss: 0.8056 - val_accuracy: 0.1667\n",
            "Epoch 977/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.3663 - accuracy: 0.7710 - val_loss: 0.8060 - val_accuracy: 0.1667\n",
            "Epoch 978/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.3663 - accuracy: 0.7710 - val_loss: 0.8047 - val_accuracy: 0.1667\n",
            "Epoch 979/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.3663 - accuracy: 0.7710 - val_loss: 0.8053 - val_accuracy: 0.1667\n",
            "Epoch 980/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.3662 - accuracy: 0.7710 - val_loss: 0.8042 - val_accuracy: 0.1667\n",
            "Epoch 981/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.3662 - accuracy: 0.7694 - val_loss: 0.8035 - val_accuracy: 0.1667\n",
            "Epoch 982/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.3663 - accuracy: 0.7694 - val_loss: 0.8029 - val_accuracy: 0.1667\n",
            "Epoch 983/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.3667 - accuracy: 0.7727 - val_loss: 0.8055 - val_accuracy: 0.1667\n",
            "Epoch 984/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.3662 - accuracy: 0.7710 - val_loss: 0.8063 - val_accuracy: 0.1667\n",
            "Epoch 985/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.3660 - accuracy: 0.7702 - val_loss: 0.8056 - val_accuracy: 0.1667\n",
            "Epoch 986/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.3662 - accuracy: 0.7710 - val_loss: 0.8060 - val_accuracy: 0.1667\n",
            "Epoch 987/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.3664 - accuracy: 0.7719 - val_loss: 0.8040 - val_accuracy: 0.1667\n",
            "Epoch 988/1000\n",
            "594/594 [==============================] - 0s 20us/sample - loss: 0.3665 - accuracy: 0.7727 - val_loss: 0.8063 - val_accuracy: 0.1667\n",
            "Epoch 989/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.3662 - accuracy: 0.7710 - val_loss: 0.8075 - val_accuracy: 0.1667\n",
            "Epoch 990/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.3659 - accuracy: 0.7694 - val_loss: 0.8072 - val_accuracy: 0.1667\n",
            "Epoch 991/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.3659 - accuracy: 0.7685 - val_loss: 0.8057 - val_accuracy: 0.1667\n",
            "Epoch 992/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.3659 - accuracy: 0.7710 - val_loss: 0.8059 - val_accuracy: 0.1667\n",
            "Epoch 993/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.3658 - accuracy: 0.7694 - val_loss: 0.8051 - val_accuracy: 0.1667\n",
            "Epoch 994/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.3660 - accuracy: 0.7719 - val_loss: 0.8061 - val_accuracy: 0.1667\n",
            "Epoch 995/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.3657 - accuracy: 0.7702 - val_loss: 0.8061 - val_accuracy: 0.1667\n",
            "Epoch 996/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.3659 - accuracy: 0.7668 - val_loss: 0.8044 - val_accuracy: 0.1667\n",
            "Epoch 997/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.3657 - accuracy: 0.7685 - val_loss: 0.8039 - val_accuracy: 0.1667\n",
            "Epoch 998/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.3659 - accuracy: 0.7710 - val_loss: 0.8054 - val_accuracy: 0.1667\n",
            "Epoch 999/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.3655 - accuracy: 0.7702 - val_loss: 0.8052 - val_accuracy: 0.1667\n",
            "Epoch 1000/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.3657 - accuracy: 0.7685 - val_loss: 0.8042 - val_accuracy: 0.1667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAGFCAYAAADAc+UQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkVwowYiISC6UYEREJBf/D0Myt+UPe87IAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKyDPGnWlRAM",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAnUCEkXlROz",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vK7IBx_DlRZb",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26RksZZrksa3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ae332b82-356d-4e07-8736-4c45e86cc679"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "mlp = Sequential()\n",
        "mlp.add(Dense(16, input_dim=2, activation='relu'))\n",
        "mlp.add(Dense(16, activation='relu'))\n",
        "mlp.add(Dense(16, activation='sigmoid'))\n",
        "mlp.add(Dense(2, activation='sigmoid'))\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(factor=0.5, monitor='accuracy',\n",
        "                              patience=50, min_lr=0.00000001,\n",
        "                              verbose = 1)\n",
        "\n",
        "stop_save = EarlyStopping(patience=200, monitor='accuracy',\n",
        "                          verbose=1, \n",
        "                          restore_best_weights=True)\n",
        "\n",
        "# All parameter gradients will be clipped to\n",
        "# a maximum norm of 1.\n",
        "sgd = optimizers.SGD(lr=1., clipnorm=1.)\n",
        "\n",
        "mlp.compile(loss='binary_crossentropy',\n",
        "            optimizer=sgd,\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "# trains the model\n",
        "mlp.fit(X, yv, epochs=1000, batch_size=297,\n",
        "        verbose=1, callbacks=[reduce_lr, stop_save], \n",
        "        validation_split = 0.01)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 594 samples, validate on 6 samples\n",
            "Epoch 1/1000\n",
            "594/594 [==============================] - 0s 480us/sample - loss: 0.7010 - accuracy: 0.4907 - val_loss: 0.7151 - val_accuracy: 0.3333\n",
            "Epoch 2/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6957 - accuracy: 0.4579 - val_loss: 0.7188 - val_accuracy: 0.3333\n",
            "Epoch 3/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6938 - accuracy: 0.4857 - val_loss: 0.7089 - val_accuracy: 0.5000\n",
            "Epoch 4/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6932 - accuracy: 0.5118 - val_loss: 0.7249 - val_accuracy: 0.1667\n",
            "Epoch 5/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6936 - accuracy: 0.4949 - val_loss: 0.6763 - val_accuracy: 0.5833\n",
            "Epoch 6/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6908 - accuracy: 0.5210 - val_loss: 0.7255 - val_accuracy: 0.1667\n",
            "Epoch 7/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6890 - accuracy: 0.5227 - val_loss: 0.7155 - val_accuracy: 0.2500\n",
            "Epoch 8/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6878 - accuracy: 0.5488 - val_loss: 0.7102 - val_accuracy: 0.3333\n",
            "Epoch 9/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6876 - accuracy: 0.5522 - val_loss: 0.6973 - val_accuracy: 0.3333\n",
            "Epoch 10/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6862 - accuracy: 0.5623 - val_loss: 0.7413 - val_accuracy: 0.2500\n",
            "Epoch 11/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6841 - accuracy: 0.5715 - val_loss: 0.7204 - val_accuracy: 0.3333\n",
            "Epoch 12/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6844 - accuracy: 0.5943 - val_loss: 0.7579 - val_accuracy: 0.0833\n",
            "Epoch 13/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6817 - accuracy: 0.5547 - val_loss: 0.7167 - val_accuracy: 0.3333\n",
            "Epoch 14/1000\n",
            "594/594 [==============================] - 0s 36us/sample - loss: 0.6795 - accuracy: 0.6069 - val_loss: 0.7281 - val_accuracy: 0.3333\n",
            "Epoch 15/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6776 - accuracy: 0.5993 - val_loss: 0.7346 - val_accuracy: 0.3333\n",
            "Epoch 16/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6772 - accuracy: 0.6035 - val_loss: 0.7754 - val_accuracy: 0.1667\n",
            "Epoch 17/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6753 - accuracy: 0.5960 - val_loss: 0.7163 - val_accuracy: 0.3333\n",
            "Epoch 18/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6717 - accuracy: 0.6111 - val_loss: 0.7371 - val_accuracy: 0.3333\n",
            "Epoch 19/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6684 - accuracy: 0.6044 - val_loss: 0.7677 - val_accuracy: 0.2500\n",
            "Epoch 20/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6676 - accuracy: 0.6178 - val_loss: 0.7341 - val_accuracy: 0.3333\n",
            "Epoch 21/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6655 - accuracy: 0.6044 - val_loss: 0.7393 - val_accuracy: 0.3333\n",
            "Epoch 22/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6608 - accuracy: 0.6094 - val_loss: 0.7938 - val_accuracy: 0.2500\n",
            "Epoch 23/1000\n",
            "594/594 [==============================] - 0s 33us/sample - loss: 0.6579 - accuracy: 0.6204 - val_loss: 0.7821 - val_accuracy: 0.2500\n",
            "Epoch 24/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6566 - accuracy: 0.6103 - val_loss: 0.8248 - val_accuracy: 0.1667\n",
            "Epoch 25/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6553 - accuracy: 0.6094 - val_loss: 0.8397 - val_accuracy: 0.1667\n",
            "Epoch 26/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6512 - accuracy: 0.6237 - val_loss: 0.8071 - val_accuracy: 0.1667\n",
            "Epoch 27/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6491 - accuracy: 0.6136 - val_loss: 0.8262 - val_accuracy: 0.1667\n",
            "Epoch 28/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6477 - accuracy: 0.6212 - val_loss: 0.8365 - val_accuracy: 0.1667\n",
            "Epoch 29/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6498 - accuracy: 0.6162 - val_loss: 0.8842 - val_accuracy: 0.1667\n",
            "Epoch 30/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6456 - accuracy: 0.6313 - val_loss: 0.8348 - val_accuracy: 0.1667\n",
            "Epoch 31/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6440 - accuracy: 0.6212 - val_loss: 0.8192 - val_accuracy: 0.1667\n",
            "Epoch 32/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6448 - accuracy: 0.6103 - val_loss: 0.8870 - val_accuracy: 0.1667\n",
            "Epoch 33/1000\n",
            "594/594 [==============================] - 0s 35us/sample - loss: 0.6427 - accuracy: 0.6330 - val_loss: 0.8665 - val_accuracy: 0.1667\n",
            "Epoch 34/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6437 - accuracy: 0.6271 - val_loss: 0.8050 - val_accuracy: 0.2500\n",
            "Epoch 35/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6416 - accuracy: 0.6086 - val_loss: 0.8314 - val_accuracy: 0.2500\n",
            "Epoch 36/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6401 - accuracy: 0.6229 - val_loss: 0.8643 - val_accuracy: 0.1667\n",
            "Epoch 37/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6397 - accuracy: 0.6246 - val_loss: 0.8710 - val_accuracy: 0.1667\n",
            "Epoch 38/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6392 - accuracy: 0.6271 - val_loss: 0.8467 - val_accuracy: 0.2500\n",
            "Epoch 39/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6387 - accuracy: 0.6221 - val_loss: 0.8604 - val_accuracy: 0.2500\n",
            "Epoch 40/1000\n",
            "594/594 [==============================] - 0s 36us/sample - loss: 0.6386 - accuracy: 0.6237 - val_loss: 0.8736 - val_accuracy: 0.2500\n",
            "Epoch 41/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6382 - accuracy: 0.6313 - val_loss: 0.8478 - val_accuracy: 0.2500\n",
            "Epoch 42/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6376 - accuracy: 0.6221 - val_loss: 0.8581 - val_accuracy: 0.2500\n",
            "Epoch 43/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6374 - accuracy: 0.6279 - val_loss: 0.8577 - val_accuracy: 0.2500\n",
            "Epoch 44/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6377 - accuracy: 0.6296 - val_loss: 0.8481 - val_accuracy: 0.2500\n",
            "Epoch 45/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6383 - accuracy: 0.6237 - val_loss: 0.8346 - val_accuracy: 0.3333\n",
            "Epoch 46/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.6370 - accuracy: 0.6195 - val_loss: 0.8442 - val_accuracy: 0.3333\n",
            "Epoch 47/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6369 - accuracy: 0.6187 - val_loss: 0.8776 - val_accuracy: 0.2500\n",
            "Epoch 48/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6367 - accuracy: 0.6246 - val_loss: 0.8818 - val_accuracy: 0.2500\n",
            "Epoch 49/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6372 - accuracy: 0.6246 - val_loss: 0.8932 - val_accuracy: 0.2500\n",
            "Epoch 50/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6391 - accuracy: 0.6086 - val_loss: 0.9124 - val_accuracy: 0.2500\n",
            "Epoch 51/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6363 - accuracy: 0.6305 - val_loss: 0.8661 - val_accuracy: 0.3333\n",
            "Epoch 52/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6354 - accuracy: 0.6204 - val_loss: 0.8800 - val_accuracy: 0.2500\n",
            "Epoch 53/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.6352 - accuracy: 0.6338 - val_loss: 0.8432 - val_accuracy: 0.3333\n",
            "Epoch 54/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6349 - accuracy: 0.6187 - val_loss: 0.8839 - val_accuracy: 0.2500\n",
            "Epoch 55/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6342 - accuracy: 0.6296 - val_loss: 0.8549 - val_accuracy: 0.3333\n",
            "Epoch 56/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.6345 - accuracy: 0.6364 - val_loss: 0.8362 - val_accuracy: 0.3333\n",
            "Epoch 57/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6346 - accuracy: 0.6204 - val_loss: 0.8925 - val_accuracy: 0.2500\n",
            "Epoch 58/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6334 - accuracy: 0.6380 - val_loss: 0.8625 - val_accuracy: 0.3333\n",
            "Epoch 59/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.6330 - accuracy: 0.6212 - val_loss: 0.8777 - val_accuracy: 0.2500\n",
            "Epoch 60/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6336 - accuracy: 0.6465 - val_loss: 0.8187 - val_accuracy: 0.3333\n",
            "Epoch 61/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6320 - accuracy: 0.6271 - val_loss: 0.8638 - val_accuracy: 0.2500\n",
            "Epoch 62/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6312 - accuracy: 0.6372 - val_loss: 0.8578 - val_accuracy: 0.2500\n",
            "Epoch 63/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6316 - accuracy: 0.6372 - val_loss: 0.8319 - val_accuracy: 0.3333\n",
            "Epoch 64/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6441 - accuracy: 0.6364 - val_loss: 0.7505 - val_accuracy: 0.5000\n",
            "Epoch 65/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6325 - accuracy: 0.6254 - val_loss: 0.8386 - val_accuracy: 0.3333\n",
            "Epoch 66/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6297 - accuracy: 0.6389 - val_loss: 0.8564 - val_accuracy: 0.3333\n",
            "Epoch 67/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6315 - accuracy: 0.6397 - val_loss: 0.8966 - val_accuracy: 0.1667\n",
            "Epoch 68/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6293 - accuracy: 0.6498 - val_loss: 0.8568 - val_accuracy: 0.2500\n",
            "Epoch 69/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6291 - accuracy: 0.6498 - val_loss: 0.8205 - val_accuracy: 0.3333\n",
            "Epoch 70/1000\n",
            "594/594 [==============================] - 0s 34us/sample - loss: 0.6285 - accuracy: 0.6305 - val_loss: 0.8718 - val_accuracy: 0.2500\n",
            "Epoch 71/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6285 - accuracy: 0.6490 - val_loss: 0.8698 - val_accuracy: 0.2500\n",
            "Epoch 72/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6285 - accuracy: 0.6414 - val_loss: 0.8783 - val_accuracy: 0.2500\n",
            "Epoch 73/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6274 - accuracy: 0.6465 - val_loss: 0.8595 - val_accuracy: 0.2500\n",
            "Epoch 74/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6280 - accuracy: 0.6305 - val_loss: 0.8820 - val_accuracy: 0.1667\n",
            "Epoch 75/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6273 - accuracy: 0.6515 - val_loss: 0.8148 - val_accuracy: 0.3333\n",
            "Epoch 76/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6262 - accuracy: 0.6372 - val_loss: 0.8698 - val_accuracy: 0.2500\n",
            "Epoch 77/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6264 - accuracy: 0.6532 - val_loss: 0.8187 - val_accuracy: 0.3333\n",
            "Epoch 78/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6257 - accuracy: 0.6397 - val_loss: 0.8616 - val_accuracy: 0.2500\n",
            "Epoch 79/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6246 - accuracy: 0.6549 - val_loss: 0.8308 - val_accuracy: 0.3333\n",
            "Epoch 80/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6254 - accuracy: 0.6481 - val_loss: 0.8151 - val_accuracy: 0.3333\n",
            "Epoch 81/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6240 - accuracy: 0.6490 - val_loss: 0.8306 - val_accuracy: 0.3333\n",
            "Epoch 82/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6236 - accuracy: 0.6549 - val_loss: 0.8238 - val_accuracy: 0.3333\n",
            "Epoch 83/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6234 - accuracy: 0.6507 - val_loss: 0.8163 - val_accuracy: 0.3333\n",
            "Epoch 84/1000\n",
            "594/594 [==============================] - 0s 46us/sample - loss: 0.6235 - accuracy: 0.6448 - val_loss: 0.8346 - val_accuracy: 0.2500\n",
            "Epoch 85/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6223 - accuracy: 0.6515 - val_loss: 0.8375 - val_accuracy: 0.2500\n",
            "Epoch 86/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6262 - accuracy: 0.6465 - val_loss: 0.8900 - val_accuracy: 0.1667\n",
            "Epoch 87/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6280 - accuracy: 0.6380 - val_loss: 0.8945 - val_accuracy: 0.1667\n",
            "Epoch 88/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6252 - accuracy: 0.6481 - val_loss: 0.8730 - val_accuracy: 0.1667\n",
            "Epoch 89/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6225 - accuracy: 0.6490 - val_loss: 0.8529 - val_accuracy: 0.1667\n",
            "Epoch 90/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6264 - accuracy: 0.6490 - val_loss: 0.7497 - val_accuracy: 0.5000\n",
            "Epoch 91/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6212 - accuracy: 0.6439 - val_loss: 0.8502 - val_accuracy: 0.1667\n",
            "Epoch 92/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6202 - accuracy: 0.6574 - val_loss: 0.8241 - val_accuracy: 0.3333\n",
            "Epoch 93/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6197 - accuracy: 0.6540 - val_loss: 0.8375 - val_accuracy: 0.2500\n",
            "Epoch 94/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6238 - accuracy: 0.6456 - val_loss: 0.7611 - val_accuracy: 0.5000\n",
            "Epoch 95/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6196 - accuracy: 0.6498 - val_loss: 0.8293 - val_accuracy: 0.2500\n",
            "Epoch 96/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6187 - accuracy: 0.6566 - val_loss: 0.8126 - val_accuracy: 0.3333\n",
            "Epoch 97/1000\n",
            "594/594 [==============================] - 0s 33us/sample - loss: 0.6191 - accuracy: 0.6481 - val_loss: 0.8522 - val_accuracy: 0.1667\n",
            "Epoch 98/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6186 - accuracy: 0.6574 - val_loss: 0.7968 - val_accuracy: 0.3333\n",
            "Epoch 99/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6185 - accuracy: 0.6557 - val_loss: 0.8590 - val_accuracy: 0.1667\n",
            "Epoch 100/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6213 - accuracy: 0.6448 - val_loss: 0.8886 - val_accuracy: 0.1667\n",
            "Epoch 101/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.6184 - accuracy: 0.6549 - val_loss: 0.7810 - val_accuracy: 0.5000\n",
            "Epoch 102/1000\n",
            "594/594 [==============================] - 0s 34us/sample - loss: 0.6179 - accuracy: 0.6540 - val_loss: 0.8051 - val_accuracy: 0.3333\n",
            "Epoch 103/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6172 - accuracy: 0.6574 - val_loss: 0.8638 - val_accuracy: 0.1667\n",
            "Epoch 104/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6166 - accuracy: 0.6574 - val_loss: 0.8028 - val_accuracy: 0.3333\n",
            "Epoch 105/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6164 - accuracy: 0.6608 - val_loss: 0.8038 - val_accuracy: 0.3333\n",
            "Epoch 106/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6158 - accuracy: 0.6633 - val_loss: 0.8476 - val_accuracy: 0.1667\n",
            "Epoch 107/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6148 - accuracy: 0.6574 - val_loss: 0.7990 - val_accuracy: 0.4167\n",
            "Epoch 108/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6141 - accuracy: 0.6641 - val_loss: 0.8386 - val_accuracy: 0.1667\n",
            "Epoch 109/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6159 - accuracy: 0.6532 - val_loss: 0.8621 - val_accuracy: 0.1667\n",
            "Epoch 110/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6146 - accuracy: 0.6566 - val_loss: 0.8409 - val_accuracy: 0.1667\n",
            "Epoch 111/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6151 - accuracy: 0.6540 - val_loss: 0.8819 - val_accuracy: 0.1667\n",
            "Epoch 112/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6125 - accuracy: 0.6557 - val_loss: 0.8156 - val_accuracy: 0.2500\n",
            "Epoch 113/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6131 - accuracy: 0.6599 - val_loss: 0.8843 - val_accuracy: 0.1667\n",
            "Epoch 114/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6116 - accuracy: 0.6566 - val_loss: 0.8417 - val_accuracy: 0.1667\n",
            "Epoch 115/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6121 - accuracy: 0.6599 - val_loss: 0.8917 - val_accuracy: 0.1667\n",
            "Epoch 116/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6104 - accuracy: 0.6625 - val_loss: 0.8481 - val_accuracy: 0.1667\n",
            "Epoch 117/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6117 - accuracy: 0.6574 - val_loss: 0.9079 - val_accuracy: 0.1667\n",
            "Epoch 118/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6113 - accuracy: 0.6515 - val_loss: 0.8792 - val_accuracy: 0.1667\n",
            "Epoch 119/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6090 - accuracy: 0.6532 - val_loss: 0.7953 - val_accuracy: 0.5000\n",
            "Epoch 120/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6160 - accuracy: 0.6591 - val_loss: 0.9965 - val_accuracy: 0.1667\n",
            "Epoch 121/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6082 - accuracy: 0.6566 - val_loss: 0.8133 - val_accuracy: 0.4167\n",
            "Epoch 122/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6064 - accuracy: 0.6785 - val_loss: 0.8593 - val_accuracy: 0.1667\n",
            "Epoch 123/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6050 - accuracy: 0.6692 - val_loss: 0.9075 - val_accuracy: 0.1667\n",
            "Epoch 124/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6035 - accuracy: 0.6684 - val_loss: 0.8414 - val_accuracy: 0.3333\n",
            "Epoch 125/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6029 - accuracy: 0.6667 - val_loss: 0.8157 - val_accuracy: 0.4167\n",
            "Epoch 126/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6012 - accuracy: 0.6776 - val_loss: 0.8551 - val_accuracy: 0.1667\n",
            "Epoch 127/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6008 - accuracy: 0.6877 - val_loss: 0.9271 - val_accuracy: 0.1667\n",
            "Epoch 128/1000\n",
            "594/594 [==============================] - 0s 36us/sample - loss: 0.6042 - accuracy: 0.6599 - val_loss: 0.9328 - val_accuracy: 0.1667\n",
            "Epoch 129/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.5991 - accuracy: 0.6658 - val_loss: 0.8144 - val_accuracy: 0.4167\n",
            "Epoch 130/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5978 - accuracy: 0.6902 - val_loss: 0.8568 - val_accuracy: 0.3333\n",
            "Epoch 131/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6000 - accuracy: 0.6709 - val_loss: 0.9662 - val_accuracy: 0.1667\n",
            "Epoch 132/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5970 - accuracy: 0.6818 - val_loss: 0.8650 - val_accuracy: 0.3333\n",
            "Epoch 133/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5951 - accuracy: 0.6726 - val_loss: 0.8222 - val_accuracy: 0.4167\n",
            "Epoch 134/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5935 - accuracy: 0.6919 - val_loss: 0.8845 - val_accuracy: 0.1667\n",
            "Epoch 135/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.5934 - accuracy: 0.6835 - val_loss: 0.8902 - val_accuracy: 0.1667\n",
            "Epoch 136/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5967 - accuracy: 0.6810 - val_loss: 0.9499 - val_accuracy: 0.1667\n",
            "Epoch 137/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5914 - accuracy: 0.6717 - val_loss: 0.8321 - val_accuracy: 0.4167\n",
            "Epoch 138/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.5924 - accuracy: 0.6700 - val_loss: 0.8235 - val_accuracy: 0.5833\n",
            "Epoch 139/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5915 - accuracy: 0.6911 - val_loss: 0.8051 - val_accuracy: 0.5833\n",
            "Epoch 140/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5906 - accuracy: 0.6776 - val_loss: 0.8124 - val_accuracy: 0.5000\n",
            "Epoch 141/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5869 - accuracy: 0.6852 - val_loss: 0.8670 - val_accuracy: 0.3333\n",
            "Epoch 142/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5853 - accuracy: 0.6860 - val_loss: 0.8937 - val_accuracy: 0.1667\n",
            "Epoch 143/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5851 - accuracy: 0.6684 - val_loss: 0.7883 - val_accuracy: 0.6667\n",
            "Epoch 144/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5826 - accuracy: 0.7012 - val_loss: 0.9130 - val_accuracy: 0.1667\n",
            "Epoch 145/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.5832 - accuracy: 0.6650 - val_loss: 0.8041 - val_accuracy: 0.6667\n",
            "Epoch 146/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5825 - accuracy: 0.7104 - val_loss: 0.9513 - val_accuracy: 0.1667\n",
            "Epoch 147/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.5857 - accuracy: 0.6810 - val_loss: 0.9578 - val_accuracy: 0.1667\n",
            "Epoch 148/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5912 - accuracy: 0.6709 - val_loss: 1.0187 - val_accuracy: 0.1667\n",
            "Epoch 149/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5937 - accuracy: 0.6709 - val_loss: 0.9979 - val_accuracy: 0.1667\n",
            "Epoch 150/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5777 - accuracy: 0.6970 - val_loss: 0.8590 - val_accuracy: 0.4167\n",
            "Epoch 151/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.5739 - accuracy: 0.6827 - val_loss: 0.8407 - val_accuracy: 0.5000\n",
            "Epoch 152/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5753 - accuracy: 0.6919 - val_loss: 0.8480 - val_accuracy: 0.5000\n",
            "Epoch 153/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5735 - accuracy: 0.7012 - val_loss: 0.8130 - val_accuracy: 0.5000\n",
            "Epoch 154/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5815 - accuracy: 0.6835 - val_loss: 0.6881 - val_accuracy: 0.6667\n",
            "Epoch 155/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5777 - accuracy: 0.6633 - val_loss: 0.8277 - val_accuracy: 0.5833\n",
            "Epoch 156/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5730 - accuracy: 0.6869 - val_loss: 0.7558 - val_accuracy: 0.6667\n",
            "Epoch 157/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.5839 - accuracy: 0.6768 - val_loss: 0.7309 - val_accuracy: 0.6667\n",
            "Epoch 158/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5725 - accuracy: 0.6591 - val_loss: 0.8393 - val_accuracy: 0.5833\n",
            "Epoch 159/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.5667 - accuracy: 0.6827 - val_loss: 0.7005 - val_accuracy: 0.6667\n",
            "Epoch 160/1000\n",
            "594/594 [==============================] - 0s 35us/sample - loss: 0.5808 - accuracy: 0.6423 - val_loss: 0.6487 - val_accuracy: 0.6667\n",
            "Epoch 161/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5663 - accuracy: 0.6827 - val_loss: 0.8792 - val_accuracy: 0.2500\n",
            "Epoch 162/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5597 - accuracy: 0.6860 - val_loss: 0.7947 - val_accuracy: 0.6667\n",
            "Epoch 163/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5642 - accuracy: 0.6877 - val_loss: 0.7449 - val_accuracy: 0.6667\n",
            "Epoch 164/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5871 - accuracy: 0.6448 - val_loss: 0.6602 - val_accuracy: 0.6667\n",
            "Epoch 165/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5733 - accuracy: 0.6650 - val_loss: 0.7803 - val_accuracy: 0.6667\n",
            "Epoch 166/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5718 - accuracy: 0.6700 - val_loss: 0.6198 - val_accuracy: 0.6667\n",
            "Epoch 167/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5821 - accuracy: 0.6448 - val_loss: 0.7458 - val_accuracy: 0.6667\n",
            "Epoch 168/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5820 - accuracy: 0.6801 - val_loss: 0.5848 - val_accuracy: 0.6667\n",
            "Epoch 169/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.5913 - accuracy: 0.6448 - val_loss: 0.6523 - val_accuracy: 0.6667\n",
            "Epoch 170/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5518 - accuracy: 0.6869 - val_loss: 0.9861 - val_accuracy: 0.0833\n",
            "Epoch 171/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5756 - accuracy: 0.6549 - val_loss: 1.1429 - val_accuracy: 0.0000e+00\n",
            "Epoch 172/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6052 - accuracy: 0.6406 - val_loss: 1.0609 - val_accuracy: 0.0000e+00\n",
            "Epoch 173/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5755 - accuracy: 0.6465 - val_loss: 0.9709 - val_accuracy: 0.0000e+00\n",
            "Epoch 174/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5705 - accuracy: 0.6524 - val_loss: 1.1262 - val_accuracy: 0.0000e+00\n",
            "Epoch 175/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5617 - accuracy: 0.6852 - val_loss: 0.9361 - val_accuracy: 0.3333\n",
            "Epoch 176/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5520 - accuracy: 0.6768 - val_loss: 0.9853 - val_accuracy: 0.0833\n",
            "Epoch 177/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5396 - accuracy: 0.6759 - val_loss: 0.7766 - val_accuracy: 0.6667\n",
            "Epoch 178/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.5363 - accuracy: 0.7172 - val_loss: 0.8523 - val_accuracy: 0.6667\n",
            "Epoch 179/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5428 - accuracy: 0.7104 - val_loss: 1.1654 - val_accuracy: 0.0000e+00\n",
            "Epoch 180/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6036 - accuracy: 0.6246 - val_loss: 1.1574 - val_accuracy: 0.0000e+00\n",
            "Epoch 181/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6103 - accuracy: 0.6717 - val_loss: 1.1568 - val_accuracy: 0.0000e+00\n",
            "Epoch 182/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6039 - accuracy: 0.6204 - val_loss: 1.0141 - val_accuracy: 0.0000e+00\n",
            "Epoch 183/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5577 - accuracy: 0.6759 - val_loss: 1.0048 - val_accuracy: 0.0000e+00\n",
            "Epoch 184/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5430 - accuracy: 0.6751 - val_loss: 0.8877 - val_accuracy: 0.5000\n",
            "Epoch 185/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.5389 - accuracy: 0.7155 - val_loss: 0.8480 - val_accuracy: 0.5000\n",
            "Epoch 186/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5639 - accuracy: 0.6768 - val_loss: 1.1090 - val_accuracy: 0.0000e+00\n",
            "Epoch 187/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5992 - accuracy: 0.6490 - val_loss: 1.1497 - val_accuracy: 0.0000e+00\n",
            "Epoch 188/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5764 - accuracy: 0.6507 - val_loss: 0.8610 - val_accuracy: 0.2500\n",
            "Epoch 189/1000\n",
            "594/594 [==============================] - 0s 43us/sample - loss: 0.5334 - accuracy: 0.6717 - val_loss: 0.9283 - val_accuracy: 0.0833\n",
            "Epoch 190/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5460 - accuracy: 0.6700 - val_loss: 1.1053 - val_accuracy: 0.0000e+00\n",
            "Epoch 191/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5864 - accuracy: 0.6279 - val_loss: 1.0864 - val_accuracy: 0.0000e+00\n",
            "Epoch 192/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5662 - accuracy: 0.6717 - val_loss: 0.9994 - val_accuracy: 0.0000e+00\n",
            "Epoch 193/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5711 - accuracy: 0.6641 - val_loss: 1.0087 - val_accuracy: 0.0000e+00\n",
            "Epoch 194/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5872 - accuracy: 0.6288 - val_loss: 1.0165 - val_accuracy: 0.0000e+00\n",
            "Epoch 195/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5566 - accuracy: 0.6667 - val_loss: 0.8412 - val_accuracy: 0.0833\n",
            "Epoch 196/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5416 - accuracy: 0.6423 - val_loss: 0.9884 - val_accuracy: 0.0000e+00\n",
            "Epoch 197/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5709 - accuracy: 0.6431 - val_loss: 0.9935 - val_accuracy: 0.0000e+00\n",
            "Epoch 198/1000\n",
            "594/594 [==============================] - 0s 40us/sample - loss: 0.5585 - accuracy: 0.6566 - val_loss: 1.0438 - val_accuracy: 0.0000e+00\n",
            "Epoch 199/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.5544 - accuracy: 0.6540 - val_loss: 0.9207 - val_accuracy: 0.0000e+00\n",
            "Epoch 200/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.5530 - accuracy: 0.6532 - val_loss: 0.9924 - val_accuracy: 0.0000e+00\n",
            "Epoch 201/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5263 - accuracy: 0.6852 - val_loss: 0.8004 - val_accuracy: 0.4167\n",
            "Epoch 202/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5114 - accuracy: 0.7079 - val_loss: 0.8991 - val_accuracy: 0.0833\n",
            "Epoch 203/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5075 - accuracy: 0.6911 - val_loss: 0.8348 - val_accuracy: 0.3333\n",
            "Epoch 204/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5143 - accuracy: 0.6860 - val_loss: 0.8902 - val_accuracy: 0.0833\n",
            "Epoch 205/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5309 - accuracy: 0.6633 - val_loss: 1.0781 - val_accuracy: 0.0000e+00\n",
            "Epoch 206/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5467 - accuracy: 0.6684 - val_loss: 0.9250 - val_accuracy: 0.0000e+00\n",
            "Epoch 207/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.5444 - accuracy: 0.6616 - val_loss: 1.0704 - val_accuracy: 0.0000e+00\n",
            "Epoch 208/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5539 - accuracy: 0.6684 - val_loss: 1.0322 - val_accuracy: 0.0000e+00\n",
            "Epoch 209/1000\n",
            "594/594 [==============================] - 0s 33us/sample - loss: 0.5492 - accuracy: 0.6944 - val_loss: 1.0257 - val_accuracy: 0.0000e+00\n",
            "Epoch 210/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5209 - accuracy: 0.6944 - val_loss: 0.9777 - val_accuracy: 0.0000e+00\n",
            "Epoch 211/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.5474 - accuracy: 0.6524 - val_loss: 1.0416 - val_accuracy: 0.0000e+00\n",
            "Epoch 212/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5366 - accuracy: 0.6801 - val_loss: 1.0387 - val_accuracy: 0.0000e+00\n",
            "Epoch 213/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5102 - accuracy: 0.6843 - val_loss: 0.9110 - val_accuracy: 0.3333\n",
            "Epoch 214/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5031 - accuracy: 0.6886 - val_loss: 1.0090 - val_accuracy: 0.2500\n",
            "Epoch 215/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5109 - accuracy: 0.6894 - val_loss: 0.9981 - val_accuracy: 0.1667\n",
            "Epoch 216/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5004 - accuracy: 0.6726 - val_loss: 0.9889 - val_accuracy: 0.0833\n",
            "Epoch 217/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5212 - accuracy: 0.6785 - val_loss: 0.9790 - val_accuracy: 0.0000e+00\n",
            "Epoch 218/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5166 - accuracy: 0.6877 - val_loss: 0.9786 - val_accuracy: 0.0833\n",
            "Epoch 219/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5063 - accuracy: 0.7088 - val_loss: 0.9863 - val_accuracy: 0.2500\n",
            "Epoch 220/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.4971 - accuracy: 0.7096 - val_loss: 0.9320 - val_accuracy: 0.4167\n",
            "Epoch 221/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4685 - accuracy: 0.7088 - val_loss: 0.8394 - val_accuracy: 0.3333\n",
            "Epoch 222/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.4709 - accuracy: 0.7155 - val_loss: 0.9597 - val_accuracy: 0.3333\n",
            "Epoch 223/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4944 - accuracy: 0.7071 - val_loss: 1.0319 - val_accuracy: 0.0833\n",
            "Epoch 224/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5322 - accuracy: 0.6961 - val_loss: 1.1880 - val_accuracy: 0.0000e+00\n",
            "Epoch 225/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5281 - accuracy: 0.6852 - val_loss: 0.8795 - val_accuracy: 0.0833\n",
            "Epoch 226/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.4885 - accuracy: 0.7205 - val_loss: 0.8212 - val_accuracy: 0.3333\n",
            "Epoch 227/1000\n",
            "594/594 [==============================] - 0s 34us/sample - loss: 0.4576 - accuracy: 0.7357 - val_loss: 0.9073 - val_accuracy: 0.3333\n",
            "Epoch 228/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.4402 - accuracy: 0.7517 - val_loss: 0.6220 - val_accuracy: 0.5000\n",
            "Epoch 229/1000\n",
            "594/594 [==============================] - 0s 38us/sample - loss: 0.4414 - accuracy: 0.7256 - val_loss: 0.5763 - val_accuracy: 0.5000\n",
            "Epoch 230/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.4521 - accuracy: 0.7037 - val_loss: 0.5241 - val_accuracy: 0.6667\n",
            "Epoch 231/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4478 - accuracy: 0.7037 - val_loss: 0.5700 - val_accuracy: 0.6667\n",
            "Epoch 232/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4200 - accuracy: 0.7290 - val_loss: 0.6951 - val_accuracy: 0.6667\n",
            "Epoch 233/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.4301 - accuracy: 0.7239 - val_loss: 0.8650 - val_accuracy: 0.6667\n",
            "Epoch 234/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.4655 - accuracy: 0.7306 - val_loss: 0.7533 - val_accuracy: 0.3333\n",
            "Epoch 235/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4345 - accuracy: 0.7441 - val_loss: 0.7701 - val_accuracy: 0.3333\n",
            "Epoch 236/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4508 - accuracy: 0.7500 - val_loss: 1.0300 - val_accuracy: 0.1667\n",
            "Epoch 237/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5571 - accuracy: 0.7029 - val_loss: 0.8920 - val_accuracy: 0.0000e+00\n",
            "Epoch 238/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.4657 - accuracy: 0.7332 - val_loss: 0.8528 - val_accuracy: 0.3333\n",
            "Epoch 239/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.4258 - accuracy: 0.7694 - val_loss: 0.7930 - val_accuracy: 0.3333\n",
            "Epoch 240/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.4280 - accuracy: 0.7618 - val_loss: 0.8609 - val_accuracy: 0.3333\n",
            "Epoch 241/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.4304 - accuracy: 0.7626 - val_loss: 1.0894 - val_accuracy: 0.3333\n",
            "Epoch 242/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.4571 - accuracy: 0.7542 - val_loss: 0.9968 - val_accuracy: 0.0000e+00\n",
            "Epoch 243/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4504 - accuracy: 0.7315 - val_loss: 0.9135 - val_accuracy: 0.0000e+00\n",
            "Epoch 244/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4756 - accuracy: 0.7559 - val_loss: 1.1385 - val_accuracy: 0.0000e+00\n",
            "Epoch 245/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.5718 - accuracy: 0.6734 - val_loss: 1.0330 - val_accuracy: 0.0000e+00\n",
            "Epoch 246/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5388 - accuracy: 0.6810 - val_loss: 0.9525 - val_accuracy: 0.0000e+00\n",
            "Epoch 247/1000\n",
            "594/594 [==============================] - 0s 40us/sample - loss: 0.4551 - accuracy: 0.7290 - val_loss: 0.9071 - val_accuracy: 0.5000\n",
            "Epoch 248/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4567 - accuracy: 0.7685 - val_loss: 0.8328 - val_accuracy: 0.1667\n",
            "Epoch 249/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4283 - accuracy: 0.7534 - val_loss: 0.7962 - val_accuracy: 0.1667\n",
            "Epoch 250/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.4154 - accuracy: 0.7761 - val_loss: 0.9156 - val_accuracy: 0.1667\n",
            "Epoch 251/1000\n",
            "594/594 [==============================] - 0s 34us/sample - loss: 0.4345 - accuracy: 0.7483 - val_loss: 0.8777 - val_accuracy: 0.3333\n",
            "Epoch 252/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.4153 - accuracy: 0.7702 - val_loss: 0.8032 - val_accuracy: 0.5000\n",
            "Epoch 253/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.3863 - accuracy: 0.7618 - val_loss: 0.6684 - val_accuracy: 0.6667\n",
            "Epoch 254/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.3759 - accuracy: 0.7660 - val_loss: 0.6382 - val_accuracy: 0.6667\n",
            "Epoch 255/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.3794 - accuracy: 0.7626 - val_loss: 0.7330 - val_accuracy: 0.4167\n",
            "Epoch 256/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4155 - accuracy: 0.7668 - val_loss: 0.7802 - val_accuracy: 0.1667\n",
            "Epoch 257/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4260 - accuracy: 0.7685 - val_loss: 1.0349 - val_accuracy: 0.1667\n",
            "Epoch 258/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4657 - accuracy: 0.7416 - val_loss: 0.9234 - val_accuracy: 0.3333\n",
            "Epoch 259/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4515 - accuracy: 0.7424 - val_loss: 0.7585 - val_accuracy: 0.5000\n",
            "Epoch 260/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.3880 - accuracy: 0.8199 - val_loss: 0.6187 - val_accuracy: 0.6667\n",
            "Epoch 261/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.3648 - accuracy: 0.7803 - val_loss: 0.5960 - val_accuracy: 0.6667\n",
            "Epoch 262/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.3496 - accuracy: 0.7946 - val_loss: 0.5596 - val_accuracy: 0.8333\n",
            "Epoch 263/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.3479 - accuracy: 0.7904 - val_loss: 0.5482 - val_accuracy: 0.8333\n",
            "Epoch 264/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.3471 - accuracy: 0.7744 - val_loss: 0.5226 - val_accuracy: 0.8333\n",
            "Epoch 265/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.3497 - accuracy: 0.7668 - val_loss: 0.5711 - val_accuracy: 0.8333\n",
            "Epoch 266/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.3494 - accuracy: 0.7727 - val_loss: 0.5540 - val_accuracy: 0.8333\n",
            "Epoch 267/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.3328 - accuracy: 0.8030 - val_loss: 0.5116 - val_accuracy: 0.8333\n",
            "Epoch 268/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.3277 - accuracy: 0.7904 - val_loss: 0.5057 - val_accuracy: 0.8333\n",
            "Epoch 269/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.3285 - accuracy: 0.7837 - val_loss: 0.5048 - val_accuracy: 0.8333\n",
            "Epoch 270/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.3272 - accuracy: 0.8081 - val_loss: 0.5153 - val_accuracy: 0.8333\n",
            "Epoch 271/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.3207 - accuracy: 0.8047 - val_loss: 0.5110 - val_accuracy: 0.8333\n",
            "Epoch 272/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.3205 - accuracy: 0.8005 - val_loss: 0.4572 - val_accuracy: 0.8333\n",
            "Epoch 273/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.3193 - accuracy: 0.7904 - val_loss: 0.4842 - val_accuracy: 0.8333\n",
            "Epoch 274/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3167 - accuracy: 0.7955 - val_loss: 0.4897 - val_accuracy: 0.8333\n",
            "Epoch 275/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3105 - accuracy: 0.8173 - val_loss: 0.4887 - val_accuracy: 0.8333\n",
            "Epoch 276/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.3087 - accuracy: 0.8081 - val_loss: 0.4915 - val_accuracy: 0.8333\n",
            "Epoch 277/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.3060 - accuracy: 0.8089 - val_loss: 0.5217 - val_accuracy: 0.6667\n",
            "Epoch 278/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.3159 - accuracy: 0.8098 - val_loss: 0.5764 - val_accuracy: 0.6667\n",
            "Epoch 279/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.4893 - accuracy: 0.7189 - val_loss: 2.1954 - val_accuracy: 0.0000e+00\n",
            "Epoch 280/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 1.0806 - accuracy: 0.5657 - val_loss: 0.4868 - val_accuracy: 1.0000\n",
            "Epoch 281/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4500 - accuracy: 0.7096 - val_loss: 0.5477 - val_accuracy: 0.8333\n",
            "Epoch 282/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4020 - accuracy: 0.7803 - val_loss: 0.6078 - val_accuracy: 0.5000\n",
            "Epoch 283/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.3884 - accuracy: 0.7912 - val_loss: 0.6149 - val_accuracy: 0.5000\n",
            "Epoch 284/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.3771 - accuracy: 0.7837 - val_loss: 0.5769 - val_accuracy: 0.6667\n",
            "Epoch 285/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.3725 - accuracy: 0.8199 - val_loss: 0.5839 - val_accuracy: 0.6667\n",
            "Epoch 286/1000\n",
            "594/594 [==============================] - 0s 33us/sample - loss: 0.3680 - accuracy: 0.8274 - val_loss: 0.6027 - val_accuracy: 0.5833\n",
            "Epoch 287/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4132 - accuracy: 0.7601 - val_loss: 0.5704 - val_accuracy: 0.8333\n",
            "Epoch 288/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.3920 - accuracy: 0.7971 - val_loss: 0.5214 - val_accuracy: 0.8333\n",
            "Epoch 289/1000\n",
            "594/594 [==============================] - 0s 39us/sample - loss: 0.3684 - accuracy: 0.8190 - val_loss: 0.4834 - val_accuracy: 0.8333\n",
            "Epoch 290/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.3763 - accuracy: 0.8089 - val_loss: 0.5018 - val_accuracy: 0.6667\n",
            "Epoch 291/1000\n",
            "594/594 [==============================] - 0s 34us/sample - loss: 0.4215 - accuracy: 0.7500 - val_loss: 0.5141 - val_accuracy: 0.8333\n",
            "Epoch 292/1000\n",
            "594/594 [==============================] - 0s 40us/sample - loss: 0.4228 - accuracy: 0.7921 - val_loss: 0.4290 - val_accuracy: 0.9167\n",
            "Epoch 293/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4733 - accuracy: 0.7365 - val_loss: 0.4739 - val_accuracy: 1.0000\n",
            "Epoch 294/1000\n",
            "594/594 [==============================] - 0s 46us/sample - loss: 0.6515 - accuracy: 0.6077 - val_loss: 0.3907 - val_accuracy: 1.0000\n",
            "Epoch 295/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.7130 - accuracy: 0.6077 - val_loss: 0.6351 - val_accuracy: 0.5000\n",
            "Epoch 296/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4081 - accuracy: 0.8039 - val_loss: 0.5870 - val_accuracy: 0.5000\n",
            "Epoch 297/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.3676 - accuracy: 0.7955 - val_loss: 0.4872 - val_accuracy: 0.8333\n",
            "Epoch 298/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.3504 - accuracy: 0.8283 - val_loss: 0.5603 - val_accuracy: 0.5833\n",
            "Epoch 299/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3483 - accuracy: 0.8283 - val_loss: 0.5266 - val_accuracy: 0.6667\n",
            "Epoch 300/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.3346 - accuracy: 0.8392 - val_loss: 0.5013 - val_accuracy: 0.6667\n",
            "Epoch 301/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.3334 - accuracy: 0.8401 - val_loss: 0.5379 - val_accuracy: 0.6667\n",
            "Epoch 302/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.3252 - accuracy: 0.8527 - val_loss: 0.4848 - val_accuracy: 0.6667\n",
            "Epoch 303/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.3218 - accuracy: 0.8552 - val_loss: 0.4483 - val_accuracy: 0.6667\n",
            "Epoch 304/1000\n",
            "594/594 [==============================] - 0s 41us/sample - loss: 0.3170 - accuracy: 0.8527 - val_loss: 0.5148 - val_accuracy: 0.6667\n",
            "Epoch 305/1000\n",
            "594/594 [==============================] - 0s 34us/sample - loss: 0.3234 - accuracy: 0.8653 - val_loss: 0.4321 - val_accuracy: 0.8333\n",
            "Epoch 306/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.3090 - accuracy: 0.8653 - val_loss: 0.4515 - val_accuracy: 0.6667\n",
            "Epoch 307/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.3048 - accuracy: 0.8493 - val_loss: 0.5098 - val_accuracy: 0.6667\n",
            "Epoch 308/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.2929 - accuracy: 0.8636 - val_loss: 0.5766 - val_accuracy: 0.6667\n",
            "Epoch 309/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.2962 - accuracy: 0.8662 - val_loss: 0.6350 - val_accuracy: 0.5000\n",
            "Epoch 310/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3909 - accuracy: 0.8199 - val_loss: 0.8582 - val_accuracy: 0.3333\n",
            "Epoch 311/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.5889 - accuracy: 0.6928 - val_loss: 0.7807 - val_accuracy: 0.3333\n",
            "Epoch 312/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.3737 - accuracy: 0.8300 - val_loss: 0.6715 - val_accuracy: 0.3333\n",
            "Epoch 313/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.3224 - accuracy: 0.8460 - val_loss: 0.5569 - val_accuracy: 0.6667\n",
            "Epoch 314/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.2983 - accuracy: 0.8645 - val_loss: 0.4600 - val_accuracy: 0.6667\n",
            "Epoch 315/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.2873 - accuracy: 0.8620 - val_loss: 0.5020 - val_accuracy: 0.6667\n",
            "Epoch 316/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.2883 - accuracy: 0.8737 - val_loss: 0.4179 - val_accuracy: 0.8333\n",
            "Epoch 317/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.3162 - accuracy: 0.8535 - val_loss: 0.4542 - val_accuracy: 0.8333\n",
            "Epoch 318/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4385 - accuracy: 0.7753 - val_loss: 0.6122 - val_accuracy: 0.5000\n",
            "Epoch 319/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.3736 - accuracy: 0.8190 - val_loss: 0.3323 - val_accuracy: 1.0000\n",
            "Epoch 320/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5218 - accuracy: 0.7020 - val_loss: 0.2962 - val_accuracy: 1.0000\n",
            "Epoch 321/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.7458 - accuracy: 0.6675 - val_loss: 0.4293 - val_accuracy: 1.0000\n",
            "Epoch 322/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6651 - accuracy: 0.6801 - val_loss: 0.4049 - val_accuracy: 1.0000\n",
            "Epoch 323/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4217 - accuracy: 0.7559 - val_loss: 0.4672 - val_accuracy: 1.0000\n",
            "Epoch 324/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.3372 - accuracy: 0.8333 - val_loss: 0.4767 - val_accuracy: 0.6667\n",
            "Epoch 325/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.3018 - accuracy: 0.8510 - val_loss: 0.4152 - val_accuracy: 1.0000\n",
            "Epoch 326/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.2906 - accuracy: 0.8838 - val_loss: 0.4613 - val_accuracy: 0.8333\n",
            "Epoch 327/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.2851 - accuracy: 0.8443 - val_loss: 0.3999 - val_accuracy: 1.0000\n",
            "Epoch 328/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.2727 - accuracy: 0.8864 - val_loss: 0.4389 - val_accuracy: 1.0000\n",
            "Epoch 329/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.2776 - accuracy: 0.8830 - val_loss: 0.7808 - val_accuracy: 0.5000\n",
            "Epoch 330/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.4422 - accuracy: 0.8392 - val_loss: 0.6980 - val_accuracy: 0.4167\n",
            "Epoch 331/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.4124 - accuracy: 0.7475 - val_loss: 0.6484 - val_accuracy: 0.6667\n",
            "Epoch 332/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3006 - accuracy: 0.8788 - val_loss: 0.4453 - val_accuracy: 0.8333\n",
            "Epoch 333/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.2639 - accuracy: 0.9234 - val_loss: 0.4949 - val_accuracy: 0.6667\n",
            "Epoch 334/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.2557 - accuracy: 0.8914 - val_loss: 0.4251 - val_accuracy: 0.8333\n",
            "Epoch 335/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.2509 - accuracy: 0.9234 - val_loss: 0.4449 - val_accuracy: 0.8333\n",
            "Epoch 336/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.2479 - accuracy: 0.9268 - val_loss: 0.4839 - val_accuracy: 0.6667\n",
            "Epoch 337/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.2382 - accuracy: 0.9099 - val_loss: 0.3754 - val_accuracy: 0.9167\n",
            "Epoch 338/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.2374 - accuracy: 0.9032 - val_loss: 0.3078 - val_accuracy: 1.0000\n",
            "Epoch 339/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.2335 - accuracy: 0.9554 - val_loss: 0.6356 - val_accuracy: 0.6667\n",
            "Epoch 340/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.2861 - accuracy: 0.9032 - val_loss: 0.8425 - val_accuracy: 0.6667\n",
            "Epoch 341/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.3696 - accuracy: 0.8316 - val_loss: 0.4150 - val_accuracy: 0.8333\n",
            "Epoch 342/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.2597 - accuracy: 0.9259 - val_loss: 0.3879 - val_accuracy: 0.8333\n",
            "Epoch 343/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.2343 - accuracy: 0.9192 - val_loss: 0.3970 - val_accuracy: 0.8333\n",
            "Epoch 344/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.2259 - accuracy: 0.9360 - val_loss: 0.4256 - val_accuracy: 0.7500\n",
            "Epoch 345/1000\n",
            "594/594 [==============================] - 0s 34us/sample - loss: 0.2188 - accuracy: 0.9318 - val_loss: 0.3900 - val_accuracy: 0.8333\n",
            "Epoch 346/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.2133 - accuracy: 0.9487 - val_loss: 0.3735 - val_accuracy: 0.8333\n",
            "Epoch 347/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.2107 - accuracy: 0.9402 - val_loss: 0.3620 - val_accuracy: 0.8333\n",
            "Epoch 348/1000\n",
            "594/594 [==============================] - 0s 39us/sample - loss: 0.2033 - accuracy: 0.9419 - val_loss: 0.3397 - val_accuracy: 0.8333\n",
            "Epoch 349/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.2015 - accuracy: 0.9512 - val_loss: 0.3102 - val_accuracy: 0.8333\n",
            "Epoch 350/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.1978 - accuracy: 0.9529 - val_loss: 0.3656 - val_accuracy: 0.8333\n",
            "Epoch 351/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.2000 - accuracy: 0.9604 - val_loss: 0.3015 - val_accuracy: 0.8333\n",
            "Epoch 352/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.1927 - accuracy: 0.9554 - val_loss: 0.3448 - val_accuracy: 0.8333\n",
            "Epoch 353/1000\n",
            "594/594 [==============================] - 0s 34us/sample - loss: 0.1897 - accuracy: 0.9596 - val_loss: 0.4084 - val_accuracy: 0.6667\n",
            "Epoch 354/1000\n",
            "594/594 [==============================] - 0s 36us/sample - loss: 0.1850 - accuracy: 0.9621 - val_loss: 0.2612 - val_accuracy: 1.0000\n",
            "Epoch 355/1000\n",
            "594/594 [==============================] - 0s 33us/sample - loss: 0.1817 - accuracy: 0.9646 - val_loss: 0.2851 - val_accuracy: 0.8333\n",
            "Epoch 356/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.1793 - accuracy: 0.9638 - val_loss: 0.3235 - val_accuracy: 0.8333\n",
            "Epoch 357/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.1752 - accuracy: 0.9722 - val_loss: 0.2924 - val_accuracy: 0.8333\n",
            "Epoch 358/1000\n",
            "594/594 [==============================] - 0s 33us/sample - loss: 0.1714 - accuracy: 0.9739 - val_loss: 0.3071 - val_accuracy: 0.8333\n",
            "Epoch 359/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.1707 - accuracy: 0.9731 - val_loss: 0.3473 - val_accuracy: 0.8333\n",
            "Epoch 360/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.1747 - accuracy: 0.9604 - val_loss: 0.3528 - val_accuracy: 0.8333\n",
            "Epoch 361/1000\n",
            "594/594 [==============================] - 0s 33us/sample - loss: 0.1650 - accuracy: 0.9705 - val_loss: 0.3174 - val_accuracy: 0.8333\n",
            "Epoch 362/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.1733 - accuracy: 0.9646 - val_loss: 0.2292 - val_accuracy: 0.9167\n",
            "Epoch 363/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4268 - accuracy: 0.8704 - val_loss: 0.3592 - val_accuracy: 0.8333\n",
            "Epoch 364/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.7723 - accuracy: 0.6633 - val_loss: 0.0880 - val_accuracy: 1.0000\n",
            "Epoch 365/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.7696 - accuracy: 0.6355 - val_loss: 0.3623 - val_accuracy: 1.0000\n",
            "Epoch 366/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 1.1518 - accuracy: 0.6540 - val_loss: 0.5911 - val_accuracy: 0.6667\n",
            "Epoch 367/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 1.0363 - accuracy: 0.7054 - val_loss: 0.4716 - val_accuracy: 0.6667\n",
            "Epoch 368/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5509 - accuracy: 0.7517 - val_loss: 0.5046 - val_accuracy: 1.0000\n",
            "Epoch 369/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.2860 - accuracy: 0.8771 - val_loss: 0.4276 - val_accuracy: 0.6667\n",
            "Epoch 370/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.2577 - accuracy: 0.8636 - val_loss: 0.3557 - val_accuracy: 0.8333\n",
            "Epoch 371/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.2414 - accuracy: 0.9049 - val_loss: 0.4277 - val_accuracy: 0.6667\n",
            "Epoch 372/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.2330 - accuracy: 0.8931 - val_loss: 0.4057 - val_accuracy: 0.7500\n",
            "Epoch 373/1000\n",
            "594/594 [==============================] - 0s 36us/sample - loss: 0.2260 - accuracy: 0.9091 - val_loss: 0.4006 - val_accuracy: 0.7500\n",
            "Epoch 374/1000\n",
            "594/594 [==============================] - 0s 38us/sample - loss: 0.2194 - accuracy: 0.9386 - val_loss: 0.3681 - val_accuracy: 0.8333\n",
            "Epoch 375/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.2189 - accuracy: 0.9217 - val_loss: 0.3789 - val_accuracy: 0.8333\n",
            "Epoch 376/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.2118 - accuracy: 0.9276 - val_loss: 0.3448 - val_accuracy: 0.8333\n",
            "Epoch 377/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.2026 - accuracy: 0.9327 - val_loss: 0.3328 - val_accuracy: 0.8333\n",
            "Epoch 378/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.1928 - accuracy: 0.9352 - val_loss: 0.3202 - val_accuracy: 0.8333\n",
            "Epoch 379/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.1785 - accuracy: 0.9655 - val_loss: 0.3440 - val_accuracy: 0.8333\n",
            "Epoch 380/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.1744 - accuracy: 0.9604 - val_loss: 0.4159 - val_accuracy: 0.6667\n",
            "Epoch 381/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.1664 - accuracy: 0.9537 - val_loss: 0.3037 - val_accuracy: 0.8333\n",
            "Epoch 382/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.1577 - accuracy: 0.9646 - val_loss: 0.2762 - val_accuracy: 0.8333\n",
            "Epoch 383/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.1608 - accuracy: 0.9571 - val_loss: 0.3411 - val_accuracy: 0.8333\n",
            "Epoch 384/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.1556 - accuracy: 0.9655 - val_loss: 0.2645 - val_accuracy: 0.8333\n",
            "Epoch 385/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.1508 - accuracy: 0.9621 - val_loss: 0.2309 - val_accuracy: 0.9167\n",
            "Epoch 386/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.1562 - accuracy: 0.9604 - val_loss: 0.2137 - val_accuracy: 1.0000\n",
            "Epoch 387/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.1428 - accuracy: 0.9823 - val_loss: 0.2922 - val_accuracy: 0.8333\n",
            "Epoch 388/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.1421 - accuracy: 0.9714 - val_loss: 0.2472 - val_accuracy: 0.8333\n",
            "Epoch 389/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.1492 - accuracy: 0.9621 - val_loss: 0.2428 - val_accuracy: 0.8333\n",
            "Epoch 390/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.1471 - accuracy: 0.9579 - val_loss: 0.2382 - val_accuracy: 1.0000\n",
            "Epoch 391/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.1834 - accuracy: 0.9428 - val_loss: 1.0825 - val_accuracy: 0.6667\n",
            "Epoch 392/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4908 - accuracy: 0.8106 - val_loss: 0.8348 - val_accuracy: 0.5833\n",
            "Epoch 393/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6549 - accuracy: 0.7500 - val_loss: 1.2136 - val_accuracy: 0.3333\n",
            "Epoch 394/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6022 - accuracy: 0.7163 - val_loss: 1.9430 - val_accuracy: 0.1667\n",
            "Epoch 395/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.7895 - accuracy: 0.6288 - val_loss: 3.8639 - val_accuracy: 0.0833\n",
            "Epoch 396/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 1.0427 - accuracy: 0.7121 - val_loss: 0.4033 - val_accuracy: 1.0000\n",
            "Epoch 397/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.2924 - accuracy: 0.8502 - val_loss: 0.4750 - val_accuracy: 0.6667\n",
            "Epoch 398/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.2325 - accuracy: 0.9074 - val_loss: 0.4831 - val_accuracy: 0.7500\n",
            "Epoch 399/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.2102 - accuracy: 0.9545 - val_loss: 0.5993 - val_accuracy: 0.6667\n",
            "Epoch 400/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.2018 - accuracy: 0.9562 - val_loss: 0.4464 - val_accuracy: 0.7500\n",
            "Epoch 401/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.1739 - accuracy: 0.9705 - val_loss: 0.3502 - val_accuracy: 0.8333\n",
            "Epoch 402/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.1598 - accuracy: 0.9840 - val_loss: 0.3137 - val_accuracy: 0.8333\n",
            "Epoch 403/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.1502 - accuracy: 0.9848 - val_loss: 0.2963 - val_accuracy: 0.8333\n",
            "Epoch 404/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.1486 - accuracy: 0.9806 - val_loss: 0.3293 - val_accuracy: 0.8333\n",
            "Epoch 405/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.1485 - accuracy: 0.9705 - val_loss: 0.3916 - val_accuracy: 0.8333\n",
            "Epoch 406/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.1508 - accuracy: 0.9596 - val_loss: 0.3586 - val_accuracy: 0.8333\n",
            "Epoch 407/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.1406 - accuracy: 0.9655 - val_loss: 0.2662 - val_accuracy: 0.8333\n",
            "Epoch 408/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.1279 - accuracy: 0.9840 - val_loss: 0.2593 - val_accuracy: 0.8333\n",
            "Epoch 409/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.1211 - accuracy: 0.9891 - val_loss: 0.2318 - val_accuracy: 0.8333\n",
            "Epoch 410/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.1173 - accuracy: 0.9857 - val_loss: 0.2117 - val_accuracy: 1.0000\n",
            "Epoch 411/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.1171 - accuracy: 0.9891 - val_loss: 0.1845 - val_accuracy: 1.0000\n",
            "Epoch 412/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.1137 - accuracy: 0.9857 - val_loss: 0.2455 - val_accuracy: 0.8333\n",
            "Epoch 413/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.1109 - accuracy: 0.9899 - val_loss: 0.2564 - val_accuracy: 0.8333\n",
            "Epoch 414/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.1113 - accuracy: 0.9848 - val_loss: 0.2256 - val_accuracy: 1.0000\n",
            "Epoch 415/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.1079 - accuracy: 0.9865 - val_loss: 0.2363 - val_accuracy: 0.8333\n",
            "Epoch 416/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.1027 - accuracy: 0.9865 - val_loss: 0.2100 - val_accuracy: 1.0000\n",
            "Epoch 417/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.1050 - accuracy: 0.9848 - val_loss: 0.3710 - val_accuracy: 0.6667\n",
            "Epoch 418/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.1201 - accuracy: 0.9747 - val_loss: 1.1248 - val_accuracy: 0.6667\n",
            "Epoch 419/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.7199 - accuracy: 0.8746 - val_loss: 0.4060 - val_accuracy: 0.6667\n",
            "Epoch 420/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.8697 - accuracy: 0.7348 - val_loss: 1.0827 - val_accuracy: 0.6667\n",
            "Epoch 421/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5070 - accuracy: 0.8443 - val_loss: 1.2608 - val_accuracy: 0.3333\n",
            "Epoch 422/1000\n",
            "594/594 [==============================] - 0s 42us/sample - loss: 0.8348 - accuracy: 0.7551 - val_loss: 2.7405 - val_accuracy: 0.3333\n",
            "Epoch 423/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.7711 - accuracy: 0.8064 - val_loss: 0.3217 - val_accuracy: 0.8333\n",
            "Epoch 424/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.2298 - accuracy: 0.9335 - val_loss: 0.3508 - val_accuracy: 0.8333\n",
            "Epoch 425/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.1510 - accuracy: 0.9722 - val_loss: 0.2683 - val_accuracy: 0.8333\n",
            "Epoch 426/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.1387 - accuracy: 0.9747 - val_loss: 0.1963 - val_accuracy: 1.0000\n",
            "Epoch 427/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.1286 - accuracy: 0.9790 - val_loss: 0.2229 - val_accuracy: 1.0000\n",
            "Epoch 428/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.1207 - accuracy: 0.9832 - val_loss: 0.2040 - val_accuracy: 1.0000\n",
            "Epoch 429/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.1134 - accuracy: 0.9823 - val_loss: 0.2678 - val_accuracy: 0.8333\n",
            "Epoch 430/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.1081 - accuracy: 0.9916 - val_loss: 0.1821 - val_accuracy: 1.0000\n",
            "Epoch 431/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.1044 - accuracy: 0.9899 - val_loss: 0.2253 - val_accuracy: 0.8333\n",
            "Epoch 432/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.1034 - accuracy: 0.9865 - val_loss: 0.2108 - val_accuracy: 0.8333\n",
            "Epoch 433/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.1007 - accuracy: 0.9848 - val_loss: 0.2281 - val_accuracy: 0.8333\n",
            "Epoch 434/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.0964 - accuracy: 0.9882 - val_loss: 0.2398 - val_accuracy: 0.8333\n",
            "Epoch 435/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.0930 - accuracy: 0.9899 - val_loss: 0.2136 - val_accuracy: 0.8333\n",
            "Epoch 436/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.0928 - accuracy: 0.9874 - val_loss: 0.1976 - val_accuracy: 0.9167\n",
            "Epoch 437/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.0893 - accuracy: 0.9891 - val_loss: 0.2635 - val_accuracy: 0.8333\n",
            "Epoch 438/1000\n",
            "594/594 [==============================] - 0s 19us/sample - loss: 0.0885 - accuracy: 0.9916 - val_loss: 0.2010 - val_accuracy: 0.8333\n",
            "Epoch 439/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.0859 - accuracy: 0.9865 - val_loss: 0.2017 - val_accuracy: 0.8333\n",
            "Epoch 440/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.0865 - accuracy: 0.9857 - val_loss: 0.1898 - val_accuracy: 0.8333\n",
            "Epoch 441/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.0831 - accuracy: 0.9874 - val_loss: 0.2243 - val_accuracy: 0.8333\n",
            "Epoch 442/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.0834 - accuracy: 0.9899 - val_loss: 0.2064 - val_accuracy: 0.8333\n",
            "Epoch 443/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.0805 - accuracy: 0.9865 - val_loss: 0.1552 - val_accuracy: 1.0000\n",
            "Epoch 444/1000\n",
            "594/594 [==============================] - 0s 19us/sample - loss: 0.0783 - accuracy: 0.9907 - val_loss: 0.1638 - val_accuracy: 1.0000\n",
            "Epoch 445/1000\n",
            "594/594 [==============================] - 0s 20us/sample - loss: 0.0763 - accuracy: 0.9899 - val_loss: 0.2074 - val_accuracy: 0.8333\n",
            "Epoch 446/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.0766 - accuracy: 0.9899 - val_loss: 0.1493 - val_accuracy: 1.0000\n",
            "Epoch 447/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.0741 - accuracy: 0.9882 - val_loss: 0.1736 - val_accuracy: 0.8333\n",
            "Epoch 448/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.0730 - accuracy: 0.9891 - val_loss: 0.1778 - val_accuracy: 0.8333\n",
            "Epoch 449/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.0726 - accuracy: 0.9865 - val_loss: 0.3027 - val_accuracy: 0.8333\n",
            "Epoch 450/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.0748 - accuracy: 0.9874 - val_loss: 0.2015 - val_accuracy: 0.8333\n",
            "Epoch 451/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.0690 - accuracy: 0.9916 - val_loss: 0.1660 - val_accuracy: 0.9167\n",
            "Epoch 452/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.0695 - accuracy: 0.9882 - val_loss: 0.1784 - val_accuracy: 0.8333\n",
            "Epoch 453/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.0664 - accuracy: 0.9899 - val_loss: 0.2241 - val_accuracy: 0.8333\n",
            "Epoch 454/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.0646 - accuracy: 0.9899 - val_loss: 0.1795 - val_accuracy: 0.8333\n",
            "Epoch 455/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.0652 - accuracy: 0.9899 - val_loss: 0.2759 - val_accuracy: 0.8333\n",
            "Epoch 456/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.0652 - accuracy: 0.9899 - val_loss: 0.1885 - val_accuracy: 0.8333\n",
            "Epoch 457/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.0623 - accuracy: 0.9899 - val_loss: 0.1996 - val_accuracy: 0.8333\n",
            "Epoch 458/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.0633 - accuracy: 0.9865 - val_loss: 0.2412 - val_accuracy: 0.8333\n",
            "Epoch 459/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.0644 - accuracy: 0.9882 - val_loss: 0.1571 - val_accuracy: 0.8333\n",
            "Epoch 460/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.0613 - accuracy: 0.9882 - val_loss: 0.1815 - val_accuracy: 0.8333\n",
            "Epoch 461/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.0583 - accuracy: 0.9916 - val_loss: 0.2109 - val_accuracy: 0.8333\n",
            "Epoch 462/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.0584 - accuracy: 0.9907 - val_loss: 0.2329 - val_accuracy: 0.8333\n",
            "Epoch 463/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.0599 - accuracy: 0.9916 - val_loss: 0.1743 - val_accuracy: 0.8333\n",
            "Epoch 464/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0583 - accuracy: 0.9899 - val_loss: 0.2038 - val_accuracy: 0.8333\n",
            "Epoch 465/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.0554 - accuracy: 0.9899 - val_loss: 0.1767 - val_accuracy: 0.8333\n",
            "Epoch 466/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.0550 - accuracy: 0.9899 - val_loss: 0.2527 - val_accuracy: 0.8333\n",
            "Epoch 467/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.0542 - accuracy: 0.9899 - val_loss: 0.1632 - val_accuracy: 0.8333\n",
            "Epoch 468/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.0539 - accuracy: 0.9899 - val_loss: 0.1837 - val_accuracy: 0.8333\n",
            "Epoch 469/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.0549 - accuracy: 0.9916 - val_loss: 0.1770 - val_accuracy: 0.8333\n",
            "Epoch 470/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.0598 - accuracy: 0.9865 - val_loss: 0.2515 - val_accuracy: 0.8333\n",
            "Epoch 471/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.0555 - accuracy: 0.9899 - val_loss: 0.3286 - val_accuracy: 0.8333\n",
            "Epoch 472/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.0552 - accuracy: 0.9899 - val_loss: 0.2074 - val_accuracy: 0.8333\n",
            "Epoch 473/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.0524 - accuracy: 0.9916 - val_loss: 0.1907 - val_accuracy: 0.8333\n",
            "Epoch 474/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.0514 - accuracy: 0.9899 - val_loss: 0.1814 - val_accuracy: 0.8333\n",
            "Epoch 475/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.0507 - accuracy: 0.9899 - val_loss: 0.2051 - val_accuracy: 0.8333\n",
            "Epoch 476/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.0496 - accuracy: 0.9899 - val_loss: 0.2212 - val_accuracy: 0.8333\n",
            "Epoch 477/1000\n",
            "594/594 [==============================] - 0s 20us/sample - loss: 0.0490 - accuracy: 0.9916 - val_loss: 0.2461 - val_accuracy: 0.8333\n",
            "Epoch 478/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.0485 - accuracy: 0.9899 - val_loss: 0.2184 - val_accuracy: 0.8333\n",
            "Epoch 479/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.0479 - accuracy: 0.9899 - val_loss: 0.2832 - val_accuracy: 0.8333\n",
            "Epoch 480/1000\n",
            "297/594 [==============>...............] - ETA: 0s - loss: 0.0446 - accuracy: 0.9933\n",
            "Epoch 00480: ReduceLROnPlateau reducing learning rate to 0.5.\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0494 - accuracy: 0.9899 - val_loss: 0.2491 - val_accuracy: 0.8333\n",
            "Epoch 481/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.0475 - accuracy: 0.9916 - val_loss: 0.2278 - val_accuracy: 0.8333\n",
            "Epoch 482/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.0461 - accuracy: 0.9907 - val_loss: 0.2168 - val_accuracy: 0.8333\n",
            "Epoch 483/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.0464 - accuracy: 0.9899 - val_loss: 0.2512 - val_accuracy: 0.8333\n",
            "Epoch 484/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.0460 - accuracy: 0.9916 - val_loss: 0.2176 - val_accuracy: 0.8333\n",
            "Epoch 485/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.0455 - accuracy: 0.9899 - val_loss: 0.2441 - val_accuracy: 0.8333\n",
            "Epoch 486/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.0452 - accuracy: 0.9916 - val_loss: 0.2394 - val_accuracy: 0.8333\n",
            "Epoch 487/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.0452 - accuracy: 0.9916 - val_loss: 0.2323 - val_accuracy: 0.8333\n",
            "Epoch 488/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.0447 - accuracy: 0.9899 - val_loss: 0.2493 - val_accuracy: 0.8333\n",
            "Epoch 489/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.0449 - accuracy: 0.9916 - val_loss: 0.2608 - val_accuracy: 0.8333\n",
            "Epoch 490/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.0444 - accuracy: 0.9916 - val_loss: 0.2437 - val_accuracy: 0.8333\n",
            "Epoch 491/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.0439 - accuracy: 0.9916 - val_loss: 0.2404 - val_accuracy: 0.8333\n",
            "Epoch 492/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.0443 - accuracy: 0.9907 - val_loss: 0.2240 - val_accuracy: 0.8333\n",
            "Epoch 493/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0447 - accuracy: 0.9916 - val_loss: 0.2204 - val_accuracy: 0.8333\n",
            "Epoch 494/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.0437 - accuracy: 0.9899 - val_loss: 0.2275 - val_accuracy: 0.8333\n",
            "Epoch 495/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.0436 - accuracy: 0.9916 - val_loss: 0.2292 - val_accuracy: 0.8333\n",
            "Epoch 496/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.0439 - accuracy: 0.9916 - val_loss: 0.2581 - val_accuracy: 0.8333\n",
            "Epoch 497/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.0429 - accuracy: 0.9916 - val_loss: 0.2441 - val_accuracy: 0.8333\n",
            "Epoch 498/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.0431 - accuracy: 0.9916 - val_loss: 0.2348 - val_accuracy: 0.8333\n",
            "Epoch 499/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.0432 - accuracy: 0.9907 - val_loss: 0.2282 - val_accuracy: 0.8333\n",
            "Epoch 500/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.0427 - accuracy: 0.9916 - val_loss: 0.2498 - val_accuracy: 0.8333\n",
            "Epoch 501/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.0424 - accuracy: 0.9916 - val_loss: 0.2357 - val_accuracy: 0.8333\n",
            "Epoch 502/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.0429 - accuracy: 0.9916 - val_loss: 0.2295 - val_accuracy: 0.8333\n",
            "Epoch 503/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.0430 - accuracy: 0.9899 - val_loss: 0.2334 - val_accuracy: 0.8333\n",
            "Epoch 504/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0424 - accuracy: 0.9907 - val_loss: 0.2562 - val_accuracy: 0.8333\n",
            "Epoch 505/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.0419 - accuracy: 0.9916 - val_loss: 0.2578 - val_accuracy: 0.8333\n",
            "Epoch 506/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.0425 - accuracy: 0.9899 - val_loss: 0.2658 - val_accuracy: 0.8333\n",
            "Epoch 507/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.0414 - accuracy: 0.9916 - val_loss: 0.2514 - val_accuracy: 0.8333\n",
            "Epoch 508/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.0418 - accuracy: 0.9916 - val_loss: 0.2708 - val_accuracy: 0.8333\n",
            "Epoch 509/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.0423 - accuracy: 0.9916 - val_loss: 0.2787 - val_accuracy: 0.8333\n",
            "Epoch 510/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.0419 - accuracy: 0.9907 - val_loss: 0.2697 - val_accuracy: 0.8333\n",
            "Epoch 511/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0410 - accuracy: 0.9916 - val_loss: 0.2577 - val_accuracy: 0.8333\n",
            "Epoch 512/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.0419 - accuracy: 0.9916 - val_loss: 0.2380 - val_accuracy: 0.8333\n",
            "Epoch 513/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.0422 - accuracy: 0.9907 - val_loss: 0.2897 - val_accuracy: 0.8333\n",
            "Epoch 514/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.0407 - accuracy: 0.9916 - val_loss: 0.2728 - val_accuracy: 0.8333\n",
            "Epoch 515/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.0413 - accuracy: 0.9916 - val_loss: 0.2434 - val_accuracy: 0.8333\n",
            "Epoch 516/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.0402 - accuracy: 0.9899 - val_loss: 0.2556 - val_accuracy: 0.8333\n",
            "Epoch 517/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.0400 - accuracy: 0.9916 - val_loss: 0.2635 - val_accuracy: 0.8333\n",
            "Epoch 518/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.0401 - accuracy: 0.9916 - val_loss: 0.2712 - val_accuracy: 0.8333\n",
            "Epoch 519/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.0403 - accuracy: 0.9899 - val_loss: 0.2699 - val_accuracy: 0.8333\n",
            "Epoch 520/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.0400 - accuracy: 0.9916 - val_loss: 0.2432 - val_accuracy: 0.8333\n",
            "Epoch 521/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.0397 - accuracy: 0.9916 - val_loss: 0.2441 - val_accuracy: 0.8333\n",
            "Epoch 522/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.0394 - accuracy: 0.9916 - val_loss: 0.2481 - val_accuracy: 0.8333\n",
            "Epoch 523/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.0400 - accuracy: 0.9916 - val_loss: 0.2448 - val_accuracy: 0.8333\n",
            "Epoch 524/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.0396 - accuracy: 0.9916 - val_loss: 0.2654 - val_accuracy: 0.8333\n",
            "Epoch 525/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.0390 - accuracy: 0.9916 - val_loss: 0.2688 - val_accuracy: 0.8333\n",
            "Epoch 526/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.0390 - accuracy: 0.9916 - val_loss: 0.2514 - val_accuracy: 0.8333\n",
            "Epoch 527/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.0386 - accuracy: 0.9916 - val_loss: 0.2584 - val_accuracy: 0.8333\n",
            "Epoch 528/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.0395 - accuracy: 0.9916 - val_loss: 0.2722 - val_accuracy: 0.8333\n",
            "Epoch 529/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.0384 - accuracy: 0.9916 - val_loss: 0.2701 - val_accuracy: 0.8333\n",
            "Epoch 530/1000\n",
            "297/594 [==============>...............] - ETA: 0s - loss: 0.0366 - accuracy: 0.9899\n",
            "Epoch 00530: ReduceLROnPlateau reducing learning rate to 0.25.\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.0385 - accuracy: 0.9916 - val_loss: 0.2576 - val_accuracy: 0.8333\n",
            "Epoch 531/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.0381 - accuracy: 0.9916 - val_loss: 0.2638 - val_accuracy: 0.8333\n",
            "Epoch 532/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.0380 - accuracy: 0.9916 - val_loss: 0.2671 - val_accuracy: 0.8333\n",
            "Epoch 533/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.0380 - accuracy: 0.9916 - val_loss: 0.2692 - val_accuracy: 0.8333\n",
            "Epoch 534/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.0381 - accuracy: 0.9916 - val_loss: 0.2721 - val_accuracy: 0.8333\n",
            "Epoch 535/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.0379 - accuracy: 0.9916 - val_loss: 0.2687 - val_accuracy: 0.8333\n",
            "Epoch 536/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.0377 - accuracy: 0.9916 - val_loss: 0.2711 - val_accuracy: 0.8333\n",
            "Epoch 537/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0378 - accuracy: 0.9916 - val_loss: 0.2741 - val_accuracy: 0.8333\n",
            "Epoch 538/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.0378 - accuracy: 0.9916 - val_loss: 0.2747 - val_accuracy: 0.8333\n",
            "Epoch 539/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.0379 - accuracy: 0.9916 - val_loss: 0.2720 - val_accuracy: 0.8333\n",
            "Epoch 540/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.0377 - accuracy: 0.9916 - val_loss: 0.2705 - val_accuracy: 0.8333\n",
            "Epoch 541/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.0374 - accuracy: 0.9916 - val_loss: 0.2723 - val_accuracy: 0.8333\n",
            "Epoch 542/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0375 - accuracy: 0.9916 - val_loss: 0.2742 - val_accuracy: 0.8333\n",
            "Epoch 543/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.0377 - accuracy: 0.9916 - val_loss: 0.2676 - val_accuracy: 0.8333\n",
            "Epoch 544/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.0374 - accuracy: 0.9916 - val_loss: 0.2695 - val_accuracy: 0.8333\n",
            "Epoch 545/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.0376 - accuracy: 0.9916 - val_loss: 0.2749 - val_accuracy: 0.8333\n",
            "Epoch 546/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.0374 - accuracy: 0.9916 - val_loss: 0.2739 - val_accuracy: 0.8333\n",
            "Epoch 547/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.0373 - accuracy: 0.9916 - val_loss: 0.2713 - val_accuracy: 0.8333\n",
            "Epoch 548/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.0379 - accuracy: 0.9916 - val_loss: 0.2646 - val_accuracy: 0.8333\n",
            "Epoch 549/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.0374 - accuracy: 0.9916 - val_loss: 0.2654 - val_accuracy: 0.8333\n",
            "Epoch 550/1000\n",
            "594/594 [==============================] - 0s 35us/sample - loss: 0.0371 - accuracy: 0.9916 - val_loss: 0.2705 - val_accuracy: 0.8333\n",
            "Epoch 551/1000\n",
            "594/594 [==============================] - 0s 36us/sample - loss: 0.0369 - accuracy: 0.9916 - val_loss: 0.2725 - val_accuracy: 0.8333\n",
            "Epoch 552/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.0370 - accuracy: 0.9916 - val_loss: 0.2717 - val_accuracy: 0.8333\n",
            "Epoch 553/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.0373 - accuracy: 0.9916 - val_loss: 0.2703 - val_accuracy: 0.8333\n",
            "Epoch 554/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.0370 - accuracy: 0.9916 - val_loss: 0.2744 - val_accuracy: 0.8333\n",
            "Epoch 555/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.0367 - accuracy: 0.9916 - val_loss: 0.2751 - val_accuracy: 0.8333\n",
            "Epoch 556/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.0373 - accuracy: 0.9916 - val_loss: 0.2830 - val_accuracy: 0.8333\n",
            "Epoch 557/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.0367 - accuracy: 0.9916 - val_loss: 0.2816 - val_accuracy: 0.8333\n",
            "Epoch 558/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.0366 - accuracy: 0.9916 - val_loss: 0.2806 - val_accuracy: 0.8333\n",
            "Epoch 559/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.0367 - accuracy: 0.9916 - val_loss: 0.2829 - val_accuracy: 0.8333\n",
            "Epoch 560/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.0367 - accuracy: 0.9916 - val_loss: 0.2816 - val_accuracy: 0.8333\n",
            "Epoch 561/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.0366 - accuracy: 0.9916 - val_loss: 0.2832 - val_accuracy: 0.8333\n",
            "Epoch 562/1000\n",
            "594/594 [==============================] - 0s 20us/sample - loss: 0.0363 - accuracy: 0.9916 - val_loss: 0.2817 - val_accuracy: 0.8333\n",
            "Epoch 563/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.0364 - accuracy: 0.9916 - val_loss: 0.2768 - val_accuracy: 0.8333\n",
            "Epoch 564/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.0363 - accuracy: 0.9916 - val_loss: 0.2776 - val_accuracy: 0.8333\n",
            "Epoch 565/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.0365 - accuracy: 0.9916 - val_loss: 0.2733 - val_accuracy: 0.8333\n",
            "Epoch 566/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0365 - accuracy: 0.9916 - val_loss: 0.2703 - val_accuracy: 0.8333\n",
            "Epoch 567/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0364 - accuracy: 0.9916 - val_loss: 0.2759 - val_accuracy: 0.8333\n",
            "Epoch 568/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0361 - accuracy: 0.9916 - val_loss: 0.2807 - val_accuracy: 0.8333\n",
            "Epoch 569/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0362 - accuracy: 0.9916 - val_loss: 0.2793 - val_accuracy: 0.8333\n",
            "Epoch 570/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.0361 - accuracy: 0.9916 - val_loss: 0.2828 - val_accuracy: 0.8333\n",
            "Epoch 571/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0359 - accuracy: 0.9916 - val_loss: 0.2816 - val_accuracy: 0.8333\n",
            "Epoch 572/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0359 - accuracy: 0.9916 - val_loss: 0.2802 - val_accuracy: 0.8333\n",
            "Epoch 573/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.0361 - accuracy: 0.9916 - val_loss: 0.2789 - val_accuracy: 0.8333\n",
            "Epoch 574/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.0358 - accuracy: 0.9916 - val_loss: 0.2802 - val_accuracy: 0.8333\n",
            "Epoch 575/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0358 - accuracy: 0.9916 - val_loss: 0.2798 - val_accuracy: 0.8333\n",
            "Epoch 576/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.0360 - accuracy: 0.9916 - val_loss: 0.2866 - val_accuracy: 0.8333\n",
            "Epoch 577/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.0357 - accuracy: 0.9916 - val_loss: 0.2864 - val_accuracy: 0.8333\n",
            "Epoch 578/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.0357 - accuracy: 0.9916 - val_loss: 0.2817 - val_accuracy: 0.8333\n",
            "Epoch 579/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.0358 - accuracy: 0.9916 - val_loss: 0.2791 - val_accuracy: 0.8333\n",
            "Epoch 580/1000\n",
            "297/594 [==============>...............] - ETA: 0s - loss: 0.0286 - accuracy: 0.9933\n",
            "Epoch 00580: ReduceLROnPlateau reducing learning rate to 0.125.\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.0356 - accuracy: 0.9916 - val_loss: 0.2793 - val_accuracy: 0.8333\n",
            "Epoch 581/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0355 - accuracy: 0.9916 - val_loss: 0.2818 - val_accuracy: 0.8333\n",
            "Epoch 582/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0355 - accuracy: 0.9916 - val_loss: 0.2823 - val_accuracy: 0.8333\n",
            "Epoch 583/1000\n",
            "594/594 [==============================] - 0s 36us/sample - loss: 0.0355 - accuracy: 0.9916 - val_loss: 0.2840 - val_accuracy: 0.8333\n",
            "Epoch 584/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0356 - accuracy: 0.9916 - val_loss: 0.2828 - val_accuracy: 0.8333\n",
            "Epoch 585/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.0357 - accuracy: 0.9916 - val_loss: 0.2857 - val_accuracy: 0.8333\n",
            "Epoch 586/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.0354 - accuracy: 0.9916 - val_loss: 0.2865 - val_accuracy: 0.8333\n",
            "Epoch 587/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.0356 - accuracy: 0.9916 - val_loss: 0.2847 - val_accuracy: 0.8333\n",
            "Epoch 588/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.0354 - accuracy: 0.9916 - val_loss: 0.2844 - val_accuracy: 0.8333\n",
            "Epoch 589/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.0354 - accuracy: 0.9916 - val_loss: 0.2847 - val_accuracy: 0.8333\n",
            "Epoch 590/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.0354 - accuracy: 0.9916 - val_loss: 0.2842 - val_accuracy: 0.8333\n",
            "Epoch 591/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.0353 - accuracy: 0.9916 - val_loss: 0.2837 - val_accuracy: 0.8333\n",
            "Epoch 592/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.0358 - accuracy: 0.9916 - val_loss: 0.2864 - val_accuracy: 0.8333\n",
            "Epoch 593/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.0353 - accuracy: 0.9916 - val_loss: 0.2873 - val_accuracy: 0.8333\n",
            "Epoch 594/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.0352 - accuracy: 0.9916 - val_loss: 0.2867 - val_accuracy: 0.8333\n",
            "Epoch 595/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.0355 - accuracy: 0.9916 - val_loss: 0.2895 - val_accuracy: 0.8333\n",
            "Epoch 596/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.0352 - accuracy: 0.9916 - val_loss: 0.2893 - val_accuracy: 0.8333\n",
            "Epoch 597/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.0352 - accuracy: 0.9916 - val_loss: 0.2897 - val_accuracy: 0.8333\n",
            "Epoch 598/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0354 - accuracy: 0.9916 - val_loss: 0.2872 - val_accuracy: 0.8333\n",
            "Epoch 599/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.0351 - accuracy: 0.9916 - val_loss: 0.2879 - val_accuracy: 0.8333\n",
            "Epoch 600/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.0350 - accuracy: 0.9916 - val_loss: 0.2880 - val_accuracy: 0.8333\n",
            "Epoch 601/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0350 - accuracy: 0.9916 - val_loss: 0.2884 - val_accuracy: 0.8333\n",
            "Epoch 602/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.0351 - accuracy: 0.9916 - val_loss: 0.2895 - val_accuracy: 0.8333\n",
            "Epoch 603/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.0352 - accuracy: 0.9916 - val_loss: 0.2877 - val_accuracy: 0.8333\n",
            "Epoch 604/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0351 - accuracy: 0.9916 - val_loss: 0.2869 - val_accuracy: 0.8333\n",
            "Epoch 605/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.0350 - accuracy: 0.9916 - val_loss: 0.2875 - val_accuracy: 0.8333\n",
            "Epoch 606/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.0349 - accuracy: 0.9916 - val_loss: 0.2879 - val_accuracy: 0.8333\n",
            "Epoch 607/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.0350 - accuracy: 0.9916 - val_loss: 0.2868 - val_accuracy: 0.8333\n",
            "Epoch 608/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.0349 - accuracy: 0.9916 - val_loss: 0.2876 - val_accuracy: 0.8333\n",
            "Epoch 609/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.0350 - accuracy: 0.9916 - val_loss: 0.2893 - val_accuracy: 0.8333\n",
            "Epoch 610/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.0351 - accuracy: 0.9916 - val_loss: 0.2875 - val_accuracy: 0.8333\n",
            "Epoch 611/1000\n",
            "594/594 [==============================] - 0s 36us/sample - loss: 0.0348 - accuracy: 0.9916 - val_loss: 0.2877 - val_accuracy: 0.8333\n",
            "Epoch 612/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.0349 - accuracy: 0.9916 - val_loss: 0.2873 - val_accuracy: 0.8333\n",
            "Epoch 613/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0348 - accuracy: 0.9916 - val_loss: 0.2878 - val_accuracy: 0.8333\n",
            "Epoch 614/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.0348 - accuracy: 0.9916 - val_loss: 0.2874 - val_accuracy: 0.8333\n",
            "Epoch 615/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.0348 - accuracy: 0.9916 - val_loss: 0.2871 - val_accuracy: 0.8333\n",
            "Epoch 616/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.0349 - accuracy: 0.9916 - val_loss: 0.2893 - val_accuracy: 0.8333\n",
            "Epoch 617/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.0347 - accuracy: 0.9916 - val_loss: 0.2905 - val_accuracy: 0.8333\n",
            "Epoch 618/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0347 - accuracy: 0.9916 - val_loss: 0.2908 - val_accuracy: 0.8333\n",
            "Epoch 619/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0347 - accuracy: 0.9916 - val_loss: 0.2906 - val_accuracy: 0.8333\n",
            "Epoch 620/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.0346 - accuracy: 0.9916 - val_loss: 0.2905 - val_accuracy: 0.8333\n",
            "Epoch 621/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.0346 - accuracy: 0.9916 - val_loss: 0.2903 - val_accuracy: 0.8333\n",
            "Epoch 622/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.0347 - accuracy: 0.9916 - val_loss: 0.2915 - val_accuracy: 0.8333\n",
            "Epoch 623/1000\n",
            "594/594 [==============================] - 0s 46us/sample - loss: 0.0346 - accuracy: 0.9916 - val_loss: 0.2919 - val_accuracy: 0.8333\n",
            "Epoch 624/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.0346 - accuracy: 0.9916 - val_loss: 0.2923 - val_accuracy: 0.8333\n",
            "Epoch 625/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0349 - accuracy: 0.9916 - val_loss: 0.2902 - val_accuracy: 0.8333\n",
            "Epoch 626/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.0348 - accuracy: 0.9916 - val_loss: 0.2899 - val_accuracy: 0.8333\n",
            "Epoch 627/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.0345 - accuracy: 0.9916 - val_loss: 0.2902 - val_accuracy: 0.8333\n",
            "Epoch 628/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.0346 - accuracy: 0.9916 - val_loss: 0.2897 - val_accuracy: 0.8333\n",
            "Epoch 629/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.0345 - accuracy: 0.9916 - val_loss: 0.2898 - val_accuracy: 0.8333\n",
            "Epoch 630/1000\n",
            "297/594 [==============>...............] - ETA: 0s - loss: 0.0353 - accuracy: 0.9899\n",
            "Epoch 00630: ReduceLROnPlateau reducing learning rate to 0.0625.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.0345 - accuracy: 0.9916 - val_loss: 0.2897 - val_accuracy: 0.8333\n",
            "Epoch 00630: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3e5dbe36d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyvcC004RVfh",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LtIbpp5dDlH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "outputId": "36fc8733-ca17-4455-d310-8dfcdd12bb95"
      },
      "source": [
        "y_pred = mlp.predict(X)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
        "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n",
        "                     np.arange(y_min, y_max, 0.02))\n",
        "Z = None\n",
        "Z = mlp.predict(np.c_[xx.ravel(), yy.ravel()])[:,1]\n",
        "Z = Z.reshape(xx.shape)\n",
        "cm = plt.cm.bwr\n",
        "\n",
        "fig = plt.figure(figsize=(6,6))\n",
        "\n",
        "plt.contourf(xx, yy, Z, cmap=cm, alpha=.25)\n",
        "\n",
        "plt.plot(X[1,0],X[1,1],'+', color='#648fff', label='Positive Class')\n",
        "plt.plot(X[2,1],X[2,1],'_', color='#fe6100', label='Negative Class')\n",
        "\n",
        "for i in range(len(y)):\n",
        "  x1 = X[i,0]\n",
        "  x2 = X[i,1]\n",
        "  if y[i]==1: \n",
        "    if (y_pred[i] == 0):\n",
        "      plt.plot(x1,x2,'+', color='#648fff')\n",
        "    else:\n",
        "      plt.plot(x1,x2,'k.', alpha=0.25)\n",
        "  else:\n",
        "    if (y_pred[i] == 1):\n",
        "      plt.plot(x1,x2,'_', color='#fe6100')\n",
        "    else:\n",
        "      plt.plot(x1,x2,'k.', alpha=0.25)\n",
        "\n",
        "accuracy = np.sum(np.equal(y_pred,y_actual))/len(y_actual)\n",
        "\n",
        "plt.axis('tight')\n",
        "plt.xlim(min(X[:,0])-0.1, max(X[:,0])+0.1)\n",
        "plt.ylim(min(X[:,1])-0.1, max(X[:,1])+0.1)\n",
        "plt.xlabel('$x_1$')\n",
        "plt.ylabel('$x_2$')\n",
        "plt.legend()\n",
        "plt.title('Keras-based 4-layer MLP on spiral dataset. Accuracy: {:04.3}'.format(accuracy))\n",
        "plt.savefig('ch.6.MLP.keras.deep.g.spirals.png', dpi=350, bbox_inches='tight')\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAGFCAYAAADAc+UQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBDS5-PA6CCO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "670fa5af-3fd0-4f88-e102-71ace7ca2b2c"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "mlp = Sequential()\n",
        "mlp.add(Dense(16, input_dim=2, activation='relu'))\n",
        "mlp.add(Dense(16, activation='relu'))\n",
        "mlp.add(Dense(16, activation='relu'))\n",
        "mlp.add(Dense(16, activation='sigmoid'))\n",
        "mlp.add(Dense(2, activation='sigmoid'))\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(factor=0.5, monitor='accuracy',\n",
        "                              patience=50, min_lr=0.00000001,\n",
        "                              verbose = 1)\n",
        "\n",
        "stop_save = EarlyStopping(patience=200, monitor='accuracy',\n",
        "                          verbose=1, \n",
        "                          restore_best_weights=True)\n",
        "\n",
        "# All parameter gradients will be clipped to\n",
        "# a maximum norm of 1.\n",
        "sgd = optimizers.SGD(lr=1., clipnorm=1.)\n",
        "\n",
        "mlp.compile(loss='binary_crossentropy',\n",
        "            optimizer=sgd,\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "# trains the model\n",
        "mlp.fit(X, yv, epochs=1000, batch_size=297,\n",
        "        verbose=1, callbacks=[reduce_lr, stop_save], \n",
        "        validation_split = 0.01)\n",
        "\n",
        "y_pred = mlp.predict(X)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
        "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n",
        "                     np.arange(y_min, y_max, 0.02))\n",
        "Z = None\n",
        "Z = mlp.predict(np.c_[xx.ravel(), yy.ravel()])[:,1]\n",
        "Z = Z.reshape(xx.shape)\n",
        "cm = plt.cm.bwr\n",
        "\n",
        "fig = plt.figure(figsize=(6,6))\n",
        "\n",
        "plt.contourf(xx, yy, Z, cmap=cm, alpha=.25)\n",
        "\n",
        "plt.plot(X[1,0],X[1,1],'+', color='#648fff', label='Positive Class')\n",
        "plt.plot(X[2,1],X[2,1],'_', color='#fe6100', label='Negative Class')\n",
        "\n",
        "for i in range(len(y)):\n",
        "  x1 = X[i,0]\n",
        "  x2 = X[i,1]\n",
        "  if y[i]==1: \n",
        "    if (y_pred[i] == 0):\n",
        "      plt.plot(x1,x2,'+', color='#648fff')\n",
        "    else:\n",
        "      plt.plot(x1,x2,'k.', alpha=0.25)\n",
        "  else:\n",
        "    if (y_pred[i] == 1):\n",
        "      plt.plot(x1,x2,'_', color='#fe6100')\n",
        "    else:\n",
        "      plt.plot(x1,x2,'k.', alpha=0.25)\n",
        "\n",
        "accuracy = np.sum(np.equal(y_pred,y_actual))/len(y_actual)\n",
        "\n",
        "plt.axis('tight')\n",
        "plt.xlim(min(X[:,0])-0.1, max(X[:,0])+0.1)\n",
        "plt.ylim(min(X[:,1])-0.1, max(X[:,1])+0.1)\n",
        "plt.xlabel('$x_1$')\n",
        "plt.ylabel('$x_2$')\n",
        "plt.legend()\n",
        "plt.title('Keras-based 4-layer MLP on spiral dataset. Accuracy: {:04.3}'.format(accuracy))\n",
        "plt.savefig('ch.6.MLP.keras.deep.j.spirals.png', dpi=350, bbox_inches='tight')\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 594 samples, validate on 6 samples\n",
            "Epoch 1/1000\n",
            "594/594 [==============================] - 0s 497us/sample - loss: 0.7033 - accuracy: 0.5000 - val_loss: 0.6716 - val_accuracy: 0.8333\n",
            "Epoch 2/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6947 - accuracy: 0.4798 - val_loss: 0.6762 - val_accuracy: 1.0000\n",
            "Epoch 3/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6919 - accuracy: 0.5455 - val_loss: 0.6965 - val_accuracy: 0.4167\n",
            "Epoch 4/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6909 - accuracy: 0.5598 - val_loss: 0.7161 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6896 - accuracy: 0.5051 - val_loss: 0.6938 - val_accuracy: 0.5833\n",
            "Epoch 6/1000\n",
            "594/594 [==============================] - 0s 36us/sample - loss: 0.6899 - accuracy: 0.5715 - val_loss: 0.7305 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6872 - accuracy: 0.5320 - val_loss: 0.7115 - val_accuracy: 0.0833\n",
            "Epoch 8/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6856 - accuracy: 0.5530 - val_loss: 0.7090 - val_accuracy: 0.2500\n",
            "Epoch 9/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6841 - accuracy: 0.6019 - val_loss: 0.7114 - val_accuracy: 0.2500\n",
            "Epoch 10/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6845 - accuracy: 0.5404 - val_loss: 0.6793 - val_accuracy: 0.6667\n",
            "Epoch 11/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6821 - accuracy: 0.6010 - val_loss: 0.7357 - val_accuracy: 0.1667\n",
            "Epoch 12/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6803 - accuracy: 0.5968 - val_loss: 0.7425 - val_accuracy: 0.1667\n",
            "Epoch 13/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6763 - accuracy: 0.6061 - val_loss: 0.7081 - val_accuracy: 0.3333\n",
            "Epoch 14/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6746 - accuracy: 0.6162 - val_loss: 0.6941 - val_accuracy: 0.5833\n",
            "Epoch 15/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6729 - accuracy: 0.6254 - val_loss: 0.6909 - val_accuracy: 0.6667\n",
            "Epoch 16/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6678 - accuracy: 0.6330 - val_loss: 0.7333 - val_accuracy: 0.3333\n",
            "Epoch 17/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6646 - accuracy: 0.6153 - val_loss: 0.7428 - val_accuracy: 0.2500\n",
            "Epoch 18/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6619 - accuracy: 0.6187 - val_loss: 0.7201 - val_accuracy: 0.5000\n",
            "Epoch 19/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6584 - accuracy: 0.6195 - val_loss: 0.7522 - val_accuracy: 0.2500\n",
            "Epoch 20/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6601 - accuracy: 0.6296 - val_loss: 0.8111 - val_accuracy: 0.1667\n",
            "Epoch 21/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6557 - accuracy: 0.6162 - val_loss: 0.7923 - val_accuracy: 0.1667\n",
            "Epoch 22/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6513 - accuracy: 0.6162 - val_loss: 0.7727 - val_accuracy: 0.2500\n",
            "Epoch 23/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6487 - accuracy: 0.6195 - val_loss: 0.7589 - val_accuracy: 0.3333\n",
            "Epoch 24/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6480 - accuracy: 0.6128 - val_loss: 0.7449 - val_accuracy: 0.5000\n",
            "Epoch 25/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6458 - accuracy: 0.6229 - val_loss: 0.7985 - val_accuracy: 0.1667\n",
            "Epoch 26/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6442 - accuracy: 0.6111 - val_loss: 0.7905 - val_accuracy: 0.1667\n",
            "Epoch 27/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6488 - accuracy: 0.6254 - val_loss: 0.8734 - val_accuracy: 0.1667\n",
            "Epoch 28/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6432 - accuracy: 0.6086 - val_loss: 0.7629 - val_accuracy: 0.4167\n",
            "Epoch 29/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6417 - accuracy: 0.6187 - val_loss: 0.7906 - val_accuracy: 0.2500\n",
            "Epoch 30/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6426 - accuracy: 0.6296 - val_loss: 0.8586 - val_accuracy: 0.1667\n",
            "Epoch 31/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6408 - accuracy: 0.6195 - val_loss: 0.8211 - val_accuracy: 0.1667\n",
            "Epoch 32/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6393 - accuracy: 0.6170 - val_loss: 0.7859 - val_accuracy: 0.3333\n",
            "Epoch 33/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6384 - accuracy: 0.6204 - val_loss: 0.8261 - val_accuracy: 0.1667\n",
            "Epoch 34/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6380 - accuracy: 0.6195 - val_loss: 0.8190 - val_accuracy: 0.1667\n",
            "Epoch 35/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6374 - accuracy: 0.6229 - val_loss: 0.7950 - val_accuracy: 0.2500\n",
            "Epoch 36/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6371 - accuracy: 0.6204 - val_loss: 0.8158 - val_accuracy: 0.1667\n",
            "Epoch 37/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6369 - accuracy: 0.6153 - val_loss: 0.8498 - val_accuracy: 0.1667\n",
            "Epoch 38/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6371 - accuracy: 0.6246 - val_loss: 0.8582 - val_accuracy: 0.1667\n",
            "Epoch 39/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6358 - accuracy: 0.6246 - val_loss: 0.8370 - val_accuracy: 0.1667\n",
            "Epoch 40/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6395 - accuracy: 0.6195 - val_loss: 0.7423 - val_accuracy: 0.5000\n",
            "Epoch 41/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6394 - accuracy: 0.6212 - val_loss: 0.7815 - val_accuracy: 0.3333\n",
            "Epoch 42/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6359 - accuracy: 0.6128 - val_loss: 0.8003 - val_accuracy: 0.2500\n",
            "Epoch 43/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6349 - accuracy: 0.6237 - val_loss: 0.8270 - val_accuracy: 0.1667\n",
            "Epoch 44/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6356 - accuracy: 0.6271 - val_loss: 0.8788 - val_accuracy: 0.1667\n",
            "Epoch 45/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6346 - accuracy: 0.6204 - val_loss: 0.7691 - val_accuracy: 0.4167\n",
            "Epoch 46/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6378 - accuracy: 0.6263 - val_loss: 0.7668 - val_accuracy: 0.4167\n",
            "Epoch 47/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6339 - accuracy: 0.6263 - val_loss: 0.8139 - val_accuracy: 0.1667\n",
            "Epoch 48/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6357 - accuracy: 0.6237 - val_loss: 0.7603 - val_accuracy: 0.5000\n",
            "Epoch 49/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6362 - accuracy: 0.6178 - val_loss: 0.7874 - val_accuracy: 0.3333\n",
            "Epoch 50/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6314 - accuracy: 0.6212 - val_loss: 0.8451 - val_accuracy: 0.1667\n",
            "Epoch 51/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6320 - accuracy: 0.6212 - val_loss: 0.8749 - val_accuracy: 0.1667\n",
            "Epoch 52/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6407 - accuracy: 0.6128 - val_loss: 0.9543 - val_accuracy: 0.1667\n",
            "Epoch 53/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6411 - accuracy: 0.6330 - val_loss: 0.9174 - val_accuracy: 0.1667\n",
            "Epoch 54/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6325 - accuracy: 0.6254 - val_loss: 0.8696 - val_accuracy: 0.1667\n",
            "Epoch 55/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6316 - accuracy: 0.6170 - val_loss: 0.8879 - val_accuracy: 0.1667\n",
            "Epoch 56/1000\n",
            "594/594 [==============================] - 0s 35us/sample - loss: 0.6295 - accuracy: 0.6254 - val_loss: 0.7968 - val_accuracy: 0.3333\n",
            "Epoch 57/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6327 - accuracy: 0.6153 - val_loss: 0.9305 - val_accuracy: 0.1667\n",
            "Epoch 58/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6334 - accuracy: 0.6254 - val_loss: 0.8790 - val_accuracy: 0.1667\n",
            "Epoch 59/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6332 - accuracy: 0.6288 - val_loss: 0.7177 - val_accuracy: 0.5833\n",
            "Epoch 60/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6315 - accuracy: 0.6279 - val_loss: 0.8165 - val_accuracy: 0.2500\n",
            "Epoch 61/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6288 - accuracy: 0.6111 - val_loss: 0.8950 - val_accuracy: 0.1667\n",
            "Epoch 62/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6267 - accuracy: 0.6338 - val_loss: 0.8342 - val_accuracy: 0.1667\n",
            "Epoch 63/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6266 - accuracy: 0.6288 - val_loss: 0.8284 - val_accuracy: 0.1667\n",
            "Epoch 64/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6267 - accuracy: 0.6187 - val_loss: 0.8939 - val_accuracy: 0.1667\n",
            "Epoch 65/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6255 - accuracy: 0.6212 - val_loss: 0.8405 - val_accuracy: 0.1667\n",
            "Epoch 66/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6251 - accuracy: 0.6263 - val_loss: 0.8813 - val_accuracy: 0.1667\n",
            "Epoch 67/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6251 - accuracy: 0.6322 - val_loss: 0.8025 - val_accuracy: 0.3333\n",
            "Epoch 68/1000\n",
            "594/594 [==============================] - 0s 39us/sample - loss: 0.6251 - accuracy: 0.6271 - val_loss: 0.8370 - val_accuracy: 0.1667\n",
            "Epoch 69/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6242 - accuracy: 0.6347 - val_loss: 0.7871 - val_accuracy: 0.3333\n",
            "Epoch 70/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6237 - accuracy: 0.6254 - val_loss: 0.8241 - val_accuracy: 0.2500\n",
            "Epoch 71/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.6226 - accuracy: 0.6423 - val_loss: 0.8090 - val_accuracy: 0.3333\n",
            "Epoch 72/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6216 - accuracy: 0.6296 - val_loss: 0.8678 - val_accuracy: 0.1667\n",
            "Epoch 73/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6213 - accuracy: 0.6473 - val_loss: 0.8068 - val_accuracy: 0.3333\n",
            "Epoch 74/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6221 - accuracy: 0.6237 - val_loss: 0.9204 - val_accuracy: 0.1667\n",
            "Epoch 75/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6222 - accuracy: 0.6490 - val_loss: 0.8539 - val_accuracy: 0.1667\n",
            "Epoch 76/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6221 - accuracy: 0.6397 - val_loss: 0.8414 - val_accuracy: 0.3333\n",
            "Epoch 77/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6193 - accuracy: 0.6456 - val_loss: 0.8377 - val_accuracy: 0.1667\n",
            "Epoch 78/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6213 - accuracy: 0.6456 - val_loss: 0.7454 - val_accuracy: 0.4167\n",
            "Epoch 79/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6194 - accuracy: 0.6515 - val_loss: 0.8417 - val_accuracy: 0.1667\n",
            "Epoch 80/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6355 - accuracy: 0.6431 - val_loss: 0.6161 - val_accuracy: 0.6667\n",
            "Epoch 81/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6334 - accuracy: 0.6490 - val_loss: 0.8123 - val_accuracy: 0.1667\n",
            "Epoch 82/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.6215 - accuracy: 0.6481 - val_loss: 0.7207 - val_accuracy: 0.6667\n",
            "Epoch 83/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6178 - accuracy: 0.6406 - val_loss: 0.9016 - val_accuracy: 0.1667\n",
            "Epoch 84/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6163 - accuracy: 0.6692 - val_loss: 0.7744 - val_accuracy: 0.3333\n",
            "Epoch 85/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6166 - accuracy: 0.6423 - val_loss: 0.8263 - val_accuracy: 0.1667\n",
            "Epoch 86/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6195 - accuracy: 0.6439 - val_loss: 0.8569 - val_accuracy: 0.1667\n",
            "Epoch 87/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6161 - accuracy: 0.6406 - val_loss: 0.8552 - val_accuracy: 0.1667\n",
            "Epoch 88/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6157 - accuracy: 0.6532 - val_loss: 0.7538 - val_accuracy: 0.5000\n",
            "Epoch 89/1000\n",
            "594/594 [==============================] - 0s 33us/sample - loss: 0.6142 - accuracy: 0.6498 - val_loss: 0.9429 - val_accuracy: 0.1667\n",
            "Epoch 90/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6147 - accuracy: 0.6549 - val_loss: 0.7220 - val_accuracy: 0.5833\n",
            "Epoch 91/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6141 - accuracy: 0.6608 - val_loss: 0.8236 - val_accuracy: 0.1667\n",
            "Epoch 92/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6126 - accuracy: 0.6507 - val_loss: 0.9086 - val_accuracy: 0.1667\n",
            "Epoch 93/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6110 - accuracy: 0.6582 - val_loss: 0.7778 - val_accuracy: 0.3333\n",
            "Epoch 94/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6214 - accuracy: 0.6574 - val_loss: 0.6685 - val_accuracy: 0.6667\n",
            "Epoch 95/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6429 - accuracy: 0.6397 - val_loss: 0.6197 - val_accuracy: 0.6667\n",
            "Epoch 96/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6293 - accuracy: 0.6178 - val_loss: 0.7297 - val_accuracy: 0.6667\n",
            "Epoch 97/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6220 - accuracy: 0.6684 - val_loss: 0.6650 - val_accuracy: 0.6667\n",
            "Epoch 98/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6351 - accuracy: 0.6263 - val_loss: 0.6370 - val_accuracy: 0.6667\n",
            "Epoch 99/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6224 - accuracy: 0.6330 - val_loss: 0.7329 - val_accuracy: 0.6667\n",
            "Epoch 100/1000\n",
            "594/594 [==============================] - 0s 34us/sample - loss: 0.6106 - accuracy: 0.6776 - val_loss: 0.7918 - val_accuracy: 0.3333\n",
            "Epoch 101/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6096 - accuracy: 0.6599 - val_loss: 0.7643 - val_accuracy: 0.5000\n",
            "Epoch 102/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6094 - accuracy: 0.6667 - val_loss: 0.7925 - val_accuracy: 0.3333\n",
            "Epoch 103/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6067 - accuracy: 0.6801 - val_loss: 0.8934 - val_accuracy: 0.1667\n",
            "Epoch 104/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6075 - accuracy: 0.6616 - val_loss: 0.7020 - val_accuracy: 0.6667\n",
            "Epoch 105/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6142 - accuracy: 0.6658 - val_loss: 0.7399 - val_accuracy: 0.6667\n",
            "Epoch 106/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6062 - accuracy: 0.6768 - val_loss: 0.9438 - val_accuracy: 0.1667\n",
            "Epoch 107/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6062 - accuracy: 0.6734 - val_loss: 0.7613 - val_accuracy: 0.5833\n",
            "Epoch 108/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6064 - accuracy: 0.6961 - val_loss: 0.9414 - val_accuracy: 0.1667\n",
            "Epoch 109/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6050 - accuracy: 0.6684 - val_loss: 0.7541 - val_accuracy: 0.5833\n",
            "Epoch 110/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6041 - accuracy: 0.6944 - val_loss: 0.7831 - val_accuracy: 0.4167\n",
            "Epoch 111/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6087 - accuracy: 0.6726 - val_loss: 0.6615 - val_accuracy: 0.6667\n",
            "Epoch 112/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6245 - accuracy: 0.6372 - val_loss: 0.5932 - val_accuracy: 0.6667\n",
            "Epoch 113/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6042 - accuracy: 0.6557 - val_loss: 0.9709 - val_accuracy: 0.0833\n",
            "Epoch 114/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6128 - accuracy: 0.6616 - val_loss: 0.8925 - val_accuracy: 0.2500\n",
            "Epoch 115/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6021 - accuracy: 0.6869 - val_loss: 0.6816 - val_accuracy: 0.6667\n",
            "Epoch 116/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5997 - accuracy: 0.6877 - val_loss: 0.9852 - val_accuracy: 0.0000e+00\n",
            "Epoch 117/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6027 - accuracy: 0.6717 - val_loss: 0.8127 - val_accuracy: 0.4167\n",
            "Epoch 118/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.5984 - accuracy: 0.7003 - val_loss: 0.7418 - val_accuracy: 0.6667\n",
            "Epoch 119/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5967 - accuracy: 0.7088 - val_loss: 0.8496 - val_accuracy: 0.3333\n",
            "Epoch 120/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.5955 - accuracy: 0.6936 - val_loss: 0.7207 - val_accuracy: 0.6667\n",
            "Epoch 121/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6027 - accuracy: 0.6785 - val_loss: 0.6392 - val_accuracy: 0.6667\n",
            "Epoch 122/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6100 - accuracy: 0.6288 - val_loss: 0.5866 - val_accuracy: 0.6667\n",
            "Epoch 123/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6269 - accuracy: 0.6094 - val_loss: 0.5269 - val_accuracy: 0.6667\n",
            "Epoch 124/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6272 - accuracy: 0.6010 - val_loss: 0.6509 - val_accuracy: 0.6667\n",
            "Epoch 125/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6071 - accuracy: 0.6473 - val_loss: 0.6461 - val_accuracy: 0.6667\n",
            "Epoch 126/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6210 - accuracy: 0.6077 - val_loss: 0.5436 - val_accuracy: 0.6667\n",
            "Epoch 127/1000\n",
            "594/594 [==============================] - 0s 46us/sample - loss: 0.6489 - accuracy: 0.5800 - val_loss: 0.4901 - val_accuracy: 0.8333\n",
            "Epoch 128/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6457 - accuracy: 0.5985 - val_loss: 0.5857 - val_accuracy: 0.6667\n",
            "Epoch 129/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6062 - accuracy: 0.6094 - val_loss: 0.7167 - val_accuracy: 0.6667\n",
            "Epoch 130/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5929 - accuracy: 0.7029 - val_loss: 0.8768 - val_accuracy: 0.2500\n",
            "Epoch 131/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5947 - accuracy: 0.6843 - val_loss: 0.8367 - val_accuracy: 0.3333\n",
            "Epoch 132/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5885 - accuracy: 0.6978 - val_loss: 0.7578 - val_accuracy: 0.6667\n",
            "Epoch 133/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5886 - accuracy: 0.7071 - val_loss: 0.8549 - val_accuracy: 0.3333\n",
            "Epoch 134/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5905 - accuracy: 0.6902 - val_loss: 0.7950 - val_accuracy: 0.5000\n",
            "Epoch 135/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.5877 - accuracy: 0.7029 - val_loss: 0.9399 - val_accuracy: 0.3333\n",
            "Epoch 136/1000\n",
            "594/594 [==============================] - 0s 34us/sample - loss: 0.5860 - accuracy: 0.6869 - val_loss: 0.7777 - val_accuracy: 0.6667\n",
            "Epoch 137/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5843 - accuracy: 0.6978 - val_loss: 0.6999 - val_accuracy: 0.6667\n",
            "Epoch 138/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5813 - accuracy: 0.7012 - val_loss: 0.8573 - val_accuracy: 0.3333\n",
            "Epoch 139/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5792 - accuracy: 0.6869 - val_loss: 0.6879 - val_accuracy: 0.6667\n",
            "Epoch 140/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5812 - accuracy: 0.7029 - val_loss: 0.9198 - val_accuracy: 0.3333\n",
            "Epoch 141/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5868 - accuracy: 0.6380 - val_loss: 0.9013 - val_accuracy: 0.1667\n",
            "Epoch 142/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5799 - accuracy: 0.6768 - val_loss: 0.8599 - val_accuracy: 0.3333\n",
            "Epoch 143/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.5957 - accuracy: 0.6582 - val_loss: 0.9103 - val_accuracy: 0.3333\n",
            "Epoch 144/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5857 - accuracy: 0.6759 - val_loss: 0.7987 - val_accuracy: 0.3333\n",
            "Epoch 145/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5764 - accuracy: 0.6860 - val_loss: 0.8010 - val_accuracy: 0.3333\n",
            "Epoch 146/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5717 - accuracy: 0.6742 - val_loss: 0.7699 - val_accuracy: 0.3333\n",
            "Epoch 147/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5766 - accuracy: 0.6515 - val_loss: 0.6925 - val_accuracy: 0.4167\n",
            "Epoch 148/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5747 - accuracy: 0.6414 - val_loss: 0.7377 - val_accuracy: 0.3333\n",
            "Epoch 149/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5826 - accuracy: 0.6288 - val_loss: 0.4947 - val_accuracy: 0.8333\n",
            "Epoch 150/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6754 - accuracy: 0.5867 - val_loss: 0.3648 - val_accuracy: 1.0000\n",
            "Epoch 151/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6717 - accuracy: 0.6086 - val_loss: 0.5745 - val_accuracy: 0.6667\n",
            "Epoch 152/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5727 - accuracy: 0.6338 - val_loss: 0.9111 - val_accuracy: 0.1667\n",
            "Epoch 153/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.5840 - accuracy: 0.6153 - val_loss: 0.9607 - val_accuracy: 0.0000e+00\n",
            "Epoch 154/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5951 - accuracy: 0.6120 - val_loss: 1.0535 - val_accuracy: 0.0000e+00\n",
            "Epoch 155/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.5856 - accuracy: 0.6347 - val_loss: 0.9228 - val_accuracy: 0.2500\n",
            "Epoch 156/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5843 - accuracy: 0.6355 - val_loss: 1.0874 - val_accuracy: 0.0000e+00\n",
            "Epoch 157/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5812 - accuracy: 0.6860 - val_loss: 0.8739 - val_accuracy: 0.2500\n",
            "Epoch 158/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.5441 - accuracy: 0.6608 - val_loss: 0.7589 - val_accuracy: 0.5000\n",
            "Epoch 159/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5330 - accuracy: 0.6498 - val_loss: 0.7526 - val_accuracy: 0.5000\n",
            "Epoch 160/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5374 - accuracy: 0.6650 - val_loss: 0.7099 - val_accuracy: 0.5000\n",
            "Epoch 161/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5425 - accuracy: 0.6288 - val_loss: 0.7932 - val_accuracy: 0.3333\n",
            "Epoch 162/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.5490 - accuracy: 0.6667 - val_loss: 0.7896 - val_accuracy: 0.3333\n",
            "Epoch 163/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.5490 - accuracy: 0.6717 - val_loss: 0.7334 - val_accuracy: 0.4167\n",
            "Epoch 164/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.5378 - accuracy: 0.6625 - val_loss: 0.7413 - val_accuracy: 0.5000\n",
            "Epoch 165/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.5775 - accuracy: 0.6692 - val_loss: 0.8919 - val_accuracy: 0.3333\n",
            "Epoch 166/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.5731 - accuracy: 0.6549 - val_loss: 1.0513 - val_accuracy: 0.0833\n",
            "Epoch 167/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.5612 - accuracy: 0.6700 - val_loss: 1.0903 - val_accuracy: 0.0833\n",
            "Epoch 168/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.5866 - accuracy: 0.6742 - val_loss: 1.2720 - val_accuracy: 0.0000e+00\n",
            "Epoch 169/1000\n",
            "297/594 [==============>...............] - ETA: 0s - loss: 0.5974 - accuracy: 0.6987\n",
            "Epoch 00169: ReduceLROnPlateau reducing learning rate to 0.5.\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5925 - accuracy: 0.6894 - val_loss: 1.1887 - val_accuracy: 0.0000e+00\n",
            "Epoch 170/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5797 - accuracy: 0.6549 - val_loss: 0.7390 - val_accuracy: 0.3333\n",
            "Epoch 171/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4986 - accuracy: 0.6995 - val_loss: 0.8131 - val_accuracy: 0.5000\n",
            "Epoch 172/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4876 - accuracy: 0.6776 - val_loss: 0.6906 - val_accuracy: 0.5000\n",
            "Epoch 173/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4854 - accuracy: 0.6953 - val_loss: 0.6986 - val_accuracy: 0.5000\n",
            "Epoch 174/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.4877 - accuracy: 0.7020 - val_loss: 0.7875 - val_accuracy: 0.5000\n",
            "Epoch 175/1000\n",
            "594/594 [==============================] - 0s 33us/sample - loss: 0.4797 - accuracy: 0.7332 - val_loss: 0.8527 - val_accuracy: 0.3333\n",
            "Epoch 176/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.4658 - accuracy: 0.7281 - val_loss: 0.6470 - val_accuracy: 0.5000\n",
            "Epoch 177/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.4741 - accuracy: 0.7146 - val_loss: 0.6596 - val_accuracy: 0.5000\n",
            "Epoch 178/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.4683 - accuracy: 0.7222 - val_loss: 0.6885 - val_accuracy: 0.5000\n",
            "Epoch 179/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4528 - accuracy: 0.7281 - val_loss: 0.6985 - val_accuracy: 0.5000\n",
            "Epoch 180/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.4500 - accuracy: 0.7306 - val_loss: 0.8187 - val_accuracy: 0.3333\n",
            "Epoch 181/1000\n",
            "594/594 [==============================] - 0s 33us/sample - loss: 0.4523 - accuracy: 0.7449 - val_loss: 0.5983 - val_accuracy: 0.6667\n",
            "Epoch 182/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.4525 - accuracy: 0.7189 - val_loss: 0.6661 - val_accuracy: 0.5000\n",
            "Epoch 183/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.4415 - accuracy: 0.7475 - val_loss: 0.6247 - val_accuracy: 0.5000\n",
            "Epoch 184/1000\n",
            "594/594 [==============================] - 0s 36us/sample - loss: 0.4442 - accuracy: 0.7239 - val_loss: 0.6001 - val_accuracy: 0.6667\n",
            "Epoch 185/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4377 - accuracy: 0.7433 - val_loss: 0.6306 - val_accuracy: 0.5000\n",
            "Epoch 186/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.4281 - accuracy: 0.7576 - val_loss: 0.6179 - val_accuracy: 0.6667\n",
            "Epoch 187/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.4229 - accuracy: 0.7736 - val_loss: 0.5993 - val_accuracy: 0.6667\n",
            "Epoch 188/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.4350 - accuracy: 0.7551 - val_loss: 0.5632 - val_accuracy: 0.7500\n",
            "Epoch 189/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4476 - accuracy: 0.7407 - val_loss: 0.6145 - val_accuracy: 0.6667\n",
            "Epoch 190/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.4410 - accuracy: 0.7559 - val_loss: 0.5418 - val_accuracy: 0.8333\n",
            "Epoch 191/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.4509 - accuracy: 0.7247 - val_loss: 0.5844 - val_accuracy: 0.6667\n",
            "Epoch 192/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4305 - accuracy: 0.7609 - val_loss: 0.6096 - val_accuracy: 0.6667\n",
            "Epoch 193/1000\n",
            "594/594 [==============================] - 0s 35us/sample - loss: 0.4714 - accuracy: 0.7374 - val_loss: 0.5323 - val_accuracy: 0.8333\n",
            "Epoch 194/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4618 - accuracy: 0.7508 - val_loss: 0.5659 - val_accuracy: 0.6667\n",
            "Epoch 195/1000\n",
            "594/594 [==============================] - 0s 34us/sample - loss: 0.4231 - accuracy: 0.7870 - val_loss: 0.5573 - val_accuracy: 0.8333\n",
            "Epoch 196/1000\n",
            "594/594 [==============================] - 0s 36us/sample - loss: 0.4032 - accuracy: 0.7946 - val_loss: 0.5781 - val_accuracy: 0.6667\n",
            "Epoch 197/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.3929 - accuracy: 0.8207 - val_loss: 0.5366 - val_accuracy: 0.8333\n",
            "Epoch 198/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.3854 - accuracy: 0.7904 - val_loss: 0.5444 - val_accuracy: 0.8333\n",
            "Epoch 199/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.3830 - accuracy: 0.8005 - val_loss: 0.5249 - val_accuracy: 0.8333\n",
            "Epoch 200/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.3709 - accuracy: 0.7946 - val_loss: 0.5718 - val_accuracy: 0.8333\n",
            "Epoch 201/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3778 - accuracy: 0.8182 - val_loss: 0.5887 - val_accuracy: 0.8333\n",
            "Epoch 202/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.4177 - accuracy: 0.7811 - val_loss: 0.8586 - val_accuracy: 0.3333\n",
            "Epoch 203/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5317 - accuracy: 0.6431 - val_loss: 1.3893 - val_accuracy: 0.1667\n",
            "Epoch 204/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.5720 - accuracy: 0.7155 - val_loss: 0.4811 - val_accuracy: 0.8333\n",
            "Epoch 205/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.4040 - accuracy: 0.7769 - val_loss: 0.5531 - val_accuracy: 0.8333\n",
            "Epoch 206/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3628 - accuracy: 0.8182 - val_loss: 0.5394 - val_accuracy: 0.8333\n",
            "Epoch 207/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.3530 - accuracy: 0.8064 - val_loss: 0.6249 - val_accuracy: 0.6667\n",
            "Epoch 208/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3559 - accuracy: 0.8131 - val_loss: 0.7027 - val_accuracy: 0.5000\n",
            "Epoch 209/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.3692 - accuracy: 0.7971 - val_loss: 0.7458 - val_accuracy: 0.5000\n",
            "Epoch 210/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.3699 - accuracy: 0.8064 - val_loss: 0.5395 - val_accuracy: 0.7500\n",
            "Epoch 211/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3583 - accuracy: 0.8114 - val_loss: 0.7910 - val_accuracy: 0.3333\n",
            "Epoch 212/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.3625 - accuracy: 0.8030 - val_loss: 0.6016 - val_accuracy: 0.5000\n",
            "Epoch 213/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.3426 - accuracy: 0.8333 - val_loss: 0.4802 - val_accuracy: 0.8333\n",
            "Epoch 214/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.3274 - accuracy: 0.8460 - val_loss: 0.4682 - val_accuracy: 0.8333\n",
            "Epoch 215/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.3256 - accuracy: 0.8409 - val_loss: 0.4468 - val_accuracy: 0.8333\n",
            "Epoch 216/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.3294 - accuracy: 0.8384 - val_loss: 0.4328 - val_accuracy: 0.8333\n",
            "Epoch 217/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.3341 - accuracy: 0.8384 - val_loss: 0.5046 - val_accuracy: 0.6667\n",
            "Epoch 218/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.3178 - accuracy: 0.8401 - val_loss: 0.5480 - val_accuracy: 0.5000\n",
            "Epoch 219/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.3108 - accuracy: 0.8418 - val_loss: 0.5463 - val_accuracy: 0.5000\n",
            "Epoch 220/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.3098 - accuracy: 0.8510 - val_loss: 0.5515 - val_accuracy: 0.5000\n",
            "Epoch 221/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.3041 - accuracy: 0.8586 - val_loss: 0.5131 - val_accuracy: 0.5833\n",
            "Epoch 222/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.2969 - accuracy: 0.8822 - val_loss: 0.4592 - val_accuracy: 0.6667\n",
            "Epoch 223/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.2954 - accuracy: 0.8569 - val_loss: 0.5215 - val_accuracy: 0.5000\n",
            "Epoch 224/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.2914 - accuracy: 0.8434 - val_loss: 0.5231 - val_accuracy: 0.5000\n",
            "Epoch 225/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.2877 - accuracy: 0.8611 - val_loss: 0.4676 - val_accuracy: 0.6667\n",
            "Epoch 226/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.2824 - accuracy: 0.8822 - val_loss: 0.4429 - val_accuracy: 0.6667\n",
            "Epoch 227/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.2804 - accuracy: 0.8754 - val_loss: 0.4197 - val_accuracy: 0.6667\n",
            "Epoch 228/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.2780 - accuracy: 0.8788 - val_loss: 0.5320 - val_accuracy: 0.5000\n",
            "Epoch 229/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.2749 - accuracy: 0.8628 - val_loss: 0.4606 - val_accuracy: 0.5000\n",
            "Epoch 230/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.2707 - accuracy: 0.8813 - val_loss: 0.4561 - val_accuracy: 0.5000\n",
            "Epoch 231/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.2683 - accuracy: 0.8771 - val_loss: 0.4622 - val_accuracy: 0.5000\n",
            "Epoch 232/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.2633 - accuracy: 0.8704 - val_loss: 0.4007 - val_accuracy: 0.6667\n",
            "Epoch 233/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.2799 - accuracy: 0.8502 - val_loss: 0.2893 - val_accuracy: 1.0000\n",
            "Epoch 234/1000\n",
            "594/594 [==============================] - 0s 33us/sample - loss: 0.5507 - accuracy: 0.7500 - val_loss: 0.8155 - val_accuracy: 0.6667\n",
            "Epoch 235/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.6167 - accuracy: 0.6734 - val_loss: 0.4785 - val_accuracy: 0.8333\n",
            "Epoch 236/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.4172 - accuracy: 0.7239 - val_loss: 0.3700 - val_accuracy: 1.0000\n",
            "Epoch 237/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.5638 - accuracy: 0.6961 - val_loss: 0.3305 - val_accuracy: 1.0000\n",
            "Epoch 238/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.5186 - accuracy: 0.7315 - val_loss: 0.5649 - val_accuracy: 0.8333\n",
            "Epoch 239/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.3872 - accuracy: 0.7811 - val_loss: 0.6938 - val_accuracy: 0.5000\n",
            "Epoch 240/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.3433 - accuracy: 0.8451 - val_loss: 0.8150 - val_accuracy: 0.1667\n",
            "Epoch 241/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.3274 - accuracy: 0.8098 - val_loss: 0.6908 - val_accuracy: 0.3333\n",
            "Epoch 242/1000\n",
            "594/594 [==============================] - 0s 34us/sample - loss: 0.3139 - accuracy: 0.8493 - val_loss: 0.6589 - val_accuracy: 0.3333\n",
            "Epoch 243/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.2908 - accuracy: 0.8476 - val_loss: 0.4753 - val_accuracy: 0.5000\n",
            "Epoch 244/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.2741 - accuracy: 0.8645 - val_loss: 0.4941 - val_accuracy: 0.5000\n",
            "Epoch 245/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.2617 - accuracy: 0.8645 - val_loss: 0.4532 - val_accuracy: 0.5000\n",
            "Epoch 246/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.2517 - accuracy: 0.8855 - val_loss: 0.4363 - val_accuracy: 0.5000\n",
            "Epoch 247/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.2442 - accuracy: 0.8729 - val_loss: 0.3799 - val_accuracy: 0.8333\n",
            "Epoch 248/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.2391 - accuracy: 0.8847 - val_loss: 0.3707 - val_accuracy: 0.8333\n",
            "Epoch 249/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.2357 - accuracy: 0.9015 - val_loss: 0.3630 - val_accuracy: 0.8333\n",
            "Epoch 250/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.2309 - accuracy: 0.9099 - val_loss: 0.3572 - val_accuracy: 0.8333\n",
            "Epoch 251/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.2264 - accuracy: 0.9057 - val_loss: 0.3503 - val_accuracy: 0.9167\n",
            "Epoch 252/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.2278 - accuracy: 0.8906 - val_loss: 0.2634 - val_accuracy: 1.0000\n",
            "Epoch 253/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.2355 - accuracy: 0.8746 - val_loss: 0.2412 - val_accuracy: 1.0000\n",
            "Epoch 254/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.2237 - accuracy: 0.9066 - val_loss: 0.3032 - val_accuracy: 1.0000\n",
            "Epoch 255/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.2196 - accuracy: 0.9150 - val_loss: 0.2224 - val_accuracy: 1.0000\n",
            "Epoch 256/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.2223 - accuracy: 0.9125 - val_loss: 0.2485 - val_accuracy: 1.0000\n",
            "Epoch 257/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.2186 - accuracy: 0.9125 - val_loss: 0.2476 - val_accuracy: 1.0000\n",
            "Epoch 258/1000\n",
            "594/594 [==============================] - 0s 35us/sample - loss: 0.2096 - accuracy: 0.9226 - val_loss: 0.2495 - val_accuracy: 1.0000\n",
            "Epoch 259/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.1974 - accuracy: 0.9268 - val_loss: 0.2294 - val_accuracy: 1.0000\n",
            "Epoch 260/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.1880 - accuracy: 0.9545 - val_loss: 0.2504 - val_accuracy: 1.0000\n",
            "Epoch 261/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.1838 - accuracy: 0.9419 - val_loss: 0.2058 - val_accuracy: 1.0000\n",
            "Epoch 262/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.1827 - accuracy: 0.9293 - val_loss: 0.1808 - val_accuracy: 1.0000\n",
            "Epoch 263/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.1927 - accuracy: 0.9209 - val_loss: 0.1302 - val_accuracy: 1.0000\n",
            "Epoch 264/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.1932 - accuracy: 0.9082 - val_loss: 0.1943 - val_accuracy: 1.0000\n",
            "Epoch 265/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.1703 - accuracy: 0.9764 - val_loss: 0.2336 - val_accuracy: 1.0000\n",
            "Epoch 266/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.1573 - accuracy: 0.9714 - val_loss: 0.2296 - val_accuracy: 1.0000\n",
            "Epoch 267/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.1524 - accuracy: 0.9781 - val_loss: 0.2185 - val_accuracy: 1.0000\n",
            "Epoch 268/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.1486 - accuracy: 0.9781 - val_loss: 0.1754 - val_accuracy: 1.0000\n",
            "Epoch 269/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.1425 - accuracy: 0.9781 - val_loss: 0.1909 - val_accuracy: 1.0000\n",
            "Epoch 270/1000\n",
            "594/594 [==============================] - 0s 34us/sample - loss: 0.1388 - accuracy: 0.9815 - val_loss: 0.2218 - val_accuracy: 1.0000\n",
            "Epoch 271/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.1425 - accuracy: 0.9714 - val_loss: 0.2778 - val_accuracy: 1.0000\n",
            "Epoch 272/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.1402 - accuracy: 0.9722 - val_loss: 0.2212 - val_accuracy: 1.0000\n",
            "Epoch 273/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.1402 - accuracy: 0.9621 - val_loss: 0.2992 - val_accuracy: 0.8333\n",
            "Epoch 274/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.1940 - accuracy: 0.9293 - val_loss: 0.7817 - val_accuracy: 0.5000\n",
            "Epoch 275/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.4433 - accuracy: 0.7946 - val_loss: 3.9382 - val_accuracy: 0.0000e+00\n",
            "Epoch 276/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 1.8564 - accuracy: 0.5724 - val_loss: 1.9904 - val_accuracy: 0.6667\n",
            "Epoch 277/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 1.5007 - accuracy: 0.6431 - val_loss: 2.5899 - val_accuracy: 0.5000\n",
            "Epoch 278/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 1.0572 - accuracy: 0.6507 - val_loss: 2.2239 - val_accuracy: 0.5000\n",
            "Epoch 279/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.7369 - accuracy: 0.7340 - val_loss: 2.0793 - val_accuracy: 0.5000\n",
            "Epoch 280/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6587 - accuracy: 0.7677 - val_loss: 1.6224 - val_accuracy: 0.6667\n",
            "Epoch 281/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.5577 - accuracy: 0.8039 - val_loss: 1.2061 - val_accuracy: 0.5000\n",
            "Epoch 282/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4163 - accuracy: 0.8165 - val_loss: 0.8056 - val_accuracy: 0.5000\n",
            "Epoch 283/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.2893 - accuracy: 0.9024 - val_loss: 0.5542 - val_accuracy: 0.8333\n",
            "Epoch 284/1000\n",
            "594/594 [==============================] - 0s 20us/sample - loss: 0.2509 - accuracy: 0.9150 - val_loss: 0.4790 - val_accuracy: 0.7500\n",
            "Epoch 285/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.2208 - accuracy: 0.9495 - val_loss: 0.4416 - val_accuracy: 0.6667\n",
            "Epoch 286/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.1930 - accuracy: 0.9529 - val_loss: 0.3385 - val_accuracy: 0.9167\n",
            "Epoch 287/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.1809 - accuracy: 0.9596 - val_loss: 0.2352 - val_accuracy: 1.0000\n",
            "Epoch 288/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.1709 - accuracy: 0.9613 - val_loss: 0.2342 - val_accuracy: 1.0000\n",
            "Epoch 289/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.1543 - accuracy: 0.9806 - val_loss: 0.2310 - val_accuracy: 1.0000\n",
            "Epoch 290/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.1476 - accuracy: 0.9739 - val_loss: 0.1770 - val_accuracy: 1.0000\n",
            "Epoch 291/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.1421 - accuracy: 0.9790 - val_loss: 0.2077 - val_accuracy: 1.0000\n",
            "Epoch 292/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.1352 - accuracy: 0.9790 - val_loss: 0.1802 - val_accuracy: 1.0000\n",
            "Epoch 293/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.1305 - accuracy: 0.9756 - val_loss: 0.1732 - val_accuracy: 1.0000\n",
            "Epoch 294/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.1244 - accuracy: 0.9781 - val_loss: 0.1860 - val_accuracy: 1.0000\n",
            "Epoch 295/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.1190 - accuracy: 0.9848 - val_loss: 0.1743 - val_accuracy: 1.0000\n",
            "Epoch 296/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.1159 - accuracy: 0.9815 - val_loss: 0.1791 - val_accuracy: 1.0000\n",
            "Epoch 297/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.1113 - accuracy: 0.9857 - val_loss: 0.1885 - val_accuracy: 1.0000\n",
            "Epoch 298/1000\n",
            "594/594 [==============================] - 0s 37us/sample - loss: 0.1091 - accuracy: 0.9832 - val_loss: 0.1651 - val_accuracy: 1.0000\n",
            "Epoch 299/1000\n",
            "594/594 [==============================] - 0s 38us/sample - loss: 0.1046 - accuracy: 0.9865 - val_loss: 0.1757 - val_accuracy: 1.0000\n",
            "Epoch 300/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.1025 - accuracy: 0.9815 - val_loss: 0.1694 - val_accuracy: 1.0000\n",
            "Epoch 301/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0981 - accuracy: 0.9848 - val_loss: 0.1161 - val_accuracy: 1.0000\n",
            "Epoch 302/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.0978 - accuracy: 0.9798 - val_loss: 0.1300 - val_accuracy: 1.0000\n",
            "Epoch 303/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.0927 - accuracy: 0.9848 - val_loss: 0.1783 - val_accuracy: 1.0000\n",
            "Epoch 304/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.0921 - accuracy: 0.9865 - val_loss: 0.1508 - val_accuracy: 1.0000\n",
            "Epoch 305/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.0893 - accuracy: 0.9815 - val_loss: 0.1680 - val_accuracy: 1.0000\n",
            "Epoch 306/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.0852 - accuracy: 0.9848 - val_loss: 0.1274 - val_accuracy: 1.0000\n",
            "Epoch 307/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.0826 - accuracy: 0.9848 - val_loss: 0.1165 - val_accuracy: 1.0000\n",
            "Epoch 308/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0799 - accuracy: 0.9865 - val_loss: 0.1038 - val_accuracy: 1.0000\n",
            "Epoch 309/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.0797 - accuracy: 0.9865 - val_loss: 0.0823 - val_accuracy: 1.0000\n",
            "Epoch 310/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.0813 - accuracy: 0.9840 - val_loss: 0.0832 - val_accuracy: 1.0000\n",
            "Epoch 311/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0798 - accuracy: 0.9882 - val_loss: 0.0752 - val_accuracy: 1.0000\n",
            "Epoch 312/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0744 - accuracy: 0.9840 - val_loss: 0.0988 - val_accuracy: 1.0000\n",
            "Epoch 313/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0707 - accuracy: 0.9882 - val_loss: 0.0679 - val_accuracy: 1.0000\n",
            "Epoch 314/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.0703 - accuracy: 0.9848 - val_loss: 0.1056 - val_accuracy: 1.0000\n",
            "Epoch 315/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.0664 - accuracy: 0.9882 - val_loss: 0.0809 - val_accuracy: 1.0000\n",
            "Epoch 316/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.0646 - accuracy: 0.9865 - val_loss: 0.0807 - val_accuracy: 1.0000\n",
            "Epoch 317/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.0625 - accuracy: 0.9882 - val_loss: 0.0735 - val_accuracy: 1.0000\n",
            "Epoch 318/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.0609 - accuracy: 0.9865 - val_loss: 0.1008 - val_accuracy: 1.0000\n",
            "Epoch 319/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.0593 - accuracy: 0.9882 - val_loss: 0.0629 - val_accuracy: 1.0000\n",
            "Epoch 320/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.0579 - accuracy: 0.9882 - val_loss: 0.0866 - val_accuracy: 1.0000\n",
            "Epoch 321/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.0571 - accuracy: 0.9882 - val_loss: 0.0841 - val_accuracy: 1.0000\n",
            "Epoch 322/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.0604 - accuracy: 0.9865 - val_loss: 0.1294 - val_accuracy: 1.0000\n",
            "Epoch 323/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.0739 - accuracy: 0.9832 - val_loss: 0.1580 - val_accuracy: 1.0000\n",
            "Epoch 324/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.0965 - accuracy: 0.9689 - val_loss: 0.4627 - val_accuracy: 0.8333\n",
            "Epoch 325/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6924 - accuracy: 0.8375 - val_loss: 1.9006 - val_accuracy: 0.6667\n",
            "Epoch 326/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.9425 - accuracy: 0.7172 - val_loss: 1.2054 - val_accuracy: 0.6667\n",
            "Epoch 327/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.4969 - accuracy: 0.7870 - val_loss: 2.1205 - val_accuracy: 0.5000\n",
            "Epoch 328/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6703 - accuracy: 0.7508 - val_loss: 0.2712 - val_accuracy: 1.0000\n",
            "Epoch 329/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.4915 - accuracy: 0.7971 - val_loss: 0.8758 - val_accuracy: 0.6667\n",
            "Epoch 330/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.7285 - accuracy: 0.6700 - val_loss: 0.3876 - val_accuracy: 0.8333\n",
            "Epoch 331/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.2428 - accuracy: 0.9040 - val_loss: 0.2247 - val_accuracy: 1.0000\n",
            "Epoch 332/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.1431 - accuracy: 0.9790 - val_loss: 0.1682 - val_accuracy: 1.0000\n",
            "Epoch 333/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.1239 - accuracy: 0.9764 - val_loss: 0.1532 - val_accuracy: 1.0000\n",
            "Epoch 334/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.1095 - accuracy: 0.9857 - val_loss: 0.1284 - val_accuracy: 1.0000\n",
            "Epoch 335/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.0986 - accuracy: 0.9899 - val_loss: 0.1311 - val_accuracy: 1.0000\n",
            "Epoch 336/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.0912 - accuracy: 0.9882 - val_loss: 0.1056 - val_accuracy: 1.0000\n",
            "Epoch 337/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.0850 - accuracy: 0.9899 - val_loss: 0.1110 - val_accuracy: 1.0000\n",
            "Epoch 338/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.0789 - accuracy: 0.9933 - val_loss: 0.1156 - val_accuracy: 1.0000\n",
            "Epoch 339/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.0742 - accuracy: 0.9865 - val_loss: 0.1127 - val_accuracy: 1.0000\n",
            "Epoch 340/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.0725 - accuracy: 0.9899 - val_loss: 0.1311 - val_accuracy: 1.0000\n",
            "Epoch 341/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.0698 - accuracy: 0.9882 - val_loss: 0.1150 - val_accuracy: 1.0000\n",
            "Epoch 342/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.0636 - accuracy: 0.9933 - val_loss: 0.0926 - val_accuracy: 1.0000\n",
            "Epoch 343/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.0615 - accuracy: 0.9949 - val_loss: 0.0701 - val_accuracy: 1.0000\n",
            "Epoch 344/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.0630 - accuracy: 0.9848 - val_loss: 0.0609 - val_accuracy: 1.0000\n",
            "Epoch 345/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.0557 - accuracy: 0.9924 - val_loss: 0.0896 - val_accuracy: 1.0000\n",
            "Epoch 346/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0538 - accuracy: 0.9933 - val_loss: 0.0824 - val_accuracy: 1.0000\n",
            "Epoch 347/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0516 - accuracy: 0.9933 - val_loss: 0.0708 - val_accuracy: 1.0000\n",
            "Epoch 348/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.0503 - accuracy: 0.9933 - val_loss: 0.0615 - val_accuracy: 1.0000\n",
            "Epoch 349/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.0481 - accuracy: 0.9949 - val_loss: 0.0535 - val_accuracy: 1.0000\n",
            "Epoch 350/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.0486 - accuracy: 0.9899 - val_loss: 0.0502 - val_accuracy: 1.0000\n",
            "Epoch 351/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.0479 - accuracy: 0.9916 - val_loss: 0.0477 - val_accuracy: 1.0000\n",
            "Epoch 352/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.0453 - accuracy: 0.9933 - val_loss: 0.0510 - val_accuracy: 1.0000\n",
            "Epoch 353/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.0462 - accuracy: 0.9949 - val_loss: 0.0445 - val_accuracy: 1.0000\n",
            "Epoch 354/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.0581 - accuracy: 0.9874 - val_loss: 0.0370 - val_accuracy: 1.0000\n",
            "Epoch 355/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.0885 - accuracy: 0.9630 - val_loss: 0.0373 - val_accuracy: 1.0000\n",
            "Epoch 356/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.0786 - accuracy: 0.9781 - val_loss: 0.0542 - val_accuracy: 1.0000\n",
            "Epoch 357/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.0437 - accuracy: 0.9857 - val_loss: 0.0673 - val_accuracy: 1.0000\n",
            "Epoch 358/1000\n",
            "594/594 [==============================] - 0s 35us/sample - loss: 0.0498 - accuracy: 0.9882 - val_loss: 0.0635 - val_accuracy: 1.0000\n",
            "Epoch 359/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.0398 - accuracy: 0.9933 - val_loss: 0.0522 - val_accuracy: 1.0000\n",
            "Epoch 360/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.0391 - accuracy: 0.9949 - val_loss: 0.0390 - val_accuracy: 1.0000\n",
            "Epoch 361/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.0416 - accuracy: 0.9899 - val_loss: 0.0427 - val_accuracy: 1.0000\n",
            "Epoch 362/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.0361 - accuracy: 0.9899 - val_loss: 0.0509 - val_accuracy: 1.0000\n",
            "Epoch 363/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.0350 - accuracy: 0.9949 - val_loss: 0.0419 - val_accuracy: 1.0000\n",
            "Epoch 364/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.0343 - accuracy: 0.9924 - val_loss: 0.0489 - val_accuracy: 1.0000\n",
            "Epoch 365/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.0350 - accuracy: 0.9916 - val_loss: 0.0364 - val_accuracy: 1.0000\n",
            "Epoch 366/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.0388 - accuracy: 0.9882 - val_loss: 0.0574 - val_accuracy: 1.0000\n",
            "Epoch 367/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.0368 - accuracy: 0.9899 - val_loss: 0.0438 - val_accuracy: 1.0000\n",
            "Epoch 368/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.0345 - accuracy: 0.9949 - val_loss: 0.0332 - val_accuracy: 1.0000\n",
            "Epoch 369/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.0354 - accuracy: 0.9899 - val_loss: 0.0379 - val_accuracy: 1.0000\n",
            "Epoch 370/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0328 - accuracy: 0.9916 - val_loss: 0.0394 - val_accuracy: 1.0000\n",
            "Epoch 371/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.0321 - accuracy: 0.9916 - val_loss: 0.0328 - val_accuracy: 1.0000\n",
            "Epoch 372/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.0325 - accuracy: 0.9933 - val_loss: 0.0312 - val_accuracy: 1.0000\n",
            "Epoch 373/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.0316 - accuracy: 0.9933 - val_loss: 0.0358 - val_accuracy: 1.0000\n",
            "Epoch 374/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.0312 - accuracy: 0.9916 - val_loss: 0.0311 - val_accuracy: 1.0000\n",
            "Epoch 375/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.0294 - accuracy: 0.9933 - val_loss: 0.0319 - val_accuracy: 1.0000\n",
            "Epoch 376/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.0285 - accuracy: 0.9899 - val_loss: 0.0346 - val_accuracy: 1.0000\n",
            "Epoch 377/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.0316 - accuracy: 0.9916 - val_loss: 0.0359 - val_accuracy: 1.0000\n",
            "Epoch 378/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.0291 - accuracy: 0.9949 - val_loss: 0.0290 - val_accuracy: 1.0000\n",
            "Epoch 379/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.0288 - accuracy: 0.9916 - val_loss: 0.0285 - val_accuracy: 1.0000\n",
            "Epoch 380/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.0289 - accuracy: 0.9916 - val_loss: 0.0286 - val_accuracy: 1.0000\n",
            "Epoch 381/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.0270 - accuracy: 0.9899 - val_loss: 0.0323 - val_accuracy: 1.0000\n",
            "Epoch 382/1000\n",
            "594/594 [==============================] - 0s 33us/sample - loss: 0.0274 - accuracy: 0.9899 - val_loss: 0.0317 - val_accuracy: 1.0000\n",
            "Epoch 383/1000\n",
            "594/594 [==============================] - 0s 36us/sample - loss: 0.0287 - accuracy: 0.9899 - val_loss: 0.0302 - val_accuracy: 1.0000\n",
            "Epoch 384/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0290 - accuracy: 0.9949 - val_loss: 0.0259 - val_accuracy: 1.0000\n",
            "Epoch 385/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.0271 - accuracy: 0.9933 - val_loss: 0.0301 - val_accuracy: 1.0000\n",
            "Epoch 386/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.0253 - accuracy: 0.9933 - val_loss: 0.0287 - val_accuracy: 1.0000\n",
            "Epoch 387/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.0250 - accuracy: 0.9933 - val_loss: 0.0277 - val_accuracy: 1.0000\n",
            "Epoch 388/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.0256 - accuracy: 0.9907 - val_loss: 0.0285 - val_accuracy: 1.0000\n",
            "Epoch 389/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.0270 - accuracy: 0.9907 - val_loss: 0.0288 - val_accuracy: 1.0000\n",
            "Epoch 390/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.0266 - accuracy: 0.9916 - val_loss: 0.0268 - val_accuracy: 1.0000\n",
            "Epoch 391/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.0255 - accuracy: 0.9899 - val_loss: 0.0288 - val_accuracy: 1.0000\n",
            "Epoch 392/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.0254 - accuracy: 0.9949 - val_loss: 0.0232 - val_accuracy: 1.0000\n",
            "Epoch 393/1000\n",
            "297/594 [==============>...............] - ETA: 0s - loss: 0.0290 - accuracy: 0.9899\n",
            "Epoch 00393: ReduceLROnPlateau reducing learning rate to 0.25.\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0257 - accuracy: 0.9933 - val_loss: 0.0225 - val_accuracy: 1.0000\n",
            "Epoch 394/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.0236 - accuracy: 0.9899 - val_loss: 0.0242 - val_accuracy: 1.0000\n",
            "Epoch 395/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.0238 - accuracy: 0.9916 - val_loss: 0.0248 - val_accuracy: 1.0000\n",
            "Epoch 396/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.0241 - accuracy: 0.9933 - val_loss: 0.0242 - val_accuracy: 1.0000\n",
            "Epoch 397/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.0232 - accuracy: 0.9949 - val_loss: 0.0234 - val_accuracy: 1.0000\n",
            "Epoch 398/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.0230 - accuracy: 0.9916 - val_loss: 0.0233 - val_accuracy: 1.0000\n",
            "Epoch 399/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0229 - accuracy: 0.9916 - val_loss: 0.0231 - val_accuracy: 1.0000\n",
            "Epoch 400/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.0229 - accuracy: 0.9899 - val_loss: 0.0233 - val_accuracy: 1.0000\n",
            "Epoch 401/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0228 - accuracy: 0.9916 - val_loss: 0.0224 - val_accuracy: 1.0000\n",
            "Epoch 402/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.0229 - accuracy: 0.9924 - val_loss: 0.0222 - val_accuracy: 1.0000\n",
            "Epoch 403/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.0230 - accuracy: 0.9916 - val_loss: 0.0221 - val_accuracy: 1.0000\n",
            "Epoch 404/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.0230 - accuracy: 0.9933 - val_loss: 0.0220 - val_accuracy: 1.0000\n",
            "Epoch 405/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.0232 - accuracy: 0.9916 - val_loss: 0.0215 - val_accuracy: 1.0000\n",
            "Epoch 406/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.0225 - accuracy: 0.9916 - val_loss: 0.0217 - val_accuracy: 1.0000\n",
            "Epoch 407/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.0223 - accuracy: 0.9899 - val_loss: 0.0217 - val_accuracy: 1.0000\n",
            "Epoch 408/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.0221 - accuracy: 0.9916 - val_loss: 0.0216 - val_accuracy: 1.0000\n",
            "Epoch 409/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.0242 - accuracy: 0.9916 - val_loss: 0.0209 - val_accuracy: 1.0000\n",
            "Epoch 410/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.0232 - accuracy: 0.9899 - val_loss: 0.0218 - val_accuracy: 1.0000\n",
            "Epoch 411/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.0219 - accuracy: 0.9933 - val_loss: 0.0208 - val_accuracy: 1.0000\n",
            "Epoch 412/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.0218 - accuracy: 0.9916 - val_loss: 0.0210 - val_accuracy: 1.0000\n",
            "Epoch 413/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.0217 - accuracy: 0.9916 - val_loss: 0.0205 - val_accuracy: 1.0000\n",
            "Epoch 414/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.0239 - accuracy: 0.9899 - val_loss: 0.0194 - val_accuracy: 1.0000\n",
            "Epoch 415/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.0220 - accuracy: 0.9899 - val_loss: 0.0198 - val_accuracy: 1.0000\n",
            "Epoch 416/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0219 - accuracy: 0.9916 - val_loss: 0.0199 - val_accuracy: 1.0000\n",
            "Epoch 417/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.0218 - accuracy: 0.9916 - val_loss: 0.0199 - val_accuracy: 1.0000\n",
            "Epoch 418/1000\n",
            "594/594 [==============================] - 0s 39us/sample - loss: 0.0213 - accuracy: 0.9899 - val_loss: 0.0199 - val_accuracy: 1.0000\n",
            "Epoch 419/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.0226 - accuracy: 0.9899 - val_loss: 0.0193 - val_accuracy: 1.0000\n",
            "Epoch 420/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.0214 - accuracy: 0.9899 - val_loss: 0.0198 - val_accuracy: 1.0000\n",
            "Epoch 421/1000\n",
            "594/594 [==============================] - 0s 34us/sample - loss: 0.0229 - accuracy: 0.9916 - val_loss: 0.0185 - val_accuracy: 1.0000\n",
            "Epoch 422/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.0212 - accuracy: 0.9899 - val_loss: 0.0191 - val_accuracy: 1.0000\n",
            "Epoch 423/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.0219 - accuracy: 0.9899 - val_loss: 0.0196 - val_accuracy: 1.0000\n",
            "Epoch 424/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.0211 - accuracy: 0.9949 - val_loss: 0.0191 - val_accuracy: 1.0000\n",
            "Epoch 425/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0218 - accuracy: 0.9916 - val_loss: 0.0192 - val_accuracy: 1.0000\n",
            "Epoch 426/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.0208 - accuracy: 0.9933 - val_loss: 0.0187 - val_accuracy: 1.0000\n",
            "Epoch 427/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.0212 - accuracy: 0.9899 - val_loss: 0.0190 - val_accuracy: 1.0000\n",
            "Epoch 428/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.0211 - accuracy: 0.9899 - val_loss: 0.0188 - val_accuracy: 1.0000\n",
            "Epoch 429/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.0217 - accuracy: 0.9924 - val_loss: 0.0180 - val_accuracy: 1.0000\n",
            "Epoch 430/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.0212 - accuracy: 0.9916 - val_loss: 0.0180 - val_accuracy: 1.0000\n",
            "Epoch 431/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0207 - accuracy: 0.9899 - val_loss: 0.0184 - val_accuracy: 1.0000\n",
            "Epoch 432/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.0212 - accuracy: 0.9916 - val_loss: 0.0178 - val_accuracy: 1.0000\n",
            "Epoch 433/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.0203 - accuracy: 0.9899 - val_loss: 0.0180 - val_accuracy: 1.0000\n",
            "Epoch 434/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.0205 - accuracy: 0.9899 - val_loss: 0.0180 - val_accuracy: 1.0000\n",
            "Epoch 435/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.0207 - accuracy: 0.9916 - val_loss: 0.0178 - val_accuracy: 1.0000\n",
            "Epoch 436/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0207 - accuracy: 0.9949 - val_loss: 0.0170 - val_accuracy: 1.0000\n",
            "Epoch 437/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0226 - accuracy: 0.9916 - val_loss: 0.0165 - val_accuracy: 1.0000\n",
            "Epoch 438/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.0208 - accuracy: 0.9916 - val_loss: 0.0169 - val_accuracy: 1.0000\n",
            "Epoch 439/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0202 - accuracy: 0.9899 - val_loss: 0.0173 - val_accuracy: 1.0000\n",
            "Epoch 440/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.0199 - accuracy: 0.9916 - val_loss: 0.0170 - val_accuracy: 1.0000\n",
            "Epoch 441/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.0202 - accuracy: 0.9916 - val_loss: 0.0166 - val_accuracy: 1.0000\n",
            "Epoch 442/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0221 - accuracy: 0.9916 - val_loss: 0.0160 - val_accuracy: 1.0000\n",
            "Epoch 443/1000\n",
            "297/594 [==============>...............] - ETA: 0s - loss: 0.0193 - accuracy: 0.9899\n",
            "Epoch 00443: ReduceLROnPlateau reducing learning rate to 0.125.\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.0206 - accuracy: 0.9899 - val_loss: 0.0164 - val_accuracy: 1.0000\n",
            "Epoch 444/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0197 - accuracy: 0.9899 - val_loss: 0.0166 - val_accuracy: 1.0000\n",
            "Epoch 445/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0197 - accuracy: 0.9899 - val_loss: 0.0167 - val_accuracy: 1.0000\n",
            "Epoch 446/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.0201 - accuracy: 0.9899 - val_loss: 0.0167 - val_accuracy: 1.0000\n",
            "Epoch 447/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.0197 - accuracy: 0.9899 - val_loss: 0.0166 - val_accuracy: 1.0000\n",
            "Epoch 448/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.0197 - accuracy: 0.9933 - val_loss: 0.0164 - val_accuracy: 1.0000\n",
            "Epoch 449/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0196 - accuracy: 0.9899 - val_loss: 0.0163 - val_accuracy: 1.0000\n",
            "Epoch 450/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.0201 - accuracy: 0.9899 - val_loss: 0.0162 - val_accuracy: 1.0000\n",
            "Epoch 451/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0198 - accuracy: 0.9899 - val_loss: 0.0163 - val_accuracy: 1.0000\n",
            "Epoch 452/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.0194 - accuracy: 0.9907 - val_loss: 0.0163 - val_accuracy: 1.0000\n",
            "Epoch 453/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.0195 - accuracy: 0.9899 - val_loss: 0.0161 - val_accuracy: 1.0000\n",
            "Epoch 454/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0194 - accuracy: 0.9899 - val_loss: 0.0161 - val_accuracy: 1.0000\n",
            "Epoch 455/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0193 - accuracy: 0.9899 - val_loss: 0.0161 - val_accuracy: 1.0000\n",
            "Epoch 456/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.0193 - accuracy: 0.9899 - val_loss: 0.0161 - val_accuracy: 1.0000\n",
            "Epoch 457/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0195 - accuracy: 0.9916 - val_loss: 0.0159 - val_accuracy: 1.0000\n",
            "Epoch 458/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.0194 - accuracy: 0.9899 - val_loss: 0.0159 - val_accuracy: 1.0000\n",
            "Epoch 459/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.0197 - accuracy: 0.9899 - val_loss: 0.0160 - val_accuracy: 1.0000\n",
            "Epoch 460/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.0196 - accuracy: 0.9916 - val_loss: 0.0158 - val_accuracy: 1.0000\n",
            "Epoch 461/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.0195 - accuracy: 0.9899 - val_loss: 0.0158 - val_accuracy: 1.0000\n",
            "Epoch 462/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.0196 - accuracy: 0.9916 - val_loss: 0.0157 - val_accuracy: 1.0000\n",
            "Epoch 463/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.0191 - accuracy: 0.9899 - val_loss: 0.0157 - val_accuracy: 1.0000\n",
            "Epoch 464/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0193 - accuracy: 0.9899 - val_loss: 0.0157 - val_accuracy: 1.0000\n",
            "Epoch 465/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.0193 - accuracy: 0.9916 - val_loss: 0.0155 - val_accuracy: 1.0000\n",
            "Epoch 466/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.0194 - accuracy: 0.9899 - val_loss: 0.0156 - val_accuracy: 1.0000\n",
            "Epoch 467/1000\n",
            "594/594 [==============================] - 0s 45us/sample - loss: 0.0192 - accuracy: 0.9899 - val_loss: 0.0155 - val_accuracy: 1.0000\n",
            "Epoch 468/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.0191 - accuracy: 0.9899 - val_loss: 0.0154 - val_accuracy: 1.0000\n",
            "Epoch 469/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0192 - accuracy: 0.9899 - val_loss: 0.0154 - val_accuracy: 1.0000\n",
            "Epoch 470/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.0192 - accuracy: 0.9899 - val_loss: 0.0153 - val_accuracy: 1.0000\n",
            "Epoch 471/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0189 - accuracy: 0.9899 - val_loss: 0.0153 - val_accuracy: 1.0000\n",
            "Epoch 472/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.0190 - accuracy: 0.9899 - val_loss: 0.0154 - val_accuracy: 1.0000\n",
            "Epoch 473/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.0189 - accuracy: 0.9899 - val_loss: 0.0153 - val_accuracy: 1.0000\n",
            "Epoch 474/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0190 - accuracy: 0.9899 - val_loss: 0.0153 - val_accuracy: 1.0000\n",
            "Epoch 475/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.0189 - accuracy: 0.9907 - val_loss: 0.0152 - val_accuracy: 1.0000\n",
            "Epoch 476/1000\n",
            "594/594 [==============================] - 0s 45us/sample - loss: 0.0191 - accuracy: 0.9899 - val_loss: 0.0152 - val_accuracy: 1.0000\n",
            "Epoch 477/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.0188 - accuracy: 0.9916 - val_loss: 0.0151 - val_accuracy: 1.0000\n",
            "Epoch 478/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.0190 - accuracy: 0.9899 - val_loss: 0.0150 - val_accuracy: 1.0000\n",
            "Epoch 479/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.0189 - accuracy: 0.9899 - val_loss: 0.0150 - val_accuracy: 1.0000\n",
            "Epoch 480/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.0189 - accuracy: 0.9907 - val_loss: 0.0149 - val_accuracy: 1.0000\n",
            "Epoch 481/1000\n",
            "594/594 [==============================] - 0s 35us/sample - loss: 0.0188 - accuracy: 0.9899 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
            "Epoch 482/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.0188 - accuracy: 0.9899 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
            "Epoch 483/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.0187 - accuracy: 0.9899 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
            "Epoch 484/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.0188 - accuracy: 0.9899 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
            "Epoch 485/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.0188 - accuracy: 0.9899 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
            "Epoch 486/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.0186 - accuracy: 0.9907 - val_loss: 0.0147 - val_accuracy: 1.0000\n",
            "Epoch 487/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.0186 - accuracy: 0.9899 - val_loss: 0.0147 - val_accuracy: 1.0000\n",
            "Epoch 488/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0194 - accuracy: 0.9899 - val_loss: 0.0145 - val_accuracy: 1.0000\n",
            "Epoch 489/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.0185 - accuracy: 0.9899 - val_loss: 0.0146 - val_accuracy: 1.0000\n",
            "Epoch 490/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.0191 - accuracy: 0.9899 - val_loss: 0.0145 - val_accuracy: 1.0000\n",
            "Epoch 491/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.0187 - accuracy: 0.9899 - val_loss: 0.0145 - val_accuracy: 1.0000\n",
            "Epoch 492/1000\n",
            "594/594 [==============================] - 0s 33us/sample - loss: 0.0184 - accuracy: 0.9899 - val_loss: 0.0144 - val_accuracy: 1.0000\n",
            "Epoch 493/1000\n",
            "297/594 [==============>...............] - ETA: 0s - loss: 0.0191 - accuracy: 0.9899\n",
            "Epoch 00493: ReduceLROnPlateau reducing learning rate to 0.0625.\n",
            "594/594 [==============================] - 0s 33us/sample - loss: 0.0187 - accuracy: 0.9916 - val_loss: 0.0143 - val_accuracy: 1.0000\n",
            "Epoch 494/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.0185 - accuracy: 0.9899 - val_loss: 0.0143 - val_accuracy: 1.0000\n",
            "Epoch 495/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.0184 - accuracy: 0.9899 - val_loss: 0.0143 - val_accuracy: 1.0000\n",
            "Epoch 496/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.0185 - accuracy: 0.9907 - val_loss: 0.0143 - val_accuracy: 1.0000\n",
            "Epoch 497/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.0185 - accuracy: 0.9899 - val_loss: 0.0143 - val_accuracy: 1.0000\n",
            "Epoch 498/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.0184 - accuracy: 0.9899 - val_loss: 0.0143 - val_accuracy: 1.0000\n",
            "Epoch 499/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.0184 - accuracy: 0.9899 - val_loss: 0.0143 - val_accuracy: 1.0000\n",
            "Epoch 500/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.0183 - accuracy: 0.9899 - val_loss: 0.0143 - val_accuracy: 1.0000\n",
            "Epoch 501/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.0183 - accuracy: 0.9899 - val_loss: 0.0142 - val_accuracy: 1.0000\n",
            "Epoch 502/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.0184 - accuracy: 0.9899 - val_loss: 0.0142 - val_accuracy: 1.0000\n",
            "Epoch 503/1000\n",
            "594/594 [==============================] - 0s 34us/sample - loss: 0.0183 - accuracy: 0.9899 - val_loss: 0.0142 - val_accuracy: 1.0000\n",
            "Epoch 504/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.0183 - accuracy: 0.9899 - val_loss: 0.0142 - val_accuracy: 1.0000\n",
            "Epoch 505/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.0183 - accuracy: 0.9899 - val_loss: 0.0141 - val_accuracy: 1.0000\n",
            "Epoch 506/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.0183 - accuracy: 0.9899 - val_loss: 0.0141 - val_accuracy: 1.0000\n",
            "Epoch 507/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.0186 - accuracy: 0.9899 - val_loss: 0.0141 - val_accuracy: 1.0000\n",
            "Epoch 508/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.0186 - accuracy: 0.9899 - val_loss: 0.0141 - val_accuracy: 1.0000\n",
            "Epoch 509/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.0183 - accuracy: 0.9907 - val_loss: 0.0141 - val_accuracy: 1.0000\n",
            "Epoch 510/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.0187 - accuracy: 0.9899 - val_loss: 0.0140 - val_accuracy: 1.0000\n",
            "Epoch 511/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.0182 - accuracy: 0.9899 - val_loss: 0.0140 - val_accuracy: 1.0000\n",
            "Epoch 512/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.0185 - accuracy: 0.9916 - val_loss: 0.0140 - val_accuracy: 1.0000\n",
            "Epoch 513/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.0183 - accuracy: 0.9899 - val_loss: 0.0140 - val_accuracy: 1.0000\n",
            "Epoch 514/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.0186 - accuracy: 0.9899 - val_loss: 0.0140 - val_accuracy: 1.0000\n",
            "Epoch 515/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.0182 - accuracy: 0.9899 - val_loss: 0.0140 - val_accuracy: 1.0000\n",
            "Epoch 516/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.0182 - accuracy: 0.9899 - val_loss: 0.0139 - val_accuracy: 1.0000\n",
            "Epoch 517/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.0182 - accuracy: 0.9899 - val_loss: 0.0139 - val_accuracy: 1.0000\n",
            "Epoch 518/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.0181 - accuracy: 0.9899 - val_loss: 0.0139 - val_accuracy: 1.0000\n",
            "Epoch 519/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.0182 - accuracy: 0.9899 - val_loss: 0.0139 - val_accuracy: 1.0000\n",
            "Epoch 520/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.0182 - accuracy: 0.9899 - val_loss: 0.0138 - val_accuracy: 1.0000\n",
            "Epoch 521/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0182 - accuracy: 0.9899 - val_loss: 0.0138 - val_accuracy: 1.0000\n",
            "Epoch 522/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.0184 - accuracy: 0.9899 - val_loss: 0.0138 - val_accuracy: 1.0000\n",
            "Epoch 523/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.0183 - accuracy: 0.9916 - val_loss: 0.0138 - val_accuracy: 1.0000\n",
            "Epoch 524/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.0182 - accuracy: 0.9899 - val_loss: 0.0137 - val_accuracy: 1.0000\n",
            "Epoch 525/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.0181 - accuracy: 0.9899 - val_loss: 0.0137 - val_accuracy: 1.0000\n",
            "Epoch 526/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0181 - accuracy: 0.9899 - val_loss: 0.0137 - val_accuracy: 1.0000\n",
            "Epoch 527/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.0184 - accuracy: 0.9899 - val_loss: 0.0137 - val_accuracy: 1.0000\n",
            "Epoch 528/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.0184 - accuracy: 0.9899 - val_loss: 0.0137 - val_accuracy: 1.0000\n",
            "Epoch 529/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.0181 - accuracy: 0.9899 - val_loss: 0.0137 - val_accuracy: 1.0000\n",
            "Epoch 530/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0184 - accuracy: 0.9899 - val_loss: 0.0137 - val_accuracy: 1.0000\n",
            "Epoch 531/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.0180 - accuracy: 0.9899 - val_loss: 0.0136 - val_accuracy: 1.0000\n",
            "Epoch 532/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.0184 - accuracy: 0.9907 - val_loss: 0.0136 - val_accuracy: 1.0000\n",
            "Epoch 533/1000\n",
            "594/594 [==============================] - 0s 35us/sample - loss: 0.0180 - accuracy: 0.9899 - val_loss: 0.0136 - val_accuracy: 1.0000\n",
            "Epoch 534/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.0181 - accuracy: 0.9899 - val_loss: 0.0136 - val_accuracy: 1.0000\n",
            "Epoch 535/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.0180 - accuracy: 0.9899 - val_loss: 0.0136 - val_accuracy: 1.0000\n",
            "Epoch 536/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.0180 - accuracy: 0.9899 - val_loss: 0.0135 - val_accuracy: 1.0000\n",
            "Epoch 537/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0180 - accuracy: 0.9899 - val_loss: 0.0135 - val_accuracy: 1.0000\n",
            "Epoch 538/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0180 - accuracy: 0.9899 - val_loss: 0.0135 - val_accuracy: 1.0000\n",
            "Epoch 539/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.0179 - accuracy: 0.9899 - val_loss: 0.0135 - val_accuracy: 1.0000\n",
            "Epoch 540/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.0179 - accuracy: 0.9899 - val_loss: 0.0134 - val_accuracy: 1.0000\n",
            "Epoch 541/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.0179 - accuracy: 0.9899 - val_loss: 0.0134 - val_accuracy: 1.0000\n",
            "Epoch 542/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.0180 - accuracy: 0.9899 - val_loss: 0.0134 - val_accuracy: 1.0000\n",
            "Epoch 543/1000\n",
            "297/594 [==============>...............] - ETA: 0s - loss: 0.0190 - accuracy: 0.9865\n",
            "Epoch 00543: ReduceLROnPlateau reducing learning rate to 0.03125.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "594/594 [==============================] - 0s 34us/sample - loss: 0.0182 - accuracy: 0.9899 - val_loss: 0.0134 - val_accuracy: 1.0000\n",
            "Epoch 00543: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAGFCAYAAADAc+UQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "791sg7TlUQXJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "da62dd46-f2f1-465d-a0aa-91a4884119cf"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "mlp = Sequential()\n",
        "mlp.add(Dense(16, input_dim=2, activation='relu'))\n",
        "mlp.add(Dense(16, activation='relu'))\n",
        "mlp.add(Dense(16, activation='relu'))\n",
        "mlp.add(Dense(16, activation='sigmoid'))\n",
        "mlp.add(Dense(16, activation='sigmoid'))\n",
        "mlp.add(Dense(2, activation='sigmoid'))\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(factor=0.5, monitor='accuracy',\n",
        "                              patience=50, min_lr=0.00000001,\n",
        "                              verbose = 1)\n",
        "\n",
        "stop_save = EarlyStopping(patience=200, monitor='accuracy',\n",
        "                          verbose=1, \n",
        "                          restore_best_weights=True)\n",
        "\n",
        "# All parameter gradients will be clipped to\n",
        "# a maximum norm of 1.\n",
        "sgd = optimizers.SGD(lr=1., clipnorm=1.)\n",
        "\n",
        "mlp.compile(loss='binary_crossentropy',\n",
        "            optimizer=sgd,\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "# trains the model\n",
        "mlp.fit(X, yv, epochs=1000, batch_size=297,\n",
        "        verbose=1, callbacks=[reduce_lr, stop_save], \n",
        "        validation_split = 0.01)\n",
        "\n",
        "y_pred = mlp.predict(X)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
        "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n",
        "                     np.arange(y_min, y_max, 0.02))\n",
        "Z = None\n",
        "Z = mlp.predict(np.c_[xx.ravel(), yy.ravel()])[:,1]\n",
        "Z = Z.reshape(xx.shape)\n",
        "cm = plt.cm.bwr\n",
        "\n",
        "fig = plt.figure(figsize=(6,6))\n",
        "\n",
        "plt.contourf(xx, yy, Z, cmap=cm, alpha=.25)\n",
        "\n",
        "plt.plot(X[1,0],X[1,1],'+', color='#648fff', label='Positive Class')\n",
        "plt.plot(X[2,1],X[2,1],'_', color='#fe6100', label='Negative Class')\n",
        "\n",
        "for i in range(len(y)):\n",
        "  x1 = X[i,0]\n",
        "  x2 = X[i,1]\n",
        "  if y[i]==1: \n",
        "    if (y_pred[i] == 0):\n",
        "      plt.plot(x1,x2,'+', color='#648fff')\n",
        "    else:\n",
        "      plt.plot(x1,x2,'k.', alpha=0.25)\n",
        "  else:\n",
        "    if (y_pred[i] == 1):\n",
        "      plt.plot(x1,x2,'_', color='#fe6100')\n",
        "    else:\n",
        "      plt.plot(x1,x2,'k.', alpha=0.25)\n",
        "\n",
        "accuracy = np.sum(np.equal(y_pred,y_actual))/len(y_actual)\n",
        "\n",
        "plt.axis('tight')\n",
        "plt.xlim(min(X[:,0])-0.1, max(X[:,0])+0.1)\n",
        "plt.ylim(min(X[:,1])-0.1, max(X[:,1])+0.1)\n",
        "plt.xlabel('$x_1$')\n",
        "plt.ylabel('$x_2$')\n",
        "plt.legend()\n",
        "plt.title('Keras-based 4-layer MLP on spiral dataset. Accuracy: {:04.3}'.format(accuracy))\n",
        "plt.savefig('ch.6.MLP.keras.deep.k.spirals.png', dpi=350, bbox_inches='tight')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 594 samples, validate on 6 samples\n",
            "Epoch 1/1000\n",
            "594/594 [==============================] - 0s 544us/sample - loss: 0.7439 - accuracy: 0.5118 - val_loss: 0.7788 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6969 - accuracy: 0.4891 - val_loss: 0.7364 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6933 - accuracy: 0.5051 - val_loss: 0.7048 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6930 - accuracy: 0.5160 - val_loss: 0.7027 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6955 - accuracy: 0.4865 - val_loss: 0.7356 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6933 - accuracy: 0.5008 - val_loss: 0.7151 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6929 - accuracy: 0.5051 - val_loss: 0.7042 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6928 - accuracy: 0.5505 - val_loss: 0.7053 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6939 - accuracy: 0.4916 - val_loss: 0.7258 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6929 - accuracy: 0.5051 - val_loss: 0.7033 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6927 - accuracy: 0.5412 - val_loss: 0.7052 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6926 - accuracy: 0.5480 - val_loss: 0.7058 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6930 - accuracy: 0.5067 - val_loss: 0.7182 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.7204 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6931 - accuracy: 0.4941 - val_loss: 0.7209 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6957 - accuracy: 0.4562 - val_loss: 0.7414 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6936 - accuracy: 0.5152 - val_loss: 0.7266 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6924 - accuracy: 0.5051 - val_loss: 0.7090 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6923 - accuracy: 0.5210 - val_loss: 0.6989 - val_accuracy: 0.1667\n",
            "Epoch 20/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6922 - accuracy: 0.5480 - val_loss: 0.7101 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6935 - accuracy: 0.4882 - val_loss: 0.7298 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6921 - accuracy: 0.5227 - val_loss: 0.7122 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6919 - accuracy: 0.5253 - val_loss: 0.7023 - val_accuracy: 0.0833\n",
            "Epoch 24/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6921 - accuracy: 0.5354 - val_loss: 0.6957 - val_accuracy: 0.1667\n",
            "Epoch 25/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6922 - accuracy: 0.5269 - val_loss: 0.6923 - val_accuracy: 0.7500\n",
            "Epoch 26/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6918 - accuracy: 0.5269 - val_loss: 0.7146 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6924 - accuracy: 0.4992 - val_loss: 0.7259 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6917 - accuracy: 0.5051 - val_loss: 0.6992 - val_accuracy: 0.1667\n",
            "Epoch 29/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6917 - accuracy: 0.5497 - val_loss: 0.7187 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6911 - accuracy: 0.5429 - val_loss: 0.7060 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6910 - accuracy: 0.5909 - val_loss: 0.7096 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6908 - accuracy: 0.5581 - val_loss: 0.7076 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6909 - accuracy: 0.5572 - val_loss: 0.7154 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6905 - accuracy: 0.5455 - val_loss: 0.7062 - val_accuracy: 0.0833\n",
            "Epoch 35/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6918 - accuracy: 0.5370 - val_loss: 0.7312 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6906 - accuracy: 0.5589 - val_loss: 0.7193 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6904 - accuracy: 0.5244 - val_loss: 0.6968 - val_accuracy: 0.2500\n",
            "Epoch 38/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6898 - accuracy: 0.5976 - val_loss: 0.7118 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6905 - accuracy: 0.5488 - val_loss: 0.7275 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6922 - accuracy: 0.4882 - val_loss: 0.7432 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6902 - accuracy: 0.5051 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 42/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6888 - accuracy: 0.5884 - val_loss: 0.7095 - val_accuracy: 0.0833\n",
            "Epoch 43/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6900 - accuracy: 0.5379 - val_loss: 0.6866 - val_accuracy: 0.8333\n",
            "Epoch 44/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6884 - accuracy: 0.5859 - val_loss: 0.7047 - val_accuracy: 0.2500\n",
            "Epoch 45/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.6879 - accuracy: 0.6322 - val_loss: 0.7152 - val_accuracy: 0.0833\n",
            "Epoch 46/1000\n",
            "594/594 [==============================] - 0s 33us/sample - loss: 0.6882 - accuracy: 0.5724 - val_loss: 0.7281 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.6885 - accuracy: 0.5463 - val_loss: 0.6901 - val_accuracy: 0.4167\n",
            "Epoch 48/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6906 - accuracy: 0.5101 - val_loss: 0.7508 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6868 - accuracy: 0.5783 - val_loss: 0.7237 - val_accuracy: 0.0833\n",
            "Epoch 50/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6865 - accuracy: 0.6120 - val_loss: 0.7306 - val_accuracy: 0.0000e+00\n",
            "Epoch 51/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6863 - accuracy: 0.5968 - val_loss: 0.7351 - val_accuracy: 0.0000e+00\n",
            "Epoch 52/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6849 - accuracy: 0.6103 - val_loss: 0.7233 - val_accuracy: 0.1667\n",
            "Epoch 53/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6851 - accuracy: 0.5934 - val_loss: 0.7373 - val_accuracy: 0.0833\n",
            "Epoch 54/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6841 - accuracy: 0.6002 - val_loss: 0.7024 - val_accuracy: 0.3333\n",
            "Epoch 55/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6837 - accuracy: 0.6120 - val_loss: 0.6994 - val_accuracy: 0.3333\n",
            "Epoch 56/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6822 - accuracy: 0.6212 - val_loss: 0.7162 - val_accuracy: 0.2500\n",
            "Epoch 57/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6819 - accuracy: 0.6170 - val_loss: 0.7374 - val_accuracy: 0.1667\n",
            "Epoch 58/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6806 - accuracy: 0.6322 - val_loss: 0.7152 - val_accuracy: 0.3333\n",
            "Epoch 59/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.6799 - accuracy: 0.6330 - val_loss: 0.7114 - val_accuracy: 0.3333\n",
            "Epoch 60/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6804 - accuracy: 0.6019 - val_loss: 0.6972 - val_accuracy: 0.3333\n",
            "Epoch 61/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6778 - accuracy: 0.6061 - val_loss: 0.7320 - val_accuracy: 0.2500\n",
            "Epoch 62/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6767 - accuracy: 0.6313 - val_loss: 0.7386 - val_accuracy: 0.2500\n",
            "Epoch 63/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6760 - accuracy: 0.6473 - val_loss: 0.7167 - val_accuracy: 0.3333\n",
            "Epoch 64/1000\n",
            "594/594 [==============================] - 0s 36us/sample - loss: 0.6754 - accuracy: 0.6111 - val_loss: 0.7563 - val_accuracy: 0.1667\n",
            "Epoch 65/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6739 - accuracy: 0.6481 - val_loss: 0.7189 - val_accuracy: 0.3333\n",
            "Epoch 66/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6721 - accuracy: 0.6094 - val_loss: 0.7447 - val_accuracy: 0.3333\n",
            "Epoch 67/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6708 - accuracy: 0.6279 - val_loss: 0.7468 - val_accuracy: 0.3333\n",
            "Epoch 68/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6725 - accuracy: 0.6237 - val_loss: 0.7044 - val_accuracy: 0.3333\n",
            "Epoch 69/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6694 - accuracy: 0.6288 - val_loss: 0.7262 - val_accuracy: 0.3333\n",
            "Epoch 70/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6671 - accuracy: 0.6187 - val_loss: 0.7404 - val_accuracy: 0.3333\n",
            "Epoch 71/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6655 - accuracy: 0.6145 - val_loss: 0.7515 - val_accuracy: 0.3333\n",
            "Epoch 72/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6648 - accuracy: 0.6204 - val_loss: 0.7373 - val_accuracy: 0.3333\n",
            "Epoch 73/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6640 - accuracy: 0.6111 - val_loss: 0.7873 - val_accuracy: 0.1667\n",
            "Epoch 74/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6620 - accuracy: 0.6237 - val_loss: 0.7795 - val_accuracy: 0.3333\n",
            "Epoch 75/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6603 - accuracy: 0.6254 - val_loss: 0.7582 - val_accuracy: 0.3333\n",
            "Epoch 76/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6608 - accuracy: 0.6086 - val_loss: 0.8073 - val_accuracy: 0.1667\n",
            "Epoch 77/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6584 - accuracy: 0.6406 - val_loss: 0.7557 - val_accuracy: 0.3333\n",
            "Epoch 78/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6566 - accuracy: 0.6120 - val_loss: 0.7720 - val_accuracy: 0.3333\n",
            "Epoch 79/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6553 - accuracy: 0.6103 - val_loss: 0.7767 - val_accuracy: 0.3333\n",
            "Epoch 80/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6541 - accuracy: 0.6145 - val_loss: 0.7877 - val_accuracy: 0.3333\n",
            "Epoch 81/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6540 - accuracy: 0.6153 - val_loss: 0.8156 - val_accuracy: 0.1667\n",
            "Epoch 82/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6552 - accuracy: 0.6187 - val_loss: 0.8341 - val_accuracy: 0.1667\n",
            "Epoch 83/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6517 - accuracy: 0.6254 - val_loss: 0.8068 - val_accuracy: 0.2500\n",
            "Epoch 84/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6503 - accuracy: 0.6170 - val_loss: 0.7816 - val_accuracy: 0.3333\n",
            "Epoch 85/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6493 - accuracy: 0.6136 - val_loss: 0.7882 - val_accuracy: 0.3333\n",
            "Epoch 86/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6496 - accuracy: 0.6086 - val_loss: 0.8356 - val_accuracy: 0.1667\n",
            "Epoch 87/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6514 - accuracy: 0.6195 - val_loss: 0.8498 - val_accuracy: 0.1667\n",
            "Epoch 88/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6473 - accuracy: 0.6254 - val_loss: 0.7857 - val_accuracy: 0.3333\n",
            "Epoch 89/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6470 - accuracy: 0.6162 - val_loss: 0.7816 - val_accuracy: 0.3333\n",
            "Epoch 90/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6457 - accuracy: 0.6212 - val_loss: 0.8054 - val_accuracy: 0.2500\n",
            "Epoch 91/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6458 - accuracy: 0.6128 - val_loss: 0.8505 - val_accuracy: 0.1667\n",
            "Epoch 92/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6447 - accuracy: 0.6296 - val_loss: 0.8351 - val_accuracy: 0.1667\n",
            "Epoch 93/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6444 - accuracy: 0.6212 - val_loss: 0.7878 - val_accuracy: 0.3333\n",
            "Epoch 94/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6433 - accuracy: 0.6221 - val_loss: 0.8276 - val_accuracy: 0.1667\n",
            "Epoch 95/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6451 - accuracy: 0.6187 - val_loss: 0.7722 - val_accuracy: 0.5000\n",
            "Epoch 96/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6441 - accuracy: 0.6120 - val_loss: 0.8698 - val_accuracy: 0.1667\n",
            "Epoch 97/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6417 - accuracy: 0.6313 - val_loss: 0.8205 - val_accuracy: 0.1667\n",
            "Epoch 98/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6430 - accuracy: 0.6128 - val_loss: 0.7841 - val_accuracy: 0.5000\n",
            "Epoch 99/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6412 - accuracy: 0.6145 - val_loss: 0.8549 - val_accuracy: 0.1667\n",
            "Epoch 100/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6404 - accuracy: 0.6221 - val_loss: 0.8216 - val_accuracy: 0.1667\n",
            "Epoch 101/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6399 - accuracy: 0.6229 - val_loss: 0.8429 - val_accuracy: 0.1667\n",
            "Epoch 102/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6395 - accuracy: 0.6263 - val_loss: 0.8496 - val_accuracy: 0.1667\n",
            "Epoch 103/1000\n",
            "594/594 [==============================] - 0s 37us/sample - loss: 0.6406 - accuracy: 0.6178 - val_loss: 0.7973 - val_accuracy: 0.4167\n",
            "Epoch 104/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6391 - accuracy: 0.6221 - val_loss: 0.8456 - val_accuracy: 0.1667\n",
            "Epoch 105/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6387 - accuracy: 0.6263 - val_loss: 0.8418 - val_accuracy: 0.1667\n",
            "Epoch 106/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6428 - accuracy: 0.6204 - val_loss: 0.7670 - val_accuracy: 0.5000\n",
            "Epoch 107/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6391 - accuracy: 0.6128 - val_loss: 0.8500 - val_accuracy: 0.1667\n",
            "Epoch 108/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6375 - accuracy: 0.6254 - val_loss: 0.8363 - val_accuracy: 0.2500\n",
            "Epoch 109/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6374 - accuracy: 0.6221 - val_loss: 0.8182 - val_accuracy: 0.3333\n",
            "Epoch 110/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6375 - accuracy: 0.6237 - val_loss: 0.8287 - val_accuracy: 0.2500\n",
            "Epoch 111/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6367 - accuracy: 0.6204 - val_loss: 0.8535 - val_accuracy: 0.1667\n",
            "Epoch 112/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6362 - accuracy: 0.6288 - val_loss: 0.8539 - val_accuracy: 0.1667\n",
            "Epoch 113/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6371 - accuracy: 0.6221 - val_loss: 0.8878 - val_accuracy: 0.1667\n",
            "Epoch 114/1000\n",
            "594/594 [==============================] - 0s 34us/sample - loss: 0.6363 - accuracy: 0.6170 - val_loss: 0.8137 - val_accuracy: 0.3333\n",
            "Epoch 115/1000\n",
            "297/594 [==============>...............] - ETA: 0s - loss: 0.6473 - accuracy: 0.6044\n",
            "Epoch 00115: ReduceLROnPlateau reducing learning rate to 0.5.\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6359 - accuracy: 0.6246 - val_loss: 0.8346 - val_accuracy: 0.2500\n",
            "Epoch 116/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6351 - accuracy: 0.6246 - val_loss: 0.8379 - val_accuracy: 0.2500\n",
            "Epoch 117/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6355 - accuracy: 0.6221 - val_loss: 0.8351 - val_accuracy: 0.3333\n",
            "Epoch 118/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6353 - accuracy: 0.6229 - val_loss: 0.8334 - val_accuracy: 0.3333\n",
            "Epoch 119/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6344 - accuracy: 0.6246 - val_loss: 0.8410 - val_accuracy: 0.3333\n",
            "Epoch 120/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6343 - accuracy: 0.6246 - val_loss: 0.8420 - val_accuracy: 0.3333\n",
            "Epoch 121/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6340 - accuracy: 0.6263 - val_loss: 0.8518 - val_accuracy: 0.1667\n",
            "Epoch 122/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6342 - accuracy: 0.6254 - val_loss: 0.8412 - val_accuracy: 0.3333\n",
            "Epoch 123/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6338 - accuracy: 0.6263 - val_loss: 0.8417 - val_accuracy: 0.3333\n",
            "Epoch 124/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6335 - accuracy: 0.6263 - val_loss: 0.8478 - val_accuracy: 0.2500\n",
            "Epoch 125/1000\n",
            "594/594 [==============================] - 0s 33us/sample - loss: 0.6333 - accuracy: 0.6305 - val_loss: 0.8466 - val_accuracy: 0.2500\n",
            "Epoch 126/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6337 - accuracy: 0.6237 - val_loss: 0.8419 - val_accuracy: 0.3333\n",
            "Epoch 127/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6331 - accuracy: 0.6254 - val_loss: 0.8473 - val_accuracy: 0.2500\n",
            "Epoch 128/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6330 - accuracy: 0.6254 - val_loss: 0.8440 - val_accuracy: 0.3333\n",
            "Epoch 129/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6327 - accuracy: 0.6271 - val_loss: 0.8500 - val_accuracy: 0.2500\n",
            "Epoch 130/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6353 - accuracy: 0.6237 - val_loss: 0.8247 - val_accuracy: 0.3333\n",
            "Epoch 131/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6327 - accuracy: 0.6221 - val_loss: 0.8498 - val_accuracy: 0.3333\n",
            "Epoch 132/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6329 - accuracy: 0.6288 - val_loss: 0.8615 - val_accuracy: 0.1667\n",
            "Epoch 133/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6325 - accuracy: 0.6279 - val_loss: 0.8552 - val_accuracy: 0.2500\n",
            "Epoch 134/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6320 - accuracy: 0.6288 - val_loss: 0.8483 - val_accuracy: 0.3333\n",
            "Epoch 135/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6322 - accuracy: 0.6263 - val_loss: 0.8561 - val_accuracy: 0.2500\n",
            "Epoch 136/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6352 - accuracy: 0.6195 - val_loss: 0.8208 - val_accuracy: 0.3333\n",
            "Epoch 137/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6321 - accuracy: 0.6237 - val_loss: 0.8345 - val_accuracy: 0.3333\n",
            "Epoch 138/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6322 - accuracy: 0.6153 - val_loss: 0.8548 - val_accuracy: 0.2500\n",
            "Epoch 139/1000\n",
            "594/594 [==============================] - 0s 37us/sample - loss: 0.6317 - accuracy: 0.6246 - val_loss: 0.8435 - val_accuracy: 0.3333\n",
            "Epoch 140/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6316 - accuracy: 0.6237 - val_loss: 0.8550 - val_accuracy: 0.2500\n",
            "Epoch 141/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.6309 - accuracy: 0.6271 - val_loss: 0.8490 - val_accuracy: 0.3333\n",
            "Epoch 142/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6312 - accuracy: 0.6271 - val_loss: 0.8481 - val_accuracy: 0.3333\n",
            "Epoch 143/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6325 - accuracy: 0.6162 - val_loss: 0.8289 - val_accuracy: 0.3333\n",
            "Epoch 144/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6310 - accuracy: 0.6221 - val_loss: 0.8355 - val_accuracy: 0.3333\n",
            "Epoch 145/1000\n",
            "594/594 [==============================] - 0s 33us/sample - loss: 0.6303 - accuracy: 0.6237 - val_loss: 0.8480 - val_accuracy: 0.3333\n",
            "Epoch 146/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6305 - accuracy: 0.6254 - val_loss: 0.8460 - val_accuracy: 0.3333\n",
            "Epoch 147/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6303 - accuracy: 0.6263 - val_loss: 0.8374 - val_accuracy: 0.3333\n",
            "Epoch 148/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6308 - accuracy: 0.6263 - val_loss: 0.8591 - val_accuracy: 0.2500\n",
            "Epoch 149/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6299 - accuracy: 0.6237 - val_loss: 0.8482 - val_accuracy: 0.3333\n",
            "Epoch 150/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6319 - accuracy: 0.6204 - val_loss: 0.8220 - val_accuracy: 0.3333\n",
            "Epoch 151/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6298 - accuracy: 0.6237 - val_loss: 0.8331 - val_accuracy: 0.3333\n",
            "Epoch 152/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6295 - accuracy: 0.6246 - val_loss: 0.8563 - val_accuracy: 0.3333\n",
            "Epoch 153/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6293 - accuracy: 0.6195 - val_loss: 0.8365 - val_accuracy: 0.3333\n",
            "Epoch 154/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6297 - accuracy: 0.6263 - val_loss: 0.8612 - val_accuracy: 0.2500\n",
            "Epoch 155/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6294 - accuracy: 0.6263 - val_loss: 0.8640 - val_accuracy: 0.2500\n",
            "Epoch 156/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6291 - accuracy: 0.6145 - val_loss: 0.8623 - val_accuracy: 0.3333\n",
            "Epoch 157/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6281 - accuracy: 0.6246 - val_loss: 0.8479 - val_accuracy: 0.3333\n",
            "Epoch 158/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6295 - accuracy: 0.6170 - val_loss: 0.8567 - val_accuracy: 0.3333\n",
            "Epoch 159/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6284 - accuracy: 0.6237 - val_loss: 0.8597 - val_accuracy: 0.3333\n",
            "Epoch 160/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6276 - accuracy: 0.6212 - val_loss: 0.8405 - val_accuracy: 0.3333\n",
            "Epoch 161/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6274 - accuracy: 0.6254 - val_loss: 0.8392 - val_accuracy: 0.3333\n",
            "Epoch 162/1000\n",
            "594/594 [==============================] - 0s 40us/sample - loss: 0.6274 - accuracy: 0.6212 - val_loss: 0.8293 - val_accuracy: 0.4167\n",
            "Epoch 163/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6272 - accuracy: 0.6279 - val_loss: 0.8320 - val_accuracy: 0.4167\n",
            "Epoch 164/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6268 - accuracy: 0.6279 - val_loss: 0.8372 - val_accuracy: 0.4167\n",
            "Epoch 165/1000\n",
            "297/594 [==============>...............] - ETA: 0s - loss: 0.6044 - accuracy: 0.6431\n",
            "Epoch 00165: ReduceLROnPlateau reducing learning rate to 0.25.\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6266 - accuracy: 0.6254 - val_loss: 0.8424 - val_accuracy: 0.3333\n",
            "Epoch 166/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6261 - accuracy: 0.6254 - val_loss: 0.8419 - val_accuracy: 0.3333\n",
            "Epoch 167/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6262 - accuracy: 0.6237 - val_loss: 0.8386 - val_accuracy: 0.4167\n",
            "Epoch 168/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6261 - accuracy: 0.6246 - val_loss: 0.8420 - val_accuracy: 0.3333\n",
            "Epoch 169/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6263 - accuracy: 0.6246 - val_loss: 0.8357 - val_accuracy: 0.4167\n",
            "Epoch 170/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6256 - accuracy: 0.6263 - val_loss: 0.8377 - val_accuracy: 0.4167\n",
            "Epoch 171/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6257 - accuracy: 0.6271 - val_loss: 0.8390 - val_accuracy: 0.4167\n",
            "Epoch 172/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6256 - accuracy: 0.6254 - val_loss: 0.8374 - val_accuracy: 0.4167\n",
            "Epoch 173/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6256 - accuracy: 0.6279 - val_loss: 0.8399 - val_accuracy: 0.4167\n",
            "Epoch 174/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6264 - accuracy: 0.6279 - val_loss: 0.8475 - val_accuracy: 0.3333\n",
            "Epoch 175/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6259 - accuracy: 0.6246 - val_loss: 0.8470 - val_accuracy: 0.4167\n",
            "Epoch 176/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6250 - accuracy: 0.6263 - val_loss: 0.8439 - val_accuracy: 0.4167\n",
            "Epoch 177/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6251 - accuracy: 0.6263 - val_loss: 0.8434 - val_accuracy: 0.4167\n",
            "Epoch 178/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6249 - accuracy: 0.6263 - val_loss: 0.8415 - val_accuracy: 0.4167\n",
            "Epoch 179/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6250 - accuracy: 0.6263 - val_loss: 0.8382 - val_accuracy: 0.5000\n",
            "Epoch 180/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6248 - accuracy: 0.6279 - val_loss: 0.8404 - val_accuracy: 0.4167\n",
            "Epoch 181/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6251 - accuracy: 0.6254 - val_loss: 0.8346 - val_accuracy: 0.5000\n",
            "Epoch 182/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6248 - accuracy: 0.6313 - val_loss: 0.8336 - val_accuracy: 0.5000\n",
            "Epoch 183/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6244 - accuracy: 0.6296 - val_loss: 0.8365 - val_accuracy: 0.5000\n",
            "Epoch 184/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6244 - accuracy: 0.6279 - val_loss: 0.8357 - val_accuracy: 0.5000\n",
            "Epoch 185/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6258 - accuracy: 0.6288 - val_loss: 0.8460 - val_accuracy: 0.4167\n",
            "Epoch 186/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6244 - accuracy: 0.6296 - val_loss: 0.8447 - val_accuracy: 0.4167\n",
            "Epoch 187/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6250 - accuracy: 0.6263 - val_loss: 0.8480 - val_accuracy: 0.4167\n",
            "Epoch 188/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6246 - accuracy: 0.6229 - val_loss: 0.8377 - val_accuracy: 0.5000\n",
            "Epoch 189/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6241 - accuracy: 0.6305 - val_loss: 0.8421 - val_accuracy: 0.5000\n",
            "Epoch 190/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6247 - accuracy: 0.6237 - val_loss: 0.8332 - val_accuracy: 0.5000\n",
            "Epoch 191/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6243 - accuracy: 0.6305 - val_loss: 0.8407 - val_accuracy: 0.5000\n",
            "Epoch 192/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6241 - accuracy: 0.6296 - val_loss: 0.8433 - val_accuracy: 0.5000\n",
            "Epoch 193/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6236 - accuracy: 0.6271 - val_loss: 0.8393 - val_accuracy: 0.5000\n",
            "Epoch 194/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6238 - accuracy: 0.6263 - val_loss: 0.8349 - val_accuracy: 0.5000\n",
            "Epoch 195/1000\n",
            "594/594 [==============================] - 0s 33us/sample - loss: 0.6234 - accuracy: 0.6279 - val_loss: 0.8344 - val_accuracy: 0.5000\n",
            "Epoch 196/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6255 - accuracy: 0.6288 - val_loss: 0.8468 - val_accuracy: 0.5000\n",
            "Epoch 197/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6237 - accuracy: 0.6271 - val_loss: 0.8377 - val_accuracy: 0.5000\n",
            "Epoch 198/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6230 - accuracy: 0.6305 - val_loss: 0.8378 - val_accuracy: 0.5000\n",
            "Epoch 199/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6229 - accuracy: 0.6305 - val_loss: 0.8396 - val_accuracy: 0.5000\n",
            "Epoch 200/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6229 - accuracy: 0.6271 - val_loss: 0.8369 - val_accuracy: 0.5000\n",
            "Epoch 201/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6228 - accuracy: 0.6322 - val_loss: 0.8357 - val_accuracy: 0.5000\n",
            "Epoch 202/1000\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6234 - accuracy: 0.6322 - val_loss: 0.8337 - val_accuracy: 0.5000\n",
            "Epoch 203/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6229 - accuracy: 0.6296 - val_loss: 0.8306 - val_accuracy: 0.5000\n",
            "Epoch 204/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6229 - accuracy: 0.6279 - val_loss: 0.8348 - val_accuracy: 0.5000\n",
            "Epoch 205/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6224 - accuracy: 0.6305 - val_loss: 0.8337 - val_accuracy: 0.5000\n",
            "Epoch 206/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6222 - accuracy: 0.6330 - val_loss: 0.8340 - val_accuracy: 0.5000\n",
            "Epoch 207/1000\n",
            "594/594 [==============================] - 0s 32us/sample - loss: 0.6222 - accuracy: 0.6322 - val_loss: 0.8348 - val_accuracy: 0.5000\n",
            "Epoch 208/1000\n",
            "594/594 [==============================] - 0s 37us/sample - loss: 0.6224 - accuracy: 0.6330 - val_loss: 0.8396 - val_accuracy: 0.5000\n",
            "Epoch 209/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6223 - accuracy: 0.6279 - val_loss: 0.8405 - val_accuracy: 0.5000\n",
            "Epoch 210/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6218 - accuracy: 0.6338 - val_loss: 0.8372 - val_accuracy: 0.5000\n",
            "Epoch 211/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6218 - accuracy: 0.6330 - val_loss: 0.8389 - val_accuracy: 0.5000\n",
            "Epoch 212/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6217 - accuracy: 0.6322 - val_loss: 0.8350 - val_accuracy: 0.5000\n",
            "Epoch 213/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6233 - accuracy: 0.6347 - val_loss: 0.8258 - val_accuracy: 0.5000\n",
            "Epoch 214/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6215 - accuracy: 0.6338 - val_loss: 0.8339 - val_accuracy: 0.5000\n",
            "Epoch 215/1000\n",
            "297/594 [==============>...............] - ETA: 0s - loss: 0.6163 - accuracy: 0.6498\n",
            "Epoch 00215: ReduceLROnPlateau reducing learning rate to 0.125.\n",
            "594/594 [==============================] - 0s 23us/sample - loss: 0.6247 - accuracy: 0.6305 - val_loss: 0.8462 - val_accuracy: 0.5000\n",
            "Epoch 216/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6214 - accuracy: 0.6330 - val_loss: 0.8434 - val_accuracy: 0.5000\n",
            "Epoch 217/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6214 - accuracy: 0.6355 - val_loss: 0.8395 - val_accuracy: 0.5000\n",
            "Epoch 218/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6212 - accuracy: 0.6347 - val_loss: 0.8372 - val_accuracy: 0.5000\n",
            "Epoch 219/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6211 - accuracy: 0.6347 - val_loss: 0.8359 - val_accuracy: 0.5000\n",
            "Epoch 220/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6210 - accuracy: 0.6338 - val_loss: 0.8348 - val_accuracy: 0.5000\n",
            "Epoch 221/1000\n",
            "594/594 [==============================] - 0s 40us/sample - loss: 0.6210 - accuracy: 0.6338 - val_loss: 0.8343 - val_accuracy: 0.5000\n",
            "Epoch 222/1000\n",
            "594/594 [==============================] - 0s 31us/sample - loss: 0.6210 - accuracy: 0.6338 - val_loss: 0.8358 - val_accuracy: 0.5000\n",
            "Epoch 223/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6208 - accuracy: 0.6338 - val_loss: 0.8361 - val_accuracy: 0.5000\n",
            "Epoch 224/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6210 - accuracy: 0.6322 - val_loss: 0.8342 - val_accuracy: 0.5000\n",
            "Epoch 225/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6207 - accuracy: 0.6322 - val_loss: 0.8343 - val_accuracy: 0.5000\n",
            "Epoch 226/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6207 - accuracy: 0.6330 - val_loss: 0.8345 - val_accuracy: 0.5000\n",
            "Epoch 227/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6205 - accuracy: 0.6355 - val_loss: 0.8347 - val_accuracy: 0.5000\n",
            "Epoch 228/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6206 - accuracy: 0.6330 - val_loss: 0.8336 - val_accuracy: 0.5000\n",
            "Epoch 229/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6205 - accuracy: 0.6347 - val_loss: 0.8340 - val_accuracy: 0.5000\n",
            "Epoch 230/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6205 - accuracy: 0.6364 - val_loss: 0.8350 - val_accuracy: 0.5000\n",
            "Epoch 231/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6204 - accuracy: 0.6330 - val_loss: 0.8348 - val_accuracy: 0.5000\n",
            "Epoch 232/1000\n",
            "594/594 [==============================] - 0s 36us/sample - loss: 0.6202 - accuracy: 0.6330 - val_loss: 0.8342 - val_accuracy: 0.5000\n",
            "Epoch 233/1000\n",
            "594/594 [==============================] - 0s 21us/sample - loss: 0.6203 - accuracy: 0.6347 - val_loss: 0.8348 - val_accuracy: 0.5000\n",
            "Epoch 234/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6201 - accuracy: 0.6322 - val_loss: 0.8343 - val_accuracy: 0.5000\n",
            "Epoch 235/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6200 - accuracy: 0.6330 - val_loss: 0.8336 - val_accuracy: 0.5000\n",
            "Epoch 236/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6200 - accuracy: 0.6338 - val_loss: 0.8333 - val_accuracy: 0.5000\n",
            "Epoch 237/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6202 - accuracy: 0.6330 - val_loss: 0.8346 - val_accuracy: 0.5000\n",
            "Epoch 238/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6202 - accuracy: 0.6338 - val_loss: 0.8327 - val_accuracy: 0.5000\n",
            "Epoch 239/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6200 - accuracy: 0.6338 - val_loss: 0.8316 - val_accuracy: 0.5000\n",
            "Epoch 240/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6199 - accuracy: 0.6330 - val_loss: 0.8329 - val_accuracy: 0.5000\n",
            "Epoch 241/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6204 - accuracy: 0.6322 - val_loss: 0.8353 - val_accuracy: 0.5000\n",
            "Epoch 242/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6199 - accuracy: 0.6330 - val_loss: 0.8330 - val_accuracy: 0.5000\n",
            "Epoch 243/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6196 - accuracy: 0.6372 - val_loss: 0.8339 - val_accuracy: 0.5000\n",
            "Epoch 244/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6196 - accuracy: 0.6338 - val_loss: 0.8344 - val_accuracy: 0.5000\n",
            "Epoch 245/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6195 - accuracy: 0.6338 - val_loss: 0.8343 - val_accuracy: 0.5000\n",
            "Epoch 246/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6197 - accuracy: 0.6338 - val_loss: 0.8350 - val_accuracy: 0.5000\n",
            "Epoch 247/1000\n",
            "594/594 [==============================] - 0s 27us/sample - loss: 0.6194 - accuracy: 0.6364 - val_loss: 0.8335 - val_accuracy: 0.5000\n",
            "Epoch 248/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6196 - accuracy: 0.6364 - val_loss: 0.8344 - val_accuracy: 0.5000\n",
            "Epoch 249/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6199 - accuracy: 0.6372 - val_loss: 0.8314 - val_accuracy: 0.5000\n",
            "Epoch 250/1000\n",
            "594/594 [==============================] - 0s 22us/sample - loss: 0.6192 - accuracy: 0.6372 - val_loss: 0.8311 - val_accuracy: 0.5000\n",
            "Epoch 251/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6192 - accuracy: 0.6330 - val_loss: 0.8308 - val_accuracy: 0.5000\n",
            "Epoch 252/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6196 - accuracy: 0.6380 - val_loss: 0.8293 - val_accuracy: 0.5000\n",
            "Epoch 253/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6192 - accuracy: 0.6355 - val_loss: 0.8291 - val_accuracy: 0.5000\n",
            "Epoch 254/1000\n",
            "594/594 [==============================] - 0s 30us/sample - loss: 0.6190 - accuracy: 0.6330 - val_loss: 0.8294 - val_accuracy: 0.5000\n",
            "Epoch 255/1000\n",
            "594/594 [==============================] - 0s 29us/sample - loss: 0.6191 - accuracy: 0.6322 - val_loss: 0.8309 - val_accuracy: 0.5000\n",
            "Epoch 256/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6189 - accuracy: 0.6364 - val_loss: 0.8316 - val_accuracy: 0.5000\n",
            "Epoch 257/1000\n",
            "594/594 [==============================] - 0s 28us/sample - loss: 0.6193 - accuracy: 0.6414 - val_loss: 0.8298 - val_accuracy: 0.5000\n",
            "Epoch 258/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6188 - accuracy: 0.6364 - val_loss: 0.8311 - val_accuracy: 0.5000\n",
            "Epoch 259/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6187 - accuracy: 0.6355 - val_loss: 0.8320 - val_accuracy: 0.5000\n",
            "Epoch 260/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6187 - accuracy: 0.6364 - val_loss: 0.8311 - val_accuracy: 0.5000\n",
            "Epoch 261/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6186 - accuracy: 0.6364 - val_loss: 0.8310 - val_accuracy: 0.5000\n",
            "Epoch 262/1000\n",
            "594/594 [==============================] - 0s 26us/sample - loss: 0.6189 - accuracy: 0.6355 - val_loss: 0.8327 - val_accuracy: 0.5000\n",
            "Epoch 263/1000\n",
            "594/594 [==============================] - 0s 24us/sample - loss: 0.6186 - accuracy: 0.6355 - val_loss: 0.8332 - val_accuracy: 0.5000\n",
            "Epoch 264/1000\n",
            "594/594 [==============================] - 0s 25us/sample - loss: 0.6184 - accuracy: 0.6347 - val_loss: 0.8323 - val_accuracy: 0.5000\n",
            "Epoch 265/1000\n",
            "297/594 [==============>...............] - ETA: 0s - loss: 0.6180 - accuracy: 0.6448\n",
            "Epoch 00265: ReduceLROnPlateau reducing learning rate to 0.0625.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "594/594 [==============================] - 0s 37us/sample - loss: 0.6185 - accuracy: 0.6355 - val_loss: 0.8331 - val_accuracy: 0.5000\n",
            "Epoch 00265: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAGFCAYAAADAc+UQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyhOaYJRSSnlCE4xSSilP/H/WNSf3oMQ84QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4P7zb7v8Uoxl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}